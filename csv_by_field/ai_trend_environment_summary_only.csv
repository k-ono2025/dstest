title,summary,published,year,month,category
"Intelligent Human Machine Interface Design for Advanced Product Life
  Cycle Management Systems","Designing and implementing an intelligent and user friendly human machine
interface for any kind of software or hardware oriented application is always
be a challenging task for the designers and developers because it is very
difficult to understand the psychology of the user, nature of the work and best
suit of the environment. This research paper is basically about to propose an
intelligent, flexible and user friendly machine interface for Product Life
Cycle Management products or PDM Systems since studies show that usability and
human computer interaction issues are a major cause of acceptance problems
introducing or using such systems. Going into details of the proposition, we
present prototype implementations about theme based on design requirements,
designed designs and technologies involved for the development of human machine
interface.",2010-08-07,2010,2010-08,environment
Context Capture in Software Development,"The context of a software developer is something hard to define and capture,
as it represents a complex network of elements across different dimensions that
are not limited to the work developed on an IDE. We propose the definition of a
software developer context model that takes into account all the dimensions
that characterize the work environment of the developer. We are especially
focused on what the software developer context encompasses at the project level
and how it can be captured. The experimental work done so far show that useful
context information can be extracted from project management tools. The
extraction, analysis and availability of this context information can be used
to enrich the work environment of the developer with additional knowledge to
support her/his work.",2011-01-21,2011,2011-01,environment
An architecture for the evaluation of intelligent systems,"One of the main research areas in Artificial Intelligence is the coding of
agents (programs) which are able to learn by themselves in any situation. This
means that agents must be useful for purposes other than those they were
created for, as, for example, playing chess. In this way we try to get closer
to the pristine goal of Artificial Intelligence. One of the problems to decide
whether an agent is really intelligent or not is the measurement of its
intelligence, since there is currently no way to measure it in a reliable way.
The purpose of this project is to create an interpreter that allows for the
execution of several environments, including those which are generated
randomly, so that an agent (a person or a program) can interact with them. Once
the interaction between the agent and the environment is over, the interpreter
will measure the intelligence of the agent according to the actions, states and
rewards the agent has undergone inside the environment during the test. As a
result we will be able to measure agents' intelligence in any possible
environment, and to make comparisons between several agents, in order to
determine which of them is the most intelligent. In order to perform the tests,
the interpreter must be able to randomly generate environments that are really
useful to measure agents' intelligence, since not any randomly generated
environment will serve that purpose.",2011-02-03,2011,2011-02,environment
"Planning to Be Surprised: Optimal Bayesian Exploration in Dynamic
  Environments","To maximize its success, an AGI typically needs to explore its initially
unknown world. Is there an optimal way of doing so? Here we derive an
affirmative answer for a broad class of environments.",2011-03-29,2011,2011-03,environment
The Ariadne's Clew Algorithm,"We present a new approach to path planning, called the ""Ariadne's clew
algorithm"". It is designed to find paths in high-dimensional continuous spaces
and applies to robots with many degrees of freedom in static, as well as
dynamic environments - ones where obstacles may move. The Ariadne's clew
algorithm comprises two sub-algorithms, called Search and Explore, applied in
an interleaved manner. Explore builds a representation of the accessible space
while Search looks for the target. Both are posed as optimization problems. We
describe a real implementation of the algorithm to plan paths for a six degrees
of freedom arm in a dynamic environment where another six degrees of freedom
arm is used as a moving obstacle. Experimental results show that a path is
found in about one second without any pre-processing.",2011-05-27,2011,2011-05,environment
Markov Localization for Mobile Robots in Dynamic Environments,"Localization, that is the estimation of a robot's location from sensor data,
is a fundamental problem in mobile robotics. This papers presents a version of
Markov localization which provides accurate position estimates and which is
tailored towards dynamic environments. The key idea of Markov localization is
to maintain a probability density over the space of all locations of a robot in
its environment. Our approach represents this space metrically, using a
fine-grained grid to approximate densities. It is able to globally localize the
robot from scratch and to recover from localization failures. It is robust to
approximate models of the environment (such as occupancy grid maps) and noisy
sensors (such as ultrasound sensors). Our approach also includes a filtering
technique which allows a mobile robot to reliably estimate its position even in
densely populated environments in which crowds of people block the robot's
sensors for extended periods of time. The method described here has been
implemented and tested in several real-world applications of mobile robots,
including the deployments of two mobile robots as interactive museum
tour-guides.",2011-06-01,2011,2011-06,environment
A Model of Inductive Bias Learning,"A major problem in machine learning is that of inductive bias: how to choose
a learner's hypothesis space so that it is large enough to contain a solution
to the problem being learnt, yet small enough to ensure reliable generalization
from reasonably-sized training sets. Typically such bias is supplied by hand
through the skill and insights of experts. In this paper a model for
automatically learning bias is investigated. The central assumption of the
model is that the learner is embedded within an environment of related learning
tasks. Within such an environment the learner can sample from multiple tasks,
and hence it can search for a hypothesis space that contains good solutions to
many of the problems in the environment. Under certain restrictions on the set
of all hypothesis spaces available to the learner, we show that a hypothesis
space that performs well on a sufficiently large number of training tasks will
also perform well when learning novel tasks in the same environment. Explicit
bounds are also derived demonstrating that learning multiple tasks within an
environment of related tasks can potentially give much better generalization
than learning a single task.",2011-06-01,2011,2011-06,environment
Robust Agent Teams via Socially-Attentive Monitoring,"Agents in dynamic multi-agent environments must monitor their peers to
execute individual and group plans. A key open question is how much monitoring
of other agents' states is required to be effective: The Monitoring Selectivity
Problem. We investigate this question in the context of detecting failures in
teams of cooperating agents, via Socially-Attentive Monitoring, which focuses
on monitoring for failures in the social relationships between the agents. We
empirically and analytically explore a family of socially-attentive teamwork
monitoring algorithms in two dynamic, complex, multi-agent domains, under
varying conditions of task distribution and uncertainty. We show that a
centralized scheme using a complex algorithm trades correctness for
completeness and requires monitoring all teammates. In contrast, a simple
distributed teamwork monitoring algorithm results in correct and complete
detection of teamwork failures, despite relying on limited, uncertain
knowledge, and monitoring only key agents in a team. In addition, we report on
the design of a socially-attentive monitoring system and demonstrate its
generality in monitoring several coordination relationships, diagnosing
detected failures, and both on-line and off-line applications.",2011-06-01,2011,2011-06,environment
"Learning Geometrically-Constrained Hidden Markov Models for Robot
  Navigation: Bridging the Topological-Geometrical Gap","Hidden Markov models (HMMs) and partially observable Markov decision
processes (POMDPs) provide useful tools for modeling dynamical systems. They
are particularly useful for representing the topology of environments such as
road networks and office buildings, which are typical for robot navigation and
planning. The work presented here describes a formal framework for
incorporating readily available odometric information and geometrical
constraints into both the models and the algorithm that learns them. By taking
advantage of such information, learning HMMs/POMDPs can be made to generate
better solutions and require fewer iterations, while being robust in the face
of data reduction. Experimental results, obtained from both simulated and real
robot data, demonstrate the effectiveness of the approach.",2011-06-03,2011,2011-06,environment
Accelerating Reinforcement Learning through Implicit Imitation,"Imitation can be viewed as a means of enhancing learning in multiagent
environments. It augments an agent's ability to learn useful behaviors by
making intelligent use of the knowledge implicit in behaviors demonstrated by
cooperative teachers or other more experienced agents. We propose and study a
formal model of implicit imitation that can accelerate reinforcement learning
dramatically in certain cases. Roughly, by observing a mentor, a
reinforcement-learning agent can extract information about its own capabilities
in, and the relative value of, unvisited parts of the state space. We study two
specific instantiations of this model, one in which the learning agent and the
mentor have identical abilities, and one designed to deal with agents and
mentors with different action sets. We illustrate the benefits of implicit
imitation by integrating it with prioritized sweeping, and demonstrating
improved performance and convergence through observation of single and multiple
mentors. Though we make some stringent assumptions regarding observability and
possible interactions, we briefly comment on extensions of the model that relax
these restricitions.",2011-06-03,2011,2011-06,environment
Exploiting Reputation in Distributed Virtual Environments,"The cognitive research on reputation has shown several interesting properties
that can improve both the quality of services and the security in distributed
electronic environments. In this paper, the impact of reputation on
decision-making under scarcity of information will be shown. First, a cognitive
theory of reputation will be presented, then a selection of simulation
experimental results from different studies will be discussed. Such results
concern the benefits of reputation when agents need to find out good sellers in
a virtual market-place under uncertainty and informational cheating.",2011-06-25,2011,2011-06,environment
"Reinforcement Learning for Agents with Many Sensors and Actuators Acting
  in Categorizable Environments","In this paper, we confront the problem of applying reinforcement learning to
agents that perceive the environment through many sensors and that can perform
parallel actions using many actuators as is the case in complex autonomous
robots. We argue that reinforcement learning can only be successfully applied
to this case if strong assumptions are made on the characteristics of the
environment in which the learning is performed, so that the relevant sensor
readings and motor commands can be readily identified. The introduction of such
assumptions leads to strongly-biased learning systems that can eventually lose
the generality of traditional reinforcement-learning algorithms. In this line,
we observe that, in realistic situations, the reward received by the robot
depends only on a reduced subset of all the executed actions and that only a
reduced subset of the sensor inputs (possibly different in each situation and
for each action) are relevant to predict the reward. We formalize this property
in the so called 'categorizability assumption' and we present an algorithm that
takes advantage of the categorizability of the environment, allowing a decrease
in the learning time with respect to existing reinforcement-learning
algorithms. Results of the application of the algorithm to a couple of
simulated realistic-robotic problems (landmark-based navigation and the
six-legged robot gait generation) are reported to validate our approach and to
compare it to existing flat and generalization-based reinforcement-learning
approaches.",2011-06-30,2011,2011-06,environment
"Towards a Reliable Framework of Uncertainty-Based Group Decision Support
  System","This study proposes a framework of Uncertainty-based Group Decision Support
System (UGDSS). It provides a platform for multiple criteria decision analysis
in six aspects including (1) decision environment, (2) decision problem, (3)
decision group, (4) decision conflict, (5) decision schemes and (6) group
negotiation. Based on multiple artificial intelligent technologies, this
framework provides reliable support for the comprehensive manipulation of
applications and advanced decision approaches through the design of an
integrated multi-agents architecture.",2011-07-01,2011,2011-07,environment
"An Information Theoretic Representation of Agent Dynamics as Set
  Intersections","We represent agents as sets of strings. Each string encodes a potential
interaction with another agent or environment. We represent the total set of
dynamics between two agents as the intersection of their respective strings, we
prove complexity properties of player interactions using Algorithmic
Information Theory. We show how the proposed construction is compatible with
Universal Artificial Intelligence, in that the AIXI model can be seen as
universal with respect to interaction.",2011-07-05,2011,2011-07,environment
"Information, Utility & Bounded Rationality","Perfectly rational decision-makers maximize expected utility, but crucially
ignore the resource costs incurred when determining optimal actions. Here we
employ an axiomatic framework for bounded rational decision-making based on a
thermodynamic interpretation of resource costs as information costs. This leads
to a variational ""free utility"" principle akin to thermodynamical free energy
that trades off utility and information costs. We show that bounded optimal
control solutions can be derived from this variational principle, which leads
in general to stochastic policies. Furthermore, we show that risk-sensitive and
robust (minimax) control schemes fall out naturally from this framework if the
environment is considered as a bounded rational and perfectly rational
opponent, respectively. When resource costs are ignored, the maximum expected
utility principle is recovered.",2011-07-28,2011,2011-07,environment
A prototype of a knowledge-based programming environment,"In this paper we present a proposal for a knowledge-based programming
environment. In such an environment, declarative background knowledge,
procedures, and concrete data are represented in suitable languages and
combined in a flexible manner. This leads to a highly declarative programming
style. We illustrate our approach on an example and report about our prototype
implementation.",2011-08-29,2011,2011-08,environment
ATP and Presentation Service for Mizar Formalizations,"This paper describes the Automated Reasoning for Mizar (MizAR) service, which
integrates several automated reasoning, artificial intelligence, and
presentation tools with Mizar and its authoring environment. The service
provides ATP assistance to Mizar authors in finding and explaining proofs, and
offers generation of Mizar problems as challenges to ATP systems. The service
is based on a sound translation from the Mizar language to that of first-order
ATP systems, and relies on the recent progress in application of ATP systems in
large theories containing tens of thousands of available facts. We present the
main features of MizAR services, followed by an account of initial experiments
in finding proofs with the ATP assistance. Our initial experience indicates
that the tool offers substantial help in exploring the Mizar library and in
preparing new Mizar articles.",2011-09-03,2011,2011-09,environment
"Semantic Matchmaking as Non-Monotonic Reasoning: A Description Logic
  Approach","Matchmaking arises when supply and demand meet in an electronic marketplace,
or when agents search for a web service to perform some task, or even when
recruiting agencies match curricula and job profiles. In such open
environments, the objective of a matchmaking process is to discover best
available offers to a given request. We address the problem of matchmaking from
a knowledge representation perspective, with a formalization based on
Description Logics. We devise Concept Abduction and Concept Contraction as
non-monotonic inferences in Description Logics suitable for modeling
matchmaking in a logical framework, and prove some related complexity results.
We also present reasonable algorithms for semantic matchmaking based on the
devised inferences, and prove that they obey to some commonsense properties.
Finally, we report on the implementation of the proposed matchmaking framework,
which has been used both as a mediator in e-marketplaces and for semantic web
services discovery.",2011-10-12,2011,2011-10,environment
Resource Allocation Among Agents with MDP-Induced Preferences,"Allocating scarce resources among agents to maximize global utility is, in
general, computationally challenging. We focus on problems where resources
enable agents to execute actions in stochastic environments, modeled as Markov
decision processes (MDPs), such that the value of a resource bundle is defined
as the expected value of the optimal MDP policy realizable given these
resources. We present an algorithm that simultaneously solves the
resource-allocation and the policy-optimization problems. This allows us to
avoid explicitly representing utilities over exponentially many resource
bundles, leading to drastic (often exponential) reductions in computational
complexity. We then use this algorithm in the context of self-interested agents
to design a combinatorial auction for allocating resources. We empirically
demonstrate the effectiveness of our approach by showing that it can, in
minutes, optimally solve problems for which a straightforward combinatorial
resource-allocation technique would require the agents to enumerate up to 2^100
resource bundles and the auctioneer to solve an NP-complete problem with an
input of that size.",2011-10-12,2011,2011-10,environment
"Emotional control - conditio sine qua non for advanced artificial
  intelligences?","Humans dispose of two intertwined information processing pathways, cognitive
information processing via neural firing patterns and diffusive volume control
via neuromodulation. The cognitive information processing in the brain is
traditionally considered to be the prime neural correlate of human
intelligence, clinical studies indicate that human emotions intrinsically
correlate with the activation of the neuromodulatory system.
  We examine here the question: Why do humans dispose of the diffusive
emotional control system? Is this a coincidence, a caprice of nature, perhaps a
leftover of our genetic heritage, or a necessary aspect of any advanced
intelligence, being it biological or synthetic? We argue here that emotional
control is necessary to solve the motivational problem, viz the selection of
short-term utility functions, in the context of an environment where
information, computing power and time constitute scarce resources.",2011-12-06,2011,2011-12,environment
"Performance Evaluation of Road Traffic Control Using a Fuzzy Cellular
  Model","In this paper a method is proposed for performance evaluation of road traffic
control systems. The method is designed to be implemented in an on-line
simulation environment, which enables optimisation of adaptive traffic control
strategies. Performance measures are computed using a fuzzy cellular traffic
model, formulated as a hybrid system combining cellular automata and fuzzy
calculus. Experimental results show that the introduced method allows the
performance to be evaluated using imprecise traffic measurements. Moreover, the
fuzzy definitions of performance measures are convenient for uncertainty
determination in traffic control decisions.",2011-12-17,2011,2011-12,environment
A Well-typed Lightweight Situation Calculus,"Situation calculus has been widely applied in Artificial Intelligence related
fields. This formalism is considered as a dialect of logic programming language
and mostly used in dynamic domain modeling. However, type systems are hardly
deployed in situation calculus in the literature. To achieve a correct and
sound typed program written in situation calculus, adding typing elements into
the current situation calculus will be quite helpful. In this paper, we propose
to add more typing mechanisms to the current version of situation calculus,
especially for three basic elements in situation calculus: situations, actions
and objects, and then perform rigid type checking for existing situation
calculus programs to find out the well-typed and ill-typed ones. In this way,
type correctness and soundness in situation calculus programs can be guaranteed
by type checking based on our type system. This modified version of a
lightweight situation calculus is proved to be a robust and well-typed system.",2012-01-11,2012,2012-01,environment
"Dynamic Shared Context Processing in an E-Collaborative Learning
  Environment","In this paper, we propose a dynamic shared context processing method based on
DSC (Dynamic Shared Context) model, applied in an e-collaborative learning
environment. Firstly, we present the model. This is a way to measure the
relevance between events and roles in collaborative environments. With this
method, we can share the most appropriate event information for each role
instead of sharing all information to all roles in a collaborative work
environment. Then, we apply and verify this method in our project with Google
App supported e-learning collaborative environment. During this experiment, we
compared DSC method measured relevance of events and roles to manual measured
relevance. And we describe the favorable points from this comparison and our
finding. Finally, we discuss our future research of a hybrid DSC method to make
dynamical information shared more effective in a collaborative work
environment.",2012-01-18,2012,2012-01,environment
"On the influence of intelligence in (social) intelligence testing
  environments","This paper analyses the influence of including agents of different degrees of
intelligence in a multiagent system. The goal is to better understand how we
can develop intelligence tests that can evaluate social intelligence. We
analyse several reinforcement algorithms in several contexts of cooperation and
competition. Our experimental setting is inspired by the recently developed
Darwin-Wallace distribution.",2012-02-03,2012,2012-02,environment
One Decade of Universal Artificial Intelligence,"The first decade of this century has seen the nascency of the first
mathematical theory of general artificial intelligence. This theory of
Universal Artificial Intelligence (UAI) has made significant contributions to
many theoretical, philosophical, and practical AI questions. In a series of
papers culminating in book (Hutter, 2005), an exciting sound and complete
mathematical model for a super intelligent agent (AIXI) has been developed and
rigorously analyzed. While nowadays most AI researchers avoid discussing
intelligence, the award-winning PhD thesis (Legg, 2008) provided the
philosophical embedding and investigated the UAI-based universal measure of
rational intelligence, which is formal, objective and non-anthropocentric.
Recently, effective approximations of AIXI have been derived and experimentally
investigated in JAIR paper (Veness et al. 2011). This practical breakthrough
has resulted in some impressive applications, finally muting earlier critique
that UAI is only a theory. For the first time, without providing any domain
knowledge, the same agent is able to self-adapt to a diverse range of
interactive environments. For instance, AIXI is able to learn from scratch to
play TicTacToe, Pacman, Kuhn Poker, and other games by trial and error, without
even providing the rules of the games.
  These achievements give new hope that the grand goal of Artificial General
Intelligence is not elusive.
  This article provides an informal overview of UAI in context. It attempts to
gently introduce a very theoretical, formal, and mathematical subject, and
discusses philosophical and technical ingredients, traits of intelligence, some
social questions, and the past and future of UAI.",2012-02-28,2012,2012-02,environment
Truthful Feedback for Sanctioning Reputation Mechanisms,"For product rating environments, similar to that of Amazon Reviews, it has
been shown that the truthful elicitation of feedback is possible through
mechanisms which pay buyer reports contingent on the reports of other buyers.
We study whether similar mechanisms can be designed for reputation mechanisms
at online auction sites where the buyers' experiences are partially determined
by a strategic seller. We show that this is impossible for the basic setting.
However, introducing a small prior belief that the seller is a cooperative
commitment player leads to a payment scheme with a truthful perfect Bayesian
equilibrium.",2012-03-15,2012,2012-03,environment
Variance-Based Rewards for Approximate Bayesian Reinforcement Learning,"The explore{exploit dilemma is one of the central challenges in Reinforcement
Learning (RL). Bayesian RL solves the dilemma by providing the agent with
information in the form of a prior distribution over environments; however,
full Bayesian planning is intractable. Planning with the mean MDP is a common
myopic approximation of Bayesian planning. We derive a novel reward bonus that
is a function of the posterior distribution over environments, which, when
added to the reward in planning with the mean MDP, results in an agent which
explores efficiently and effectively. Although our method is similar to
existing methods when given an uninformative or unstructured prior, unlike
existing methods, our method can exploit structured priors. We prove that our
method results in a polynomial sample complexity and empirically demonstrate
its advantages in a structured exploration task.",2012-03-15,2012,2012-03,environment
Bayesian Inference in Monte-Carlo Tree Search,"Monte-Carlo Tree Search (MCTS) methods are drawing great interest after
yielding breakthrough results in computer Go. This paper proposes a Bayesian
approach to MCTS that is inspired by distributionfree approaches such as UCT
[13], yet significantly differs in important respects. The Bayesian framework
allows potentially much more accurate (Bayes-optimal) estimation of node values
and node uncertainties from a limited number of simulation trials. We further
propose propagating inference in the tree via fast analytic Gaussian
approximation methods: this can make the overhead of Bayesian inference
manageable in domains such as Go, while preserving high accuracy of
expected-value estimates. We find substantial empirical outperformance of UCT
in an idealized bandit-tree test environment, where we can obtain valuable
insights by comparing with known ground truth. Additionally we rigorously prove
on-policy and off-policy convergence of the proposed methods.",2012-03-15,2012,2012-03,environment
"When majority voting fails: Comparing quality assurance methods for
  noisy human computation environment","Quality assurance remains a key topic in human computation research. Prior
work indicates that majority voting is effective for low difficulty tasks, but
has limitations for harder tasks. This paper explores two methods of addressing
this problem: tournament selection and elimination selection, which exploit 2-,
3- and 4-way comparisons between different answers to human computation tasks.
Our experimental results and statistical analyses show that both methods
produce the correct answer in noisy human computation environment more often
than majority voting. Furthermore, we find that the use of 4-way comparisons
can significantly reduce the cost of quality assurance relative to the use of
2-way comparisons.",2012-04-16,2012,2012-04,environment
Generating Optimal Plans in Highly-Dynamic Domains,"Generating optimal plans in highly dynamic environments is challenging. Plans
are predicated on an assumed initial state, but this state can change
unexpectedly during plan generation, potentially invalidating the planning
effort. In this paper we make three contributions: (1) We propose a novel
algorithm for generating optimal plans in settings where frequent, unexpected
events interfere with planning. It is able to quickly distinguish relevant from
irrelevant state changes, and to update the existing planning search tree if
necessary. (2) We argue for a new criterion for evaluating plan adaptation
techniques: the relative running time compared to the ""size"" of changes. This
is significant since during recovery more changes may occur that need to be
recovered from subsequently, and in order for this process of repeated recovery
to terminate, recovery time has to converge. (3) We show empirically that our
approach can converge and find optimal plans in environments that would
ordinarily defy planning due to their high dynamics.",2012-05-09,2012,2012-05,environment
"A Sampling-Based Approach to Computing Equilibria in Succinct
  Extensive-Form Games","A central task of artificial intelligence is the design of artificial agents
that act towards specified goals in partially observed environments. Since such
environments frequently include interaction over time with other agents with
their own goals, reasoning about such interaction relies on sequential
game-theoretic models such as extensive-form games or some of their succinct
representations such as multi-agent influence diagrams. The current algorithms
for calculating equilibria either work with inefficient representations,
possibly doubly exponential inthe number of time steps, or place strong
assumptions on the game structure. In this paper,we propose a sampling-based
approach, which calculates extensive-form correlated equilibria with small
representations without placing such strong assumptions. Thus, it is practical
in situations where the previous approaches would fail. In addition, our
algorithm allows control over characteristics of the target equilibrium, e.g.,
we can ask for an equilibrium with high social welfare. Our approach is based
on a multiplicativeweight update algorithm analogous to AdaBoost, and Markov
chain Monte Carlo sampling. We prove convergence guarantees and explore the
utility of our approach on several moderately sized multi-player games.",2012-05-09,2012,2012-05,environment
Improving Gradient Estimation by Incorporating Sensor Data,"An efficient policy search algorithm should estimate the local gradient of
the objective function, with respect to the policy parameters, from as few
trials as possible. Whereas most policy search methods estimate this gradient
by observing the rewards obtained during policy trials, we show, both
theoretically and empirically, that taking into account the sensor data as well
gives better gradient estimates and hence faster learning. The reason is that
rewards obtained during policy execution vary from trial to trial due to noise
in the environment; sensor data, which correlates with the noise, can be used
to partially correct for this variation, resulting in an estimatorwith lower
variance.",2012-06-13,2012,2012-06,environment
CT-NOR: Representing and Reasoning About Events in Continuous Time,"We present a generative model for representing and reasoning about the
relationships among events in continuous time. We apply the model to the domain
of networked and distributed computing environments where we fit the parameters
of the model from timestamp observations, and then use hypothesis testing to
discover dependencies between the events and changes in behavior for monitoring
and diagnosis. After introducing the model, we present an EM algorithm for
fitting the parameters and then present the hypothesis testing approach for
both dependence discovery and change-point detection. We validate the approach
for both tasks using real data from a trace of network events at Microsoft
Research Cambridge. Finally, we formalize the relationship between the proposed
model and the noisy-or gate for cases when time can be discretized.",2012-06-13,2012,2012-06,environment
Probabilistic Models for Anomaly Detection in Remote Sensor Data Streams,"Remote sensors are becoming the standard for observing and recording
ecological data in the field. Such sensors can record data at fine temporal
resolutions, and they can operate under extreme conditions prohibitive to human
access. Unfortunately, sensor data streams exhibit many kinds of errors ranging
from corrupt communications to partial or total sensor failures. This means
that the raw data stream must be cleaned before it can be used by domain
scientists. In our application environment|the H.J. Andrews Experimental
Forest|this data cleaning is performed manually. This paper introduces a
Dynamic Bayesian Network model for analyzing sensor observations and
distinguishing sensor failures from valid data for the case of air temperature
measured at 15 minute time resolution. The model combines an accurate
distribution of long-term and short-term temperature variations with a single
generalized fault model. Experiments with historical data show that the
precision and recall of the method is comparable to that of the domain expert.
The system is currently being deployed to perform real-time automated data
cleaning.",2012-06-20,2012,2012-06,environment
"Predicting the behavior of interacting humans by fusing data from
  multiple sources","Multi-fidelity methods combine inexpensive low-fidelity simulations with
costly but high-fidelity simulations to produce an accurate model of a system
of interest at minimal cost. They have proven useful in modeling physical
systems and have been applied to engineering problems such as wing-design
optimization. During human-in-the-loop experimentation, it has become
increasingly common to use online platforms, like Mechanical Turk, to run
low-fidelity experiments to gather human performance data in an efficient
manner. One concern with these experiments is that the results obtained from
the online environment generalize poorly to the actual domain of interest. To
address this limitation, we extend traditional multi-fidelity approaches to
allow us to combine fewer data points from high-fidelity human-in-the-loop
experiments with plentiful but less accurate data from low-fidelity experiments
to produce accurate models of how humans interact. We present both model-based
and model-free methods, and summarize the predictive performance of each method
under different conditions.",2012-06-26,2012,2012-06,environment
"Apprenticeship Learning for Model Parameters of Partially Observable
  Environments","We consider apprenticeship learning, i.e., having an agent learn a task by
observing an expert demonstrating the task in a partially observable
environment when the model of the environment is uncertain. This setting is
useful in applications where the explicit modeling of the environment is
difficult, such as a dialogue system. We show that we can extract information
about the environment model by inferring action selection process behind the
demonstration, under the assumption that the expert is choosing optimal actions
based on knowledge of the true model of the target environment. Proposed
algorithms can achieve more accurate estimates of POMDP parameters and better
policies from a short demonstration, compared to methods that learns only from
the reaction from the environment.",2012-06-27,2012,2012-06,environment
"Optimal Coordinated Planning Amongst Self-Interested Agents with Private
  State","Consider a multi-agent system in a dynamic and uncertain environment. Each
agent's local decision problem is modeled as a Markov decision process (MDP)
and agents must coordinate on a joint action in each period, which provides a
reward to each agent and causes local state transitions. A social planner knows
the model of every agent's MDP and wants to implement the optimal joint policy,
but agents are self-interested and have private local state. We provide an
incentive-compatible mechanism for eliciting state information that achieves
the optimal joint plan in a Markov perfect equilibrium of the induced
stochastic game. In the special case in which local problems are Markov chains
and agents compete to take a single action in each period, we leverage Gittins
allocation indices to provide an efficient factored algorithm and distribute
computation of the optimal policy among the agents. Distributed, optimal
coordinated learning in a multi-agent variant of the multi-armed bandit problem
is obtained as a special case.",2012-06-27,2012,2012-06,environment
"A compact, hierarchical Q-function decomposition","Previous work in hierarchical reinforcement learning has faced a dilemma:
either ignore the values of different possible exit states from a subroutine,
thereby risking suboptimal behavior, or represent those values explicitly
thereby incurring a possibly large representation cost because exit values
refer to nonlocal aspects of the world (i.e., all subsequent rewards). This
paper shows that, in many cases, one can avoid both of these problems. The
solution is based on recursively decomposing the exit value function in terms
of Q-functions at higher levels of the hierarchy. This leads to an intuitively
appealing runtime architecture in which a parent subroutine passes to its child
a value function on the exit states and the child reasons about how its choices
affect the exit value. We also identify structural conditions on the value
function and transition distributions that allow much more concise
representations of exit state distributions, leading to further state
abstraction. In essence, the only variables whose exit values need be
considered are those that the parent cares about and the child affects. We
demonstrate the utility of our algorithms on a series of increasingly complex
environments.",2012-06-27,2012,2012-06,environment
"A unified setting for inference and decision: An argumentation-based
  approach","Inferring from inconsistency and making decisions are two problems which have
always been treated separately by researchers in Artificial Intelligence.
Consequently, different models have been proposed for each category. Different
argumentation systems [2, 7, 10, 11] have been developed for handling
inconsistency in knowledge bases. Recently, other argumentation systems [3, 4,
8] have been defined for making decisions under uncertainty. The aim of this
paper is to present a general argumentation framework in which both inferring
from inconsistency and decision making are captured. The proposed framework can
be used for decision under uncertainty, multiple criteria decision, rule-based
decision and finally case-based decision. Moreover, works on classical decision
suppose that the information about environment is coherent, and this no longer
required by this general framework.",2012-07-04,2012,2012-07,environment
Robotic Mapping with Polygonal Random Fields,"Two types of probabilistic maps are popular in the mobile robotics
literature: occupancy grids and geometric maps. Occupancy grids have the
advantages of simplicity and speed, but they represent only a restricted class
of maps and they make incorrect independence assumptions. On the other hand,
current geometric approaches, which characterize the environment by features
such as line segments, can represent complex environments compactly. However,
they do not reason explicitly about occupancy, a necessity for motion planning;
and, they lack a complete probability model over environmental structures. In
this paper we present a probabilistic mapping technique based on polygonal
random fields (PRF), which combines the advantages of both approaches. Our
approach explicitly represents occupancy using a geometric representation, and
it is based upon a consistent probability distribution over environments which
avoids the incorrect independence assumptions made by occupancy grids. We show
how sampling techniques for PRFs can be applied to localized laser and sonar
data, and we demonstrate significant improvements in mapping performance over
occupancy grids.",2012-07-04,2012,2012-07,environment
MAA*: A Heuristic Search Algorithm for Solving Decentralized POMDPs,"We present multi-agent A* (MAA*), the first complete and optimal heuristic
search algorithm for solving decentralized partially-observable Markov decision
problems (DEC-POMDPs) with finite horizon. The algorithm is suitable for
computing optimal plans for a cooperative group of agents that operate in a
stochastic environment such as multirobot coordination, network traffic
control, `or distributed resource allocation. Solving such problems efiectively
is a major challenge in the area of planning under uncertainty. Our solution is
based on a synthesis of classical heuristic search and decentralized control
theory. Experimental results show that MAA* has significant advantages. We
introduce an anytime variant of MAA* and conclude with a discussion of
promising extensions such as an approach to solving infinite horizon problems.",2012-07-04,2012,2012-07,environment
Counterexample-guided Planning,"Planning in adversarial and uncertain environments can be modeled as the
problem of devising strategies in stochastic perfect information games. These
games are generalizations of Markov decision processes (MDPs): there are two
(adversarial) players, and a source of randomness. The main practical obstacle
to computing winning strategies in such games is the size of the state space.
In practice therefore, one typically works with abstractions of the model. The
diffculty is to come up with an abstraction that is neither too coarse to
remove all winning strategies (plans), nor too fine to be intractable. In
verification, the paradigm of counterexample-guided abstraction refinement has
been successful to construct useful but parsimonious abstractions
automatically. We extend this paradigm to probabilistic models (namely, perfect
information games and, as a special case, MDPs). This allows us to apply the
counterexample-guided abstraction paradigm to the AI planning problem. As
special cases, we get planning algorithms for MDPs and deterministic systems
that automatically construct system abstractions.",2012-07-04,2012,2012-07,environment
Unsupervised Activity Discovery and Characterization From Event-Streams,"We present a framework to discover and characterize different classes of
everyday activities from event-streams. We begin by representing activities as
bags of event n-grams. This allows us to analyze the global structural
information of activities, using their local event statistics. We demonstrate
how maximal cliques in an undirected edge-weighted graph of activities, can be
used for activity-class discovery in an unsupervised manner. We show how
modeling an activity as a variable length Markov process, can be used to
discover recurrent event-motifs to characterize the discovered
activity-classes. We present results over extensive data-sets, collected from
multiple active environments, to show the competence and generalizability of
our proposed framework.",2012-07-04,2012,2012-07,environment
"The Arcade Learning Environment: An Evaluation Platform for General
  Agents","In this article we introduce the Arcade Learning Environment (ALE): both a
challenge problem and a platform and methodology for evaluating the development
of general, domain-independent AI technology. ALE provides an interface to
hundreds of Atari 2600 game environments, each one different, interesting, and
designed to be a challenge for human players. ALE presents significant research
challenges for reinforcement learning, model learning, model-based planning,
imitation learning, transfer learning, and intrinsic motivation. Most
importantly, it provides a rigorous testbed for evaluating and comparing
approaches to these problems. We illustrate the promise of ALE by developing
and benchmarking domain-independent agents designed using well-established AI
techniques for both reinforcement learning and planning. In doing so, we also
propose an evaluation methodology made possible by ALE, reporting empirical
results on over 55 different games. All of the software, including the
benchmark agents, is publicly available.",2012-07-19,2012,2012-07,environment
Optimistic Agents are Asymptotically Optimal,"We use optimism to introduce generic asymptotically optimal reinforcement
learning agents. They achieve, with an arbitrary finite or compact class of
environments, asymptotically optimal behavior. Furthermore, in the finite
deterministic case we provide finite error bounds.",2012-09-29,2012,2012-09,environment
Dynamic Teaching in Sequential Decision Making Environments,"We describe theoretical bounds and a practical algorithm for teaching a model
by demonstration in a sequential decision making environment. Unlike previous
efforts that have optimized learners that watch a teacher demonstrate a static
policy, we focus on the teacher as a decision maker who can dynamically choose
different policies to teach different parts of the environment. We develop
several teaching frameworks based on previously defined supervised protocols,
such as Teaching Dimension, extending them to handle noise and sequences of
inputs encountered in an MDP.We provide theoretical bounds on the learnability
of several important model classes in this setting and suggest a practical
algorithm for dynamic teaching.",2012-10-16,2012,2012-10,environment
The Do-Calculus Revisited,"The do-calculus was developed in 1995 to facilitate the identification of
causal effects in non-parametric models. The completeness proofs of [Huang and
Valtorta, 2006] and [Shpitser and Pearl, 2006] and the graphical criteria of
[Tian and Shpitser, 2010] have laid this identification problem to rest. Recent
explorations unveil the usefulness of the do-calculus in three additional
areas: mediation analysis [Pearl, 2012], transportability [Pearl and
Bareinboim, 2011] and metasynthesis. Meta-synthesis (freshly coined) is the
task of fusing empirical results from several diverse studies, conducted on
heterogeneous populations and under different conditions, so as to synthesize
an estimate of a causal relation in some target environment, potentially
different from those under study. The talk surveys these results with emphasis
on the challenges posed by meta-synthesis. For background material, see
http://bayes.cs.ucla.edu/csl_papers.html",2012-10-16,2012,2012-10,environment
"The Revisiting Problem in Mobile Robot Map Building: A Hierarchical
  Bayesian Approach","We present an application of hierarchical Bayesian estimation to robot map
building. The revisiting problem occurs when a robot has to decide whether it
is seeing a previously-built portion of a map, or is exploring new territory.
This is a difficult decision problem, requiring the probability of being
outside of the current known map. To estimate this probability, we model the
structure of a ""typical"" environment as a hidden Markov model that generates
sequences of views observed by a robot navigating through the environment. A
Dirichlet prior over structural models is learned from previously explored
environments. Whenever a robot explores a new environment, the posterior over
the model is estimated by Dirichlet hyperparameters. Our approach is
implemented and tested in the context of multi-robot map merging, a
particularly difficult instance of the revisiting problem. Experiments with
robot data show that the technique yields strong improvements over alternative
methods.",2012-10-19,2012,2012-10,environment
Symbolic Generalization for On-line Planning,"Symbolic representations have been used successfully in off-line planning
algorithms for Markov decision processes. We show that they can also improve
the performance of on-line planners. In addition to reducing computation time,
symbolic generalization can reduce the amount of costly real-world interactions
required for convergence. We introduce Symbolic Real-Time Dynamic Programming
(or sRTDP), an extension of RTDP. After each step of on-line interaction with
an environment, sRTDP uses symbolic model-checking techniques to generalizes
its experience by updating a group of states rather than a single state. We
examine two heuristic approaches to dynamic grouping of states and show that
they accelerate the planning process significantly in terms of both CPU time
and the number of steps of interaction with the environment.",2012-10-19,2012,2012-10,environment
Decentralized Sensor Fusion With Distributed Particle Filters,"This paper presents a scalable Bayesian technique for decentralized state
estimation from multiple platforms in dynamic environments. As has long been
recognized, centralized architectures impose severe scaling limitations for
distributed systems due to the enormous communication overheads. We propose a
strictly decentralized approach in which only nearby platforms exchange
information. They do so through an interactive communication protocol aimed at
maximizing information flow. Our approach is evaluated in the context of a
distributed surveillance scenario that arises in a robotic system for playing
the game of laser tag. Our results, both from simulation and using physical
robots, illustrate an unprecedented scaling capability to large teams of
vehicles.",2012-10-19,2012,2012-10,environment
Ambiente de Planejamento Ipê,"In this work we investigate the systems that implements algorithms for the
planning problem in Artificial Intelligence, called planners, with especial
attention to the planners based on the plan graph. We analyze the problem of
comparing the performance of the different algorithms and we propose an
environment for the development and analysis of planners.",2012-10-23,2012,2012-10,environment
"Dynamic Decision Support System Based on Bayesian Networks Application
  to fight against the Nosocomial Infections","The improvement of medical care quality is a significant interest for the
future years. The fight against nosocomial infections (NI) in the intensive
care units (ICU) is a good example. We will focus on a set of observations
which reflect the dynamic aspect of the decision, result of the application of
a Medical Decision Support System (MDSS). This system has to make dynamic
decision on temporal data. We use dynamic Bayesian network (DBN) to model this
dynamic process. It is a temporal reasoning within a real-time environment; we
are interested in the Dynamic Decision Support Systems in healthcare domain
(MDDSS).",2012-11-09,2012,2012-11,environment
"An ontology-based approach to relax traffic regulation for autonomous
  vehicle assistance","Traffic regulation must be respected by all vehicles, either human- or
computer- driven. However, extreme traffic situations might exhibit practical
cases in which a vehicle should safely and reasonably relax traffic regulation,
e.g., in order not to be indefinitely blocked and to keep circulating. In this
paper, we propose a high-level representation of an automated vehicle, other
vehicles and their environment, which can assist drivers in taking such
""illegal"" but practical relaxation decisions. This high-level representation
(an ontology) includes topological knowledge and inference rules, in order to
compute the next high-level motion an automated vehicle should take, as
assistance to a driver. Results on practical cases are presented.",2012-12-04,2012,2012-12,environment
Particle Filters in Robotics (Invited Talk),"This presentation will introduce the audience to a new, emerging body of
research on sequential Monte Carlo techniques in robotics. In recent years,
particle filters have solved several hard perceptual robotic problems. Early
successes were limited to low-dimensional problems, such as the problem of
robot localization in environments with known maps. More recently, researchers
have begun exploiting structural properties of robotic domains that have led to
successful particle filter applications in spaces with as many as 100,000
dimensions. The presentation will discuss specific tricks necessary to make
these techniques work in real - world domains,and also discuss open challenges
for researchers IN the UAI community.",2012-12-12,2012,2012-12,environment
"Learning Hierarchical Object Maps Of Non-Stationary Environments with
  mobile robots","Building models, or maps, of robot environments is a highly active research
area; however, most existing techniques construct unstructured maps and assume
static environments. In this paper, we present an algorithm for learning object
models of non-stationary objects found in office-type environments. Our
algorithm exploits the fact that many objects found in office environments look
alike (e.g., chairs, recycling bins). It does so through a two-level
hierarchical representation, which links individual objects with generic shape
templates of object classes. We derive an approximate EM algorithm for learning
shape parameters at both levels of the hierarchy, using local occupancy grid
maps for representing shape. Additionally, we develop a Bayesian model
selection algorithm that enables the robot to estimate the total number of
objects and object templates in the environment. Experimental results using a
real robot equipped with a laser range finder indicate that our approach
performs well at learning object-based maps of simple office environments. The
approach outperforms a previously developed non-hierarchical algorithm that
models objects but lacks class templates.",2012-12-12,2012,2012-12,environment
"Artificial Intelligence Framework for Simulating Clinical
  Decision-Making: A Markov Decision Process Approach","In the modern healthcare system, rapidly expanding costs/complexity, the
growing myriad of treatment options, and exploding information streams that
often do not effectively reach the front lines hinder the ability to choose
optimal treatment decisions over time. The goal in this paper is to develop a
general purpose (non-disease-specific) computational/artificial intelligence
(AI) framework to address these challenges. This serves two potential
functions: 1) a simulation environment for exploring various healthcare
policies, payment methodologies, etc., and 2) the basis for clinical artificial
intelligence - an AI that can think like a doctor. This approach combines
Markov decision processes and dynamic decision networks to learn from clinical
data and develop complex plans via simulation of alternative sequential
decision paths while capturing the sometimes conflicting, sometimes synergistic
interactions of various components in the healthcare system. It can operate in
partially observable environments (in the case of missing observations or data)
by maintaining belief states about patient health status and functions as an
online agent that plans and re-plans. This framework was evaluated using real
patient data from an electronic health record. Such an AI framework easily
outperforms the current treatment-as-usual (TAU) case-rate/fee-for-service
models of healthcare (Cost per Unit Change: $189 vs. $497) while obtaining a
30-35% increase in patient outcomes. Tweaking certain model parameters further
enhances this advantage, obtaining roughly 50% more improvement for roughly
half the costs. Given careful design and problem formulation, an AI simulation
framework can approximate optimal decisions even in complex and uncertain
environments. Future work is described that outlines potential lines of
research and integration of machine learning algorithms for personalized
medicine.",2013-01-10,2013,2013-01,environment
"A Possibilistic Model for Qualitative Sequential Decision Problems under
  Uncertainty in Partially Observable Environments","In this article we propose a qualitative (ordinal) counterpart for the
Partially Observable Markov Decision Processes model (POMDP) in which the
uncertainty, as well as the preferences of the agent, are modeled by
possibility distributions. This qualitative counterpart of the POMDP model
relies on a possibilistic theory of decision under uncertainty, recently
developed. One advantage of such a qualitative framework is its ability to
escape from the classical obstacle of stochastic POMDPs, in which even with a
finite state space, the obtained belief state space of the POMDP is infinite.
Instead, in the possibilistic framework even if exponentially larger than the
state space, the belief state space remains finite.",2013-01-23,2013,2013-01,environment
Practical Uses of Belief Functions,"We present examples where the use of belief functions provided sound and
elegant solutions to real life problems. These are essentially characterized by
?missing' information. The examples deal with 1) discriminant analysis using a
learning set where classes are only partially known; 2) an information
retrieval systems handling inter-documents relationships; 3) the combination of
data from sensors competent on partially overlapping frames; 4) the
determination of the number of sources in a multi-sensor environment by
studying the inter-sensors contradiction. The purpose of the paper is to report
on such applications where the use of belief functions provides a convenient
tool to handle ?messy' data problems.",2013-01-23,2013,2013-01,environment
Learning Hidden Markov Models with Geometrical Constraints,"Hidden Markov models (HMMs) and partially observable Markov decision
processes (POMDPs) form a useful tool for modeling dynamical systems. They are
particularly useful for representing environments such as road networks and
office buildings, which are typical for robot navigation and planning. The work
presented here is concerned with acquiring such models. We demonstrate how
domain-specific information and constraints can be incorporated into the
statistical estimation process, greatly improving the learned models in terms
of the model quality, the number of iterations required for convergence and
robustness to reduction in the amount of available data. We present new
initialization heuristics which can be used even when the data suffers from
cumulative rotational error, new update rules for the model parameters, as an
instance of generalized EM, and a strategy for enforcing complete geometrical
consistency in the model. Experimental results demonstrate the effectiveness of
our approach for both simulated and real robot data, in traditionally
hard-to-learn environments.",2013-01-23,2013,2013-01,environment
Multi-objects association in perception of dynamical situation,"In current perception systems applied to the rebuilding of the environment
for intelligent vehicles, the part reserved to object association for the
tracking is increasingly significant. This allows firstly to follow the objects
temporal evolution and secondly to increase the reliability of environment
perception. We propose in this communication the development of a multi-objects
association algorithm with ambiguity removal entering into the design of such a
dynamic perception system for intelligent vehicles. This algorithm uses the
belief theory and data modelling with fuzzy mathematics in order to be able to
handle inaccurate as well as uncertain information due to imperfect sensors.
These theories also allow the fusion of numerical as well as symbolic data. We
develop in this article the problem of matching between known and perceived
objects. This makes it possible to update a dynamic environment map for a
vehicle. The belief theory will enable us to quantify the belief in the
association of each perceived object with each known object. Conflicts can
appear in the case of object appearance or disappearance, or in the case of a
confused situation or bad perception. These conflicts are removed or solved
using an assignment algorithm, giving a solution called the "" best "" and so
ensuring the tracking of some objects present in our environment.",2013-01-23,2013,2013-01,environment
Model-Based Bayesian Exploration,"Reinforcement learning systems are often concerned with balancing exploration
of untested actions against exploitation of actions that are known to be good.
The benefit of exploration can be estimated using the classical notion of Value
of Information - the expected improvement in future decision quality arising
from the information acquired by exploration. Estimating this quantity requires
an assessment of the agent's uncertainty about its current value estimates for
states. In this paper we investigate ways of representing and reasoning about
this uncertainty in algorithms where the system attempts to learn a model of
its environment. We explicitly represent uncertainty about the parameters of
the model and build probability distributions over Q-values based on these.
These distributions are used to compute a myopic approximation to the value of
information for each action and hence to select the action that best balances
exploration and exploitation.",2013-01-23,2013,2013-01,environment
Learning Finite-State Controllers for Partially Observable Environments,"Reactive (memoryless) policies are sufficient in completely observable Markov
decision processes (MDPs), but some kind of memory is usually necessary for
optimal control of a partially observable MDP. Policies with finite memory can
be represented as finite-state automata. In this paper, we extend Baird and
Moore's VAPS algorithm to the problem of learning general finite-state
automata. Because it performs stochastic gradient descent, this algorithm can
be shown to converge to a locally optimal finite-state controller. We provide
the details of the algorithm and then consider the question of under what
conditions stochastic gradient descent will outperform exact gradient descent.
We conclude with empirical results comparing the performance of stochastic and
exact gradient descent, and showing the ability of our algorithm to extract the
useful information contained in the sequence of past observations to compensate
for the lack of observability at each time-step.",2013-01-23,2013,2013-01,environment
Subjective Reality and Strong Artificial Intelligence,"The main prospective aim of modern research related to Artificial
Intelligence is the creation of technical systems that implement the idea of
Strong Intelligence. According our point of view the path to the development of
such systems comes through the research in the field related to perceptions.
Here we formulate the model of the perception of external world which may be
used for the description of perceptual activity of intelligent beings. We
consider a number of issues related to the development of the set of patterns
which will be used by the intelligent system when interacting with environment.
The key idea of the presented perception model is the idea of subjective
reality. The principle of the relativity of perceived world is formulated. It
is shown that this principle is the immediate consequence of the idea of
subjective reality. In this paper we show how the methodology of subjective
reality may be used for the creation of different types of Strong AI systems.",2013-01-27,2013,2013-01,environment
Dealing with Uncertainty on the Initial State of a Petri Net,"This paper proposes a method to find the actual state of a complex dynamic
system from information coming from the sensors on the system himself, or on
its environment. The nominal evolution of the system is a priori known and can
be modeled (by an expert, for example), by different methods. In this paper,
the Petri nets have been chosen. Contrary to the usual use of the Petri nets,
the initial state of the system is unknown. So a degree of belief is bound to
each places, or set of places. The theory used to model this uncertainty is the
Dempster-Shafer's one which is well adapted to this type of problems. From the
given Petri net characterizing the nominal evolution of the dynamic system, and
from the observation inputs, the proposed method allows to determine according
to the reliability of the model and the inputs, the state of the system at any
time.",2013-01-30,2013,2013-01,environment
On Stable Multi-Agent Behavior in Face of Uncertainty,"A stable joint plan should guarantee the achievement of a designer's goal in
a multi-agent environment, while ensuring that deviations from the prescribed
plan would be detected. We present a computational framework where stable joint
plans can be studied, as well as several basic results about the
representation, verification and synthesis of stable joint plans.",2013-02-06,2013,2013-02,environment
"Incremental Map Generation by Low Cost Robots Based on
  Possibility/Necessity Grids","In this paper we present some results obtained with a troupe of low-cost
robots designed to cooperatively explore and adquire the map of unknown
structured orthogonal environments. In order to improve the covering of the
explored zone, the robots show different behaviours and cooperate by
transferring each other the perceived environment when they meet. The returning
robots deliver to a host computer their partial maps and the host incrementally
generates the map of the environment by means of apossibility/ necessity grid.",2013-02-06,2013,2013-02,environment
Bayes Networks for Sonar Sensor Fusion,"Wide-angle sonar mapping of the environment by mobile robot is nontrivial due
to several sources of uncertainty: dropouts due to ""specular"" reflections,
obstacle location uncertainty due to the wide beam, and distance measurement
error. Earlier papers address the latter problems, but dropouts remain a
problem in many environments. We present an approach that lifts the
overoptimistic independence assumption used in earlier work, and use Bayes nets
to represent the dependencies between objects of the model. Objects of the
model consist of readings, and of regions in which ""quasi location invariance""
of the (possible) obstacles exists, with respect to the readings. Simulation
supports the method's feasibility. The model is readily extensible to allow for
prior distributions, as well as other types of sensing operations.",2013-02-06,2013,2013-02,environment
Complexity distribution of agent policies,"We analyse the complexity of environments according to the policies that need
to be used to achieve high performance. The performance results for a
population of policies leads to a distribution that is examined in terms of
policy complexity and analysed through several diagrams and indicators. The
notion of environment response curve is also introduced, by inverting the
performance results into an ability scale. We apply all these concepts,
diagrams and indicators to a minimalistic environment class, agent-populated
elementary cellular automata, showing how the difficulty, discriminating power
and ranges (previous to normalisation) may vary for several environments.",2013-02-08,2013,2013-02,environment
Plan Development using Local Probabilistic Models,"Approximate models of world state transitions are necessary when building
plans for complex systems operating in dynamic environments. External event
probabilities can depend on state feature values as well as time spent in that
particular state. We assign temporally -dependent probability functions to
state transitions. These functions are used to locally compute state
probabilities, which are then used to select highly probable goal paths and
eliminate improbable states. This probabilistic model has been implemented in
the Cooperative Intelligent Real-time Control Architecture (CIRCA), which
combines an AI planner with a separate real-time system such that plans are
developed, scheduled, and executed with real-time guarantees. We present flight
simulation tests that demonstrate how our probabilistic model may improve CIRCA
performance.",2013-02-13,2013,2013-02,environment
Probabilistic Exploration in Planning while Learning,"Sequential decision tasks with incomplete information are characterized by
the exploration problem; namely the trade-off between further exploration for
learning more about the environment and immediate exploitation of the accrued
information for decision-making. Within artificial intelligence, there has been
an increasing interest in studying planning-while-learning algorithms for these
decision tasks. In this paper we focus on the exploration problem in
reinforcement learning and Q-learning in particular. The existing exploration
strategies for Q-learning are of a heuristic nature and they exhibit limited
scaleability in tasks with large (or infinite) state and action spaces.
Efficient experimentation is needed for resolving uncertainties when possible
plans are compared (i.e. exploration). The experimentation should be sufficient
for selecting with statistical significance a locally optimal plan (i.e.
exploitation). For this purpose, we develop a probabilistic hill-climbing
algorithm that uses a statistical selection procedure to decide how much
exploration is needed for selecting a plan which is, with arbitrarily high
probability, arbitrarily close to a locally optimal one. Due to its generality
the algorithm can be employed for the exploration strategy of robust
Q-learning. An experiment on a relatively complex control task shows that the
proposed exploration strategy performs better than a typical exploration
strategy.",2013-02-20,2013,2013-02,environment
"A Structured, Probabilistic Representation of Action","When agents devise plans for execution in the real world, they face two
important forms of uncertainty: they can never have complete knowledge about
the state of the world, and they do not have complete control, as the effects
of their actions are uncertain. While most classical planning methods avoid
explicit uncertainty reasoning, we believe that uncertainty should be
explicitly represented and reasoned about. We develop a probabilistic
representation for states and actions, based on belief networks. We define
conditional belief nets (CBNs) to capture the probabilistic dependency of the
effects of an action upon the state of the world. We also use a CBN to
represent the intrinsic relationships among entities in the environment, which
persist from state to state. We present a simple projection algorithm to
construct the belief network of the state succeeding an action, using the
environment CBN model to infer indirect effects. We discuss how the qualitative
aspects of belief networks and CBNs make them appropriate for the various
stages of the problem solving process, from model construction to the design of
planning algorithms.",2013-02-27,2013,2013-02,environment
Operator Selection While Planning Under Uncertainty,"This paper describes the best first search strategy used by U-Plan (Mansell
1993a), a planning system that constructs quantitatively ranked plans given an
incomplete description of an uncertain environment. U-Plan uses uncertain and
incomplete evidence de scribing the environment, characterizes it using a
Dempster-Shafer interval, and generates a set of possible world states. Plan
construction takes place in an abstraction hierarchy where strategic decisions
are made before tactical decisions. Search through this abstraction hierarchy
is guided by a quantitative measure (expected fulfillment) based on decision
theory. The search strategy is best first with the provision to update expected
fulfillment and review previous decisions in the light of planning
developments. U-Plan generates multiple plans for multiple possible worlds, and
attempts to use existing plans for new world situations. A super-plan is then
constructed, based on merging the set of plans and appropriately timed
knowledge acquisition operators, which are used to decide between plan
alternatives during plan execution.",2013-02-27,2013,2013-02,environment
Robust Planning in Uncertain Environments,"This paper describes a novel approach to planning which takes advantage of
decision theory to greatly improve robustness in an uncertain environment. We
present an algorithm which computes conditional plans of maximum expected
utility. This algorithm relies on a representation of the search space as an
AND/OR tree and employs a depth-limit to control computation costs. A numeric
robustness factor, which parameterizes the utility function, allows the user to
modulate the degree of risk-aversion employed by the planner. Via a look-ahead
search, the planning algorithm seeks to find an optimal plan using expected
utility as its optimization criterion. We present experimental results obtained
by applying our algorithm to a non-deterministic extension of the blocks world
domain. Our results demonstrate that the robustness factor governs the degree
of risk embodied in the conditional plans computed by our algorithm.",2013-02-27,2013,2013-02,environment
Learning in Multi-level Stochastic games with Delayed Information,"Distributed decision-makers are modeled as players in a game with two levels.
High level decisions concern the game environment and determine the willingness
of the players to form a coalition (or group). Low level decisions involve the
actions to be implemented within the chosen environment. Coalition and action
strategies are determined by probability distributions, which are updated using
learning automata schemes. The payoffs are also probabilistic and there is
uncertainty in the state vector since information is delayed. The goal is to
reach equilibrium in both levels of decision making; the results show the
conditions for instability, based on the age of information.",2013-02-27,2013,2013-02,environment
The Automated Mapping of Plans for Plan Recognition,"To coordinate with other agents in its environment, an agent needs models of
what the other agents are trying to do. When communication is impossible or
expensive, this information must be acquired indirectly via plan recognition.
Typical approaches to plan recognition start with a specification of the
possible plans the other agents may be following, and develop special
techniques for discriminating among the possibilities. Perhaps more desirable
would be a uniform procedure for mapping plans to general structures supporting
inference based on uncertain and incomplete observations. In this paper, we
describe a set of methods for converting plans represented in a flexible
procedural language to observation models represented as probabilistic belief
networks.",2013-02-27,2013,2013-02,environment
Syntax-based Default Reasoning as Probabilistic Model-based Diagnosis,"We view the syntax-based approaches to default reasoning as a model-based
diagnosis problem, where each source giving a piece of information is
considered as a component. It is formalized in the ATMS framework (each source
corresponds to an assumption). We assume then that all sources are independent
and ""fail"" with a very small probability. This leads to a probability
assignment on the set of candidates, or equivalently on the set of consistent
environments. This probability assignment induces a Dempster-Shafer belief
function which measures the probability that a proposition can be deduced from
the evidence. This belief function can be used in several different ways to
define a non-monotonic consequence relation. We study and compare these
consequence relations. The -case of prioritized knowledge bases is briefly
considered.",2013-02-27,2013,2013-02,environment
The Semantic Web takes Wing: Programming Ontologies with Tawny-OWL,"The Tawny-OWL library provides a fully-programmatic environment for ontology
building; it enables the use of a rich set of tools for ontology development,
by recasting development as a form of programming. It is built in Clojure - a
modern Lisp dialect, and is backed by the OWL API. Used simply, it has a
similar syntax to OWL Manchester syntax, but it provides arbitrary
extensibility and abstraction. It builds on existing facilities for Clojure,
which provides a rich and modern programming tool chain, for versioning,
distributed development, build, testing and continuous integration. In this
paper, we describe the library, this environment and the its potential
implications for the ontology development process.",2013-03-01,2013,2013-03,environment
"Representing and Reasoning With Probabilistic Knowledge: A Bayesian
  Approach","PAGODA (Probabilistic Autonomous Goal-Directed Agent) is a model for
autonomous learning in probabilistic domains [desJardins, 1992] that
incorporates innovative techniques for using the agent's existing knowledge to
guide and constrain the learning process and for representing, reasoning with,
and learning probabilistic knowledge. This paper describes the probabilistic
representation and inference mechanism used in PAGODA. PAGODA forms theories
about the effects of its actions and the world state on the environment over
time. These theories are represented as conditional probability distributions.
A restriction is imposed on the structure of the theories that allows the
inference mechanism to find a unique predicted distribution for any action and
world state description. These restricted theories are called uniquely
predictive theories. The inference mechanism, Probability Combination using
Independence (PCI), uses minimal independence assumptions to combine the
probabilities in a theory to make probabilistic predictions.",2013-03-06,2013,2013-03,environment
A Method for Planning Given Uncertain and Incomplete Information,"This paper describes ongoing research into planning in an uncertain
environment. In particular, it introduces U-Plan, a planning system that
constructs quantitatively ranked plans given an incomplete description of the
state of the world. U-Plan uses a DempsterShafer interval to characterise
uncertain and incomplete information about the state of the world. The planner
takes as input what is known about the world, and constructs a number of
possible initial states with representations at different abstraction levels. A
plan is constructed for the initial state with the greatest support, and this
plan is tested to see if it will work for other possible initial states. All,
part, or none of the existing plans may be used in the generation of the plans
for the remaining possible worlds. Planning takes place in an abstraction
hierarchy where strategic decisions are made before tactical decisions. A
super-plan is then constructed, based on merging the set of plans and the
appropriately timed acquisition of essential knowledge, which is used to decide
between plan alternatives. U-Plan usually produces a super-plan in less time
than a classical planner would take to produce a set of plans, one for each
possible world.",2013-03-06,2013,2013-03,environment
Sensor Validation Using Dynamic Belief Networks,"The trajectory of a robot is monitored in a restricted dynamic environment
using light beam sensor data. We have a Dynamic Belief Network (DBN), based on
a discrete model of the domain, which provides discrete monitoring analogous to
conventional quantitative filter techniques. Sensor observations are added to
the basic DBN in the form of specific evidence. However, sensor data is often
partially or totally incorrect. We show how the basic DBN, which infers only an
impossible combination of evidence, may be modified to handle specific types of
incorrect data which may occur in the domain. We then present an extension to
the DBN, the addition of an invalidating node, which models the status of the
sensor as working or defective. This node provides a qualitative explanation of
inconsistent data: it is caused by a defective sensor. The connection of
successive instances of the invalidating node models the status of a sensor
over time, allowing the DBN to handle both persistent and intermittent faults.",2013-03-13,2013,2013-03,environment
High Level Path Planning with Uncertainty,"For high level path planning, environments are usually modeled as distance
graphs, and path planning problems are reduced to computing the shortest path
in distance graphs. One major drawback of this modeling is the inability to
model uncertainties, which are often encountered in practice. In this paper, a
new tool, called U-yraph, is proposed for environment modeling. A U-graph is an
extension of distance graphs with the ability to handle a kind of uncertainty.
By modeling an uncertain environment as a U-graph, and a navigation problem as
a Markovian decision process, we can precisely define a new optimality
criterion for navigation plans, and more importantly, we can come up with a
general algorithm for computing optimal plans for navigation tasks.",2013-03-20,2013,2013-03,environment
Ergo: A Graphical Environment for Constructing Bayesian,"We describe an environment that considerably simplifies the process of
generating Bayesian belief networks. The system has been implemented on readily
available, inexpensive hardware, and provides clarity and high performance. We
present an introduction to Bayesian belief networks, discuss algorithms for
inference with these networks, and delineate the classes of problems that can
be solved with this paradigm. We then describe the hardware and software that
constitute the system, and illustrate Ergo's use with several example",2013-03-27,2013,2013-03,environment
A Probabilistic Reasoning Environment,"A framework is presented for a computational theory of probabilistic
argument. The Probabilistic Reasoning Environment encodes knowledge at three
levels. At the deepest level are a set of schemata encoding the system's domain
knowledge. This knowledge is used to build a set of second-level arguments,
which are structured for efficient recapture of the knowledge used to construct
them. Finally, at the top level is a Bayesian network constructed from the
arguments. The system is designed to facilitate not just propagation of beliefs
and assimilation of evidence, but also the dynamic process of constructing a
belief network, evaluating its adequacy, and revising it when necessary.",2013-03-27,2013,2013-03,environment
IDEAL: A Software Package for Analysis of Influence Diagrams,"IDEAL (Influence Diagram Evaluation and Analysis in Lisp) is a software
environment for creation and evaluation of belief networks and influence
diagrams. IDEAL is primarily a research tool and provides an implementation of
many of the latest developments in belief network and influence diagram
evaluation in a unified framework. This paper describes IDEAL and some lessons
learned during its development.",2013-03-27,2013,2013-03,environment
"An Uncertainty Management Calculus for Ordering Searches in Distributed
  Dynamic Databases","MINDS is a distributed system of cooperating query engines that customize,
document retrieval for each user in a dynamic environment. It improves its
performance and adapts to changing patterns of document distribution by
observing system-user interactions and modifying the appropriate certainty
factors, which act as search control parameters. It argued here that the
uncertainty management calculus must account for temporal precedence,
reliability of evidence, degree of support for a proposition, and saturation
effects. The calculus presented here possesses these features. Some results
obtained with this scheme are discussed.",2013-03-27,2013,2013-03,environment
Exact Reasoning Under Uncertainty,"This paper focuses on designing expert systems to support decision making in
complex, uncertain environments. In this context, our research indicates that
strictly probabilistic representations, which enable the use of
decision-theoretic reasoning, are highly preferable to recently proposed
alternatives (e.g., fuzzy set theory and Dempster-Shafer theory). Furthermore,
we discuss the language of influence diagrams and a corresponding methodology
-decision analysis -- that allows decision theory to be used effectively and
efficiently as a decision-making aid. Finally, we use RACHEL, a system that
helps infertile couples select medical treatments, to illustrate the
methodology of decision analysis as basis for expert decision systems.",2013-03-27,2013,2013-03,environment
Probabilistic Conflict Resolution in Hierarchical Hypothesis Spaces,"Artificial intelligence applications such as industrial robotics, military
surveillance, and hazardous environment clean-up, require situation
understanding based on partial, uncertain, and ambiguous or erroneous evidence.
It is necessary to evaluate the relative likelihood of multiple possible
hypotheses of the (current) situation faced by the decision making program.
Often, the evidence and hypotheses are hierarchical in nature. In image
understanding tasks, for example, evidence begins with raw imagery, from which
ambiguous features are extracted which have multiple possible aggregations
providing evidential support for the presence of multiple hypothesis of objects
and terrain, which in turn aggregate in multiple ways to provide partial
evidence for different interpretations of the ambient scene. Information fusion
for military situation understanding has a similar evidence/hypothesis
hierarchy from multiple sensor through message level interpretations, and also
provides evidence at multiple levels of the doctrinal hierarchy of military
forces.",2013-03-27,2013,2013-03,environment
Reducing Uncertainty in Navigation and Exploration,"A significant problem in designing mobile robot control systems involves
coping with the uncertainty that arises in moving about in an unknown or
partially unknown environment and relying on noisy or ambiguous sensor data to
acquire knowledge about that environment. We describe a control system that
chooses what activity to engage in next on the basis of expectations about how
the information re- turned as a result of a given activity will improve 2 its
knowledge about the spatial layout of its environment. Certain of the
higher-level components of the control system are specified in terms of
probabilistic decision models whose output is used to mediate the behavior of
lower-level control components responsible for movement and sensing.",2013-03-27,2013,2013-03,environment
Application of Evidential Reasoning to Helicopter Flight Path Control,"This paper presents a methodology for research and development of the
inferencing and knowledge representation aspects of an Expert System approach
for performing reasoning under uncertainty in support of a real time vehicle
guidance and navigation system. Such a system could be of major benefit for
non-terrain following low altitude flight systems operating in foreign hostile
environments such as might be experienced by NOE helicopter or similar mission
craft. An innovative extension of the evidential reasoning methodology, termed
the Sum-and-Lattice-Points Method, has been developed. The research and
development effort presented in this paper consists of a formal mathematical
development of the Sum-and-Lattice-Points Method, its formulation and
representation in a parallel environment, prototype software development of the
method within an expert system, and initial testing of the system within the
confines of the vehicle guidance system.",2013-03-27,2013,2013-03,environment
"An Empirical Evaluation of a Randomized Algorithm for Probabilistic
  Inference","In recent years, researchers in decision analysis and artificial intelligence
(Al) have used Bayesian belief networks to build models of expert opinion.
Using standard methods drawn from the theory of computational complexity,
workers in the field have shown that the problem of probabilistic inference in
belief networks is difficult and almost certainly intractable. K N ET, a
software environment for constructing knowledge-based systems within the
axiomatic framework of decision theory, contains a randomized approximation
scheme for probabilistic inference. The algorithm can, in many circumstances,
perform efficient approximate inference in large and richly interconnected
models of medical diagnosis. Unlike previously described stochastic algorithms
for probabilistic inference, the randomized approximation scheme computes a
priori bounds on running time by analyzing the structure and contents of the
belief network. In this article, we describe a randomized algorithm for
probabilistic inference and analyze its performance mathematically. Then, we
devote the major portion of the paper to a discussion of the algorithm's
empirical behavior. The results indicate that the generation of good trials
(that is, trials whose distribution closely matches the true distribution),
rather than the computation of numerous mediocre trials, dominates the
performance of stochastic simulation. Key words: probabilistic inference,
belief networks, stochastic simulation, computational complexity theory,
randomized algorithms.",2013-03-27,2013,2013-03,environment
A Decision-Theoretic Model for Using Scientific Data,"Many Artificial Intelligence systems depend on the agent's updating its
beliefs about the world on the basis of experience. Experiments constitute one
type of experience, so scientific methodology offers a natural environment for
examining the issues attendant to using this class of evidence. This paper
presents a framework which structures the process of using scientific data from
research reports for the purpose of making decisions, using decision analysis
as the basis for the structure and using medical research as the general
scientific domain. The structure extends the basic influence diagram for
updating belief in an object domain parameter of interest by expanding the
parameter into four parts: those of the patient, the population, the study
sample, and the effective study sample. The structure uses biases to perform
the transformation of one parameter into another, so that, for instance,
selection biases, in concert with the population parameter, yield the study
sample parameter. The influence diagram structure provides decision theoretic
justification for practices of good clinical research such as randomized
assignment and blindfolding of care providers. The model covers most research
designs used in medicine: case-control studies, cohort studies, and controlled
clinical trials, and provides an architecture to separate clearly between
statistical knowledge and domain knowledge. The proposed general model can be
the basis for clinical epidemiological advisory systems, when coupled with
heuristic pruning of irrelevant biases; of statistical workstations, when the
computational machinery for calculation of posterior distributions is added;
and of meta-analytic reviews, when multiple studies may impact on a single
population parameter.",2013-03-27,2013,2013-03,environment
"Now that I Have a Good Theory of Uncertainty, What Else Do I Need?","Rather than discussing the isolated merits of a nominative theory of
uncertainty, this paper focuses on a class of problems, referred to as Dynamic
Classification Problem (DCP), which requires the integration of many theories,
including a prescriptive theory of uncertainty. We start by analyzing the
Dynamic Classification Problem and by defining its induced requirements on a
supporting (plausible) reasoning system. We provide a summary of the underlying
theory (based on the semantics of many-valed logics) and illustrate the
constraints imposed upon it to ensure the modularity and computational
performance required by the applications. We describe the technologies used for
knowledge engineering (such as object-based simulator to exercise requirements,
and development tools to build the Knowledge Base and functionally validate
it). We emphasize the difference between development environment and run-time
system, describe the rule cross-compiler, and the real-time inference engine
with meta-reasoning capabilities. Finally, we illustrate how our proposed
technology satisfies the pop's requirements and analyze some of the lessons
reamed from its applications to situation assessment problems for Pilot's
Associate and Submarine Commander Associate.",2013-03-27,2013,2013-03,environment
"Hierarchical Evidence Accumulation in the Pseiki System and Experiments
  in Model-Driven Mobile Robot Navigation","In this paper, we will review the process of evidence accumulation in the
PSEIKI system for expectation-driven interpretation of images of 3-D scenes.
Expectations are presented to PSEIKI as a geometrical hierarchy of
abstractions. PSEIKI's job is then to construct abstraction hierarchies in the
perceived image taking cues from the abstraction hierarchies in the
expectations. The Dempster-Shafer formalism is used for associating belief
values with the different possible labels for the constructed abstractions in
the perceived image. This system has been used successfully for autonomous
navigation of a mobile robot in indoor environments.",2013-03-27,2013,2013-03,environment
"Decision-Theoretic Control of Problem Solving: Principles and
  Architecture","This paper presents an approach to the design of autonomous, real-time
systems operating in uncertain environments. We address issues of problem
solving and reflective control of reasoning under uncertainty in terms of two
fundamental elements: l) a set of decision-theoretic models for selecting among
alternative problem-solving methods and 2) a general computational architecture
for resource-bounded problem solving. The decisiontheoretic models provide a
set of principles for choosing among alternative problem-solving methods based
on their relative costs and benefits, where benefits are characterized in terms
of the value of information provided by the output of a reasoning activity. The
output may be an estimate of some uncertain quantity or a recommendation for
action. The computational architecture, called Schemer-ll, provides for
interleaving of and communication among various problem-solving subsystems.
These subsystems provide alternative approaches to information gathering,
belief refinement, solution construction, and solution execution. In
particular, the architecture provides a mechanism for interrupting the
subsystems in response to critical events. We provide a decision theoretic
account for scheduling problem-solving elements and for critical-event-driven
interruption of activities in an architecture such as Schemer-II.",2013-03-27,2013,2013-03,environment
Compiling Fuzzy Logic Control Rules to Hardware Implementations,"A major aspect of human reasoning involves the use of approximations.
Particularly in situations where the decision-making process is under stringent
time constraints, decisions are based largely on approximate, qualitative
assessments of the situations. Our work is concerned with the application of
approximate reasoning to real-time control. Because of the stringent processing
speed requirements in such applications, hardware implementations of fuzzy
logic inferencing are being pursued. We describe a programming environment for
translating fuzzy control rules into hardware realizations. Two methods of
hardware realizations are possible. The First is based on a special purpose
chip for fuzzy inferencing. The second is based on a simple memory chip. The
ability to directly translate a set of decision rules into hardware
implementations is expected to make fuzzy control an increasingly practical
approach to the control of complex systems.",2013-03-27,2013,2013-03,environment
Logical Fuzzy Optimization,"We present a logical framework to represent and reason about fuzzy
optimization problems based on fuzzy answer set optimization programming. This
is accomplished by allowing fuzzy optimization aggregates, e.g., minimum and
maximum in the language of fuzzy answer set optimization programming to allow
minimization or maximization of some desired criteria under fuzzy environments.
We show the application of the proposed logical fuzzy optimization framework
under the fuzzy answer set optimization programming to the fuzzy water
allocation optimization problem.",2013-04-05,2013,2013-04,environment
"A General Framework for Interacting Bayes-Optimally with Self-Interested
  Agents using Arbitrary Parametric Model and Model Prior","Recent advances in Bayesian reinforcement learning (BRL) have shown that
Bayes-optimality is theoretically achievable by modeling the environment's
latent dynamics using Flat-Dirichlet-Multinomial (FDM) prior. In
self-interested multi-agent environments, the transition dynamics are mainly
controlled by the other agent's stochastic behavior for which FDM's
independence and modeling assumptions do not hold. As a result, FDM does not
allow the other agent's behavior to be generalized across different states nor
specified using prior domain knowledge. To overcome these practical limitations
of FDM, we propose a generalization of BRL to integrate the general class of
parametric models and model priors, thus allowing practitioners' domain
knowledge to be exploited to produce a fine-grained and compact representation
of the other agent's behavior. Empirical evaluation shows that our approach
outperforms existing multi-agent reinforcement learning algorithms.",2013-04-07,2013,2013-04,environment
Universal Induction with Varying Sets of Combinators,"Universal induction is a crucial issue in AGI. Its practical applicability
can be achieved by the choice of the reference machine or representation of
algorithms agreed with the environment. This machine should be updatable for
solving subsequent tasks more efficiently. We study this problem on an example
of combinatory logic as the very simple Turing-complete reference machine,
which enables modifying program representations by introducing different sets
of primitive combinators. Genetic programming system is used to search for
combinator expressions, which are easily decomposed into sub-expressions being
recombined in crossover. Our experiments show that low-complexity induction or
prediction tasks can be solved by the developed system (much more efficiently
than using brute force); useful combinators can be revealed and included into
the representation simplifying more difficult tasks. However, optimal sets of
combinators depend on the specific task, so the reference machine should be
adaptively chosen in coordination with the search engine.",2013-06-01,2013,2013-06,environment
Direct Uncertainty Estimation in Reinforcement Learning,"Optimal probabilistic approach in reinforcement learning is computationally
infeasible. Its simplification consisting in neglecting difference between true
environment and its model estimated using limited number of observations causes
exploration vs exploitation problem. Uncertainty can be expressed in terms of a
probability distribution over the space of environment models, and this
uncertainty can be propagated to the action-value function via Bellman
iterations, which are computationally insufficiently efficient though. We
consider possibility of directly measuring uncertainty of the action-value
function, and analyze sufficiency of this facilitated approach.",2013-06-06,2013,2013-06,environment
"Cognitive Interpretation of Everyday Activities: Toward Perceptual
  Narrative Based Visuo-Spatial Scene Interpretation","We position a narrative-centred computational model for high-level knowledge
representation and reasoning in the context of a range of assistive
technologies concerned with ""visuo-spatial perception and cognition"" tasks. Our
proposed narrative model encompasses aspects such as \emph{space, events,
actions, change, and interaction} from the viewpoint of commonsense reasoning
and learning in large-scale cognitive systems. The broad focus of this paper is
on the domain of ""human-activity interpretation"" in smart environments, ambient
intelligence etc. In the backdrop of a ""smart meeting cinematography"" domain,
we position the proposed narrative model, preliminary work on perceptual
narrativisation, and the immediate outlook on constructing general-purpose
open-source tools for perceptual narrativisation.
  ACM Classification: I.2 Artificial Intelligence: I.2.0 General -- Cognitive
Simulation, I.2.4 Knowledge Representation Formalisms and Methods, I.2.10
Vision and Scene Understanding: Architecture and control structures, Motion,
Perceptual reasoning, Shape, Video analysis
  General keywords: cognitive systems; human-computer interaction; spatial
cognition and computation; commonsense reasoning; spatial and temporal
reasoning; assistive technologies",2013-06-22,2013,2013-06,environment
"Linear combination of one-step predictive information with an external
  reward in an episodic policy gradient setting: a critical analysis","One of the main challenges in the field of embodied artificial intelligence
is the open-ended autonomous learning of complex behaviours. Our approach is to
use task-independent, information-driven intrinsic motivation(s) to support
task-dependent learning. The work presented here is a preliminary step in which
we investigate the predictive information (the mutual information of the past
and future of the sensor stream) as an intrinsic drive, ideally supporting any
kind of task acquisition. Previous experiments have shown that the predictive
information (PI) is a good candidate to support autonomous, open-ended learning
of complex behaviours, because a maximisation of the PI corresponds to an
exploration of morphology- and environment-dependent behavioural regularities.
The idea is that these regularities can then be exploited in order to solve any
given task. Three different experiments are presented and their results lead to
the conclusion that the linear combination of the one-step PI with an external
reward function is not generally recommended in an episodic policy gradient
setting. Only for hard tasks a great speed-up can be achieved at the cost of an
asymptotic performance lost.",2013-09-26,2013,2013-09,environment
Changing the Environment based on Intrinsic Motivation,"One of the remarkable feats of intelligent life is that it restructures the
world it lives in for its own benefit. This extended abstract outlines how the
information-theoretic principle of empowerment, as an intrinsic motivation, can
be used to restructure the environment an agent lives in. We present a first
qualitative evaluation of how an agent in a 3d-gridworld builds a
staircase-like structure, which reflects the agent's embodiment.",2013-10-14,2013,2013-10,environment
"Emotional Responses in Artificial Agent-Based Systems: Reflexivity and
  Adaptation in Artificial Life","The current work addresses a virtual environment with self-replicating agents
whose decisions are based on a form of ""somatic computation"" (soma - body) in
which basic emotional responses, taken in parallelism to actual living
organisms, are introduced as a way to provide the agents with greater reflexive
abilities. The work provides a contribution to the field of Artificial
Intelligence (AI) and Artificial Life (ALife) in connection to a
neurobiology-based cognitive framework for artificial systems and virtual
environments' simulations. The performance of the agents capable of emotional
responses is compared with that of self-replicating automata, and the
implications of research on emotions and AI, in connection to both virtual
agents as well as robots, is addressed regarding possible future directions and
applications.",2014-01-09,2014,2014-01,environment
"A Rigorously Bayesian Beam Model and an Adaptive Full Scan Model for
  Range Finders in Dynamic Environments","This paper proposes and experimentally validates a Bayesian network model of
a range finder adapted to dynamic environments. All modeling assumptions are
rigorously explained, and all model parameters have a physical interpretation.
This approach results in a transparent and intuitive model. With respect to the
state of the art beam model this paper: (i) proposes a different functional
form for the probability of range measurements caused by unmodeled objects,
(ii) intuitively explains the discontinuity encountered in te state of the art
beam model, and (iii) reduces the number of model parameters, while maintaining
the same representational power for experimental data. The proposed beam model
is called RBBM, short for Rigorously Bayesian Beam Model. A maximum likelihood
and a variational Bayesian estimator (both based on expectation-maximization)
are proposed to learn the model parameters.
  Furthermore, the RBBM is extended to a full scan model in two steps: first,
to a full scan model for static environments and next, to a full scan model for
general, dynamic environments. The full scan model accounts for the dependency
between beams and adapts to the local sample density when using a particle
filter. In contrast to Gaussian-based state of the art models, the proposed
full scan model uses a sample-based approximation. This sample-based
approximation enables handling dynamic environments and capturing
multi-modality, which occurs even in simple static environments.",2014-01-15,2014,2014-01,environment
Online Planning Algorithms for POMDPs,"Partially Observable Markov Decision Processes (POMDPs) provide a rich
framework for sequential decision-making under uncertainty in stochastic
domains. However, solving a POMDP is often intractable except for small
problems due to their complexity. Here, we focus on online approaches that
alleviate the computational complexity by computing good local policies at each
decision step during the execution. Online algorithms generally consist of a
lookahead search to find the best action to execute at each time step in an
environment. Our objectives here are to survey the various existing online
POMDP methods, analyze their properties and discuss their advantages and
disadvantages; and to thoroughly evaluate these online approaches in different
environments under various metrics (return, error bound reduction, lower bound
improvement). Our experimental results indicate that state-of-the-art online
heuristic search methods can handle large POMDP domains efficiently.",2014-01-15,2014,2014-01,environment
Computational Logic Foundations of KGP Agents,"This paper presents the computational logic foundations of a model of agency
called the KGP (Knowledge, Goals and Plan model. This model allows the
specification of heterogeneous agents that can interact with each other, and
can exhibit both proactive and reactive behaviour allowing them to function in
dynamic environments by adjusting their goals and plans when changes happen in
such environments. KGP provides a highly modular agent architecture that
integrates a collection of reasoning and physical capabilities, synthesised
within transitions that update the agents state in response to reasoning,
sensing and acting. Transitions are orchestrated by cycle theories that specify
the order in which transitions are executed while taking into account the
dynamic context and agent preferences, as well as selection operators for
providing inputs to transitions.",2014-01-15,2014,2014-01,environment
"Learning to Make Predictions In Partially Observable Environments
  Without a Generative Model","When faced with the problem of learning a model of a high-dimensional
environment, a common approach is to limit the model to make only a restricted
set of predictions, thereby simplifying the learning problem. These partial
models may be directly useful for making decisions or may be combined together
to form a more complete, structured model. However, in partially observable
(non-Markov) environments, standard model-learning methods learn generative
models, i.e. models that provide a probability distribution over all possible
futures (such as POMDPs). It is not straightforward to restrict such models to
make only certain predictions, and doing so does not always simplify the
learning problem. In this paper we present prediction profile models:
non-generative partial models for partially observable systems that make only a
given set of predictions, and are therefore far simpler than generative models
in some cases. We formalize the problem of learning a prediction profile model
as a transformation of the original model-learning problem, and show
empirically that one can learn prediction profile models that make a small set
of important predictions even in systems that are too complex for standard
generative models.",2014-01-16,2014,2014-01,environment
Efficient Planning under Uncertainty with Macro-actions,"Deciding how to act in partially observable environments remains an active
area of research. Identifying good sequences of decisions is particularly
challenging when good control performance requires planning multiple steps into
the future in domains with many states. Towards addressing this challenge, we
present an online, forward-search algorithm called the Posterior Belief
Distribution (PBD). PBD leverages a novel method for calculating the posterior
distribution over beliefs that result after a sequence of actions is taken,
given the set of observation sequences that could be received during this
process. This method allows us to efficiently evaluate the expected reward of a
sequence of primitive actions, which we refer to as macro-actions. We present a
formal analysis of our approach, and examine its performance on two very large
simulation experiments: scientific exploration and a target monitoring domain.
We also demonstrate our algorithm being used to control a real robotic
helicopter in a target monitoring experiment, which suggests that our approach
has practical potential for planning in real-world, large partially observable
domains where a multi-step lookahead is required to achieve good performance.",2014-01-16,2014,2014-01,environment
Safe Exploration of State and Action Spaces in Reinforcement Learning,"In this paper, we consider the important problem of safe exploration in
reinforcement learning. While reinforcement learning is well-suited to domains
with complex transition dynamics and high-dimensional state-action spaces, an
additional challenge is posed by the need for safe and efficient exploration.
Traditional exploration techniques are not particularly useful for solving
dangerous tasks, where the trial and error process may lead to the selection of
actions whose execution in some states may result in damage to the learning
system (or any other system). Consequently, when an agent begins an interaction
with a dangerous and high-dimensional state-action space, an important question
arises; namely, that of how to avoid (or at least minimize) damage caused by
the exploration of the state-action space. We introduce the PI-SRL algorithm
which safely improves suboptimal albeit robust behaviors for continuous state
and action control tasks and which efficiently learns from the experience
gained from the environment. We evaluate the proposed method in four complex
tasks: automatic car parking, pole-balancing, helicopter hovering, and business
management.",2014-02-04,2014,2014-02,environment
Intelligent User Interface in Fuzzy Environment,"Human-Computer Interaction with the traditional User Interface is done using
a specified in advance script dialog menu, mainly based on human intellect and
unproductive use of navigation. This approach does not lead to making
qualitative decision in control systems, where the situations and processes
cannot be structured in advance. Any dynamic changes in the controlled business
process (as example, in organizational unit of the information fuzzy control
system) make it necessary to modify the script dialogue in User Interface. This
circumstance leads to a redesign of the components of the User Interface and of
the entire control system. In the Intelligent User Interface, where the dialog
situations are unknown in advance, fuzzy structured and artificial intelligence
is crucial, the redesign described above is impossible. To solve this and other
problems, we propose the data, information and knowledge based technology of
Smart/ Intelligent User Interface (IUI) design, which interacts with users and
systems in natural and other languages, utilizing the principles of Situational
Control and Fuzzy Logic theories, Artificial Intelligence, Linguistics,
Knowledge Base technologies and others. The proposed technology of IUI design
is defined by multi-agents of Situational Control and of data, information and
knowledge, modelling of Fuzzy Logic Inference, Generalization, Representation
and Explanation of knowledge, Planning and Decision-making, Dialog Control,
Reasoning and Systems Thinking, Fuzzy Control of organizational unit in
real-time, fuzzy conditions, heterogeneous domains, and multi-lingual
communication under uncertainty and in Fuzzy Environment.",2014-02-10,2014,2014-02,environment
Line Maps in Cluttered Environments,"This paper uses the smoothing and mapping framework to solve the SLAM problem
in indoor environments; focusing on how some key issues such as feature
extraction and data association can be handled by applying probabilistic
techniques. For feature extraction, an odds ratio approach to find multiple
lines from laser scans is proposed, this criterion allows to decide which model
must be merged and to output the best number of models. In addition, to solve
the data association problem a method based on the segments of each line is
proposed. Experimental results show that high quality indoor maps can be
obtained from noisy data",2014-02-20,2014,2014-02,environment
"Enaction-Based Artificial Intelligence: Toward Coevolution with Humans
  in the Loop","This article deals with the links between the enaction paradigm and
artificial intelligence. Enaction is considered a metaphor for artificial
intelligence, as a number of the notions which it deals with are deemed
incompatible with the phenomenal field of the virtual. After explaining this
stance, we shall review previous works regarding this issue in terms of
artifical life and robotics. We shall focus on the lack of recognition of
co-evolution at the heart of these approaches. We propose to explicitly
integrate the evolution of the environment into our approach in order to refine
the ontogenesis of the artificial system, and to compare it with the enaction
paradigm. The growing complexity of the ontogenetic mechanisms to be activated
can therefore be compensated by an interactive guidance system emanating from
the environment. This proposition does not however resolve that of the
relevance of the meaning created by the machine (sense-making). Such
reflections lead us to integrate human interaction into this environment in
order to construct relevant meaning in terms of participative artificial
intelligence. This raises a number of questions with regards to setting up an
enactive interaction. The article concludes by exploring a number of issues,
thereby enabling us to associate current approaches with the principles of
morphogenesis, guidance, the phenomenology of interactions and the use of
minimal enactive interfaces in setting up experiments which will deal with the
problem of artificial intelligence in a variety of enaction-based ways.",2014-02-26,2014,2014-02,environment
"Cortex simulation system proposal using distributed computer network
  environments","In the dawn of computer science and the eve of neuroscience we participate in
rebirth of neuroscience due to new technology that allows us to deeply and
precisely explore whole new world that dwells in our brains.",2014-03-22,2014,2014-03,environment
TurKPF: TurKontrol as a Particle Filter,"TurKontrol, and algorithm presented in (Dai et al. 2010), uses a POMDP to
model and control an iterative workflow for crowdsourced work. Here, TurKontrol
is re-implemented as ""TurKPF,"" which uses a Particle Filter to reduce
computation time & memory usage. Most importantly, in our experimental
environment with default parameter settings, the action is chosen nearly
instantaneously. Through a series of experiments we see that TurKPF and
TurKontrol perform similarly.",2014-04-20,2014,2014-04,environment
"Projective simulation applied to the grid-world and the mountain-car
  problem","We study the model of projective simulation (PS) which is a novel approach to
artificial intelligence (AI). Recently it was shown that the PS agent performs
well in a number of simple task environments, also when compared to standard
models of reinforcement learning (RL). In this paper we study the performance
of the PS agent further in more complicated scenarios. To that end we chose two
well-studied benchmarking problems, namely the ""grid-world"" and the
""mountain-car"" problem, which challenge the model with large and continuous
input space. We compare the performance of the PS agent model with those of
existing models and show that the PS agent exhibits competitive performance
also in such scenarios.",2014-05-21,2014,2014-05,environment
"A self-organizing system for urban traffic control based on predictive
  interval microscopic model","This paper introduces a self-organizing traffic signal system for an urban
road network. The key elements of this system are agents that control traffic
signals at intersections. Each agent uses an interval microscopic traffic model
to predict effects of its possible control actions in a short time horizon. The
executed control action is selected on the basis of predicted delay intervals.
Since the prediction results are represented by intervals, the agents can
recognize and suspend those control actions, whose positive effect on the
performance of traffic control is uncertain. Evaluation of the proposed traffic
control system was performed in a simulation environment. The simulation
experiments have shown that the proposed approach results in an improved
performance, particularly for non-uniform traffic streams.",2014-06-04,2014,2014-06,environment
Flow for Meta Control,"The psychological state of flow has been linked to optimizing human
performance. A key condition of flow emergence is a match between the human
abilities and complexity of the task. We propose a simple computational model
of flow for Artificial Intelligence (AI) agents. The model factors the standard
agent-environment state into a self-reflective set of the agent's abilities and
a socially learned set of the environmental complexity. Maximizing the flow
serves as a meta control for the agent. We show how to apply the meta-control
policy to a broad class of AI control policies and illustrate our approach with
a specific implementation. Results in a synthetic testbed are promising and
open interesting directions for future work.",2014-07-17,2014,2014-07,environment
Learning to Cooperate via Policy Search,"Cooperative games are those in which both agents share the same payoff
structure. Value-based reinforcement-learning algorithms, such as variants of
Q-learning, have been applied to learning cooperative games, but they only
apply when the game state is completely observable to both agents. Policy
search methods are a reasonable alternative to value-based methods for
partially observable environments. In this paper, we provide a gradient-based
distributed policy-search method for cooperative games and compare the notion
of local optimum to that of Nash equilibrium. We demonstrate the effectiveness
of this method experimentally in a small, partially observable simulated soccer
domain.",2014-08-07,2014,2014-08,environment
"Predicting the behavior of interacting humans by fusing data from
  multiple sources","Multi-fidelity methods combine inexpensive low-fidelity simulations with
costly but highfidelity simulations to produce an accurate model of a system of
interest at minimal cost. They have proven useful in modeling physical systems
and have been applied to engineering problems such as wing-design optimization.
During human-in-the-loop experimentation, it has become increasingly common to
use online platforms, like Mechanical Turk, to run low-fidelity experiments to
gather human performance data in an efficient manner. One concern with these
experiments is that the results obtained from the online environment generalize
poorly to the actual domain of interest. To address this limitation, we extend
traditional multi-fidelity approaches to allow us to combine fewer data points
from high-fidelity human-in-the-loop experiments with plentiful but less
accurate data from low-fidelity experiments to produce accurate models of how
humans interact. We present both model-based and model-free methods, and
summarize the predictive performance of each method under dierent conditions.",2014-08-09,2014,2014-08,environment
Dynamic Sweep Filtering Algorithm for FlexC,"We investigate cumulative scheduling in uncertain environments, using
constraint programming. We detail in this paper the dynamic sweep filtering
algorithm of the FlexC global constraint.",2014-08-22,2014,2014-08,environment
A Complete framework for ambush avoidance in realistic environments,"Operating vehicles in adversarial environments between a recurring
origin-destination pair requires new planning techniques. A two players
zero-sum game is introduced. The goal of the first player is to minimize the
expected casualties undergone by a convoy. The goal of the second player is to
maximize this damage. The outcome of the game is obtained via a linear program
that solves the corresponding minmax optimization problem over this outcome.
Different environment models are defined in order to compute routing strategies
over unstructured environments. To compare these methods for increasingly
accurate representations of the environment, a grid-based model is chosen to
represent the environment and the existence of a sufficient network size is
highlighted. A global framework for the generation of realistic routing
strategies between any two points is described. This framework requires a good
assessment of the potential casualties at any location, therefore the most
important parameters are identified. Finally the framework is tested on real
world environments.",2014-08-26,2014,2014-08,environment
"Hybrid Systems Knowledge Representation Using Modelling Environment
  System Techniques Artificial Intelligence","Knowledge-based or Artificial Intelligence techniques are used increasingly
as alternatives to more classical techniques to model ENVIRONMENTAL SYSTEMS.
Use of Artificial Intelligence (AI) in environmental modelling has increased
with recognition of its potential. In this paper we examine the DIFFERENT
TECHNIQUES of Artificial intelligence with profound examples of human
perception, learning and reasoning to solve complex problems. However with the
increase of complexity better methods are required. Keeping in view of the
above some researchers introduced the idea of hybrid mechanism in which two or
more methods can be combined which seems to be a positive effort for creating a
more complex; advanced and intelligent system which has the capability to in-
cooperate human decisions thus driving the landscape changes.",2014-09-03,2014,2014-09,environment
Intelligent Indoor Mobile Robot Navigation Using Stereo Vision,"Majority of the existing robot navigation systems, which facilitate the use
of laser range finders, sonar sensors or artificial landmarks, has the ability
to locate itself in an unknown environment and then build a map of the
corresponding environment. Stereo vision, while still being a rapidly
developing technique in the field of autonomous mobile robots, are currently
less preferable due to its high implementation cost. This paper aims at
describing an experimental approach for the building of a stereo vision system
that helps the robots to avoid obstacles and navigate through indoor
environments and at the same time remaining very much cost effective. This
paper discusses the fusion techniques of stereo vision and ultrasound sensors
which helps in the successful navigation through different types of complex
environments. The data from the sensor enables the robot to create the two
dimensional topological map of unknown environments and stereo vision systems
models the three dimension model of the same environment.",2014-09-10,2014,2014-09,environment
Probabilistic Selection in AgentSpeak(L),"Agent programming is mostly a symbolic discipline and, as such, draws little
benefits from probabilistic areas as machine learning and graphical models.
However, the greatest objective of agent research is the achievement of
autonomy in dynamical and complex environments --- a goal that implies
embracing uncertainty and therefore the entailed representations, algorithms
and techniques. This paper proposes an innovative and conflict free two layer
approach to agent programming that uses already established methods and tools
from both symbolic and probabilistic artificial intelligence. Moreover, this
framework is illustrated by means of a widely used agent programming example,
GoldMiners.",2014-09-12,2014,2014-09,environment
A Comparison of learning algorithms on the Arcade Learning Environment,"Reinforcement learning agents have traditionally been evaluated on small toy
problems. With advances in computing power and the advent of the Arcade
Learning Environment, it is now possible to evaluate algorithms on diverse and
difficult problems within a consistent framework. We discuss some challenges
posed by the arcade learning environment which do not manifest in simpler
environments. We then provide a comparison of model-free, linear learning
algorithms on this challenging problem set.",2014-10-31,2014,2014-10,environment
"Quantifying Natural and Artificial Intelligence in Robots and Natural
  Systems with an Algorithmic Behavioural Test","One of the most important aims of the fields of robotics, artificial
intelligence and artificial life is the design and construction of systems and
machines as versatile and as reliable as living organisms at performing high
level human-like tasks. But how are we to evaluate artificial systems if we are
not certain how to measure these capacities in living systems, let alone how to
define life or intelligence? Here I survey a concrete metric towards measuring
abstract properties of natural and artificial systems, such as the ability to
react to the environment and to control one's own behaviour.",2014-12-20,2014,2014-12,environment
Different Types of Conflicting Knowledge in AmI Environments,"We characterize different types of conflicts that may occur in complex
distributed multi-agent scenarios, such as in Ambient Intelligence (AmI)
environments, and we argue that these conflicts should be resolved in a
suitable order and with the appropriate strategies for each individual conflict
type. We call for further research with the goal of turning conflict resolution
in AmI environments and similar multi-agent domains into a more coordinated and
agreed upon process.",2014-12-26,2014,2014-12,environment
Game-theoretic Approach for Non-Cooperative Planning,"When two or more self-interested agents put their plans to execution in the
same environment, conflicts may arise as a consequence, for instance, of a
common utilization of resources. In this case, an agent can postpone the
execution of a particular action, if this punctually solves the conflict, or it
can resort to execute a different plan if the agent's payoff significantly
diminishes due to the action deferral. In this paper, we present a
game-theoretic approach to non-cooperative planning that helps predict before
execution what plan schedules agents will adopt so that the set of strategies
of all agents constitute a Nash equilibrium. We perform some experiments and
discuss the solutions obtained with our game-theoretical approach, analyzing
how the conflicts between the plans determine the strategic behavior of the
agents.",2015-03-04,2015,2015-03,environment
"Quantifying Morphological Computation based on an Information
  Decomposition of the Sensorimotor Loop","The question how an agent is affected by its embodiment has attracted growing
attention in recent years. A new field of artificial intelligence has emerged,
which is based on the idea that intelligence cannot be understood without
taking into account embodiment. We believe that a formal approach to
quantifying the embodiment's effect on the agent's behaviour is beneficial to
the fields of artificial life and artificial intelligence. The contribution of
an agent's body and environment to its behaviour is also known as morphological
computation. Therefore, in this work, we propose a quantification of
morphological computation, which is based on an information decomposition of
the sensorimotor loop into shared, unique and synergistic information. In
numerical simulation based on a formal representation of the sensorimotor loop,
we show that the unique information of the body and environment is a good
measure for morphological computation. The results are compared to our
previously derived quantification of morphological computation.",2015-03-17,2015,2015-03,environment
Monte Carlo Localization in Hand-Drawn Maps,"Robot localization is a one of the most important problems in robotics. Most
of the existing approaches assume that the map of the environment is available
beforehand and focus on accurate metrical localization. In this paper, we
address the localization problem when the map of the environment is not present
beforehand, and the robot relies on a hand-drawn map from a non-expert user. We
addressed this problem by expressing the robot pose in the pixel coordinate and
simultaneously estimate a local deformation of the hand-drawn map. Experiments
show that we are able to localize the robot in the correct room with a
robustness up to 80%",2015-04-02,2015,2015-04,environment
Projective simulation with generalization,"The ability to generalize is an important feature of any intelligent agent.
Not only because it may allow the agent to cope with large amounts of data, but
also because in some environments, an agent with no generalization capabilities
cannot learn. In this work we outline several criteria for generalization, and
present a dynamic and autonomous machinery that enables projective simulation
agents to meaningfully generalize. Projective simulation, a novel, physical
approach to artificial intelligence, was recently shown to perform well in
standard reinforcement learning problems, with applications in advanced
robotics as well as quantum experiments. Both the basic projective simulation
model and the presented generalization machinery are based on very simple
principles. This allows us to provide a full analytical analysis of the agent's
performance and to illustrate the benefit the agent gains by generalizing.
Specifically, we show that already in basic (but extreme) environments,
learning without generalization may be impossible, and demonstrate how the
presented generalization machinery enables the projective simulation agent to
learn.",2015-04-09,2015,2015-04,environment
Multi-Context Systems for Reactive Reasoning in Dynamic Environments,"We show in this paper how managed multi-context systems (mMCSs) can be turned
into a reactive formalism suitable for continuous reasoning in dynamic
environments. We extend mMCSs with (abstract) sensors and define the notion of
a run of the extended systems. We then show how typical problems arising in
online reasoning can be addressed: handling potentially inconsistent sensor
input, modeling intelligent forms of forgetting, selective integration of
knowledge, and controlling the reasoning effort spent by contexts, like setting
contexts to an idle mode. We also investigate the complexity of some important
related decision problems and discuss different design choices which are given
to the knowledge engineer.",2015-05-20,2015,2015-05,environment
Qsmodels: ASP Planning in Interactive Gaming Environment,"Qsmodels is a novel application of Answer Set Programming to interactive
gaming environment. We describe a software architecture by which the behavior
of a bot acting inside the Quake 3 Arena can be controlled by a planner. The
planner is written as an Answer Set Program and is interpreted by the Smodels
solver.",2015-05-27,2015,2015-05,environment
"A genetic algorithm for autonomous navigation in partially observable
  domain","The problem of autonomous navigation is one of the basic problems for
robotics. Although, in general, it may be challenging when an autonomous
vehicle is placed into partially observable domain. In this paper we consider
simplistic environment model and introduce a navigation algorithm based on
Learning Classifier System.",2015-07-27,2015,2015-07,environment
Framework for learning agents in quantum environments,"In this paper we provide a broad framework for describing learning agents in
general quantum environments. We analyze the types of classically specified
environments which allow for quantum enhancements in learning, by contrasting
environments to quantum oracles. We show that whether or not quantum
improvements are at all possible depends on the internal structure of the
quantum environment. If the environments are constructed and the internal
structure is appropriately chosen, or if the agent has limited capacities to
influence the internal states of the environment, we show that improvements in
learning times are possible in a broad range of scenarios. Such scenarios we
call luck-favoring settings. The case of constructed environments is
particularly relevant for the class of model-based learning agents, where our
results imply a near-generic improvement.",2015-07-30,2015,2015-07,environment
A Roadmap towards Machine Intelligence,"The development of intelligent machines is one of the biggest unsolved
challenges in computer science. In this paper, we propose some fundamental
properties these machines should have, focusing in particular on communication
and learning. We discuss a simple environment that could be used to
incrementally teach a machine the basics of natural-language-based
communication, as a prerequisite to more complex interaction with human users.
We also present some conjectures on the sort of algorithms the machine should
support in order to profitably learn from the environment.",2015-11-25,2015,2015-11,environment
"Extracting Biomolecular Interactions Using Semantic Parsing of
  Biomedical Text","We advance the state of the art in biomolecular interaction extraction with
three contributions: (i) We show that deep, Abstract Meaning Representations
(AMR) significantly improve the accuracy of a biomolecular interaction
extraction system when compared to a baseline that relies solely on surface-
and syntax-based features; (ii) In contrast with previous approaches that infer
relations on a sentence-by-sentence basis, we expand our framework to enable
consistent predictions over sets of sentences (documents); (iii) We further
modify and expand a graph kernel learning framework to enable concurrent
exploitation of automatically induced AMR (semantic) and dependency structure
(syntactic) representations. Our experiments show that our approach yields
interaction extraction systems that are more robust in environments where there
is a significant mismatch between training and test conditions.",2015-12-04,2015,2015-12,environment
"An Empirical Comparison of Neural Architectures for Reinforcement
  Learning in Partially Observable Environments","This paper explores the performance of fitted neural Q iteration for
reinforcement learning in several partially observable environments, using
three recurrent neural network architectures: Long Short-Term Memory, Gated
Recurrent Unit and MUT1, a recurrent neural architecture evolved from a pool of
several thousands candidate architectures. A variant of fitted Q iteration,
based on Advantage values instead of Q values, is also explored. The results
show that GRU performs significantly better than LSTM and MUT1 for most of the
problems considered, requiring less training episodes and less CPU time before
learning a very good policy. Advantage learning also tends to produce better
results.",2015-12-17,2015,2015-12,environment
Deep Exploration via Bootstrapped DQN,"Efficient exploration in complex environments remains a major challenge for
reinforcement learning. We propose bootstrapped DQN, a simple algorithm that
explores in a computationally and statistically efficient manner through use of
randomized value functions. Unlike dithering strategies such as epsilon-greedy
exploration, bootstrapped DQN carries out temporally-extended (or deep)
exploration; this can lead to exponentially faster learning. We demonstrate
these benefits in complex stochastic MDPs and in the large-scale Arcade
Learning Environment. Bootstrapped DQN substantially improves learning times
and performance across most Atari games.",2016-02-15,2016,2016-02,environment
Distributed Constraint Optimization Problems and Applications: A Survey,"The field of Multi-Agent System (MAS) is an active area of research within
Artificial Intelligence, with an increasingly important impact in industrial
and other real-world applications. Within a MAS, autonomous agents interact to
pursue personal interests and/or to achieve common objectives. Distributed
Constraint Optimization Problems (DCOPs) have emerged as one of the prominent
agent architectures to govern the agents' autonomous behavior, where both
algorithms and communication models are driven by the structure of the specific
problem. During the last decade, several extensions to the DCOP model have
enabled them to support MAS in complex, real-time, and uncertain environments.
This survey aims at providing an overview of the DCOP model, giving a
classification of its multiple extensions and addressing both resolution
methods and applications that find a natural mapping within each class of
DCOPs. The proposed classification suggests several future perspectives for
DCOP extensions, and identifies challenges in the design of efficient
resolution algorithms, possibly through the adaptation of strategies from
different areas.",2016-02-20,2016,2016-02,environment
Thompson Sampling is Asymptotically Optimal in General Environments,"We discuss a variant of Thompson sampling for nonparametric reinforcement
learning in a countable classes of general stochastic environments. These
environments can be non-Markov, non-ergodic, and partially observable. We show
that Thompson sampling learns the environment class in the sense that (1)
asymptotically its value converges to the optimal value in mean and (2) given a
recoverability assumption regret is sublinear.",2016-02-25,2016,2016-02,environment
Meta-learning within Projective Simulation,"Learning models of artificial intelligence can nowadays perform very well on
a large variety of tasks. However, in practice different task environments are
best handled by different learning models, rather than a single, universal,
approach. Most non-trivial models thus require the adjustment of several to
many learning parameters, which is often done on a case-by-case basis by an
external party. Meta-learning refers to the ability of an agent to autonomously
and dynamically adjust its own learning parameters, or meta-parameters. In this
work we show how projective simulation, a recently developed model of
artificial intelligence, can naturally be extended to account for meta-learning
in reinforcement learning settings. The projective simulation approach is based
on a random walk process over a network of clips. The suggested meta-learning
scheme builds upon the same design and employs clip networks to monitor the
agent's performance and to adjust its meta-parameters ""on the fly"". We
distinguish between ""reflexive adaptation"" and ""adaptation through learning"",
and show the utility of both approaches. In addition, a trade-off between
flexibility and learning-time is addressed. The extended model is examined on
three different kinds of reinforcement learning tasks, in which the agent has
different optimal values of the meta-parameters, and is shown to perform well,
reaching near-optimal to optimal success rates in all of them, without ever
needing to manually adjust any meta-parameter.",2016-02-25,2016,2016-02,environment
Category Theoretic Analysis of Photon-based Decision Making,"Decision making is a vital function in this age of machine learning and
artificial intelligence, yet its physical realization and theoretical
fundamentals are still not completely understood. In our former study, we
demonstrated that single-photons can be used to make decisions in uncertain,
dynamically changing environments. The two-armed bandit problem was
successfully solved using the dual probabilistic and particle attributes of
single photons. In this study, we present a category theoretic modeling and
analysis of single-photon-based decision making, including a quantitative
analysis that is in agreement with the experimental results. A category
theoretic model reveals the complex interdependencies of subject matter
entities in a simplified manner, even in dynamically changing environments. In
particular, the octahedral and braid structures in triangulated categories
provide a better understanding and quantitative metrics of the underlying
mechanisms of a single-photon decision maker. This study provides both insight
and a foundation for analyzing more complex and uncertain problems, to further
machine learning and artificial intelligence.",2016-02-26,2016,2016-02,environment
The AGI Containment Problem,"There is considerable uncertainty about what properties, capabilities and
motivations future AGIs will have. In some plausible scenarios, AGIs may pose
security risks arising from accidents and defects. In order to mitigate these
risks, prudent early AGI research teams will perform significant testing on
their creations before use. Unfortunately, if an AGI has human-level or greater
intelligence, testing itself may not be safe; some natural AGI goal systems
create emergent incentives for AGIs to tamper with their test environments,
make copies of themselves on the internet, or convince developers and operators
to do dangerous things. In this paper, we survey the AGI containment problem -
the question of how to build a container in which tests can be conducted safely
and reliably, even on AGIs with unknown motivations and capabilities that could
be dangerous. We identify requirements for AGI containers, available
mechanisms, and weaknesses that need to be addressed.",2016-04-02,2016,2016-04,environment
"A system of serial computation for classified rules prediction in
  non-regular ontology trees","Objects or structures that are regular take uniform dimensions. Based on the
concepts of regular models, our previous research work has developed a system
of a regular ontology that models learning structures in a multiagent system
for uniform pre-assessments in a learning environment. This regular ontology
has led to the modelling of a classified rules learning algorithm that predicts
the actual number of rules needed for inductive learning processes and decision
making in a multiagent system. But not all processes or models are regular.
Thus this paper presents a system of polynomial equation that can estimate and
predict the required number of rules of a non-regular ontology model given some
defined parameters.",2016-04-08,2016,2016-04,environment
"Why Artificial Intelligence Needs a Task Theory --- And What It Might
  Look Like","The concept of ""task"" is at the core of artificial intelligence (AI): Tasks
are used for training and evaluating AI systems, which are built in order to
perform and automatize tasks we deem useful. In other fields of engineering
theoretical foundations allow thorough evaluation of designs by methodical
manipulation of well understood parameters with a known role and importance;
this allows an aeronautics engineer, for instance, to systematically assess the
effects of wind speed on an airplane's performance and stability. No framework
exists in AI that allows this kind of methodical manipulation: Performance
results on the few tasks in current use (cf. board games, question-answering)
cannot be easily compared, however similar or different. The issue is even more
acute with respect to artificial *general* intelligence systems, which must
handle unanticipated tasks whose specifics cannot be known beforehand. A *task
theory* would enable addressing tasks at the *class* level, bypassing their
specifics, providing the appropriate formalization and classification of tasks,
environments, and their parameters, resulting in more rigorous ways of
measuring, comparing, and evaluating intelligent behavior. Even modest
improvements in this direction would surpass the current ad-hoc nature of
machine learning and AI evaluation. Here we discuss the main elements of the
argument for a task theory and present an outline of what it might look like
for physical tasks.",2016-04-15,2016,2016-04,environment
Semantic Reasoning for Context-aware Internet of Things Applications,"Advances in ICT are bringing into reality the vision of a large number of
uniquely identifiable, interconnected objects and things that gather
information from diverse physical environments and deliver the information to a
variety of innovative applications and services. These sensing objects and
things form the Internet of Things (IoT) that can improve energy and cost
efficiency and automation in many different industry fields such as
transportation and logistics, health care and manufacturing, and facilitate our
everyday lives as well. IoT applications rely on real-time context data and
allow sending information for driving the behaviors of users in intelligent
environments.",2016-04-28,2016,2016-04,environment
"Obstacle evasion using fuzzy logic in a sliding blades problem
  environment","This paper discusses obstacle avoidance using fuzzy logic and shortest path
algorithm. This paper also introduces the sliding blades problem and
illustrates how a drone can navigate itself through the swinging blade
obstacles while tracing a semi-optimal path and also maintaining constant
velocity",2016-05-03,2016,2016-05,environment
Learning Purposeful Behaviour in the Absence of Rewards,"Artificial intelligence is commonly defined as the ability to achieve goals
in the world. In the reinforcement learning framework, goals are encoded as
reward functions that guide agent behaviour, and the sum of observed rewards
provide a notion of progress. However, some domains have no such reward signal,
or have a reward signal so sparse as to appear absent. Without reward feedback,
agent behaviour is typically random, often dithering aimlessly and lacking
intentionality. In this paper we present an algorithm capable of learning
purposeful behaviour in the absence of rewards. The algorithm proceeds by
constructing temporally extended actions (options), through the identification
of purposes that are ""just out of reach"" of the agent's current behaviour.
These purposes establish intrinsic goals for the agent to learn, ultimately
resulting in a suite of behaviours that encourage the agent to visit different
parts of the state space. Moreover, the approach is particularly suited for
settings where rewards are very sparse, and such behaviours can help in the
exploration of the environment until reward is observed.",2016-05-25,2016,2016-05,environment
A PAC RL Algorithm for Episodic POMDPs,"Many interesting real world domains involve reinforcement learning (RL) in
partially observable environments. Efficient learning in such domains is
important, but existing sample complexity bounds for partially observable RL
are at least exponential in the episode length. We give, to our knowledge, the
first partially observable RL algorithm with a polynomial bound on the number
of episodes on which the algorithm may not achieve near-optimal performance.
Our algorithm is suitable for an important class of episodic POMDPs. Our
approach builds on recent advances in method of moments for latent variable
model estimation.",2016-05-25,2016,2016-05,environment
Death and Suicide in Universal Artificial Intelligence,"Reinforcement learning (RL) is a general paradigm for studying intelligent
behaviour, with applications ranging from artificial intelligence to psychology
and economics. AIXI is a universal solution to the RL problem; it can learn any
computable environment. A technical subtlety of AIXI is that it is defined
using a mixture over semimeasures that need not sum to 1, rather than over
proper probability measures. In this work we argue that the shortfall of a
semimeasure can naturally be interpreted as the agent's estimate of the
probability of its death. We formally define death for generally intelligent
agents like AIXI, and prove a number of related theorems about their behaviour.
Notable discoveries include that agent behaviour can change radically under
positive linear transformations of the reward signal (from suicidal to
dogmatically self-preserving), and that the agent's posterior belief that it
will survive increases over time.",2016-06-02,2016,2016-06,environment
"Situated Structure Learning of a Bayesian Logic Network for Commonsense
  Reasoning","This paper details the implementation of an algorithm for automatically
generating a high-level knowledge network to perform commonsense reasoning,
specifically with the application of robotic task repair. The network is
represented using a Bayesian Logic Network (BLN) (Jain, Waldherr, and Beetz
2009), which combines a set of directed relations between abstract concepts,
including IsA, AtLocation, HasProperty, and UsedFor, with a corresponding
probability distribution that models the uncertainty inherent in these
relations. Inference over this network enables reasoning over the abstract
concepts in order to perform appropriate object substitution or to locate
missing objects in the robot's environment. The structure of the network is
generated by combining information from two existing knowledge sources:
ConceptNet (Speer and Havasi 2012), and WordNet (Miller 1995). This is done in
a ""situated"" manner by only including information relevant a given context.
Results show that the generated network is able to accurately predict object
categories, locations, properties, and affordances in three different household
scenarios.",2016-07-01,2016,2016-07,environment
"Robust Natural Language Processing - Combining Reasoning, Cognitive
  Semantics and Construction Grammar for Spatial Language","We present a system for generating and understanding of dynamic and static
spatial relations in robotic interaction setups. Robots describe an environment
of moving blocks using English phrases that include spatial relations such as
""across"" and ""in front of"". We evaluate the system in robot-robot interactions
and show that the system can robustly deal with visual perception errors,
language omissions and ungrammatical utterances.",2016-07-20,2016,2016-07,environment
"Context Discovery for Model Learning in Partially Observable
  Environments","The ability to learn a model is essential for the success of autonomous
agents. Unfortunately, learning a model is difficult in partially observable
environments, where latent environmental factors influence what the agent
observes. In the absence of a supervisory training signal, autonomous agents
therefore require a mechanism to autonomously discover these environmental
factors, or sensorimotor contexts.
  This paper presents a method to discover sensorimotor contexts in partially
observable environments, by constructing a hierarchical transition model. The
method is evaluated in a simulation experiment, in which a robot learns that
different rooms are characterized by different objects that are found in them.",2016-08-02,2016,2016-08,environment
"Essentials of an Integrated Crowd Management Support System Based on
  Collective Artificial Intelligence","The simulation of the dynamical behavior of pedestrians and crowds in spatial
structures is a consolidated research and application context that still
presents challenges for researchers in different fields and disciplines.
Despite currently available commercial systems for this kind of simulation are
growingly employed by designers and planners for the evaluation of alternative
solutions, this class of systems is generally not integrated with existing
monitoring and control infrastructures, usually employed by crowd managers and
field operators for security reasons. This paper introduces the essentials and
the related computational frame- work of an Integrated Crowd Management Support
System based on a Collective Artificial Intelligence approach encompassing (i)
interfaces from and to monitored and controlled environments (respectively,
sen- sors and actuators), (ii) a set of software tools supporting the analysis
of pedestrians and crowd phenomena taking place in the environment to feed a
(iii) faster than real-time simulation of the plausible evolution of the
current situation in order to support forms of inference provid- ing decision
support to crowd managers, potentially directly controlling elements of the
environment (e.g. blocking turnstiles, escalators), com- municating orders to
operators on the field or trying to influence the pedestrians by means of
dynamic signage or audible messages.",2016-08-17,2016,2016-08,environment
Exploration Potential,"We introduce exploration potential, a quantity that measures how much a
reinforcement learning agent has explored its environment class. In contrast to
information gain, exploration potential takes the problem's reward structure
into account. This leads to an exploration criterion that is both necessary and
sufficient for asymptotic optimality (learning to act optimally across the
entire environment class). Our experiments in multi-armed bandits use
exploration potential to illustrate how different algorithms make the tradeoff
between exploration and exploitation.",2016-09-16,2016,2016-09,environment
The Option-Critic Architecture,"Temporal abstraction is key to scaling up learning and planning in
reinforcement learning. While planning with temporally extended actions is well
understood, creating such abstractions autonomously from data has remained
challenging. We tackle this problem in the framework of options [Sutton, Precup
& Singh, 1999; Precup, 2000]. We derive policy gradient theorems for options
and propose a new option-critic architecture capable of learning both the
internal policies and the termination conditions of options, in tandem with the
policy over options, and without the need to provide any additional rewards or
subgoals. Experimental results in both discrete and continuous environments
showcase the flexibility and efficiency of the framework.",2016-09-16,2016,2016-09,environment
Quantum-enhanced machine learning,"The emerging field of quantum machine learning has the potential to
substantially aid in the problems and scope of artificial intelligence. This is
only enhanced by recent successes in the field of classical machine learning.
In this work we propose an approach for the systematic treatment of machine
learning, from the perspective of quantum information. Our approach is general
and covers all three main branches of machine learning: supervised,
unsupervised and reinforcement learning. While quantum improvements in
supervised and unsupervised learning have been reported, reinforcement learning
has received much less attention. Within our approach, we tackle the problem of
quantum enhancements in reinforcement learning as well, and propose a
systematic scheme for providing improvements. As an example, we show that
quadratic improvements in learning efficiency, and exponential improvements in
performance over limited time periods, can be obtained for a broad class of
learning problems.",2016-10-26,2016,2016-10,environment
Playing SNES in the Retro Learning Environment,"Mastering a video game requires skill, tactics and strategy. While these
attributes may be acquired naturally by human players, teaching them to a
computer program is a far more challenging task. In recent years, extensive
research was carried out in the field of reinforcement learning and numerous
algorithms were introduced, aiming to learn how to perform human tasks such as
playing video games. As a result, the Arcade Learning Environment (ALE)
(Bellemare et al., 2013) has become a commonly used benchmark environment
allowing algorithms to train on various Atari 2600 games. In many games the
state-of-the-art algorithms outperform humans. In this paper we introduce a new
learning environment, the Retro Learning Environment --- RLE, that can run
games on the Super Nintendo Entertainment System (SNES), Sega Genesis and
several other gaming consoles. The environment is expandable, allowing for more
video games and consoles to be easily added to the environment, while
maintaining the same interface as ALE. Moreover, RLE is compatible with Python
and Torch. SNES games pose a significant challenge to current algorithms due to
their higher level of complexity and versatility.",2016-11-07,2016,2016-11,environment
Self-Correcting Models for Model-Based Reinforcement Learning,"When an agent cannot represent a perfectly accurate model of its
environment's dynamics, model-based reinforcement learning (MBRL) can fail
catastrophically. Planning involves composing the predictions of the model;
when flawed predictions are composed, even minor errors can compound and render
the model useless for planning. Hallucinated Replay (Talvitie 2014) trains the
model to ""correct"" itself when it produces errors, substantially improving MBRL
with flawed models. This paper theoretically analyzes this approach,
illuminates settings in which it is likely to be effective or ineffective, and
presents a novel error bound, showing that a model's ability to self-correct is
more tightly related to MBRL performance than one-step prediction error. These
results inspire an MBRL algorithm for deterministic MDPs with performance
guarantees that are robust to model class limitations.",2016-12-19,2016,2016-12,environment
"The formal-logical characterisation of lies, deception, and associated
  notions","Defining various dishonest notions in a formal way is a key step to enable
intelligent agents to act in untrustworthy environments. This review evaluates
the literature for this topic by looking at formal definitions based on modal
logic as well as other formal approaches. Criteria from philosophical
groundwork is used to assess the definitions for correctness and completeness.
The key contribution of this review is to show that only a few definitions
fully comply with this gold standard and to point out the missing steps towards
a successful application of these definitions in an actual agent environment.",2016-12-28,2016,2016-12,environment
Morphognosis: the shape of knowledge in space and time,"Artificial intelligence research to a great degree focuses on the brain and
behaviors that the brain generates. But the brain, an extremely complex
structure resulting from millions of years of evolution, can be viewed as a
solution to problems posed by an environment existing in space and time. The
environment generates signals that produce sensory events within an organism.
Building an internal spatial and temporal model of the environment allows an
organism to navigate and manipulate the environment. Higher intelligence might
be the ability to process information coming from a larger extent of
space-time. In keeping with nature's penchant for extending rather than
replacing, the purpose of the mammalian neocortex might then be to record
events from distant reaches of space and time and render them, as though yet
near and present, to the older, deeper brain whose instinctual roles have
changed little over eons. Here this notion is embodied in a model called
morphognosis (morpho = shape and gnosis = knowledge). Its basic structure is a
pyramid of event recordings called a morphognostic. At the apex of the pyramid
are the most recent and nearby events. Receding from the apex are less recent
and possibly more distant events. A morphognostic can thus be viewed as a
structure of progressively larger chunks of space-time knowledge. A set of
morphognostics forms long-term memories that are learned by exposure to the
environment. A cellular automaton is used as the platform to investigate the
morphognosis model, using a simulated organism that learns to forage in its
world for food, build a nest, and play the game of Pong.",2017-01-05,2017,2017-01,environment
"Efficient Transfer Learning Schemes for Personalized Language Modeling
  using Recurrent Neural Network","In this paper, we propose an efficient transfer leaning methods for training
a personalized language model using a recurrent neural network with long
short-term memory architecture. With our proposed fast transfer learning
schemes, a general language model is updated to a personalized language model
with a small amount of user data and a limited computing resource. These
methods are especially useful for a mobile device environment while the data is
prevented from transferring out of the device for privacy purposes. Through
experiments on dialogue data in a drama, it is verified that our transfer
learning methods have successfully generated the personalized language model,
whose output is more similar to the personal language style in both qualitative
and quantitative aspects.",2017-01-13,2017,2017-01,environment
Minimally Naturalistic Artificial Intelligence,"The rapid advancement of machine learning techniques has re-energized
research into general artificial intelligence. While the idea of
domain-agnostic meta-learning is appealing, this emerging field must come to
terms with its relationship to human cognition and the statistics and structure
of the tasks humans perform. The position of this article is that only by
aligning our agents' abilities and environments with those of humans do we
stand a chance at developing general artificial intelligence (GAI). A broad
reading of the famous 'No Free Lunch' theorem is that there is no universally
optimal inductive bias or, equivalently, bias-free learning is impossible. This
follows from the fact that there are an infinite number of ways to extrapolate
data, any of which might be the one used by the data generating environment; an
inductive bias prefers some of these extrapolations to others, which lowers
performance in environments using these adversarial extrapolations. We may
posit that the optimal GAI is the one that maximally exploits the statistics of
its environment to create its inductive bias; accepting the fact that this
agent is guaranteed to be extremely sub-optimal for some alternative
environments. This trade-off appears benign when thinking about the environment
as being the physical universe, as performance on any fictive universe is
obviously irrelevant. But, we should expect a sharper inductive bias if we
further constrain our environment. Indeed, we implicitly do so by defining GAI
in terms of accomplishing that humans consider useful. One common version of
this is need the for 'common-sense reasoning', which implicitly appeals to the
statistics of physical universe as perceived by humans.",2017-01-14,2017,2017-01,environment
"Beating the World's Best at Super Smash Bros. with Deep Reinforcement
  Learning","There has been a recent explosion in the capabilities of game-playing
artificial intelligence. Many classes of RL tasks, from Atari games to motor
control to board games, are now solvable by fairly generic algorithms, based on
deep learning, that learn to play from experience with minimal knowledge of the
specific domain of interest. In this work, we will investigate the performance
of these methods on Super Smash Bros. Melee (SSBM), a popular console fighting
game. The SSBM environment has complex dynamics and partial observability,
making it challenging for human and machine alike. The multi-player aspect
poses an additional challenge, as the vast majority of recent advances in RL
have focused on single-agent environments. Nonetheless, we will show that it is
possible to train agents that are competitive against and even surpass human
professionals, a new result for the multi-player video game setting.",2017-02-21,2017,2017-02,environment
Don't Fear the Reaper: Refuting Bostrom's Superintelligence Argument,"In recent years prominent intellectuals have raised ethical concerns about
the consequences of artificial intelligence. One concern is that an autonomous
agent might modify itself to become ""superintelligent"" and, in supremely
effective pursuit of poorly specified goals, destroy all of humanity. This
paper considers and rejects the possibility of this outcome. We argue that this
scenario depends on an agent's ability to rapidly improve its ability to
predict its environment through self-modification. Using a Bayesian model of a
reasoning agent, we show that there are important limitations to how an agent
may improve its predictive ability through self-modification alone. We conclude
that concern about this artificial intelligence outcome is misplaced and better
directed at policy questions around data access and storage.",2017-02-27,2017,2017-02,environment
What can you do with a rock? Affordance extraction via word embeddings,"Autonomous agents must often detect affordances: the set of behaviors enabled
by a situation. Affordance detection is particularly helpful in domains with
large action spaces, allowing the agent to prune its search space by avoiding
futile behaviors. This paper presents a method for affordance extraction via
word embeddings trained on a Wikipedia corpus. The resulting word vectors are
treated as a common knowledge database which can be queried using linear
algebra. We apply this method to a reinforcement learning agent in a text-only
environment and show that affordance-based action selection improves
performance most of the time. Our method increases the computational complexity
of each learning step but significantly reduces the total number of steps
needed. In addition, the agent's action selections begin to resemble those a
human would choose.",2017-03-09,2017,2017-03,environment
"Embodied Artificial Intelligence through Distributed Adaptive Control:
  An Integrated Framework","In this paper, we argue that the future of Artificial Intelligence research
resides in two keywords: integration and embodiment. We support this claim by
analyzing the recent advances of the field. Regarding integration, we note that
the most impactful recent contributions have been made possible through the
integration of recent Machine Learning methods (based in particular on Deep
Learning and Recurrent Neural Networks) with more traditional ones (e.g.
Monte-Carlo tree search, goal babbling exploration or addressable memory
systems). Regarding embodiment, we note that the traditional benchmark tasks
(e.g. visual classification or board games) are becoming obsolete as
state-of-the-art learning algorithms approach or even surpass human performance
in most of them, having recently encouraged the development of first-person 3D
game platforms embedding realistic physics. Building upon this analysis, we
first propose an embodied cognitive architecture integrating heterogenous
sub-fields of Artificial Intelligence into a unified framework. We demonstrate
the utility of our approach by showing how major contributions of the field can
be expressed within the proposed framework. We then claim that benchmarking
environments need to reproduce ecologically-valid conditions for bootstrapping
the acquisition of increasingly complex cognitive skills through the concept of
a cognitive arms race between embodied agents.",2017-04-05,2017,2017-04,environment
Environment-Independent Task Specifications via GLTL,"We propose a new task-specification language for Markov decision processes
that is designed to be an improvement over reward functions by being
environment independent. The language is a variant of Linear Temporal Logic
(LTL) that is extended to probabilistic specifications in a way that permits
approximations to be learned in finite time. We provide several small
environments that demonstrate the advantages of our geometric LTL (GLTL)
language and illustrate how it can be used to specify standard
reinforcement-learning tasks straightforwardly.",2017-04-14,2017,2017-04,environment
Beating Atari with Natural Language Guided Reinforcement Learning,"We introduce the first deep reinforcement learning agent that learns to beat
Atari games with the aid of natural language instructions. The agent uses a
multimodal embedding between environment observations and natural language to
self-monitor progress through a list of English instructions, granting itself
reward for completing instructions in addition to increasing the game score.
Our agent significantly outperforms Deep Q-Networks (DQNs), Asynchronous
Advantage Actor-Critic (A3C) agents, and the best agents posted to OpenAI Gym
on what is often considered the hardest Atari 2600 environment: Montezuma's
Revenge.",2017-04-18,2017,2017-04,environment
Ethical Artificial Intelligence - An Open Question,"Artificial Intelligence (AI) is an effective science which employs strong
enough approaches, methods, and techniques to solve unsolvable real world based
problems. Because of its unstoppable rise towards the future, there are also
some discussions about its ethics and safety. Shaping an AI friendly
environment for people and a people friendly environment for AI can be a
possible answer for finding a shared context of values for both humans and
robots. In this context, objective of this paper is to address the ethical
issues of AI and explore the moral dilemmas that arise from ethical algorithms,
from pre set or acquired values. In addition, the paper will also focus on the
subject of AI safety. As general, the paper will briefly analyze the concerns
and potential solutions to solving the ethical issues presented and increase
readers awareness on AI safety as another related research interest.",2017-05-16,2017,2017-05,environment
Experience enrichment based task independent reward model,"For most reinforcement learning approaches, the learning is performed by
maximizing an accumulative reward that is expectedly and manually defined for
specific tasks. However, in real world, rewards are emergent phenomena from the
complex interactions between agents and environments. In this paper, we propose
an implicit generic reward model for reinforcement learning. Unlike those
rewards that are manually defined for specific tasks, such implicit reward is
task independent. It only comes from the deviation from the agents' previous
experiences.",2017-05-21,2017,2017-05,environment
Universal Reinforcement Learning Algorithms: Survey and Experiments,"Many state-of-the-art reinforcement learning (RL) algorithms typically assume
that the environment is an ergodic Markov Decision Process (MDP). In contrast,
the field of universal reinforcement learning (URL) is concerned with
algorithms that make as few assumptions as possible about the environment. The
universal Bayesian agent AIXI and a family of related URL algorithms have been
developed in this setting. While numerous theoretical optimality results have
been proven for these agents, there has been no empirical investigation of
their behavior to date. We present a short and accessible survey of these URL
algorithms under a unified notation and framework, along with results of some
experiments that qualitatively illustrate some properties of the resulting
policies, and their relative performance on partially-observable gridworld
environments. We also present an open-source reference implementation of the
algorithms which we hope will facilitate further understanding of, and
experimentation with, these ideas.",2017-05-30,2017,2017-05,environment
"Dex: Incremental Learning for Complex Environments in Deep Reinforcement
  Learning","This paper introduces Dex, a reinforcement learning environment toolkit
specialized for training and evaluation of continual learning methods as well
as general reinforcement learning problems. We also present the novel continual
learning method of incremental learning, where a challenging environment is
solved using optimal weight initialization learned from first solving a similar
easier environment. We show that incremental learning can produce vastly
superior results than standard methods by providing a strong baseline method
across ten Dex environments. We finally develop a saliency method for
qualitative analysis of reinforcement learning, which shows the impact
incremental learning has on network attention.",2017-06-19,2017,2017-06,environment
An Online Development Environment for Answer Set Programming,"Recent progress in logic programming (e.g., the development of the Answer Set
Programming paradigm) has made it possible to teach it to general undergraduate
and even high school students. Given the limited exposure of these students to
computer science, the complexity of downloading, installing and using tools for
writing logic programs could be a major barrier for logic programming to reach
a much wider audience. We developed an online answer set programming
environment with a self contained file system and a simple interface, allowing
users to write logic programs and perform several tasks over the programs.",2017-06-20,2017,2017-06,environment
"A Useful Motif for Flexible Task Learning in an Embodied Two-Dimensional
  Visual Environment","Animals (especially humans) have an amazing ability to learn new tasks
quickly, and switch between them flexibly. How brains support this ability is
largely unknown, both neuroscientifically and algorithmically. One reasonable
supposition is that modules drawing on an underlying general-purpose sensory
representation are dynamically allocated on a per-task basis. Recent results
from neuroscience and artificial intelligence suggest the role of the general
purpose visual representation may be played by a deep convolutional neural
network, and give some clues how task modules based on such a representation
might be discovered and constructed. In this work, we investigate module
architectures in an embodied two-dimensional touchscreen environment, in which
an agent's learning must occur via interactions with an environment that emits
images and rewards, and accepts touches as input. This environment is designed
to capture the physical structure of the task environments that are commonly
deployed in visual neuroscience and psychophysics. We show that in this
context, very simple changes in the nonlinear activations used by such a module
can significantly influence how fast it is at learning visual tasks and how
suitable it is for switching to new tasks.",2017-06-22,2017,2017-06,environment
OPEB: Open Physical Environment Benchmark for Artificial Intelligence,"Artificial Intelligence methods to solve continuous- control tasks have made
significant progress in recent years. However, these algorithms have important
limitations and still need significant improvement to be used in industry and
real- world applications. This means that this area is still in an active
research phase. To involve a large number of research groups, standard
benchmarks are needed to evaluate and compare proposed algorithms. In this
paper, we propose a physical environment benchmark framework to facilitate
collaborative research in this area by enabling different research groups to
integrate their designed benchmarks in a unified cloud-based repository and
also share their actual implemented benchmarks via the cloud. We demonstrate
the proposed framework using an actual implementation of the classical
mountain-car example and present the results obtained using a Reinforcement
Learning algorithm.",2017-07-04,2017,2017-07,environment
"Maintaining cooperation in complex social dilemmas using deep
  reinforcement learning","Social dilemmas are situations where individuals face a temptation to
increase their payoffs at a cost to total welfare. Building artificially
intelligent agents that achieve good outcomes in these situations is important
because many real world interactions include a tension between selfish
interests and the welfare of others. We show how to modify modern reinforcement
learning methods to construct agents that act in ways that are simple to
understand, nice (begin by cooperating), provokable (try to avoid being
exploited), and forgiving (try to return to mutual cooperation). We show both
theoretically and experimentally that such agents can maintain cooperation in
Markov social dilemmas. Our construction does not require training methods
beyond a modification of self-play, thus if an environment is such that good
strategies can be constructed in the zero-sum case (eg. Atari) then we can
construct agents that solve social dilemmas in this environment.",2017-07-04,2017,2017-07,environment
"Learning to Design Games: Strategic Environments in Reinforcement
  Learning","In typical reinforcement learning (RL), the environment is assumed given and
the goal of the learning is to identify an optimal policy for the agent taking
actions through its interactions with the environment. In this paper, we extend
this setting by considering the environment is not given, but controllable and
learnable through its interaction with the agent at the same time. This
extension is motivated by environment design scenarios in the real-world,
including game design, shopping space design and traffic signal design.
Theoretically, we find a dual Markov decision process (MDP) w.r.t. the
environment to that w.r.t. the agent, and derive a policy gradient solution to
optimizing the parametrized environment. Furthermore, discontinuous
environments are addressed by a proposed general generative framework. Our
experiments on a Maze game design task show the effectiveness of the proposed
algorithms in generating diverse and challenging Mazes against various agent
settings.",2017-07-05,2017,2017-07,environment
Autoencoder-augmented Neuroevolution for Visual Doom Playing,"Neuroevolution has proven effective at many reinforcement learning tasks, but
does not seem to scale well to high-dimensional controller representations,
which are needed for tasks where the input is raw pixel data. We propose a
novel method where we train an autoencoder to create a comparatively
low-dimensional representation of the environment observation, and then use
CMA-ES to train neural network controllers acting on this input data. As the
behavior of the agent changes the nature of the input data, the autoencoder
training progresses throughout evolution. We test this method in the VizDoom
environment built on the classic FPS Doom, where it performs well on a
health-pack gathering task.",2017-07-12,2017,2017-07,environment
"Applying MAPP Algorithm for Cooperative Path Finding in Urban
  Environments","The paper considers the problem of planning a set of non-conflict
trajectories for the coalition of intelligent agents (mobile robots). Two
divergent approaches, e.g. centralized and decentralized, are surveyed and
analyzed. Decentralized planner - MAPP is described and applied to the task of
finding trajectories for dozens UAVs performing nap-of-the-earth flight in
urban environments. Results of the experimental studies provide an opportunity
to claim that MAPP is a highly efficient planner for solving considered types
of tasks.",2017-07-20,2017,2017-07,environment
"Investigating Reinforcement Learning Agents for Continuous State Space
  Environments","Given an environment with continuous state spaces and discrete actions, we
investigate using a Double Deep Q-learning Reinforcement Agent to find optimal
policies using the LunarLander-v2 OpenAI gym environment.",2017-08-08,2017,2017-08,environment
What Automated Planning can do for Business Process Management,"Business Process Management (BPM) is a central element of today
organizations. Despite over the years its main focus has been the support of
processes in highly controlled domains, nowadays many domains of interest to
the BPM community are characterized by ever-changing requirements,
unpredictable environments and increasing amounts of data that influence the
execution of process instances. Under such dynamic conditions, BPM systems must
increase their level of automation to provide the reactivity and flexibility
necessary for process management. On the other hand, the Artificial
Intelligence (AI) community has concentrated its efforts on investigating
dynamic domains that involve active control of computational entities and
physical devices (e.g., robots, software agents, etc.). In this context,
Automated Planning, which is one of the oldest areas in AI, is conceived as a
model-based approach to synthesize autonomous behaviours in automated way from
a model. In this paper, we discuss how automated planning techniques can be
leveraged to enable new levels of automation and support for business
processing, and we show some concrete examples of their successful application
to the different stages of the BPM life cycle.",2017-09-29,2017,2017-09,environment
"Cooperative Automated Vehicles: a Review of Opportunities and Challenges
  in Socially Intelligent Vehicles Beyond Networking","The connected automated vehicle has been often touted as a technology that
will become pervasive in society in the near future. One can view an automated
vehicle as having Artificial Intelligence (AI) capabilities, being able to
self-drive, sense its surroundings, recognise objects in its vicinity, and
perform reasoning and decision-making.
  Rather than being stand alone, we examine the need for automated vehicles to
cooperate and interact within their socio-cyber-physical environments,
including the problems cooperation will solve, but also the issues and
challenges. We review current work in cooperation for automated vehicles, based
on selected examples from the literature. We conclude noting the need for the
ability to behave cooperatively as a form of social-AI capability for automated
vehicles, beyond sensing the immediate environment and beyond the underlying
networking technology.",2017-10-02,2017,2017-10,environment
"Feasibility Study: Moving Non-Homogeneous Teams in Congested Video Game
  Environments","Multi-agent path finding (MAPF) is a well-studied problem in artificial
intelligence, where one needs to find collision-free paths for agents with
given start and goal locations. In video games, agents of different types often
form teams. In this paper, we demonstrate the usefulness of MAPF algorithms
from artificial intelligence for moving such non-homogeneous teams in congested
video game environments.",2017-10-04,2017,2017-10,environment
Emergent Complexity via Multi-Agent Competition,"Reinforcement learning algorithms can train agents that solve problems in
complex, interesting environments. Normally, the complexity of the trained
agent is closely related to the complexity of the environment. This suggests
that a highly capable agent requires a complex environment for training. In
this paper, we point out that a competitive multi-agent environment trained
with self-play can produce behaviors that are far more complex than the
environment itself. We also point out that such environments come with a
natural curriculum, because for any skill level, an environment full of agents
of this level will have the right level of difficulty. This work introduces
several competitive multi-agent environments where agents compete in a 3D world
with simulated physics. The trained agents learn a wide variety of complex and
interesting skills, even though the environment themselves are relatively
simple. The skills include behaviors such as running, blocking, ducking,
tackling, fooling opponents, kicking, and defending using both arms and legs. A
highlight of the learned behaviors can be found here: https://goo.gl/eR7fbX",2017-10-10,2017,2017-10,environment
"User Environment Detection with Acoustic Sensors Embedded on Mobile
  Devices for the Recognition of Activities of Daily Living","The detection of the environment where user is located, is of extreme use for
the identification of Activities of Daily Living (ADL). ADL can be identified
by use of the sensors available in many off-the-shelf mobile devices, including
magnetic and motion, and the environment can be also identified using acoustic
sensors. The study presented in this paper is divided in two parts: firstly, we
discuss the recognition of the environment using acoustic sensors (i.e.,
microphone), and secondly, we fuse this information with motion and magnetic
sensors (i.e., motion and magnetic sensors) for the recognition of standing
activities of daily living. The recognition of the environments and the ADL are
performed using pattern recognition techniques, in order to develop a system
that includes data acquisition, data processing, data fusion, and artificial
intelligence methods. The artificial intelligence methods explored in this
study are composed by different types of Artificial Neural Networks (ANN),
comparing the different types of ANN and selecting the best methods to
implement in the different stages of the system developed. Conclusions point to
the use of Deep Neural Networks (DNN) with normalized data for the
identification of ADL with 85.89% of accuracy, the use of Feedforward neural
networks with non-normalized data for the identification of the environments
with 86.50% of accuracy, and the use of DNN with normalized data for the
identification of standing activities with 100% of accuracy.",2017-10-31,2017,2017-10,environment
Teaching a Machine to Read Maps with Deep Reinforcement Learning,"The ability to use a 2D map to navigate a complex 3D environment is quite
remarkable, and even difficult for many humans. Localization and navigation is
also an important problem in domains such as robotics, and has recently become
a focus of the deep reinforcement learning community. In this paper we teach a
reinforcement learning agent to read a map in order to find the shortest way
out of a random maze it has never seen before. Our system combines several
state-of-the-art methods such as A3C and incorporates novel elements such as a
recurrent localization cell. Our agent learns to localize itself based on 3D
first person images and an approximate orientation angle. The agent generalizes
well to bigger mazes, showing that it learned useful localization and
navigation capabilities.",2017-11-20,2017,2017-11,environment
"Interactive Robot Learning of Gestures, Language and Affordances","A growing field in robotics and Artificial Intelligence (AI) research is
human-robot collaboration, whose target is to enable effective teamwork between
humans and robots. However, in many situations human teams are still superior
to human-robot teams, primarily because human teams can easily agree on a
common goal with language, and the individual members observe each other
effectively, leveraging their shared motor repertoire and sensorimotor
resources. This paper shows that for cognitive robots it is possible, and
indeed fruitful, to combine knowledge acquired from interacting with elements
of the environment (affordance exploration) with the probabilistic observation
of another agent's actions.
  We propose a model that unites (i) learning robot affordances and word
descriptions with (ii) statistical recognition of human gestures with vision
sensors. We discuss theoretical motivations, possible implementations, and we
show initial results which highlight that, after having acquired knowledge of
its surrounding environment, a humanoid robot can generalize this knowledge to
the case when it observes another agent (human partner) performing the same
motor actions previously executed during training.",2017-11-24,2017,2017-11,environment
"Simulated Autonomous Driving on Realistic Road Networks using Deep
  Reinforcement Learning","Using Deep Reinforcement Learning (DRL) can be a promising approach to handle
various tasks in the field of (simulated) autonomous driving. However, recent
publications mainly consider learning in unusual driving environments. This
paper presents Driving School for Autonomous Agents (DSA^2), a software for
validating DRL algorithms in more usual driving environments based on
artificial and realistic road networks. We also present the results of applying
DSA^2 for handling the task of driving on a straight road while regulating the
velocity of one vehicle according to different speed limits.",2017-12-12,2017,2017-12,environment
Towards a Deep Reinforcement Learning Approach for Tower Line Wars,"There have been numerous breakthroughs with reinforcement learning in the
recent years, perhaps most notably on Deep Reinforcement Learning successfully
playing and winning relatively advanced computer games. There is undoubtedly an
anticipation that Deep Reinforcement Learning will play a major role when the
first AI masters the complicated game plays needed to beat a professional
Real-Time Strategy game player. For this to be possible, there needs to be a
game environment that targets and fosters AI research, and specifically Deep
Reinforcement Learning. Some game environments already exist, however, these
are either overly simplistic such as Atari 2600 or complex such as Starcraft II
from Blizzard Entertainment. We propose a game environment in between Atari
2600 and Starcraft II, particularly targeting Deep Reinforcement Learning
algorithm research. The environment is a variant of Tower Line Wars from
Warcraft III, Blizzard Entertainment. Further, as a proof of concept that the
environment can harbor Deep Reinforcement algorithms, we propose and apply a
Deep Q-Reinforcement architecture. The architecture simplifies the state space
so that it is applicable to Q-learning, and in turn improves performance
compared to current state-of-the-art methods. Our experiments show that the
proposed architecture can learn to play the environment well, and score 33%
better than standard Deep Q-learning which in turn proves the usefulness of the
game environment.",2017-12-17,2017,2017-12,environment
Null Dynamical State Models of Human Cognitive Dysfunction,"The hard problem in artificial intelligence asks how the shuffling of
syntactical symbols in a program can lead to systems which experience semantics
and qualia. We address this question in three stages. First, we introduce a new
class of human semantic symbols which appears when unexpected and drastic
environmental change causes humans to become surprised, confused, uncertain,
and in extreme cases, unresponsive, passive and dysfunctional. For this class
of symbols, pre-learned programs become inoperative so these syntactical
programs cannot be the source of experienced qualia. Second, we model the
dysfunctional human response to a radically changed environment as being the
natural response of any learning machine facing novel inputs from well outside
its previous training set. In this situation, learning machines are unable to
extract information from their input and will typically enter a dynamical state
characterized by null outputs and a lack of response. This state immediately
predicts and explains the characteristics of the semantic experiences of humans
in similar circumstances. In the third stage, we consider learning machines
trained to implement multiple functions in simple sequential programs using
environmental data to specify subroutine names, control flow instructions,
memory calls, and so on. Drastic change in any of these environmental inputs
can again lead to inoperative programs. By examining changes specific to people
or locations we can model human cognitive symbols featuring these dependencies,
such as attachment and grief. Our approach links known dynamical machines
states with human qualia and thus offers new insight into the hard problem of
artificial intelligence.",2017-12-25,2017,2017-12,environment
SenseNet: 3D Objects Database and Tactile Simulator,"The majority of artificial intelligence research, as it relates from which to
biological senses has been focused on vision. The recent explosion of machine
learning and in particular, dee p learning, can be partially attributed to the
release of high quality data sets for algorithm s from which to model the world
on. Thus, most of these datasets are comprised of images. We believe that
focusing on sensorimotor systems and tactile feedback will create algorithms
that better mimic human intelligence. Here we present SenseNet: a collection of
tactile simulators and a large scale dataset of 3D objects for manipulation.
SenseNet was created for the purpose of researching and training Artificial
Intelligences (AIs) to interact with the environment via sensorimotor neural
systems and tactile feedback. We aim to accelerate that same explosion in image
processing, but for the domain of tactile feedback and sensorimotor research.
We hope that SenseNet can offer researchers in both the machine learning and
computational neuroscience communities brand new opportunities and avenues to
explore.",2017-12-31,2017,2017-12,environment
"Counterfactual equivalence for POMDPs, and underlying deterministic
  environments","Partially Observable Markov Decision Processes (POMDPs) are rich environments
often used in machine learning. But the issue of information and causal
structures in POMDPs has been relatively little studied. This paper presents
the concepts of equivalent and counterfactually equivalent POMDPs, where agents
cannot distinguish which environment they are in though any observations and
actions. It shows that any POMDP is counterfactually equivalent, for any finite
number of turns, to a deterministic POMDP with all uncertainty concentrated
into the initial state. This allows a better understanding of POMDP
uncertainty, information, and learning.",2018-01-11,2018,2018-01,environment
CHALET: Cornell House Agent Learning Environment,"We present CHALET, a 3D house simulator with support for navigation and
manipulation. CHALET includes 58 rooms and 10 house configuration, and allows
to easily create new house and room layouts. CHALET supports a range of common
household activities, including moving objects, toggling appliances, and
placing objects inside closeable containers. The environment and actions
available are designed to create a challenging domain to train and evaluate
autonomous agents, including for tasks that combine language, vision, and
planning in a dynamic environment.",2018-01-23,2018,2018-01,environment
Deep Reinforcement Learning using Capsules in Advanced Game Environments,"Reinforcement Learning (RL) is a research area that has blossomed
tremendously in recent years and has shown remarkable potential for artificial
intelligence based opponents in computer games. This success is primarily due
to vast capabilities of Convolutional Neural Networks (ConvNet), enabling
algorithms to extract useful information from noisy environments. Capsule
Network (CapsNet) is a recent introduction to the Deep Learning algorithm group
and has only barely begun to be explored. The network is an architecture for
image classification, with superior performance for classification of the MNIST
dataset. CapsNets have not been explored beyond image classification.
  This thesis introduces the use of CapsNet for Q-Learning based game
algorithms. To successfully apply CapsNet in advanced game play, three main
contributions follow. First, the introduction of four new game environments as
frameworks for RL research with increasing complexity, namely Flash RL, Deep
Line Wars, Deep RTS, and Deep Maze. These environments fill the gap between
relatively simple and more complex game environments available for RL research
and are in the thesis used to test and explore the CapsNet behavior.
  Second, the thesis introduces a generative modeling approach to produce
artificial training data for use in Deep Learning models including CapsNets. We
empirically show that conditional generative modeling can successfully generate
game data of sufficient quality to train a Deep Q-Network well.
  Third, we show that CapsNet is a reliable architecture for Deep Q-Learning
based algorithms for game AI. A capsule is a group of neurons that determine
the presence of objects in the data and is in the literature shown to increase
the robustness of training and predictions while lowering the amount training
data needed. It should, therefore, be ideally suited for game plays.",2018-01-29,2018,2018-01,environment
"Narrow Artificial Intelligence with Machine Learning for Real-Time
  Estimation of a Mobile Agents Location Using Hidden Markov Models","We propose to use a supervised machine learning technique to track the
location of a mobile agent in real time. Hidden Markov Models are used to build
artificial intelligence that estimates the unknown position of a mobile target
moving in a defined environment. This narrow artificial intelligence performs
two distinct tasks. First, it provides real-time estimation of the mobile
agent's position using the forward algorithm. Second, it uses the Baum-Welch
algorithm as a statistical learning tool to gain knowledge of the mobile
target. Finally, an experimental environment is proposed, namely a video game
that we use to test our artificial intelligence. We present statistical and
graphical results to illustrate the efficiency of our method.",2018-02-09,2018,2018-02,environment
"Some Considerations on Learning to Explore via Meta-Reinforcement
  Learning","We consider the problem of exploration in meta reinforcement learning. Two
new meta reinforcement learning algorithms are suggested: E-MAML and
E-$\text{RL}^2$. Results are presented on a novel environment we call `Krazy
World' and a set of maze environments. We show E-MAML and E-$\text{RL}^2$
deliver better performance on tasks where exploration is important.",2018-03-03,2018,2018-03,environment
A Multi-Objective Deep Reinforcement Learning Framework,"This paper introduces a new scalable multi-objective deep reinforcement
learning (MODRL) framework based on deep Q-networks. We develop a
high-performance MODRL framework that supports both single-policy and
multi-policy strategies, as well as both linear and non-linear approaches to
action selection. The experimental results on two benchmark problems
(two-objective deep sea treasure environment and three-objective Mountain Car
problem) indicate that the proposed framework is able to find the
Pareto-optimal solutions effectively. The proposed framework is generic and
highly modularized, which allows the integration of different deep
reinforcement learning algorithms in different complex problem domains. This
therefore overcomes many disadvantages involved with standard multi-objective
reinforcement learning methods in the current literature. The proposed
framework acts as a testbed platform that accelerates the development of MODRL
for solving increasingly complicated multi-objective problems.",2018-03-08,2018,2018-03,environment
"Challenges and Characteristics of Intelligent Autonomy for Internet of
  Battle Things in Highly Adversarial Environments","Numerous, artificially intelligent, networked things will populate the
battlefield of the future, operating in close collaboration with human
warfighters, and fighting as teams in highly adversarial environments. This
paper explores the characteristics, capabilities and intelligence required of
such a network of intelligent things and humans - Internet of Battle Things
(IOBT). It will experience unique challenges that are not yet well addressed by
the current generation of AI and machine learning.",2018-03-20,2018,2018-03,environment
"Learning State Representations for Query Optimization with Deep
  Reinforcement Learning","Deep reinforcement learning is quickly changing the field of artificial
intelligence. These models are able to capture a high level understanding of
their environment, enabling them to learn difficult dynamic tasks in a variety
of domains. In the database field, query optimization remains a difficult
problem. Our goal in this work is to explore the capabilities of deep
reinforcement learning in the context of query optimization. At each state, we
build queries incrementally and encode properties of subqueries through a
learned representation. The challenge here lies in the formation of the state
transition function, which defines how the current subquery state combines with
the next query operation (action) to yield the next state. As a first step in
this direction, we focus the state representation problem and the formation of
the state transition function. We describe our approach and show preliminary
results. We further discuss how we can use the state representation to improve
query optimization using reinforcement learning.",2018-03-22,2018,2018-03,environment
On Chatbots Exhibiting Goal-Directed Autonomy in Dynamic Environments,"Conversation interfaces (CIs), or chatbots, are a popular form of intelligent
agents that engage humans in task-oriented or informal conversation. In this
position paper and demonstration, we argue that chatbots working in dynamic
environments, like with sensor data, can not only serve as a promising platform
to research issues at the intersection of learning, reasoning, representation
and execution for goal-directed autonomy; but also handle non-trivial business
applications. We explore the underlying issues in the context of Water Advisor,
a preliminary multi-modal conversation system that can access and explain water
quality data.",2018-03-26,2018,2018-03,environment
"Scalable photonic reinforcement learning by time-division multiplexing
  of laser chaos","Reinforcement learning involves decision making in dynamic and uncertain
environments and constitutes a crucial element of artificial intelligence. In
our previous work, we experimentally demonstrated that the ultrafast chaotic
oscillatory dynamics of lasers can be used to solve the two-armed bandit
problem efficiently, which requires decision making concerning a class of
difficult trade-offs called the exploration-exploitation dilemma. However, only
two selections were employed in that research; thus, the scalability of the
laser-chaos-based reinforcement learning should be clarified. In this study, we
demonstrated a scalable, pipelined principle of resolving the multi-armed
bandit problem by introducing time-division multiplexing of chaotically
oscillated ultrafast time-series. The experimental demonstrations in which
bandit problems with up to 64 arms were successfully solved are presented in
this report. Detailed analyses are also provided that include performance
comparisons among laser chaos signals generated in different physical
conditions, which coincide with the diffusivity inherent in the time series.
This study paves the way for ultrafast reinforcement learning by taking
advantage of the ultrahigh bandwidths of light wave and practical enabling
technologies.",2018-03-26,2018,2018-03,environment
Learning to Navigate in Cities Without a Map,"Navigating through unstructured environments is a basic capability of
intelligent creatures, and thus is of fundamental interest in the study and
development of artificial intelligence. Long-range navigation is a complex
cognitive task that relies on developing an internal representation of space,
grounded by recognisable landmarks and robust visual processing, that can
simultaneously support continuous self-localisation (""I am here"") and a
representation of the goal (""I am going there""). Building upon recent research
that applies deep reinforcement learning to maze navigation problems, we
present an end-to-end deep reinforcement learning approach that can be applied
on a city scale. Recognising that successful navigation relies on integration
of general policies with locale-specific knowledge, we propose a dual pathway
architecture that allows locale-specific features to be encapsulated, while
still enabling transfer to multiple cities. We present an interactive
navigation environment that uses Google StreetView for its photographic content
and worldwide coverage, and demonstrate that our learning method allows agents
to learn to navigate multiple cities and to traverse to target destinations
that may be kilometres away. The project webpage http://streetlearn.cc contains
a video summarising our research and showing the trained agent in diverse city
environments and on the transfer task, the form to request the StreetLearn
dataset and links to further resources. The StreetLearn environment code is
available at https://github.com/deepmind/streetlearn",2018-03-31,2018,2018-03,environment
Artificial Intelligence and its Role in Near Future,"AI technology has a long history which is actively and constantly changing
and growing. It focuses on intelligent agents, which contain devices that
perceive the environment and based on which takes actions in order to maximize
goal success chances. In this paper, we will explain the modern AI basics and
various representative applications of AI. In the context of the modern
digitalized world, AI is the property of machines, computer programs, and
systems to perform the intellectual and creative functions of a person,
independently find ways to solve problems, be able to draw conclusions and make
decisions. Most artificial intelligence systems have the ability to learn,
which allows people to improve their performance over time. The recent research
on AI tools, including machine learning, deep learning and predictive analysis
intended toward increasing the planning, learning, reasoning, thinking and
action taking ability. Based on which, the proposed research intends towards
exploring on how the human intelligence differs from the artificial
intelligence. Moreover, we critically analyze what AI of today is capable of
doing, why it still cannot reach human intelligence and what are the open
challenges existing in front of AI to reach and outperform human level of
intelligence. Furthermore, it will explore the future predictions for
artificial intelligence and based on which potential solution will be
recommended to solve it within next decades.",2018-04-01,2018,2018-04,environment
"The structure of evolved representations across different substrates for
  artificial intelligence","Artificial neural networks (ANNs), while exceptionally useful for
classification, are vulnerable to misdirection. Small amounts of noise can
significantly affect their ability to correctly complete a task. Instead of
generalizing concepts, ANNs seem to focus on surface statistical regularities
in a given task. Here we compare how recurrent artificial neural networks, long
short-term memory units, and Markov Brains sense and remember their
environments. We show that information in Markov Brains is localized and
sparsely distributed, while the other neural network substrates ""smear""
information about the environment across all nodes, which makes them vulnerable
to noise.",2018-04-05,2018,2018-04,environment
Terrain RL Simulator,"We provide $89$ challenging simulation environments that range in difficulty.
The difficulty of solving a task is linked not only to the number of dimensions
in the action space but also to the size and shape of the distribution of
configurations the agent experiences. Therefore, we are releasing a number of
simulation environments that include randomly generated terrain. The library
also provides simple mechanisms to create new environments with different agent
morphologies and the option to modify the distribution of generated terrain. We
believe using these and other more complex simulations will help push the field
closer to creating human-level intelligence.",2018-04-17,2018,2018-04,environment
"The Intelligent ICU Pilot Study: Using Artificial Intelligence
  Technology for Autonomous Patient Monitoring","Currently, many critical care indices are repetitively assessed and recorded
by overburdened nurses, e.g. physical function or facial pain expressions of
nonverbal patients. In addition, many essential information on patients and
their environment are not captured at all, or are captured in a non-granular
manner, e.g. sleep disturbance factors such as bright light, loud background
noise, or excessive visitations. In this pilot study, we examined the
feasibility of using pervasive sensing technology and artificial intelligence
for autonomous and granular monitoring of critically ill patients and their
environment in the Intensive Care Unit (ICU). As an exemplar prevalent
condition, we also characterized delirious and non-delirious patients and their
environment. We used wearable sensors, light and sound sensors, and a
high-resolution camera to collected data on patients and their environment. We
analyzed collected data using deep learning and statistical analysis. Our
system performed face detection, face recognition, facial action unit
detection, head pose detection, facial expression recognition, posture
recognition, actigraphy analysis, sound pressure and light level detection, and
visitation frequency detection. We were able to detect patient's face (Mean
average precision (mAP)=0.94), recognize patient's face (mAP=0.80), and their
postures (F1=0.94). We also found that all facial expressions, 11 activity
features, visitation frequency during the day, visitation frequency during the
night, light levels, and sound pressure levels during the night were
significantly different between delirious and non-delirious patients
(p-value<0.05). In summary, we showed that granular and autonomous monitoring
of critically ill patients and their environment is feasible and can be used
for characterizing critical care conditions and related environment factors.",2018-04-25,2018,2018-04,environment
"Synthesizing Efficient Solutions for Patrolling Problems in the Internet
  Environment","We propose an algorithm for constructing efficient patrolling strategies in
the Internet environment, where the protected targets are nodes connected to
the network and the patrollers are software agents capable of
detecting/preventing undesirable activities on the nodes. The algorithm is
based on a novel compositional principle designed for a special class of
strategies, and it can quickly construct (sub)optimal solutions even if the
number of targets reaches hundreds of millions.",2018-05-08,2018,2018-05,environment
Artificial Intelligence Inspired Self-Deployment of Wireless Networks,"In this paper, we propose a self-deployment approach for finding the optimal
placement of extenders in which both the wireless back-haul and front-haul
throughput of the extender are optimized. We present an artificial intelligence
(AI) case based reasoning (CBR) framework that enables autonomous
self-deployment in which the network can learn the environment by means of
sensing and perception. New actions, i.e. extender positions, are created by
problem-specific optimization and semi-supervised learning algorithms that
balance exploration and exploitation of the search space. An IEEE 802.11
standard compliant simulations are performed to evaluate the framework on a
large scale and compare its performance against existing conventional coverage
maximization approaches. Experimental evaluation is also performed in an
enterprise environment to demonstrate the competence of the proposed
AI-framework in perceiving such a dense scenario and reason the extender
deployment that achieves user quality of service (QoS). Throughput fairness and
ubiquitous QoS satisfaction are achieved which provide a leap to apply
AI-driven self-deployment in wireless networks.",2018-05-16,2018,2018-05,environment
"A Virtual Environment with Multi-Robot Navigation, Analytics, and
  Decision Support for Critical Incident Investigation","Accidents and attacks that involve chemical, biological, radiological/nuclear
or explosive (CBRNE) substances are rare, but can be of high consequence. Since
the investigation of such events is not anybody's routine work, a range of AI
techniques can reduce investigators' cognitive load and support
decision-making, including: planning the assessment of the scene; ongoing
evaluation and updating of risks; control of autonomous vehicles for collecting
images and sensor data; reviewing images/videos for items of interest;
identification of anomalies; and retrieval of relevant documentation. Because
of the rare and high-risk nature of these events, realistic simulations can
support the development and evaluation of AI-based tools. We have developed
realistic models of CBRNE scenarios and implemented an initial set of tools.",2018-06-12,2018,2018-06,environment
"A unified strategy for implementing curiosity and empowerment driven
  reinforcement learning","Although there are many approaches to implement intrinsically motivated
artificial agents, the combined usage of multiple intrinsic drives remains
still a relatively unexplored research area. Specifically, we hypothesize that
a mechanism capable of quantifying and controlling the evolution of the
information flow between the agent and the environment could be the fundamental
component for implementing a higher degree of autonomy into artificial
intelligent agents. This paper propose a unified strategy for implementing two
semantically orthogonal intrinsic motivations: curiosity and empowerment.
Curiosity reward informs the agent about the relevance of a recent agent
action, whereas empowerment is implemented as the opposite information flow
from the agent to the environment that quantifies the agent's potential of
controlling its own future. We show that an additional homeostatic drive is
derived from the curiosity reward, which generalizes and enhances the
information gain of a classical curious/heterostatic reinforcement learning
agent. We show how a shared internal model by curiosity and empowerment
facilitates a more efficient training of the empowerment function. Finally, we
discuss future directions for further leveraging the interplay between these
two intrinsic rewards.",2018-06-18,2018,2018-06,environment
"The Temporal Singularity: time-accelerated simulated civilizations and
  their implications","Provided significant future progress in artificial intelligence and
computing, it may ultimately be possible to create multiple Artificial General
Intelligences (AGIs), and possibly entire societies living within simulated
environments. In that case, it should be possible to improve the problem
solving capabilities of the system by increasing the speed of the simulation.
If a minimal simulation with sufficient capabilities is created, it might
manage to increase its own speed by accelerating progress in science and
technology, in a way similar to the Technological Singularity. This may
ultimately lead to large simulated civilizations unfolding at extreme temporal
speedups, achieving what from the outside would look like a Temporal
Singularity. Here we discuss the feasibility of the minimal simulation and the
potential advantages, dangers, and connection to the Fermi paradox of the
Temporal Singularity. The medium-term importance of the topic derives from the
amount of computational power required to start the process, which could be
available within the next decades, making the Temporal Singularity
theoretically possible before the end of the century.",2018-06-22,2018,2018-06,environment
Autonomous Wireless Systems with Artificial Intelligence,"This paper discusses technology and opportunities to embrace artificial
intelligence (AI) in the design of autonomous wireless systems. We aim to
provide readers with motivation and general AI methodology of autonomous agents
in the context of self-organization in real time by unifying knowledge
management with sensing, reasoning and active learning. We highlight
differences between training-based methods for matching problems and
training-free methods for environment-specific problems. Finally, we
conceptually introduce the functions of an autonomous agent with knowledge
management.",2018-06-27,2018,2018-06,environment
Modeling Friends and Foes,"How can one detect friendly and adversarial behavior from raw data? Detecting
whether an environment is a friend, a foe, or anything in between, remains a
poorly understood yet desirable ability for safe and robust agents. This paper
proposes a definition of these environmental ""attitudes"" based on an
characterization of the environment's ability to react to the agent's private
strategy. We define an objective function for a one-shot game that allows
deriving the environment's probability distribution under friendly and
adversarial assumptions alongside the agent's optimal strategy. Furthermore, we
present an algorithm to compute these equilibrium strategies, and show
experimentally that both friendly and adversarial environments possess
non-trivial optimal strategies.",2018-06-30,2018,2018-06,environment
Combinatorial Bandits for Incentivizing Agents with Dynamic Preferences,"The design of personalized incentives or recommendations to improve user
engagement is gaining prominence as digital platform providers continually
emerge. We propose a multi-armed bandit framework for matching incentives to
users, whose preferences are unknown a priori and evolving dynamically in time,
in a resource constrained environment. We design an algorithm that combines
ideas from three distinct domains: (i) a greedy matching paradigm, (ii) the
upper confidence bound algorithm (UCB) for bandits, and (iii) mixing times from
the theory of Markov chains. For this algorithm, we provide theoretical bounds
on the regret and demonstrate its performance via both synthetic and realistic
(matching supply and demand in a bike-sharing platform) examples.",2018-07-06,2018,2018-07,environment
"An agent-based model of an endangered population of the Arctic fox from
  Mednyi Island","Artificial Intelligence techniques such as agent-based modeling and
probabilistic reasoning have shown promise in modeling complex biological
systems and testing ecological hypotheses through simulation. We develop an
agent-based model of Arctic foxes from Medniy Island while utilizing
Probabilistic Graphical Models to capture the conditional dependencies between
the random variables. Such models provide valuable insights in analyzing
factors behind catastrophic degradation of this population and in revealing
evolutionary mechanisms of its persistence in high-density environment. Using
empirical data from studies in Medniy Island, we create a realistic model of
Arctic foxes as agents, and study their survival and population dynamics under
a variety of conditions.",2018-07-16,2018,2018-07,environment
On Evaluation of Embodied Navigation Agents,"Skillful mobile operation in three-dimensional environments is a primary
topic of study in Artificial Intelligence. The past two years have seen a surge
of creative work on navigation. This creative output has produced a plethora of
sometimes incompatible task definitions and evaluation protocols. To coordinate
ongoing and future research in this area, we have convened a working group to
study empirical methodology in navigation research. The present document
summarizes the consensus recommendations of this working group. We discuss
different problem statements and the role of generalization, present evaluation
measures, and provide standard scenarios that can be used for benchmarking.",2018-07-18,2018,2018-07,environment
Asynchronous Advantage Actor-Critic Agent for Starcraft II,"Deep reinforcement learning, and especially the Asynchronous Advantage
Actor-Critic algorithm, has been successfully used to achieve super-human
performance in a variety of video games. Starcraft II is a new challenge for
the reinforcement learning community with the release of pysc2 learning
environment proposed by Google Deepmind and Blizzard Entertainment. Despite
being a target for several AI developers, few have achieved human level
performance. In this project we explain the complexities of this environment
and discuss the results from our experiments on the environment. We have
compared various architectures and have proved that transfer learning can be an
effective paradigm in reinforcement learning research for complex scenarios
requiring skill transfer.",2018-07-22,2018,2018-07,environment
ToriLLE: Learning Environment for Hand-to-Hand Combat,"We present Toribash Learning Environment (ToriLLE), a learning environment
for machine learning agents based on the video game Toribash. Toribash is a
MuJoCo-like environment of two humanoid character fighting each other
hand-to-hand, controlled by changing actuation modes of the joints. Competitive
nature of Toribash as well its focused domain provide a platform for evaluating
self-play methods, and evaluating machine learning agents against human
players. In this paper we describe the environment with ToriLLE's capabilities
and limitations, and experimentally show its applicability as a learning
environment. The source code of the environment and conducted experiments can
be found at https://github.com/Miffyli/ToriLLE.",2018-07-26,2018,2018-07,environment
Multi-Agent Generative Adversarial Imitation Learning,"Imitation learning algorithms can be used to learn a policy from expert
demonstrations without access to a reward signal. However, most existing
approaches are not applicable in multi-agent settings due to the existence of
multiple (Nash) equilibria and non-stationary environments. We propose a new
framework for multi-agent imitation learning for general Markov games, where we
build upon a generalized notion of inverse reinforcement learning. We further
introduce a practical multi-agent actor-critic algorithm with good empirical
performance. Our method can be used to imitate complex behaviors in
high-dimensional environments with multiple cooperative or competing agents.",2018-07-26,2018,2018-07,environment
"Experience, Imitation and Reflection; Confucius' Conjecture and Machine
  Learning","Artificial intelligence recently had a great advancements caused by the
emergence of new processing power and machine learning methods. Having said
that, the learning capability of artificial intelligence is still at its
infancy comparing to the learning capability of human and many animals. Many of
the current artificial intelligence applications can only operate in a very
orchestrated, specific environments with an extensive training set that exactly
describes the conditions that will occur during execution time. Having that in
mind, and considering the several existing machine learning methods this
question rises that 'What are some of the best ways for a machine to learn?'
Regarding the learning methods of human, Confucius' point of view is that they
are by experience, imitation and reflection. This paper tries to explore and
discuss regarding these three ways of learning and their implementations in
machines by having a look at how they happen in minds.",2018-08-01,2018,2018-08,environment
"Deep RTS: A Game Environment for Deep Reinforcement Learning in
  Real-Time Strategy Games","Reinforcement learning (RL) is an area of research that has blossomed
tremendously in recent years and has shown remarkable potential for artificial
intelligence based opponents in computer games. This success is primarily due
to the vast capabilities of convolutional neural networks, that can extract
useful features from noisy and complex data. Games are excellent tools to test
and push the boundaries of novel RL algorithms because they give valuable
insight into how well an algorithm can perform in isolated environments without
the real-life consequences. Real-time strategy games (RTS) is a genre that has
tremendous complexity and challenges the player in short and long-term
planning. There is much research that focuses on applied RL in RTS games, and
novel advances are therefore anticipated in the not too distant future.
However, there are to date few environments for testing RTS AIs. Environments
in the literature are often either overly simplistic, such as microRTS, or
complex and without the possibility for accelerated learning on consumer
hardware like StarCraft II. This paper introduces the Deep RTS game environment
for testing cutting-edge artificial intelligence algorithms for RTS games. Deep
RTS is a high-performance RTS game made specifically for artificial
intelligence research. It supports accelerated learning, meaning that it can
learn at a magnitude of 50 000 times faster compared to existing RTS games.
Deep RTS has a flexible configuration, enabling research in several different
RTS scenarios, including partially observable state-spaces and map complexity.
We show that Deep RTS lives up to our promises by comparing its performance
with microRTS, ELF, and StarCraft II on high-end consumer hardware. Using Deep
RTS, we show that a Deep Q-Network agent beats random-play agents over 70% of
the time. Deep RTS is publicly available at https://github.com/cair/DeepRTS.",2018-08-15,2018,2018-08,environment
"Three-Stage Speaker Verification Architecture in Emotional Talking
  Environments","Speaker verification performance in neutral talking environment is usually
high, while it is sharply decreased in emotional talking environments. This
performance degradation in emotional environments is due to the problem of
mismatch between training in neutral environment while testing in emotional
environments. In this work, a three-stage speaker verification architecture has
been proposed to enhance speaker verification performance in emotional
environments. This architecture is comprised of three cascaded stages: gender
identification stage followed by an emotion identification stage followed by a
speaker verification stage. The proposed framework has been evaluated on two
distinct and independent emotional speech datasets: in-house dataset and
Emotional Prosody Speech and Transcripts dataset. Our results show that speaker
verification based on both gender information and emotion information is
superior to each of speaker verification based on gender information only,
emotion information only, and neither gender information nor emotion
information. The attained average speaker verification performance based on the
proposed framework is very alike to that attained in subjective assessment by
human listeners.",2018-09-03,2018,2018-09,environment
Planning with Arithmetic and Geometric Attributes,"A desirable property of an intelligent agent is its ability to understand its
environment to quickly generalize to novel tasks and compose simpler tasks into
more complex ones. If the environment has geometric or arithmetic structure,
the agent should exploit these for faster generalization. Building on recent
work that augments the environment with user-specified attributes, we show that
further equipping these attributes with the appropriate geometric and
arithmetic structure brings substantial gains in sample complexity.",2018-09-06,2018,2018-09,environment
Unity: A General Platform for Intelligent Agents,"Recent advances in artificial intelligence have been driven by the presence
of increasingly realistic and complex simulated environments. However, many of
the existing environments provide either unrealistic visuals, inaccurate
physics, low task complexity, restricted agent perspective, or a limited
capacity for interaction among artificial agents. Furthermore, many platforms
lack the ability to flexibly configure the simulation, making the simulated
environment a black-box from the perspective of the learning system. In this
work, we propose a novel taxonomy of existing simulation platforms and discuss
the highest level class of general platforms which enable the development of
learning environments that are rich in visual, physical, task, and social
complexity. We argue that modern game engines are uniquely suited to act as
general platforms and as a case study examine the Unity engine and open source
Unity ML-Agents Toolkit. We then survey the research enabled by Unity and the
Unity ML-Agents Toolkit, discussing the kinds of research a flexible,
interactive and easily configurable general platform can facilitate.",2018-09-07,2018,2018-09,environment
"Artificial Intelligence for the Public Sector: Opportunities and
  challenges of cross-sector collaboration","Public sector organisations are increasingly interested in using data science
and artificial intelligence capabilities to deliver policy and generate
efficiencies in high uncertainty environments. The long-term success of data
science and AI in the public sector relies on effectively embedding it into
delivery solutions for policy implementation. However, governments cannot do
this integration of AI into public service delivery on their own. The UK
Government Industrial Strategy is clear that delivering on the AI grand
challenge requires collaboration between universities and public and private
sectors. This cross-sectoral collaborative approach is the norm in applied AI
centres of excellence around the world. Despite their popularity, cross-sector
collaborations entail serious management challenges that hinder their success.
In this article we discuss the opportunities and challenges from AI for public
sector. Finally, we propose a series of strategies to successfully manage these
cross-sectoral collaborations.",2018-09-12,2018,2018-09,environment
Combined Reinforcement Learning via Abstract Representations,"In the quest for efficient and robust reinforcement learning methods, both
model-free and model-based approaches offer advantages. In this paper we
propose a new way of explicitly bridging both approaches via a shared
low-dimensional learned encoding of the environment, meant to capture
summarizing abstractions. We show that the modularity brought by this approach
leads to good generalization while being computationally efficient, with
planning happening in a smaller latent state space. In addition, this approach
recovers a sufficient low-dimensional representation of the environment, which
opens up new strategies for interpretable AI, exploration and transfer
learning.",2018-09-12,2018,2018-09,environment
"Using Artificial Intelligence to Support Compliance with the General
  Data Protection Regulation","The General Data Protection Regulation (GDPR) is a European Union regulation
that will replace the existing Data Protection Directive on 25 May 2018. The
most significant change is a huge increase in the maximum fine that can be
levied for breaches of the regulation. Yet fewer than half of UK companies are
fully aware of GDPR - and a number of those who were preparing for it stopped
doing so when the Brexit vote was announced. A last-minute rush to become
compliant is therefore expected, and numerous companies are starting to offer
advice, checklists and consultancy on how to comply with GDPR. In such an
environment, artificial intelligence technologies ought to be able to assist by
providing best advice; asking all and only the relevant questions; monitoring
activities; and carrying out assessments. The paper considers four areas of
GDPR compliance where rule based technologies and/or machine learning
techniques may be relevant: * Following compliance checklists and codes of
conduct; * Supporting risk assessments; * Complying with the new regulations
regarding technologies that perform automatic profiling; * Complying with the
new regulations concerning recognising and reporting breaches of security. It
concludes that AI technology can support each of these four areas. The
requirements that GDPR (or organisations that need to comply with GDPR) state
for explanation and justification of reasoning imply that rule-based approaches
are likely to be more helpful than machine learning approaches. However, there
may be good business reasons to take a different approach in some
circumstances.",2018-09-15,2018,2018-09,environment
Federated AI for building AI Solutions across Multiple Agencies,"The different sets of regulations existing for differ-ent agencies within the
government make the task of creating AI enabled solutions in government
dif-ficult. Regulatory restrictions inhibit sharing of da-ta across different
agencies, which could be a significant impediment to training AI models. We
discuss the challenges that exist in environments where data cannot be freely
shared and assess tech-nologies which can be used to work around these
challenges. We present results on building AI models using the concept of
federated AI, which al-lows creation of models without moving the training data
around.",2018-09-20,2018,2018-09,environment
"Translating Navigation Instructions in Natural Language to a High-Level
  Plan for Behavioral Robot Navigation","We propose an end-to-end deep learning model for translating free-form
natural language instructions to a high-level plan for behavioral robot
navigation. We use attention models to connect information from both the user
instructions and a topological representation of the environment. We evaluate
our model's performance on a new dataset containing 10,050 pairs of navigation
instructions. Our model significantly outperforms baseline approaches.
Furthermore, our results suggest that it is possible to leverage the
environment map as a relevant knowledge base to facilitate the translation of
free-form navigational instruction.",2018-09-24,2018,2018-09,environment
Towards Game-based Metrics for Computational Co-creativity,"We propose the following question: what game-like interactive system would
provide a good environment for measuring the impact and success of a
co-creative, cooperative agent? Creativity is often formulated in terms of
novelty, value, surprise and interestingness. We review how these concepts are
measured in current computational intelligence research and provide a mapping
from modern electronic and tabletop games to open research problems in
mixed-initiative systems and computational co-creativity. We propose
application scenarios for future research, and a number of metrics under which
the performance of cooperative agents in these environments will be evaluated.",2018-09-26,2018,2018-09,environment
"The Dreaming Variational Autoencoder for Reinforcement Learning
  Environments","Reinforcement learning has shown great potential in generalizing over raw
sensory data using only a single neural network for value optimization. There
are several challenges in the current state-of-the-art reinforcement learning
algorithms that prevent them from converging towards the global optima. It is
likely that the solution to these problems lies in short- and long-term
planning, exploration and memory management for reinforcement learning
algorithms. Games are often used to benchmark reinforcement learning algorithms
as they provide a flexible, reproducible, and easy to control environment.
Regardless, few games feature a state-space where results in exploration,
memory, and planning are easily perceived. This paper presents The Dreaming
Variational Autoencoder (DVAE), a neural network based generative modeling
architecture for exploration in environments with sparse feedback. We further
present Deep Maze, a novel and flexible maze engine that challenges DVAE in
partial and fully-observable state-spaces, long-horizon tasks, and
deterministic and stochastic problems. We show initial findings and encourage
further work in reinforcement learning driven by generative exploration.",2018-10-02,2018,2018-10,environment
At Human Speed: Deep Reinforcement Learning with Action Delay,"There has been a recent explosion in the capabilities of game-playing
artificial intelligence. Many classes of tasks, from video games to motor
control to board games, are now solvable by fairly generic algorithms, based on
deep learning and reinforcement learning, that learn to play from experience
with minimal prior knowledge. However, these machines often do not win through
intelligence alone -- they possess vastly superior speed and precision,
allowing them to act in ways a human never could. To level the playing field,
we restrict the machine's reaction time to a human level, and find that
standard deep reinforcement learning methods quickly drop in performance. We
propose a solution to the action delay problem inspired by human perception --
to endow agents with a neural predictive model of the environment which
""undoes"" the delay inherent in their environment -- and demonstrate its
efficacy against professional players in Super Smash Bros. Melee, a popular
console fighting game.",2018-10-16,2018,2018-10,environment
"Coordinated exploration for labyrinthine environments with application
  to the Pursuit-Evasion problem","This paper introduces a multirobot cooperation approach to solve the ""pursuit
evasion"" problem for mobile robots that have omnidirectional vision sensors.
The main characteristic of this approach is to implement a real cooperation
between robots based on knowledge sharing and makes them work as a team. A
complete algorithm for computing a motion strategy of robots is also presented.
This algorithm is based on searching critical points in the environment.
Finally, the deliberation protocol which distributes the exploration task among
the team and takes the best possible outcome from the robots resources is
presented.",2018-10-19,2018,2018-10,environment
"Analysis of Fleet Modularity in an Artificial Intelligence-Based
  Attacker-Defender Game","Because combat environments change over time and technology upgrades are
widespread for ground vehicles, a large number of vehicles and equipment become
quickly obsolete. A possible solution for the U.S. Army is to develop fleets of
modular military vehicles, which are built by interchangeable substantial
components also known as modules. One of the typical characteristics of module
is their ease of assembly and disassembly through simple means such as
plug-in/pull-out actions, which allows for real-time fleet reconfiguration to
meet dynamic demands. Moreover, military demands are time-varying and highly
stochastic because commanders keep reacting to enemy's actions. To capture
these characteristics, we formulated an intelligent agent-based model to
imitate decision making process during fleet operation, which combines
real-time optimization with artificial intelligence. The agents are capable of
inferring enemy's future move based on historical data and optimize
dispatch/operation decisions accordingly. We implement our model to simulate an
attacker-defender game between two adversarial and intelligent players,
representing the commanders from modularized fleet and conventional fleet
respectively. Given the same level of combat resources and intelligence, we
highlight the tactical advantages of fleet modularity in terms of win rate,
unpredictability and suffered damage.",2018-11-09,2018,2018-11,environment
Blindfold Baselines for Embodied QA,"We explore blindfold (question-only) baselines for Embodied Question
Answering. The EmbodiedQA task requires an agent to answer a question by
intelligently navigating in a simulated environment, gathering necessary visual
information only through first-person vision before finally answering.
Consequently, a blindfold baseline which ignores the environment and visual
information is a degenerate solution, yet we show through our experiments on
the EQAv1 dataset that a simple question-only baseline achieves
state-of-the-art results on the EmbodiedQA task in all cases except when the
agent is spawned extremely close to the object.",2018-11-12,2018,2018-11,environment
On the Complexity of Exploration in Goal-Driven Navigation,"Building agents that can explore their environments intelligently is a
challenging open problem. In this paper, we make a step towards understanding
how a hierarchical design of the agent's policy can affect its exploration
capabilities. First, we design EscapeRoom environments, where the agent must
figure out how to navigate to the exit by accomplishing a number of
intermediate tasks (\emph{subgoals}), such as finding keys or opening doors.
Our environments are procedurally generated and vary in complexity, which can
be controlled by the number of subgoals and relationships between them. Next,
we propose to measure the complexity of each environment by constructing
dependency graphs between the goals and analytically computing \emph{hitting
times} of a random walk in the graph. We empirically evaluate Proximal Policy
Optimization (PPO) with sparse and shaped rewards, a variation of policy
sketches, and a hierarchical version of PPO (called HiPPO) akin to h-DQN. We
show that analytically estimated \emph{hitting time} in goal dependency graphs
is an informative metric of the environment complexity. We conjecture that the
result should hold for environments other than navigation. Finally, we show
that solving environments beyond certain level of complexity requires
hierarchical approaches.",2018-11-16,2018,2018-11,environment
"Simulated Autonomous Driving in a Realistic Driving Environment using
  Deep Reinforcement Learning and a Deterministic Finite State Machine","In the field of Autonomous Driving, the system controlling the vehicle can be
seen as an agent acting in a complex environment and thus naturally fits into
the modern framework of Reinforcement Learning. However, learning to drive can
be a challenging task and current results are often restricted to simplified
driving environments. To advance the field, we present a method to adaptively
restrict the action space of the agent according to its current driving
situation and show that it can be used to swiftly learn to drive in a realistic
environment based on the Deep Q-Network algorithm.",2018-11-19,2018,2018-11,environment
Planning in Dynamic Environments with Conditional Autoregressive Models,"We demonstrate the use of conditional autoregressive generative models (van
den Oord et al., 2016a) over a discrete latent space (van den Oord et al.,
2017b) for forward planning with MCTS. In order to test this method, we
introduce a new environment featuring varying difficulty levels, along with
moving goals and obstacles. The combination of high-quality frame generation
and classical planning approaches nearly matches true environment performance
for our task, demonstrating the usefulness of this method for model-based
planning in dynamic environments.",2018-11-25,2018,2018-11,environment
Environments for Lifelong Reinforcement Learning,"To achieve general artificial intelligence, reinforcement learning (RL)
agents should learn not only to optimize returns for one specific task but also
to constantly build more complex skills and scaffold their knowledge about the
world, without forgetting what has already been learned. In this paper, we
discuss the desired characteristics of environments that can support the
training and evaluation of lifelong reinforcement learning agents, review
existing environments from this perspective, and propose recommendations for
devising suitable environments in the future.",2018-11-26,2018,2018-11,environment
"BlockPuzzle - A Challenge in Physical Reasoning and Generalization for
  Robot Learning","In this work we propose a novel task framework under which a variety of
physical reasoning puzzles can be constructed using very simple rules. Under
sparse reward settings, most of these tasks can be very challenging for a
reinforcement learning agent to learn. We build several simple environments
with this task framework in Mujoco and OpenAI gym and attempt to solve them. We
are able to solve the environments by designing curricula to guide the agent in
learning and using imitation learning methods to transfer knowledge from a
simpler environment. This is only a first step for the task framework, and
further research on how to solve the harder tasks and transfer knowledge
between tasks is needed.",2018-11-30,2018,2018-11,environment
"Making BREAD: Biomimetic strategies for Artificial Intelligence Now and
  in the Future","The Artificial Intelligence (AI) revolution foretold of during the 1960s is
well underway in the second decade of the 21st century. Its period of
phenomenal growth likely lies ahead. Still, we believe, there are crucial
lessons that biology can offer that will enable a prosperous future for AI. For
machines in general, and for AI's especially, operating over extended periods
or in extreme environments will require energy usage orders of magnitudes more
efficient than exists today. In many operational environments, energy sources
will be constrained. Any plans for AI devices operating in a challenging
environment must begin with the question of how they are powered, where fuel is
located, how energy is stored and made available to the machine, and how long
the machine can operate on specific energy units. Hence, the materials and
technologies that provide the needed energy represent a critical challenge
towards future use-scenarios of AI and should be integrated into their design.
Here we make four recommendations for stakeholders and especially decision
makers to facilitate a successful trajectory for this technology. First, that
scientific societies and governments coordinate Biomimetic Research for
Energy-efficient, AI Designs (BREAD); a multinational initiative and a funding
strategy for investments in the future integrated design of energetics into AI.
Second, that biomimetic energetic solutions be central to design consideration
for future AI. Third, that a pre-competitive space be organized between
stakeholder partners and fourth, that a trainee pipeline be established to
ensure the human capital required for success in this area.",2018-12-04,2018,2018-12,environment
Probabilistic Model Checking of Robots Deployed in Extreme Environments,"Robots are increasingly used to carry out critical missions in extreme
environments that are hazardous for humans. This requires a high degree of
operational autonomy under uncertain conditions, and poses new challenges for
assuring the robot's safety and reliability. In this paper, we develop a
framework for probabilistic model checking on a layered Markov model to verify
the safety and reliability requirements of such robots, both at pre-mission
stage and during runtime. Two novel estimators based on conservative Bayesian
inference and imprecise probability model with sets of priors are introduced to
learn the unknown transition parameters from operational data. We demonstrate
our approach using data from a real-world deployment of unmanned underwater
vehicles in extreme environments.",2018-12-10,2018,2018-12,environment
"Lifelong Testing of Smart Autonomous Systems by Shepherding a Swarm of
  Watchdog Artificial Intelligence Agents","Artificial Intelligence (AI) technologies could be broadly categorised into
Analytics and Autonomy. Analytics focuses on algorithms offering perception,
comprehension, and projection of knowledge gleaned from sensorial data.
Autonomy revolves around decision making, and influencing and shaping the
environment through action production. A smart autonomous system (SAS) combines
analytics and autonomy to understand, learn, decide and act autonomously. To be
useful, SAS must be trusted and that requires testing. Lifelong learning of a
SAS compounds the testing process. In the remote chance that it is possible to
fully test and certify the system pre-release, which is theoretically an
undecidable problem, it is near impossible to predict the future behaviours
that these systems, alone or collectively, will exhibit. While it may be
feasible to severely restrict such systems\textquoteright \ learning abilities
to limit the potential unpredictability of their behaviours, an undesirable
consequence may be severely limiting their utility. In this paper, we propose
the architecture for a watchdog AI (WAI) agent dedicated to lifelong functional
testing of SAS. We further propose system specifications including a level of
abstraction whereby humans shepherd a swarm of WAI agents to oversee an
ecosystem made of humans and SAS. The discussion extends to the challenges,
pros, and cons of the proposed concept.",2018-12-21,2018,2018-12,environment
"Optimal Decision-Making in Mixed-Agent Partially Observable Stochastic
  Environments via Reinforcement Learning","Optimal decision making with limited or no information in stochastic
environments where multiple agents interact is a challenging topic in the realm
of artificial intelligence. Reinforcement learning (RL) is a popular approach
for arriving at optimal strategies by predicating stimuli, such as the reward
for following a strategy, on experience. RL is heavily explored in the
single-agent context, but is a nascent concept in multiagent problems. To this
end, I propose several principled model-free and partially model-based
reinforcement learning approaches for several multiagent settings. In the realm
of normative reinforcement learning, I introduce scalable extensions to Monte
Carlo exploring starts for partially observable Markov Decision Processes
(POMDP), dubbed MCES-P, where I expand the theory and algorithm to the
multiagent setting. I first examine MCES-P with probably approximately correct
(PAC) bounds in the context of multiagent setting, showing MCESP+PAC holds in
the presence of other agents. I then propose a more sample-efficient
methodology for antagonistic settings, MCESIP+PAC. For cooperative settings, I
extend MCES-P to the Multiagent POMDP, dubbed MCESMP+PAC. I then explore the
use of reinforcement learning as a methodology in searching for optima in
realistic and latent model environments. First, I explore a parameterized
Q-learning approach in modeling humans learning to reason in an uncertain,
multiagent environment. Next, I propose an implementation of MCES-P, along with
image segmentation, to create an adaptive team-based reinforcement learning
technique to positively identify the presence of phenotypically-expressed water
and pathogen stress in crop fields.",2019-01-04,2019,2019-01,environment
"Learning and Reasoning for Robot Sequential Decision Making under
  Uncertainty","Robots frequently face complex tasks that require more than one action, where
sequential decision-making (SDM) capabilities become necessary. The key
contribution of this work is a robot SDM framework, called LCORPP, that
supports the simultaneous capabilities of supervised learning for passive state
estimation, automated reasoning with declarative human knowledge, and planning
under uncertainty toward achieving long-term goals. In particular, we use a
hybrid reasoning paradigm to refine the state estimator, and provide
informative priors for the probabilistic planner. In experiments, a mobile
robot is tasked with estimating human intentions using their motion
trajectories, declarative contextual knowledge, and human-robot interaction
(dialog-based and motion-based). Results suggest that, in efficiency and
accuracy, our framework performs better than its no-learning and no-reasoning
counterparts in office environment.",2019-01-16,2019,2019-01,environment
Learning Independently-Obtainable Reward Functions,"We present a novel method for learning a set of disentangled reward functions
that sum to the original environment reward and are constrained to be
independently obtainable. We define independent obtainability in terms of value
functions with respect to obtaining one learned reward while pursuing another
learned reward. Empirically, we illustrate that our method can learn meaningful
reward decompositions in a variety of domains and that these decompositions
exhibit some form of generalization performance when the environment's reward
is modified. Theoretically, we derive results about the effect of maximizing
our method's objective on the resulting reward functions and their
corresponding optimal policies.",2019-01-24,2019,2019-01,environment
Modularization of End-to-End Learning: Case Study in Arcade Games,"Complex environments and tasks pose a difficult problem for holistic
end-to-end learning approaches. Decomposition of an environment into
interacting controllable and non-controllable objects allows supervised
learning for non-controllable objects and universal value function approximator
learning for controllable objects. Such decomposition should lead to a shorter
learning time and better generalisation capability. Here, we consider
arcade-game environments as sets of interacting objects (controllable,
non-controllable) and propose a set of functional modules that are specialized
on mastering different types of interactions in a broad range of environments.
The modules utilize regression, supervised learning, and reinforcement learning
algorithms. Results of this case study in different Atari games suggest that
human-level performance can be achieved by a learning agent within a human
amount of game experience (10-15 minutes game time) when a proper decomposition
of an environment or a task is provided. However, automatization of such
decomposition remains a challenging problem. This case study shows how a model
of a causal structure underlying an environment or a task can benefit learning
time and generalization capability of the agent, and argues in favor of
exploiting modular structure in contrast to using pure end-to-end learning
approaches.",2019-01-27,2019,2019-01,environment
Increasing city safety awareness regarding disruptive traffic stream,"Transportation systems serve the people in essence, in this study we focus in
traffic information related to violation events to respond to safety
requirements of the cities. Traffic violation events have an important role in
city safety awareness and secure travel. In this work, we describe the use of
knowledge discovery from traffic violation reports in combination with
demographics approach using inductive logic programming to automatically
extract knowledge about traffic violation behavior and their impact on the
environment.",2019-01-30,2019,2019-01,environment
Causal Simulations for Uplift Modeling,"Uplift modeling requires experimental data, preferably collected in random
fashion. This places a logistical and financial burden upon any organisation
aspiring such models. Once deployed, uplift models are subject to effects from
concept drift. Hence, methods are being developed that are able to learn from
newly gained experience, as well as handle drifting environments. As these new
methods attempt to eliminate the need for experimental data, another approach
to test such methods must be formulated. Therefore, we propose a method to
simulate environments that offer causal relationships in their parameters.",2019-02-01,2019,2019-02,environment
The Hanabi Challenge: A New Frontier for AI Research,"From the early days of computing, games have been important testbeds for
studying how well machines can do sophisticated decision making. In recent
years, machine learning has made dramatic advances with artificial agents
reaching superhuman performance in challenge domains like Go, Atari, and some
variants of poker. As with their predecessors of chess, checkers, and
backgammon, these game domains have driven research by providing sophisticated
yet well-defined challenges for artificial intelligence practitioners. We
continue this tradition by proposing the game of Hanabi as a new challenge
domain with novel problems that arise from its combination of purely
cooperative gameplay with two to five players and imperfect information. In
particular, we argue that Hanabi elevates reasoning about the beliefs and
intentions of other agents to the foreground. We believe developing novel
techniques for such theory of mind reasoning will not only be crucial for
success in Hanabi, but also in broader collaborative efforts, especially those
with human partners. To facilitate future research, we introduce the
open-source Hanabi Learning Environment, propose an experimental framework for
the research community to evaluate algorithmic advances, and assess the
performance of current state-of-the-art techniques.",2019-02-01,2019,2019-02,environment
"Confidence Trigger Detection: Accelerating Real-time
  Tracking-by-detection Systems","Real-time object tracking necessitates a delicate balance between speed and
accuracy, a challenge exacerbated by the computational demands of deep learning
methods. In this paper, we propose Confidence-Triggered Detection (CTD), an
innovative approach that strategically bypasses object detection for frames
closely resembling intermediate states, leveraging tracker confidence scores.
CTD not only enhances tracking speed but also preserves accuracy, surpassing
existing tracking algorithms. Through extensive evaluation across various
tracker confidence thresholds, we identify an optimal trade-off between
tracking speed and accuracy, providing crucial insights for parameter
fine-tuning and enhancing CTD's practicality in real-world scenarios. Our
experiments across diverse detection models underscore the robustness and
versatility of the CTD framework, demonstrating its potential to enable
real-time tracking in resource-constrained environments.",2019-02-02,2019,2019-02,environment
"Evaluation of Multidisciplinary Effects of Artificial Intelligence with
  Optimization Perspective","Artificial Intelligence has an important place in the scientific community as
a result of its successful outputs in terms of different fields. In time, the
field of Artificial Intelligence has been divided into many sub-fields because
of increasing number of different solution approaches, methods, and techniques.
Machine Learning has the most remarkable role with its functions to learn from
samples from the environment. On the other hand, intelligent optimization done
by inspiring from nature and swarms had its own unique scientific literature,
with effective solutions provided for optimization problems from different
fields. Because intelligent optimization can be applied in different fields
effectively, this study aims to provide a general discussion on
multidisciplinary effects of Artificial Intelligence by considering its
optimization oriented solutions. The study briefly focuses on background of the
intelligent optimization briefly and then gives application examples of
intelligent optimization from a multidisciplinary perspective.",2019-02-04,2019,2019-02,environment
"Obstacle Tower: A Generalization Challenge in Vision, Control, and
  Planning","The rapid pace of recent research in AI has been driven in part by the
presence of fast and challenging simulation environments. These environments
often take the form of games; with tasks ranging from simple board games, to
competitive video games. We propose a new benchmark - Obstacle Tower: a high
fidelity, 3D, 3rd person, procedurally generated environment. An agent playing
Obstacle Tower must learn to solve both low-level control and high-level
planning problems in tandem while learning from pixels and a sparse reward
signal. Unlike other benchmarks such as the Arcade Learning Environment,
evaluation of agent performance in Obstacle Tower is based on an agent's
ability to perform well on unseen instances of the environment. In this paper
we outline the environment and provide a set of baseline results produced by
current state-of-the-art Deep RL methods as well as human players. These
algorithms fail to produce agents capable of performing near human level.",2019-02-04,2019,2019-02,environment
Learning to Learn in Simulation,"Deep learning often requires the manual collection and annotation of a
training set. On robotic platforms, can we partially automate this task by
training the robot to be curious, i.e., to seek out beneficial training
information in the environment? In this work, we address the problem of
curiosity as it relates to online, real-time, human-in-the-loop training of an
object detection algorithm onboard a drone, where motion is constrained to two
dimensions. We use a 3D simulation environment and deep reinforcement learning
to train a curiosity agent to, in turn, train the object detection model. This
agent could have one of two conflicting objectives: train as quickly as
possible, or train with minimal human input. We outline a reward function that
allows the curiosity agent to learn either of these objectives, while taking
into account some of the physical characteristics of the drone platform on
which it is meant to run. In addition, We show that we can weigh the importance
of achieving these objectives by adjusting a parameter in the reward function.",2019-02-05,2019,2019-02,environment
Situational Grounding within Multimodal Simulations,"In this paper, we argue that simulation platforms enable a novel type of
embodied spatial reasoning, one facilitated by a formal model of object and
event semantics that renders the continuous quantitative search space of an
open-world, real-time environment tractable. We provide examples for how a
semantically-informed AI system can exploit the precise, numerical information
provided by a game engine to perform qualitative reasoning about objects and
events, facilitate learning novel concepts from data, and communicate with a
human to improve its models and demonstrate its understanding. We argue that
simulation environments, and game engines in particular, bring together many
different notions of ""simulation"" and many different technologies to provide a
highly-effective platform for developing both AI systems and tools to
experiment in both machine and human intelligence.",2019-02-05,2019,2019-02,environment
Visual search and recognition for robot task execution and monitoring,"Visual search of relevant targets in the environment is a crucial robot
skill. We propose a preliminary framework for the execution monitor of a robot
task, taking care of the robot attitude to visually searching the environment
for targets involved in the task. Visual search is also relevant to recover
from a failure. The framework exploits deep reinforcement learning to acquire a
""common sense"" scene structure and it takes advantage of a deep convolutional
network to detect objects and relevant relations holding between them. The
framework builds on these methods to introduce a vision-based execution
monitoring, which uses classical planning as a backbone for task execution.
Experiments show that with the proposed vision-based execution monitor the
robot can complete simple tasks and can recover from failures in autonomy.",2019-02-07,2019,2019-02,environment
EvalAI: Towards Better Evaluation Systems for AI Agents,"We introduce EvalAI, an open source platform for evaluating and comparing
machine learning (ML) and artificial intelligence algorithms (AI) at scale.
EvalAI is built to provide a scalable solution to the research community to
fulfill the critical need of evaluating machine learning models and agents
acting in an environment against annotations or with a human-in-the-loop. This
will help researchers, students, and data scientists to create, collaborate,
and participate in AI challenges organized around the globe. By simplifying and
standardizing the process of benchmarking these models, EvalAI seeks to lower
the barrier to entry for participating in the global scientific effort to push
the frontiers of machine learning and artificial intelligence, thereby
increasing the rate of measurable progress in this domain.",2019-02-10,2019,2019-02,environment
"VERIFAI: A Toolkit for the Design and Analysis of Artificial
  Intelligence-Based Systems","We present VERIFAI, a software toolkit for the formal design and analysis of
systems that include artificial intelligence (AI) and machine learning (ML)
components. VERIFAI particularly seeks to address challenges with applying
formal methods to perception and ML components, including those based on neural
networks, and to model and analyze system behavior in the presence of
environment uncertainty. We describe the initial version of VERIFAI which
centers on simulation guided by formal models and specifications. Several use
cases are illustrated with examples, including temporal-logic falsification,
model-based systematic fuzz testing, parameter synthesis, counterexample
analysis, and data set augmentation.",2019-02-12,2019,2019-02,environment
"Marathon Environments: Multi-Agent Continuous Control Benchmarks in a
  Modern Video Game Engine","Recent advances in deep reinforcement learning in the paradigm of locomotion
using continuous control have raised the interest of game makers for the
potential of digital actors using active ragdoll. Currently, the available
options to develop these ideas are either researchers' limited codebase or
proprietary closed systems. We present Marathon Environments, a suite of open
source, continuous control benchmarks implemented on the Unity game engine,
using the Unity ML- Agents Toolkit. We demonstrate through these benchmarks
that continuous control research is transferable to a commercial game engine.
Furthermore, we exhibit the robustness of these environments by reproducing
advanced continuous control research, such as learning to walk, run and
backflip from motion capture data; learning to navigate complex terrains; and
by implementing a video game input control system. We show further robustness
by training with alternative algorithms found in OpenAI.Baselines. Finally, we
share strategies for significantly reducing the training time.",2019-02-25,2019,2019-02,environment
Embedded Agency,"Traditional models of rational action treat the agent as though it is cleanly
separated from its environment, and can act on that environment from the
outside. Such agents have a known functional relationship with their
environment, can model their environment in every detail, and do not need to
reason about themselves or their internal parts.
  We provide an informal survey of obstacles to formalizing good reasoning for
agents embedded in their environment. Such agents must optimize an environment
that is not of type ""function""; they must rely on models that fit within the
modeled environment; and they must reason about themselves as just another
physical system, made of parts that can be modified and that can work at cross
purposes.",2019-02-25,2019,2019-02,environment
"Artificial Intelligence in Intelligent Tutoring Robots: A Systematic
  Review and Design Guidelines","This study provides a systematic review of the recent advances in designing
the intelligent tutoring robot (ITR), and summarises the status quo of applying
artificial intelligence (AI) techniques. We first analyse the environment of
the ITR and propose a relationship model for describing interactions of ITR
with the students, the social milieu and the curriculum. Then, we transform the
relationship model into the perception-planning-action model for exploring what
AI techniques are suitable to be applied in the ITR. This article provides
insights on promoting human-robot teaching-learning process and AI-assisted
educational techniques, illustrating the design guidelines and future research
perspectives in intelligent tutoring robots.",2019-02-26,2019,2019-02,environment
Intelligent Autonomous Things on the Battlefield,"Numerous, artificially intelligent, networked things will populate the
battlefield of the future, operating in close collaboration with human
warfighters, and fighting as teams in highly adversarial environments. This
chapter explores the characteristics, capabilities and intelli-gence required
of such a network of intelligent things and humans - Internet of Battle Things
(IOBT). The IOBT will experience unique challenges that are not yet well
addressed by the current generation of AI and machine learning.",2019-02-26,2019,2019-02,environment
A Strongly Asymptotically Optimal Agent in General Environments,"Reinforcement Learning agents are expected to eventually perform well.
Typically, this takes the form of a guarantee about the asymptotic behavior of
an algorithm given some assumptions about the environment. We present an
algorithm for a policy whose value approaches the optimal value with
probability 1 in all computable probabilistic environments, provided the agent
has a bounded horizon. This is known as strong asymptotic optimality, and it
was previously unknown whether it was possible for a policy to be strongly
asymptotically optimal in the class of all computable probabilistic
environments. Our agent, Inquisitive Reinforcement Learner (Inq), is more
likely to explore the more it expects an exploratory action to reduce its
uncertainty about which environment it is in, hence the term inquisitive.
Exploring inquisitively is a strategy that can be applied generally; for more
manageable environment classes, inquisitiveness is tractable. We conducted
experiments in ""grid-worlds"" to compare the Inquisitive Reinforcement Learner
to other weakly asymptotically optimal agents.",2019-03-04,2019,2019-03,environment
Dyna-AIL : Adversarial Imitation Learning by Planning,"Adversarial methods for imitation learning have been shown to perform well on
various control tasks. However, they require a large number of environment
interactions for convergence. In this paper, we propose an end-to-end
differentiable adversarial imitation learning algorithm in a Dyna-like
framework for switching between model-based planning and model-free learning
from expert data. Our results on both discrete and continuous environments show
that our approach of using model-based planning along with model-free learning
converges to an optimal policy with fewer number of environment interactions in
comparison to the state-of-the-art learning methods.",2019-03-08,2019,2019-03,environment
"VRKitchen: an Interactive 3D Virtual Environment for Task-oriented
  Learning","One of the main challenges of advancing task-oriented learning such as visual
task planning and reinforcement learning is the lack of realistic and
standardized environments for training and testing AI agents. Previously,
researchers often relied on ad-hoc lab environments. There have been recent
advances in virtual systems built with 3D physics engines and photo-realistic
rendering for indoor and outdoor environments, but the embodied agents in those
systems can only conduct simple interactions with the world (e.g., walking
around, moving objects, etc.). Most of the existing systems also do not allow
human participation in their simulated environments. In this work, we design
and implement a virtual reality (VR) system, VRKitchen, with integrated
functions which i) enable embodied agents powered by modern AI methods (e.g.,
planning, reinforcement learning, etc.) to perform complex tasks involving a
wide range of fine-grained object manipulations in a realistic environment, and
ii) allow human teachers to perform demonstrations to train agents (i.e.,
learning from demonstration). We also provide standardized evaluation
benchmarks and data collection tools to facilitate a broad use in research on
task-oriented learning and beyond.",2019-03-13,2019,2019-03,environment
Adaptive Variance for Changing Sparse-Reward Environments,"Robots that are trained to perform a task in a fixed environment often fail
when facing unexpected changes to the environment due to a lack of exploration.
We propose a principled way to adapt the policy for better exploration in
changing sparse-reward environments. Unlike previous works which explicitly
model environmental changes, we analyze the relationship between the value
function and the optimal exploration for a Gaussian-parameterized policy and
show that our theory leads to an effective strategy for adjusting the variance
of the policy, enabling fast adapt to changes in a variety of sparse-reward
environments.",2019-03-15,2019,2019-03,environment
"Inferring Compact Representations for Efficient Natural Language
  Understanding of Robot Instructions","The speed and accuracy with which robots are able to interpret natural
language is fundamental to realizing effective human-robot interaction. A great
deal of attention has been paid to developing models and approximate inference
algorithms that improve the efficiency of language understanding. However,
existing methods still attempt to reason over a representation of the
environment that is flat and unnecessarily detailed, which limits scalability.
An open problem is then to develop methods capable of producing the most
compact environment model sufficient for accurate and efficient natural
language understanding. We propose a model that leverages environment-related
information encoded within instructions to identify the subset of observations
and perceptual classifiers necessary to perceive a succinct,
instruction-specific environment representation. The framework uses three
probabilistic graphical models trained from a corpus of annotated instructions
to infer salient scene semantics, perceptual classifiers, and grounded symbols.
Experimental results on two robots operating in different environments
demonstrate that by exploiting the content and the structure of the
instructions, our method learns compact environment representations that
significantly improve the efficiency of natural language symbol grounding.",2019-03-21,2019,2019-03,environment
"Combining Offline Models and Online Monte-Carlo Tree Search for Planning
  from Scratch","Planning in stochastic and partially observable environments is a central
issue in artificial intelligence. One commonly used technique for solving such
a problem is by constructing an accurate model firstly. Although some recent
approaches have been proposed for learning optimal behaviour under model
uncertainty, prior knowledge about the environment is still needed to guarantee
the performance of the proposed algorithms. With the benefits of the Predictive
State Representations~(PSRs) approach for state representation and model
prediction, in this paper, we introduce an approach for planning from scratch,
where an offline PSR model is firstly learned and then combined with online
Monte-Carlo tree search for planning with model uncertainty. By comparing with
the state-of-the-art approach of planning with model uncertainty, we
demonstrated the effectiveness of the proposed approaches along with the proof
of their convergence. The effectiveness and scalability of our proposed
approach are also tested on the RockSample problem, which are infeasible for
the state-of-the-art BA-POMDP based approaches.",2019-04-05,2019,2019-04,environment
"Reinforcement Learning with Probabilistic Guarantees for Autonomous
  Driving","Designing reliable decision strategies for autonomous urban driving is
challenging. Reinforcement learning (RL) has been used to automatically derive
suitable behavior in uncertain environments, but it does not provide any
guarantee on the performance of the resulting policy. We propose a generic
approach to enforce probabilistic guarantees on an RL agent. An exploration
strategy is derived prior to training that constrains the agent to choose among
actions that satisfy a desired probabilistic specification expressed with
linear temporal logic (LTL). Reducing the search space to policies satisfying
the LTL formula helps training and simplifies reward design. This paper
outlines a case study of an intersection scenario involving multiple traffic
participants. The resulting policy outperforms a rule-based heuristic approach
in terms of efficiency while exhibiting strong guarantees on safety.",2019-04-15,2019,2019-04,environment
Object-Oriented Dynamics Learning through Multi-Level Abstraction,"Object-based approaches for learning action-conditioned dynamics has
demonstrated promise for generalization and interpretability. However, existing
approaches suffer from structural limitations and optimization difficulties for
common environments with multiple dynamic objects. In this paper, we present a
novel self-supervised learning framework, called Multi-level Abstraction
Object-oriented Predictor (MAOP), which employs a three-level learning
architecture that enables efficient object-based dynamics learning from raw
visual observations. We also design a spatial-temporal relational reasoning
mechanism for MAOP to support instance-level dynamics learning and handle
partial observability. Our results show that MAOP significantly outperforms
previous methods in terms of sample efficiency and generalization over novel
environments for learning environment models. We also demonstrate that learned
dynamics models enable efficient planning in unseen environments, comparable to
true environment models. In addition, MAOP learns semantically and visually
interpretable disentangled representations.",2019-04-16,2019,2019-04,environment
"Is coding a relevant metaphor for building AI? A commentary on ""Is
  coding a relevant metaphor for the brain?"", by Romain Brette","Brette contends that the neural coding metaphor is an invalid basis for
theories of what the brain does. Here, we argue that it is an insufficient
guide for building an artificial intelligence that learns to accomplish short-
and long-term goals in a complex, changing environment.",2019-04-18,2019,2019-04,environment
"An Efficient Reachability-Based Framework for Provably Safe Autonomous
  Navigation in Unknown Environments","Real-world autonomous vehicles often operate in a priori unknown
environments. Since most of these systems are safety-critical, it is important
to ensure they operate safely in the face of environment uncertainty, such as
unseen obstacles. Current safety analysis tools enable autonomous systems to
reason about safety given full information about the state of the environment a
priori. However, these tools do not scale well to scenarios where the
environment is being sensed in real time, such as during navigation tasks. In
this work, we propose a novel, real-time safety analysis method based on
Hamilton-Jacobi reachability that provides strong safety guarantees despite
environment uncertainty. Our safety method is planner-agnostic and provides
guarantees for a variety of mapping sensors. We demonstrate our approach in
simulation and in hardware to provide safety guarantees around a
state-of-the-art vision-based, learning-based planner.",2019-05-01,2019,2019-05,environment
"Design of Artificial Intelligence Agents for Games using Deep
  Reinforcement Learning","In order perform a large variety of tasks and to achieve human-level
performance in complex real-world environments, Artificial Intelligence (AI)
Agents must be able to learn from their past experiences and gain both
knowledge and an accurate representation of their environment from raw sensory
inputs. Traditionally, AI agents have suffered from difficulties in using only
sensory inputs to obtain a good representation of their environment and then
mapping this representation to an efficient control policy. Deep reinforcement
learning algorithms have provided a solution to this issue. In this study, the
performance of different conventional and novel deep reinforcement learning
algorithms was analysed. The proposed method utilises two types of algorithms,
one trained with a variant of Q-learning (DQN) and another trained with SARSA
learning (DSN) to assess the feasibility of using direct feedback alignment, a
novel biologically plausible method for back-propagating the error. These novel
agents, alongside two similar agents trained with the conventional
backpropagation algorithm, were tested by using the OpenAI Gym toolkit on
several classic control theory problems and Atari 2600 video games. The results
of this investigation open the way into new, biologically-inspired deep
reinforcement learning algorithms, and their implementation on neuromorphic
hardware.",2019-05-10,2019,2019-05,environment
Attention-based Deep Reinforcement Learning for Multi-view Environments,"In reinforcement learning algorithms, it is a common practice to account for
only a single view of the environment to make the desired decisions; however,
utilizing multiple views of the environment can help to promote the learning of
complicated policies. Since the views may frequently suffer from partial
observability, their provided observation can have different levels of
importance. In this paper, we present a novel attention-based deep
reinforcement learning method in a multi-view environment in which each view
can provide various representative information about the environment.
Specifically, our method learns a policy to dynamically attend to views of the
environment based on their importance in the decision-making process. We
evaluate the performance of our method on TORCS racing car simulator and three
other complex 3D environments with obstacles.",2019-05-10,2019,2019-05,environment
Randomized Adversarial Imitation Learning for Autonomous Driving,"With the evolution of various advanced driver assistance system (ADAS)
platforms, the design of autonomous driving system is becoming more complex and
safety-critical. The autonomous driving system simultaneously activates
multiple ADAS functions; and thus it is essential to coordinate various ADAS
functions. This paper proposes a randomized adversarial imitation learning
(RAIL) method that imitates the coordination of autonomous vehicle equipped
with advanced sensors. The RAIL policies are trained through derivative-free
optimization for the decision maker that coordinates the proper ADAS functions,
e.g., smart cruise control and lane keeping system. Especially, the proposed
method is also able to deal with the LIDAR data and makes decisions in complex
multi-lane highways and multi-agent environments.",2019-05-13,2019,2019-05,environment
Autonomous Penetration Testing using Reinforcement Learning,"Penetration testing (pentesting) involves performing a controlled attack on a
computer system in order to assess it's security. Although an effective method
for testing security, pentesting requires highly skilled practitioners and
currently there is a growing shortage of skilled cyber security professionals.
One avenue for alleviating this problem is automate the pentesting process
using artificial intelligence techniques. Current approaches to automated
pentesting have relied on model-based planning, however the cyber security
landscape is rapidly changing making maintaining up-to-date models of exploits
a challenge. This project investigated the application of model-free
Reinforcement Learning (RL) to automated pentesting. Model-free RL has the key
advantage over model-based planning of not requiring a model of the
environment, instead learning the best policy through interaction with the
environment. We first designed and built a fast, low compute simulator for
training and testing autonomous pentesting agents. We did this by framing
pentesting as a Markov Decision Process with the known configuration of the
network as states, the available scans and exploits as actions, the reward
determined by the value of machines on the network. We then used this simulator
to investigate the application of model-free RL to pentesting. We tested the
standard Q-learning algorithm using both tabular and neural network based
implementations. We found that within the simulated environment both tabular
and neural network implementations were able to find optimal attack paths for a
range of different network topologies and sizes without having a model of
action behaviour. However, the implemented algorithms were only practical for
smaller networks and numbers of actions. Further work is needed in developing
scalable RL algorithms and testing these algorithms in larger and higher
fidelity environments.",2019-05-15,2019,2019-05,environment
"Reinforcement Learning for Learning of Dynamical Systems in Uncertain
  Environment: a Tutorial","In this paper, a review of model-free reinforcement learning for learning of
dynamical systems in uncertain environments has discussed. For this purpose,
the Markov Decision Process (MDP) will be reviewed. Furthermore, some learning
algorithms such as Temporal Difference (TD) learning, Q-Learning, and
Approximate Q-learning as model-free algorithms which constitute the main part
of this article have been investigated, and benefits and drawbacks of each
algorithm will be discussed. The discussed concepts in each section are
explaining with details and examples.",2019-05-19,2019,2019-05,environment
"COBRA: Data-Efficient Model-Based RL through Unsupervised Object
  Discovery and Curiosity-Driven Exploration","Data efficiency and robustness to task-irrelevant perturbations are
long-standing challenges for deep reinforcement learning algorithms. Here we
introduce a modular approach to addressing these challenges in a continuous
control environment, without using hand-crafted or supervised information. Our
Curious Object-Based seaRch Agent (COBRA) uses task-free intrinsically
motivated exploration and unsupervised learning to build object-based models of
its environment and action space. Subsequently, it can learn a variety of tasks
through model-based search in very few steps and excel on structured hold-out
tests of policy robustness.",2019-05-22,2019,2019-05,environment
Deploying AI Frameworks on Secure HPC Systems with Containers,"The increasing interest in the usage of Artificial Intelligence techniques
(AI) from the research community and industry to tackle ""real world"" problems,
requires High Performance Computing (HPC) resources to efficiently compute and
scale complex algorithms across thousands of nodes. Unfortunately, typical data
scientists are not familiar with the unique requirements and characteristics of
HPC environments. They usually develop their applications with high-level
scripting languages or frameworks such as TensorFlow and the installation
process often requires connection to external systems to download open source
software during the build. HPC environments, on the other hand, are often based
on closed source applications that incorporate parallel and distributed
computing API's such as MPI and OpenMP, while users have restricted
administrator privileges, and face security restrictions such as not allowing
access to external systems. In this paper we discuss the issues associated with
the deployment of AI frameworks in a secure HPC environment and how we
successfully deploy AI frameworks on SuperMUC-NG with Charliecloud.",2019-05-24,2019,2019-05,environment
"Cognitively-inspired Agent-based Service Composition for Mobile &
  Pervasive Computing","Automatic service composition in mobile and pervasive computing faces many
challenges due to the complex and highly dynamic nature of the environment.
Common approaches consider service composition as a decision problem whose
solution is usually addressed from optimization perspectives which are not
feasible in practice due to the intractability of the problem, limited
computational resources of smart devices, service host's mobility, and time
constraints to tailor composition plans. Thus, our main contribution is the
development of a cognitively-inspired agent-based service composition model
focused on bounded rationality rather than optimality, which allows the system
to compensate for limited resources by selectively filtering out continuous
streams of data. Our approach exhibits features such as distributedness,
modularity, emergent global functionality, and robustness, which endow it with
capabilities to perform decentralized service composition by orchestrating
manifold service providers and conflicting goals from multiple users. The
evaluation of our approach shows promising results when compared against
state-of-the-art service composition models.",2019-05-29,2019,2019-05,environment
Advantage Amplification in Slowly Evolving Latent-State Environments,"Latent-state environments with long horizons, such as those faced by
recommender systems, pose significant challenges for reinforcement learning
(RL). In this work, we identify and analyze several key hurdles for RL in such
environments, including belief state error and small action advantage. We
develop a general principle of advantage amplification that can overcome these
hurdles through the use of temporal abstraction. We propose several aggregation
methods and prove they induce amplification in certain settings. We also bound
the loss in optimality incurred by our methods in environments where latent
state evolves slowly and demonstrate their performance empirically in a
stylized user-modeling task.",2019-05-29,2019,2019-05,environment
"Smart Sustainable Agriculture (SSA) Solution Underpinned by Internet of
  Things (IoT) and Artificial Intelligence (AI)","The Internet of Things (IoT) and Artificial Intelligence (AI) have been
employed in agriculture over a long period of time, alongside other advanced
computing technologies. However, increased attention is currently being paid to
the use of such smart technologies. Agriculture has provided an important
source of food for human beings over many thousands of years, including the
development of appropriate farming methods for different types of crops. The
emergence of new advanced IoT technologies has the potential to monitor the
agricultural environment to ensure high-quality products. However, there
remains a lack of research and development in relation to Smart Sustainable
Agriculture (SSA), accompanied by complex obstacles arising from the
fragmentation of agricultural processes, i.e. the control and operation of
IoT/AI machines; data sharing and management; interoperability; and large
amounts of data analysis and storage. This study firstly, explores existing
IoT/AI technologies adopted for SSA and secondly, identifies IoT/AI technical
architecture capable of underpinning the development of SSA platforms. As well
as contributing to the current body of knowledge, this research reviews
research and development within SSA and provides an IoT/AI architecture to
establish a Smart, Sustainable Agriculture platform as a solution.",2019-05-30,2019,2019-05,environment
2019 Evolutionary Algorithms Review,"Evolutionary algorithm research and applications began over 50 years ago.
Like other artificial intelligence techniques, evolutionary algorithms will
likely see increased use and development due to the increased availability of
computation, more robust and available open source software libraries, and the
increasing demand for artificial intelligence techniques. As these techniques
become more adopted and capable, it is the right time to take a perspective of
their ability to integrate into society and the human processes they intend to
augment. In this review, we explore a new taxonomy of evolutionary algorithms
and resulting classifications that look at five main areas: the ability to
manage the control of the environment with limiters, the ability to explain and
repeat the search process, the ability to understand input and output causality
within a solution, the ability to manage algorithm bias due to data or user
design, and lastly, the ability to add corrective measures. These areas are
motivated by today's pressures on industry to conform to both societies
concerns and new government regulatory rules. As many reviews of evolutionary
algorithms exist, after motivating this new taxonomy, we briefly classify a
broad range of algorithms and identify areas of future research.",2019-06-03,2019,2019-06,environment
"Escaping the State of Nature: A Hobbesian Approach to Cooperation in
  Multi-agent Reinforcement Learning","Cooperation is a phenomenon that has been widely studied across many
different disciplines. In the field of computer science, the modularity and
robustness of multi-agent systems offer significant practical advantages over
individual machines. At the same time, agents using standard reinforcement
learning algorithms often fail to achieve long-term, cooperative strategies in
unstable environments when there are short-term incentives to defect. Political
philosophy, on the other hand, studies the evolution of cooperation in humans
who face similar incentives to act individualistically, but nevertheless
succeed in forming societies. Thomas Hobbes in Leviathan provides the classic
analysis of the transition from a pre-social State of Nature, where consistent
defection results in a constant state of war, to stable political community
through the institution of an absolute Sovereign. This thesis argues that
Hobbes's natural and moral philosophy are strikingly applicable to artificially
intelligent agents and aims to show that his political solutions are
experimentally successful in producing cooperation among modified Q-Learning
agents. Cooperative play is achieved in a novel Sequential Social Dilemma
called the Civilization Game, which models the State of Nature by introducing
the Hobbesian mechanisms of opponent learning awareness and majoritarian
voting, leading to the establishment of a Sovereign.",2019-06-05,2019,2019-06,environment
Shaping Belief States with Generative Environment Models for RL,"When agents interact with a complex environment, they must form and maintain
beliefs about the relevant aspects of that environment. We propose a way to
efficiently train expressive generative models in complex environments. We show
that a predictive algorithm with an expressive generative model can form stable
belief-states in visually rich and dynamic 3D environments. More precisely, we
show that the learned representation captures the layout of the environment as
well as the position and orientation of the agent. Our experiments show that
the model substantially improves data-efficiency on a number of reinforcement
learning (RL) tasks compared with strong model-free baseline agents. We find
that predicting multiple steps into the future (overshooting), in combination
with an expressive generative model, is critical for stable representations to
emerge. In practice, using expressive generative models in RL is
computationally expensive and we propose a scheme to reduce this computational
burden, allowing us to build agents that are competitive with model-free
baselines.",2019-06-21,2019,2019-06,environment
"Developing an App to interpret Chest X-rays to support the diagnosis of
  respiratory pathology with Artificial Intelligence","In this paper we present our work to improve access to diagnosis in remote
areas where good quality medical services may be lacking. We develop new
Machine Learning methodologies for deployment onto mobile devices to help the
early diagnosis of a number of life-threatening conditions using X-ray images.
By using the latest developments in fast and portable Artificial Intelligence
environments, we develop a smartphone app using an Artificial Neural Network to
assist physicians in their diagnostic.",2019-06-26,2019,2019-06,environment
Automated Gaming Pommerman: FFA,"Our game Pommerman is based on the console game Bommerman. The game starts on
an 11 by 11 platform. Pommerman is a multi-agent environment and is made up of
a set of different situations and contains four agents.",2019-07-13,2019,2019-07,environment
"An Actor-Critic-Attention Mechanism for Deep Reinforcement Learning in
  Multi-view Environments","In reinforcement learning algorithms, leveraging multiple views of the
environment can improve the learning of complicated policies. In multi-view
environments, due to the fact that the views may frequently suffer from partial
observability, their level of importance are often different. In this paper, we
propose a deep reinforcement learning method and an attention mechanism in a
multi-view environment. Each view can provide various representative
information about the environment. Through our attention mechanism, our method
generates a single feature representation of environment given its multiple
views. It learns a policy to dynamically attend to each view based on its
importance in the decision-making process. Through experiments, we show that
our method outperforms its state-of-the-art baselines on TORCS racing car
simulator and three other complex 3D environments with obstacles. We also
provide experimental results to evaluate the performance of our method on noisy
conditions and partial observation settings.",2019-07-19,2019,2019-07,environment
"Pre-Learning Environment Representations for Data-Efficient Neural
  Instruction Following","We consider the problem of learning to map from natural language instructions
to state transitions (actions) in a data-efficient manner. Our method takes
inspiration from the idea that it should be easier to ground language to
concepts that have already been formed through pre-linguistic observation. We
augment a baseline instruction-following learner with an initial
environment-learning phase that uses observations of language-free state
transitions to induce a suitable latent representation of actions before
processing the instruction-following training data. We show that mapping to
pre-learned representations substantially improves performance over systems
whose representations are learned from limited instructional data alone.",2019-07-23,2019,2019-07,environment
Environment Probing Interaction Policies,"A key challenge in reinforcement learning (RL) is environment generalization:
a policy trained to solve a task in one environment often fails to solve the
same task in a slightly different test environment. A common approach to
improve inter-environment transfer is to learn policies that are invariant to
the distribution of testing environments. However, we argue that instead of
being invariant, the policy should identify the specific nuances of an
environment and exploit them to achieve better performance. In this work, we
propose the 'Environment-Probing' Interaction (EPI) policy, a policy that
probes a new environment to extract an implicit understanding of that
environment's behavior. Once this environment-specific information is obtained,
it is used as an additional input to a task-specific policy that can now
perform environment-conditioned actions to solve a task. To learn these
EPI-policies, we present a reward function based on transition predictability.
Specifically, a higher reward is given if the trajectory generated by the
EPI-policy can be used to better predict transitions. We experimentally show
that EPI-conditioned task-specific policies significantly outperform commonly
used policy generalization methods on novel testing environments.",2019-07-26,2019,2019-07,environment
"Multi-node environment strategy for Parallel Deterministic
  Multi-Objective Fractal Decomposition","This paper presents a new implementation of deterministic multiobjective (MO)
optimization called Multiobjective Fractal Decomposition Algorithm (Mo-FDA).
The original algorithm was designed for mono-objective large scale continuous
optimization problems. It is based on a divide and conquer strategy and a
geometric fractal decomposition of the search space using hyperspheres. Then,
to deal with MO problems a scalarization approach is used. In this work, a new
approach has been developed on a multi-node environment using containers. The
performance of Mo-FDA was compared to state of the art algorithms from the
literature on classical benchmark of multi-objective optimization",2019-08-04,2019,2019-08,environment
DoorGym: A Scalable Door Opening Environment And Baseline Agent,"In order to practically implement the door opening task, a policy ought to be
robust to a wide distribution of door types and environment settings.
Reinforcement Learning (RL) with Domain Randomization (DR) is a promising
technique to enforce policy generalization, however, there are only a few
accessible training environments that are inherently designed to train agents
in domain randomized environments. We introduce DoorGym, an open-source door
opening simulation framework designed to utilize domain randomization to train
a stable policy. We intend for our environment to lie at the intersection of
domain transfer, practical tasks, and realism. We also provide baseline
Proximal Policy Optimization and Soft Actor-Critic implementations, which
achieves success rates between 0% up to 95% for opening various types of doors
in this environment. Moreover, the real-world transfer experiment shows the
trained policy is able to work in the real world. Environment kit available
here: https://github.com/PSVL/DoorGym/",2019-08-05,2019,2019-08,environment
"Decision making in dynamic and interactive environments based on
  cognitive hierarchy theory, Bayesian inference, and predictive control","In this paper, we describe an integrated framework for autonomous decision
making in a dynamic and interactive environment. We model the interactions
between the ego agent and its operating environment as a two-player dynamic
game, and integrate cognitive behavioral models, Bayesian inference, and
receding-horizon optimal control to define a dynamically-evolving decision
strategy for the ego agent. Simulation examples representing autonomous vehicle
control in three traffic scenarios where the autonomous ego vehicle interacts
with a human-driven vehicle are reported.",2019-08-12,2019,2019-08,environment
"From Crystallized Adaptivity to Fluid Adaptivity in Deep Reinforcement
  Learning -- Insights from Biological Systems on Adaptive Flexibility","Recent developments in machine-learning algorithms have led to impressive
performance increases in many traditional application scenarios of artificial
intelligence research. In the area of deep reinforcement learning, deep
learning functional architectures are combined with incremental learning
schemes for sequential tasks that include interaction-based, but often delayed
feedback. Despite their impressive successes, modern machine-learning
approaches, including deep reinforcement learning, still perform weakly when
compared to flexibly adaptive biological systems in certain naturally occurring
scenarios. Such scenarios include transfers to environments different than the
ones in which the training took place or environments that dynamically change,
both of which are often mastered by biological systems through a capability
that we here term ""fluid adaptivity"" to contrast it from the much slower
adaptivity (""crystallized adaptivity"") of the prior learning from which the
behavior emerged. In this article, we derive and discuss research strategies,
based on analyzes of fluid adaptivity in biological systems and its neuronal
modeling, that might aid in equipping future artificially intelligent systems
with capabilities of fluid adaptivity more similar to those seen in some
biologically intelligent systems. A key component of this research strategy is
the dynamization of the problem space itself and the implementation of this
dynamization by suitably designed flexibly interacting modules.",2019-08-13,2019,2019-08,environment
"Simulation Model of Two-Robot Cooperation in Common Operating
  Environment","The article considers a simulation modelling problem related to the chess
game process occurring between two three-tier manipulators. The objective of
the game construction lies in developing the procedure of effective control of
the autonomous manipulator robots located in a common operating environment.
The simulation model is a preliminary stage of building a natural complex that
would provide cooperation of several manipulator robots within a common
operating environment. The article addresses issues of training and research.",2019-08-22,2019,2019-08,environment
Dynamics-aware Embeddings,"In this paper we consider self-supervised representation learning to improve
sample efficiency in reinforcement learning (RL). We propose a forward
prediction objective for simultaneously learning embeddings of states and
action sequences. These embeddings capture the structure of the environment's
dynamics, enabling efficient policy learning. We demonstrate that our action
embeddings alone improve the sample efficiency and peak performance of
model-free RL on control from low-dimensional states. By combining state and
action embeddings, we achieve efficient learning of high-quality policies on
goal-conditioned continuous control from pixel observations in only 1-2 million
environment steps.",2019-08-25,2019,2019-08,environment
Artificial Intelligence Approaches,"Artificial Intelligence (AI) has received tremendous attention from academia,
industry, and the general public in recent years. The integration of geography
and AI, or GeoAI, provides novel approaches for addressing a variety of
problems in the natural environment and our human society. This entry briefly
reviews the recent development of AI with a focus on machine learning and deep
learning approaches. We discuss the integration of AI with geography and
particularly geographic information science, and present a number of GeoAI
applications and possible future directions.",2019-08-27,2019,2019-08,environment
A Multimodal Alerting System for Online Class Quality Assurance,"Online 1 on 1 class is created for more personalized learning experience. It
demands a large number of teaching resources, which are scarce in China. To
alleviate this problem, we build a platform (marketplace), i.e., \emph{Dahai}
to allow college students from top Chinese universities to register as
part-time instructors for the online 1 on 1 classes. To warn the unqualified
instructors and ensure the overall education quality, we build a monitoring and
alerting system by utilizing multimodal information from the online
environment. Our system mainly consists of two key components: banned word
detector and class quality predictor. The system performance is demonstrated
both offline and online. By conducting experimental evaluation of real-world
online courses, we are able to achieve 74.3\% alerting accuracy in our
production environment.",2019-09-01,2019,2019-09,environment
"Calibrating Wayfinding Decisions in Pedestrian Simulation Models: The
  Entropy Map","This paper presents entropy maps, an approach to describing and visualising
uncertainty among alternative potential movement intentions in pedestrian
simulation models. In particular, entropy maps show the instantaneous level of
randomness in decisions of a pedestrian agent situated in a specific point of
the simulated environment with an heatmap approach. Experimental results
highlighting the relevance of this tool supporting modelers are provided and
discussed.",2019-09-06,2019,2019-09,environment
"Agora: A Unified Asset Ecosystem Going Beyond Marketplaces and Cloud
  Services","Data, algorithms, and compute/storage infrastructure are key assets that
drive data science and artificial intelligence applications. As providing all
these assets requires a huge investment, data science and artificial
intelligence technologies are currently dominated by a small number of
providers who can afford these investments. This leads to lock-in effects and
hinders features that require a flexible exchange of assets among users. In
this vision paper, we present Agora, a unified asset ecosystem. The Agora
system provides the technical infrastructure that allows for offering and using
data and algorithms, as well as physical infrastructure components. Agora is
designed as an open ecosystem of asset marketplaces and provides to a broad
audience not only data but the entire data value chain (including computational
resources and human expertise). Agora (i) leverages a fine-grained exchange of
assets, (ii) allows for combining assets to novel applications, and (iii)
flexibly executes such applications on available resources. As a result, Agora
overcomes lock-in effects and removes entry barriers for new asset providers.
In contrast to existing data management systems, Agora operates in a heavily
decentralized and dynamic environment: Data, algorithms, and even compute
resources are dynamically created, modified, and removed by different
stakeholders. Agora presents novel research directions for the data management
community as a whole: It requires to combine our traditional expertise in
scalable data processing and management with infrastructure provisioning as
well as economic and application aspects of data, algorithms, and
infrastructure.",2019-09-06,2019,2019-09,environment
"The Animal-AI Environment: Training and Testing Animal-Like Artificial
  Cognition","Recent advances in artificial intelligence have been strongly driven by the
use of game environments for training and evaluating agents. Games are often
accessible and versatile, with well-defined state-transitions and goals
allowing for intensive training and experimentation. However, agents trained in
a particular environment are usually tested on the same or slightly varied
distributions, and solutions do not necessarily imply any understanding. If we
want AI systems that can model and understand their environment, we need
environments that explicitly test for this. Inspired by the extensive
literature on animal cognition, we present an environment that keeps all the
positive elements of standard gaming environments, but is explicitly designed
for the testing of animal-like artificial cognition.",2019-09-12,2019,2019-09,environment
"Towards Sharing Task Environments to Support Reproducible Evaluations of
  Interactive Recommender Systems","Beyond sharing datasets or simulations, we believe the Recommender Systems
(RS) community should share Task Environments. In this work, we propose a
high-level logical architecture that will help to reason about the core
components of a RS Task Environment, identify the differences between
Environments, datasets and simulations; and most importantly, understand what
needs to be shared about Environments to achieve reproducible experiments. The
work presents itself as valuable initial groundwork, open to discussion and
extensions.",2019-09-13,2019,2019-09,environment
Responsive Planning and Recognition for Closed-Loop Interaction,"Many intelligent systems currently interact with others using at least one of
fixed communication inputs or preset responses, resulting in rigid interaction
experiences and extensive efforts developing a variety of scenarios for the
system. Fixed inputs limit the natural behavior of the user in order to
effectively communicate, and preset responses prevent the system from adapting
to the current situation unless it was specifically implemented. Closed-loop
interaction instead focuses on dynamic responses that account for what the user
is currently doing based on interpretations of their perceived activity. Agents
employing closed-loop interaction can also monitor their interactions to ensure
that the user responds as expected. We introduce a closed-loop interactive
agent framework that integrates planning and recognition to predict what the
user is trying to accomplish and autonomously decide on actions to take in
response to these predictions. Based on a recent demonstration of such an
assistive interactive agent in a turn-based simulated game, we also discuss new
research challenges that are not present in the areas of artificial
intelligence planning or recognition alone.",2019-09-13,2019,2019-09,environment
MDP Playground: An Analysis and Debug Testbed for Reinforcement Learning,"We present MDP Playground, a testbed for Reinforcement Learning (RL) agents
with dimensions of hardness that can be controlled independently to challenge
agents in different ways and obtain varying degrees of hardness in toy and
complex RL environments. We consider and allow control over a wide variety of
dimensions, including delayed rewards, sequence lengths, reward density,
stochasticity, image representations, irrelevant features, time unit, action
range and more. We define a parameterised collection of fast-to-run toy
environments in OpenAI Gym by varying these dimensions and propose to use these
to understand agents better. We then show how to design experiments using MDP
Playground to gain insights on the toy environments. We also provide wrappers
that can inject many of these dimensions into any Gym environment. We
experiment with these wrappers on Atari and Mujoco to allow for understanding
the effects of these dimensions on environments that are more complex than the
toy environments. We also compare the effect of the dimensions on the toy and
complex environments. Finally, we show how to use MDP Playground to debug
agents, to study the interaction of multiple dimensions and describe further
use-cases.",2019-09-17,2019,2019-09,environment
Reasoning in Highly Reactive Environments,"The aim of my Ph.D. thesis concerns Reasoning in Highly Reactive
Environments. As reasoning in highly reactive environments, we identify the
setting in which a knowledge-based agent, with given goals, is deployed in an
environment subject to repeated, sudden and possibly unknown changes. This is
for instance the typical setting in which, e.g., artificial agents for
video-games (the so called ""bots""), cleaning robots, bomb clearing robots, and
so on are deployed. In all these settings one can follow the classical approach
in which the operations of the agent are distinguished in ""sensing"" the
environment with proper interface devices, ""thinking"", and then behaving
accordingly using proper actuators. In order to operate in an highly reactive
environment, an artificial agent needs to be: 1. Responsive -> The agent must
be able to react repeatedly and in a reasonable amount of time; 2. Elastic ->
The agent must stay reactive also under varying workload; 3. Resilient -> The
agent must stay responsive also in case of internal failure or failure of one
of the programmed actions in the environment. Nowadays, thanks to new
technologies in the field of Artificial Intelligence, it is already technically
possible to create AI agents that are able to operate in reactive environments.
Nevertheless, several issues stay unsolved, and are subject of ongoing
research.",2019-09-18,2019,2019-09,environment
Deep Q-Network for Angry Birds,"Angry Birds is a popular video game in which the player is provided with a
sequence of birds to shoot from a slingshot. The task of the game is to destroy
all green pigs with maximum possible score. Angry Birds appears to be a
difficult task to solve for artificially intelligent agents due to the
sequential decision-making, non-deterministic game environment, enormous state
and action spaces and requirement to differentiate between multiple birds,
their abilities and optimum tapping times. We describe the application of Deep
Reinforcement learning by implementing Double Dueling Deep Q-network to play
Angry Birds game. One of our main goals was to build an agent that is able to
compete with previous participants and humans on the first 21 levels. In order
to do so, we have collected a dataset of game frames that we used to train our
agent on. We present different approaches and settings for DQN agent. We
evaluate our agent using results of the previous participants of AIBirds
competition, results of volunteer human players and present the results of
AIBirds 2018 competition.",2019-10-04,2019,2019-10,environment
"Using AI/ML to gain situational understanding from passive network
  observations","The data available in the network traffic fromany Government building
contains a significant amount ofinformation. An analysis of the traffic can
yield insightsand situational understanding about what is happening inthe
building. However, the use of traditional network packet inspection, either
deep or shallow, is useful for only a limited understanding of the environment,
with applicability limited to some aspects of network and security management.
If weuse AI/ML based techniques to understand the network traffic, we can gain
significant insights which increase our situational awareness of what is
happening in the environment.At IBM, we have created a system which uses a
combination of network domain knowledge and machine learning techniques to
convert network traffic into actionable insights about the on premise
environment. These insights include characterization of the communicating
devices, discovering unauthorized devices that may violate policy requirements,
identifying hidden components and vulnerability points, detecting leakage of
sensitive information, and identifying the presence of people and devices.In
this paper, we will describe the overall design of this system, the major
use-cases that have been identified for it, and the lessons learnt when
deploying this system for some of those use-cases",2019-10-14,2019,2019-10,environment
"How a minimal learning agent can infer the existence of unobserved
  variables in a complex environment","According to a mainstream position in contemporary cognitive science and
philosophy, the use of abstract compositional concepts is both a necessary and
a sufficient condition for the presence of genuine thought. In this article, we
show how the ability to develop and utilise abstract conceptual structures can
be achieved by a particular kind of learning agents. More specifically, we
provide and motivate a concrete operational definition of what it means for
these agents to be in possession of abstract concepts, before presenting an
explicit example of a minimal architecture that supports this capability. We
then proceed to demonstrate how the existence of abstract conceptual structures
can be operationally useful in the process of employing previously acquired
knowledge in the face of new experiences, thereby vindicating the natural
conjecture that the cognitive functions of abstraction and generalisation are
closely related.
  Keywords: concept formation, projective simulation, reinforcement learning,
transparent artificial intelligence, theory formation, explainable artificial
intelligence (XAI)",2019-10-15,2019,2019-10,environment
Explainable Semantic Mapping for First Responders,"One of the key challenges in the semantic mapping problem in postdisaster
environments is how to analyze a large amount of data efficiently with minimal
supervision. To address this challenge, we propose a deep learning-based
semantic mapping tool consisting of three main ideas. First, we develop a
frugal semantic segmentation algorithm that uses only a small amount of labeled
data. Next, we investigate on the problem of learning to detect a new class of
object using just a few training examples. Finally, we develop an explainable
cost map learning algorithm that can be quickly trained to generate
traversability cost maps using only raw sensor data such as aerial-view
imagery. This paper presents an overview of the proposed idea and the lessons
learned.",2019-10-15,2019,2019-10,environment
RTFM: Generalising to Novel Environment Dynamics via Reading,"Obtaining policies that can generalise to new environments in reinforcement
learning is challenging. In this work, we demonstrate that language
understanding via a reading policy learner is a promising vehicle for
generalisation to new environments. We propose a grounded policy learning
problem, Read to Fight Monsters (RTFM), in which the agent must jointly reason
over a language goal, relevant dynamics described in a document, and
environment observations. We procedurally generate environment dynamics and
corresponding language descriptions of the dynamics, such that agents must read
to understand new environment dynamics instead of memorising any particular
information. In addition, we propose txt2$\pi$, a model that captures three-way
interactions between the goal, document, and observations. On RTFM, txt2$\pi$
generalises to new environments with dynamics not seen during training via
reading. Furthermore, our model outperforms baselines such as FiLM and
language-conditioned CNNs on RTFM. Through curriculum learning, txt2$\pi$
produces policies that excel on complex RTFM tasks requiring several reasoning
and coreference steps.",2019-10-18,2019,2019-10,environment
Robot-Friendly Cities,"Robots are increasingly tested in public spaces, towards a future where urban
environments are not only for humans but for autonomous systems. While robots
are promising, for convenience and efficiency, there are challenges associated
with building cities crowded with machines. This paper provides an overview of
the problems and some solutions, and calls for greater attention on this
matter.",2019-10-22,2019,2019-10,environment
"Robotic Hierarchical Graph Neurons. A novel implementation of HGN for
  swarm robotic behaviour control","This paper explores the use of a novel form of Hierarchical Graph Neurons
(HGN) for in-operation behaviour selection in a swarm of robotic agents. This
new HGN is called Robotic-HGN (R-HGN), as it matches robot environment
observations to environment labels via fusion of match probabilities from both
temporal and intra-swarm collections. This approach is novel for HGN as it
addresses robotic observations being pseudo-continuous numbers, rather than
categorical values. Additionally, the proposed approach is memory and
computation-power conservative and thus is acceptable for use in mobile devices
such as single-board computers, which are often used in mobile robotic agents.
This R-HGN approach is validated against individual behaviour implementation
and random behaviour selection. This contrast is made in two sets of simulated
environments: environments designed to challenge the held behaviours of the
R-HGN, and randomly generated environments which are more challenging for the
robotic swarm than R-HGN training conditions. R-HGN has been found to enable
appropriate behaviour selection in both these sets, allowing significant swarm
performance in pre-trained and unexpected environment conditions.",2019-10-28,2019,2019-10,environment
RBED: Reward Based Epsilon Decay,"$\varepsilon$-greedy is a policy used to balance exploration and exploitation
in many reinforcement learning setting. In cases where the agent uses some
on-policy algorithm to learn optimal behaviour, it makes sense for the agent to
explore more initially and eventually exploit more as it approaches the target
behaviour. This shift from heavy exploration to heavy exploitation can be
represented as decay in the $\varepsilon$ value, where $\varepsilon$ depicts
the how much an agent is allowed to explore. This paper proposes a new approach
to this $\varepsilon$ decay where the decay is based on feedback from the
environment. This paper also compares and contrasts one such approach based on
rewards and compares it against standard exponential decay. The new approach,
in the environments tested, produces more consistent results that on average
perform better.",2019-10-30,2019,2019-10,environment
"Continuous Control with Contexts, Provably","A fundamental challenge in artificial intelligence is to build an agent that
generalizes and adapts to unseen environments. A common strategy is to build a
decoder that takes the context of the unseen new environment as input and
generates a policy accordingly. The current paper studies how to build a
decoder for the fundamental continuous control task, linear quadratic regulator
(LQR), which can model a wide range of real-world physical environments. We
present a simple algorithm for this problem, which uses upper confidence bound
(UCB) to refine the estimate of the decoder and balance the
exploration-exploitation trade-off. Theoretically, our algorithm enjoys a
$\widetilde{O}\left(\sqrt{T}\right)$ regret bound in the online setting where
$T$ is the number of environments the agent played. This also implies after
playing $\widetilde{O}\left(1/\epsilon^2\right)$ environments, the agent is
able to transfer the learned knowledge to obtain an $\epsilon$-suboptimal
policy for an unseen environment. To our knowledge, this is first provably
efficient algorithm to build a decoder in the continuous control setting. While
our main focus is theoretical, we also present experiments that demonstrate the
effectiveness of our algorithm.",2019-10-30,2019,2019-10,environment
"A Perceived Environment Design using a Multi-Modal Variational
  Autoencoder for learning Active-Sensing","This contribution comprises the interplay between a multi-modal variational
autoencoder and an environment to a perceived environment, on which an agent
can act. Furthermore, we conclude our work with a comparison to
curiosity-driven learning.",2019-11-01,2019,2019-11,environment
"Artificial Intelligence Strategies for National Security and Safety
  Standards","Recent advances in artificial intelligence (AI) have lead to an explosion of
multimedia applications (e.g., computer vision (CV) and natural language
processing (NLP)) for different domains such as commercial, industrial, and
intelligence. In particular, the use of AI applications in a national security
environment is often problematic because the opaque nature of the systems leads
to an inability for a human to understand how the results came about. A
reliance on 'black boxes' to generate predictions and inform decisions is
potentially disastrous. This paper explores how the application of standards
during each stage of the development of an AI system deployed and used in a
national security environment would help enable trust. Specifically, we focus
on the standards outlined in Intelligence Community Directive 203 (Analytic
Standards) to subject machine outputs to the same rigorous standards as
analysis performed by humans.",2019-11-03,2019,2019-11,environment
Being Optimistic to Be Conservative: Quickly Learning a CVaR Policy,"While maximizing expected return is the goal in most reinforcement learning
approaches, risk-sensitive objectives such as conditional value at risk (CVaR)
are more suitable for many high-stakes applications. However, relatively little
is known about how to explore to quickly learn policies with good CVaR. In this
paper, we present the first algorithm for sample-efficient learning of
CVaR-optimal policies in Markov decision processes based on the optimism in the
face of uncertainty principle. This method relies on a novel optimistic version
of the distributional Bellman operator that moves probability mass from the
lower to the upper tail of the return distribution. We prove asymptotic
convergence and optimism of this operator for the tabular policy evaluation
case. We further demonstrate that our algorithm finds CVaR-optimal policies
substantially faster than existing baselines in several simulated environments
with discrete and continuous state spaces.",2019-11-05,2019,2019-11,environment
"SIMMC: Situated Interactive Multi-Modal Conversational Data Collection
  And Evaluation Platform","As digital virtual assistants become ubiquitous, it becomes increasingly
important to understand the situated behaviour of users as they interact with
these assistants. To this end, we introduce SIMMC, an extension to ParlAI for
multi-modal conversational data collection and system evaluation. SIMMC
simulates an immersive setup, where crowd workers are able to interact with
environments constructed in AI Habitat or Unity while engaging in a
conversation. The assistant in SIMMC can be a crowd worker or Artificial
Intelligent (AI) agent. This enables both (i) a multi-player / Wizard of Oz
setting for data collection, or (ii) a single player mode for model / system
evaluation. We plan to open-source a situated conversational data-set collected
on this platform for the Conversational AI research community.",2019-11-07,2019,2019-11,environment
"Explainable Artificial Intelligence (XAI) for 6G: Improving Trust
  between Human and Machine","As the 5th Generation (5G) mobile networks are bringing about global societal
benefits, the design phase for the 6th Generation (6G) has started. 6G will
need to enable greater levels of autonomy, improve human machine interfacing,
and achieve deep connectivity in more diverse environments. The need for
increased explainability to enable trust is critical for 6G as it manages a
wide range of mission critical services (e.g. autonomous driving) to safety
critical tasks (e.g. remote surgery). As we migrate from traditional
model-based optimisation to deep learning, the trust we have in our
optimisation modules decrease. This loss of trust means we cannot understand
the impact of: 1) poor/bias/malicious data, and 2) neural network design on
decisions; nor can we explain to the engineer or the public the network's
actions. In this review, we outline the core concepts of Explainable Artificial
Intelligence (XAI) for 6G, including: public and legal motivations, definitions
of explainability, performance vs. explainability trade-offs, methods to
improve explainability, and frameworks to incorporate XAI into future wireless
systems. Our review is grounded in cases studies for both PHY and MAC layer
optimisation, and provide the community with an important research area to
embark upon.",2019-11-11,2019,2019-11,environment
"IKEA Furniture Assembly Environment for Long-Horizon Complex
  Manipulation Tasks","The IKEA Furniture Assembly Environment is one of the first benchmarks for
testing and accelerating the automation of complex manipulation tasks. The
environment is designed to advance reinforcement learning from simple toy tasks
to complex tasks requiring both long-term planning and sophisticated low-level
control. Our environment supports over 80 different furniture models, Sawyer
and Baxter robot simulation, and domain randomization. The IKEA Furniture
Assembly Environment is a testbed for methods aiming to solve complex
manipulation tasks. The environment is publicly available at
https://clvrai.com/furniture",2019-11-17,2019,2019-11,environment
Hierarchical Average Reward Policy Gradient Algorithms,"Option-critic learning is a general-purpose reinforcement learning (RL)
framework that aims to address the issue of long term credit assignment by
leveraging temporal abstractions. However, when dealing with extended
timescales, discounting future rewards can lead to incorrect credit
assignments. In this work, we address this issue by extending the hierarchical
option-critic policy gradient theorem for the average reward criterion. Our
proposed framework aims to maximize the long-term reward obtained in the
steady-state of the Markov chain defined by the agent's policy. Furthermore, we
use an ordinary differential equation based approach for our convergence
analysis and prove that the parameters of the intra-option policies,
termination functions, and value functions, converge to their corresponding
optimal values, with probability one. Finally, we illustrate the competitive
advantage of learning options, in the average reward setting, on a grid-world
environment with sparse rewards.",2019-11-20,2019,2019-11,environment
Agent Probing Interaction Policies,"Reinforcement learning in a multi agent system is difficult because these
systems are inherently non-stationary in nature. In such a case, identifying
the type of the opposite agent is crucial and can help us address this
non-stationary environment. We have investigated if we can employ some probing
policies which help us better identify the type of the other agent in the
environment. We've made a simplifying assumption that the other agent has a
stationary policy that our probing policy is trying to approximate. Our work
extends Environmental Probing Interaction Policy framework to handle multi
agent environments.",2019-11-21,2019,2019-11,environment
Information-Theoretic Confidence Bounds for Reinforcement Learning,"We integrate information-theoretic concepts into the design and analysis of
optimistic algorithms and Thompson sampling. By making a connection between
information-theoretic quantities and confidence bounds, we obtain results that
relate the per-period performance of the agent with its information gain about
the environment, thus explicitly characterizing the exploration-exploitation
tradeoff. The resulting cumulative regret bound depends on the agent's
uncertainty over the environment and quantifies the value of prior information.
We show applicability of this approach to several environments, including
linear bandits, tabular MDPs, and factored MDPs. These examples demonstrate the
potential of a general information-theoretic approach for the design and
analysis of reinforcement learning algorithms.",2019-11-21,2019,2019-11,environment
The PlayStation Reinforcement Learning Environment (PSXLE),"We propose a new benchmark environment for evaluating Reinforcement Learning
(RL) algorithms: the PlayStation Learning Environment (PSXLE), a PlayStation
emulator modified to expose a simple control API that enables rich game-state
representations. We argue that the PlayStation serves as a suitable progression
for agent evaluation and propose a framework for such an evaluation. We build
an action-driven abstraction for a PlayStation game with support for the OpenAI
Gym interface and demonstrate its use by running OpenAI Baselines.",2019-12-12,2019,2019-12,environment
"Point-Based Methods for Model Checking in Partially Observable Markov
  Decision Processes","Autonomous systems are often required to operate in partially observable
environments. They must reliably execute a specified objective even with
incomplete information about the state of the environment. We propose a
methodology to synthesize policies that satisfy a linear temporal logic formula
in a partially observable Markov decision process (POMDP). By formulating a
planning problem, we show how to use point-based value iteration methods to
efficiently approximate the maximum probability of satisfying a desired logical
formula and compute the associated belief state policy. We demonstrate that our
method scales to large POMDP domains and provides strong bounds on the
performance of the resulting policy.",2020-01-11,2020,2020-01,environment
Knowledge Representations in Technical Systems -- A Taxonomy,"The recent usage of technical systems in human-centric environments leads to
the question, how to teach technical systems, e.g., robots, to understand,
learn, and perform tasks desired by the human. Therefore, an accurate
representation of knowledge is essential for the system to work as expected.
This article mainly gives insight into different knowledge representation
techniques and their categorization into various problem domains in artificial
intelligence. Additionally, applications of presented knowledge representations
are introduced in everyday robotics tasks. By means of the provided taxonomy,
the search for a proper knowledge representation technique regarding a specific
problem should be facilitated.",2020-01-14,2020,2020-01,environment
"A Survey of Reinforcement Learning Techniques: Strategies, Recent
  Development, and Future Directions","Reinforcement learning is one of the core components in designing an
artificial intelligent system emphasizing real-time response. Reinforcement
learning influences the system to take actions within an arbitrary environment
either having previous knowledge about the environment model or not. In this
paper, we present a comprehensive study on Reinforcement Learning focusing on
various dimensions including challenges, the recent development of different
state-of-the-art techniques, and future directions. The fundamental objective
of this paper is to provide a framework for the presentation of available
methods of reinforcement learning that is informative enough and simple to
follow for the new researchers and academics in this domain considering the
latest concerns. First, we illustrated the core techniques of reinforcement
learning in an easily understandable and comparable way. Finally, we analyzed
and depicted the recent developments in reinforcement learning approaches. My
analysis pointed out that most of the models focused on tuning policy values
rather than tuning other things in a particular state of reasoning.",2020-01-19,2020,2020-01,environment
Artificial Intelligence Aided Next-Generation Networks Relying on UAVs,"Artificial intelligence (AI) assisted unmanned aerial vehicle (UAV) aided
next-generation networking is proposed for dynamic environments. In the
AI-enabled UAV-aided wireless networks (UAWN), multiple UAVs are employed as
aerial base stations, which are capable of rapidly adapting to the dynamic
environment by collecting information about the users' position and
tele-traffic demands, learning from the environment and acting upon the
feedback received from the users. Moreover, AI enables the interaction amongst
a swarm of UAVs for cooperative optimization of the system. As a benefit of the
AI framework, several challenges of conventional UAWN may be circumvented,
leading to enhanced network performance, improved reliability and agile
adaptivity. As a further benefit, dynamic trajectory design and resource
allocation are demonstrated. Finally, potential research challenges and
opportunities are discussed.",2020-01-28,2020,2020-01,environment
"On the Convergence of Artificial Intelligence and Distributed Ledger
  Technology: A Scoping Review and Future Research Agenda","Developments in Artificial Intelligence (AI) and Distributed Ledger
Technology (DLT) currently lead to lively debates in academia and practice. AI
processes data to perform tasks that were previously thought possible only for
humans. DLT has the potential to create consensus over data among a group of
participants in uncertain environments. In recent research, both technologies
are used in similar and even the same systems. Examples include the design of
secure distributed ledgers or the creation of allied learning systems
distributed across multiple nodes. This can lead to technological convergence,
which in the past, has paved the way for major innovations in information
technology. Previous work highlights several potential benefits of the
convergence of AI and DLT but only provides a limited theoretical framework to
describe upcoming real-world integration cases of both technologies. We aim to
contribute by conducting a systematic literature review on previous work and
providing rigorously derived future research opportunities. This work helps
researchers active in AI or DLT to overcome current limitations in their field,
and practitioners to develop systems along with the convergence of both
technologies.",2020-01-29,2020,2020-01,environment
Hacia los Comités de Ética en Inteligencia Artificial,"The goal of Artificial Intelligence based systems is to take decisions that
have an effect in their environment and impact society. This points out to the
necessity of mechanism that regulate the impact of this type of system in
society. For this reason, it is priority to create the rules and specialized
organizations that can oversight the following of such rules, particularly that
human rights precepts at local and international level. This work proposes the
creation, at the universities, of Ethical Committees or Commissions specialized
on Artificial Intelligence that would be in charge of define the principles and
will guarantee the following of good practices in the field Artificial
Intelligence.",2020-02-11,2020,2020-02,environment
RL agents Implicitly Learning Human Preferences,"In the real world, RL agents should be rewarded for fulfilling human
preferences. We show that RL agents implicitly learn the preferences of humans
in their environment. Training a classifier to predict if a simulated human's
preferences are fulfilled based on the activations of a RL agent's neural
network gets .93 AUC. Training a classifier on the raw environment state gets
only .8 AUC. Training the classifier off of the RL agent's activations also
does much better than training off of activations from an autoencoder. The
human preference classifier can be used as the reward function of an RL agent
to make RL agent more beneficial for humans.",2020-02-14,2020,2020-02,environment
"Wireless 2.0: Towards an Intelligent Radio Environment Empowered by
  Reconfigurable Meta-Surfaces and Artificial Intelligence","We introduce ""Wireless 2.0"": The future generation of wireless communication
networks, where the radio environment becomes controllable, programmable, and
intelligent by leveraging the emerging technologies of reconfigurable
metasurfaces and artificial intelligence (AI). This paper, in particular, puts
the emphasis on AI-based computational methods and commence with an overview of
the concept of intelligent radio environments based on reconfigurable
meta-surfaces. Later we elaborate on data management aspects, the requirements
of supervised learning by examples, and the paradigm of reinforcement learning
(RL) to learn by acting. Finally, we highlight numerous open challenges and
research directions.",2020-02-23,2020,2020-02,environment
"Facets of the PIE Environment for Proving, Interpolating and Eliminating
  on the Basis of First-Order Logic","PIE is a Prolog-embedded environment for automated reasoning on the basis of
first-order logic. Its main focus is on formulas, as constituents of complex
formalizations that are structured through formula macros, and as outputs of
reasoning tasks such as second-order quantifier elimination and Craig
interpolation. It supports a workflow based on documents that intersperse macro
definitions, invocations of reasoners, and LaTeX-formatted natural language
text. Starting from various examples, the paper discusses features and
application possibilities of PIE along with current limitations and issues for
future research.",2020-02-24,2020,2020-02,environment
TanksWorld: A Multi-Agent Environment for AI Safety Research,"The ability to create artificial intelligence (AI) capable of performing
complex tasks is rapidly outpacing our ability to ensure the safe and assured
operation of AI-enabled systems. Fortunately, a landscape of AI safety research
is emerging in response to this asymmetry and yet there is a long way to go. In
particular, recent simulation environments created to illustrate AI safety
risks are relatively simple or narrowly-focused on a particular issue. Hence,
we see a critical need for AI safety research environments that abstract
essential aspects of complex real-world applications. In this work, we
introduce the AI safety TanksWorld as an environment for AI safety research
with three essential aspects: competing performance objectives, human-machine
teaming, and multi-agent competition. The AI safety TanksWorld aims to
accelerate the advancement of safe multi-agent decision-making algorithms by
providing a software framework to support competitions with both system
performance and safety objectives. As a work in progress, this paper introduces
our research objectives and learning environment with reference code and
baseline performance metrics to follow in a future work.",2020-02-25,2020,2020-02,environment
"Environment-agnostic Multitask Learning for Natural Language Grounded
  Navigation","Recent research efforts enable study for natural language grounded navigation
in photo-realistic environments, e.g., following natural language instructions
or dialog. However, existing methods tend to overfit training data in seen
environments and fail to generalize well in previously unseen environments. To
close the gap between seen and unseen environments, we aim at learning a
generalized navigation model from two novel perspectives: (1) we introduce a
multitask navigation model that can be seamlessly trained on both
Vision-Language Navigation (VLN) and Navigation from Dialog History (NDH)
tasks, which benefits from richer natural language guidance and effectively
transfers knowledge across tasks; (2) we propose to learn environment-agnostic
representations for the navigation policy that are invariant among the
environments seen during training, thus generalizing better on unseen
environments. Extensive experiments show that environment-agnostic multitask
learning significantly reduces the performance gap between seen and unseen
environments, and the navigation agent trained so outperforms baselines on
unseen environments by 16% (relative measure on success rate) on VLN and 120%
(goal progress) on NDH. Our submission to the CVDN leaderboard establishes a
new state-of-the-art for the NDH task on the holdout test set. Code is
available at https://github.com/google-research/valan.",2020-03-01,2020,2020-03,environment
"Developing and Operating Artificial Intelligence Models in Trustworthy
  Autonomous Systems","Companies dealing with Artificial Intelligence (AI) models in Autonomous
Systems (AS) face several problems, such as users' lack of trust in adverse or
unknown conditions, gaps between software engineering and AI model development,
and operation in a continuously changing operational environment. This
work-in-progress paper aims to close the gap between the development and
operation of trustworthy AI-based AS by defining an approach that coordinates
both activities. We synthesize the main challenges of AI-based AS in industrial
settings. We reflect on the research efforts required to overcome these
challenges and propose a novel, holistic DevOps approach to put it into
practice. We elaborate on four research directions: (a) increased users' trust
by monitoring operational AI-based AS and identifying self-adaptation needs in
critical situations; (b) integrated agile process for the development and
evolution of AI models and AS; (c) continuous deployment of different
context-specific instances of AI models in a distributed setting of AS; and (d)
holistic DevOps-based lifecycle for AI-based AS.",2020-03-11,2020,2020-03,environment
"Beyond STEM, How Can Women Engage Big Data, Analytics, Robotics and
  Artificial Intelligence? An Exploratory Analysis of Confidence and
  Educational Factors in the Emerging Technology Waves Influencing the Role of,
  and Impact Upon, Women","In spite of the rapidly advancing global technological environment, the
professional participation of women in technology, big data, analytics,
artificial intelligence and information systems related domains remains
proportionately low. Furthermore, it is of no less concern that the number of
women in leadership in these domains are in even lower proportions. In spite of
numerous initiatives to improve the participation of women in technological
domains, there is an increasing need to gain additional insights into this
phenomenon especially since it occurs in nations and geographies which have
seen a sharp rise in overall female education, without such increase
translating into a corresponding spurt in information systems and technological
roles for women. The present paper presents findings from an exploratory
analysis and outlines a framework to gain insights into educational factors in
the emerging technology waves influencing the role of, and impact upon, women.
We specifically identify ways for learning and self-efficacy as key factors,
which together lead us to the Advancement of Women in Technology (AWT) insights
framework. Based on the AWT framework, we also proposition principles that can
be used to encourage higher professional engagement of women in emerging and
advanced technologies. Key Words- Women's Education, Technology, Artificial
Intelligence, Knowing, Confidence, Self-Efficacy, Learning.",2020-03-26,2020,2020-03,environment
Trust-based Multiagent Consensus or Weightings Aggregation,"We introduce a framework for reaching a consensus amongst several agents
communicating via a trust network on conflicting information about their
environment. We formalise our approach and provide an empirical and theoretical
analysis of its properties.",2020-04-06,2020,2020-04,environment
Adaptive Transformers in RL,"Recent developments in Transformers have opened new interesting areas of
research in partially observable reinforcement learning tasks. Results from
late 2019 showed that Transformers are able to outperform LSTMs on both memory
intense and reactive tasks. In this work we first partially replicate the
results shown in Stabilizing Transformers in RL on both reactive and memory
based environments. We then show performance improvement coupled with reduced
computation when adding adaptive attention span to this Stable Transformer on a
challenging DMLab30 environment. The code for all our experiments and models is
available at https://github.com/jerrodparker20/adaptive-transformers-in-rl.",2020-04-08,2020,2020-04,environment
Reinforcement Learning in a Physics-Inspired Semi-Markov Environment,"Reinforcement learning (RL) has been demonstrated to have great potential in
many applications of scientific discovery and design. Recent work includes, for
example, the design of new structures and compositions of molecules for
therapeutic drugs. Much of the existing work related to the application of RL
to scientific domains, however, assumes that the available state representation
obeys the Markov property. For reasons associated with time, cost, sensor
accuracy, and gaps in scientific knowledge, many scientific design and
discovery problems do not satisfy the Markov property. Thus, something other
than a Markov decision process (MDP) should be used to plan / find the optimal
policy. In this paper, we present a physics-inspired semi-Markov RL
environment, namely the phase change environment. In addition, we evaluate the
performance of value-based RL algorithms for both MDPs and partially observable
MDPs (POMDPs) on the proposed environment. Our results demonstrate deep
recurrent Q-networks (DRQN) significantly outperform deep Q-networks (DQN), and
that DRQNs benefit from training with hindsight experience replay. Implications
for the use of semi-Markovian RL and POMDPs for scientific laboratories are
also discussed.",2020-04-15,2020,2020-04,environment
Intention as Commitment toward Time,"In this paper we address the interplay among intention, time, and belief in
dynamic environments. The first contribution is a logic for reasoning about
intention, time and belief, in which assumptions of intentions are represented
by preconditions of intended actions. Intentions and beliefs are coherent as
long as these assumptions are not violated, i.e. as long as intended actions
can be performed such that their preconditions hold as well. The second
contribution is the formalization of what-if scenarios: what happens with
intentions and beliefs if a new (possibly conflicting) intention is adopted, or
a new fact is learned? An agent is committed to its intended actions as long as
its belief-intention database is coherent. We conceptualize intention as
commitment toward time and we develop AGM-based postulates for the iterated
revision of belief-intention databases, and we prove a Katsuno-Mendelzon-style
representation theorem.",2020-04-17,2020,2020-04,environment
"SAIA: Split Artificial Intelligence Architecture for Mobile Healthcare
  System","As the advancement of deep learning (DL), the Internet of Things and cloud
computing techniques for biomedical and healthcare problems, mobile healthcare
systems have received unprecedented attention. Since DL techniques usually
require enormous amount of computation, most of them cannot be directly
deployed on the resource-constrained mobile and IoT devices. Hence, most of the
mobile healthcare systems leverage the cloud computing infrastructure, where
the data collected by the mobile and IoT devices would be transmitted to the
cloud computing platforms for analysis. However, in the contested environments,
relying on the cloud might not be practical at all times. For instance, the
satellite communication might be denied or disrupted. We propose SAIA, a Split
Artificial Intelligence Architecture for mobile healthcare systems. Unlike
traditional approaches for artificial intelligence (AI) which solely exploits
the computational power of the cloud server, SAIA could not only relies on the
cloud computing infrastructure while the wireless communication is available,
but also utilizes the lightweight AI solutions that work locally on the client
side, hence, it can work even when the communication is impeded. In SAIA, we
propose a meta-information based decision unit, that could tune whether a
sample captured by the client should be operated by the embedded AI (i.e.,
keeping on the client) or the networked AI (i.e., sending to the server), under
different conditions. In our experimental evaluation, extensive experiments
have been conducted on two popular healthcare datasets. Our results show that
SAIA consistently outperforms its baselines in terms of both effectiveness and
efficiency.",2020-04-25,2020,2020-04,environment
Reinforcement Learning Generalization with Surprise Minimization,"Generalization remains a challenging problem for deep reinforcement learning
algorithms, which are often trained and tested on the same set of deterministic
game environments. When test environments are unseen and perturbed but the
nature of the task remains the same, generalization gaps can arise. In this
work, we propose and evaluate a surprise minimizing agent on a generalization
benchmark to show an additional reward learned from a simple density model can
show robustness in procedurally generated game environments that provide
constant source of entropy and stochasticity.",2020-04-26,2020,2020-04,environment
"Enhancing Text-based Reinforcement Learning Agents with Commonsense
  Knowledge","In this paper, we consider the recent trend of evaluating progress on
reinforcement learning technology by using text-based environments and games as
evaluation environments. This reliance on text brings advances in natural
language processing into the ambit of these agents, with a recurring thread
being the use of external knowledge to mimic and better human-level
performance. We present one such instantiation of agents that use commonsense
knowledge from ConceptNet to show promising performance on two text-based
environments.",2020-05-02,2020,2020-05,environment
"A Survey of Algorithms for Black-Box Safety Validation of Cyber-Physical
  Systems","Autonomous cyber-physical systems (CPS) can improve safety and efficiency for
safety-critical applications, but require rigorous testing before deployment.
The complexity of these systems often precludes the use of formal verification
and real-world testing can be too dangerous during development. Therefore,
simulation-based techniques have been developed that treat the system under
test as a black box operating in a simulated environment. Safety validation
tasks include finding disturbances in the environment that cause the system to
fail (falsification), finding the most-likely failure, and estimating the
probability that the system fails. Motivated by the prevalence of
safety-critical artificial intelligence, this work provides a survey of
state-of-the-art safety validation techniques for CPS with a focus on applied
algorithms and their modifications for the safety validation problem. We
present and discuss algorithms in the domains of optimization, path planning,
reinforcement learning, and importance sampling. Problem decomposition
techniques are presented to help scale algorithms to large state spaces, which
are common for CPS. A brief overview of safety-critical applications is given,
including autonomous vehicles and aircraft collision avoidance systems.
Finally, we present a survey of existing academic and commercially available
safety validation tools.",2020-05-06,2020,2020-05,environment
"Controlling Overestimation Bias with Truncated Mixture of Continuous
  Distributional Quantile Critics","The overestimation bias is one of the major impediments to accurate
off-policy learning. This paper investigates a novel way to alleviate the
overestimation bias in a continuous control setting. Our method---Truncated
Quantile Critics, TQC,---blends three ideas: distributional representation of a
critic, truncation of critics prediction, and ensembling of multiple critics.
Distributional representation and truncation allow for arbitrary granular
overestimation control, while ensembling provides additional score
improvements. TQC outperforms the current state of the art on all environments
from the continuous control benchmark suite, demonstrating 25% improvement on
the most challenging Humanoid environment.",2020-05-08,2020,2020-05,environment
"Design of a dynamic and self adapting system, supported with artificial
  intelligence, machine learning and real time intelligence for predictive
  cyber risk analytics in extreme environments, cyber risk in the colonisation
  of Mars","Multiple governmental agencies and private organisations have made
commitments for the colonisation of Mars. Such colonisation requires complex
systems and infrastructure that could be very costly to repair or replace in
cases of cyber attacks. This paper surveys deep learning algorithms, IoT cyber
security and risk models, and established mathematical formulas to identify the
best approach for developing a dynamic and self adapting system for predictive
cyber risk analytics supported with Artificial Intelligence and Machine
Learning and real time intelligence in edge computing. The paper presents a new
mathematical approach for integrating concepts for cognition engine design,
edge computing and Artificial Intelligence and Machine Learning to automate
anomaly detection. This engine instigates a step change by applying Artificial
Intelligence and Machine Learning embedded at the edge of IoT networks, to
deliver safe and functional real time intelligence for predictive cyber risk
analytics. This will enhance capacities for risk analytics and assists in the
creation of a comprehensive and systematic understanding of the opportunities
and threats that arise when edge computing nodes are deployed, and when
Artificial Intelligence and Machine Learning technologies are migrated to the
periphery of the internet and into local IoT networks.",2020-05-19,2020,2020-05,environment
"Information Acquisition Under Resource Limitations in a Noisy
  Environment","We introduce a theoretical model of information acquisition under resource
limitations in a noisy environment. An agent must guess the truth value of a
given Boolean formula $\varphi$ after performing a bounded number of noisy
tests of the truth values of variables in the formula. We observe that, in
general, the problem of finding an optimal testing strategy for $\phi$ is hard,
but we suggest a useful heuristic. The techniques we use also give insight into
two apparently unrelated, but well-studied problems: (1) \emph{rational
inattention}, that is, when it is rational to ignore pertinent information (the
optimal strategy may involve hardly ever testing variables that are clearly
relevant to $\phi$), and (2) what makes a formula hard to learn/remember.",2020-05-20,2020,2020-05,environment
Regulating Artificial Intelligence: Proposal for a Global Solution,"With increasing ubiquity of artificial intelligence (AI) in modern societies,
individual countries and the international community are working hard to create
an innovation-friendly, yet safe, regulatory environment. Adequate regulation
is key to maximize the benefits and minimize the risks stemming from AI
technologies. Developing regulatory frameworks is, however, challenging due to
AI's global reach and the existence of widespread misconceptions about the
notion of regulation. We argue that AI-related challenges cannot be tackled
effectively without sincere international coordination supported by robust,
consistent domestic and international governance arrangements. Against this
backdrop, we propose the establishment of an international AI governance
framework organized around a new AI regulatory agency that -- drawing on
interdisciplinary expertise -- could help creating uniform standards for the
regulation of AI technologies and inform the development of AI policies around
the world. We also believe that a fundamental change of mindset on what
constitutes regulation is necessary to remove existing barriers that hamper
contemporary efforts to develop AI regulatory regimes, and put forward some
recommendations on how to achieve this, and what opportunities doing so would
present.",2020-05-22,2020,2020-05,environment
Learning visual servo policies via planner cloning,"Learning control policies for visual servoing in novel environments is an
important problem. However, standard model-free policy learning methods are
slow. This paper explores planner cloning: using behavior cloning to learn
policies that mimic the behavior of a full-state motion planner in simulation.
We propose Penalized Q Cloning (PQC), a new behavior cloning algorithm. We show
that it outperforms several baselines and ablations on some challenging
problems involving visual servoing in novel environments while avoiding
obstacles. Finally, we demonstrate that these policies can be transferred
effectively onto a real robotic platform, achieving approximately an 87%
success rate both in simulation and on a real robot.",2020-05-24,2020,2020-05,environment
"Synergetic Learning Systems: Concept, Architecture, and Algorithms","Drawing on the idea that brain development is a Darwinian process of
``evolution + selection'' and the idea that the current state is a local
equilibrium state of many bodies with self-organization and evolution processes
driven by the temperature and gravity in our universe, in this work, we
describe an artificial intelligence system called the ``Synergetic Learning
Systems''. The system is composed of two or more subsystems (models, agents or
virtual bodies), and it is an open complex giant system. Inspired by natural
intelligence, the system achieves intelligent information processing and
decision-making in a given environment through cooperative/competitive
synergetic learning. The intelligence evolved by the natural law of ``it is not
the strongest of the species that survives, but the one most responsive to
change,'' while an artificial intelligence system should adopt the law of
``human selection'' in the evolution process. Therefore, we expect that the
proposed system architecture can also be adapted in human-machine synergy or
multi-agent synergetic systems. It is also expected that under our design
criteria, the proposed system will eventually achieve artificial general
intelligence through long term coevolution.",2020-05-31,2020,2020-05,environment
Temporal-Differential Learning in Continuous Environments,"In this paper, a new reinforcement learning (RL) method known as the method
of temporal differential is introduced. Compared to the traditional
temporal-difference learning method, it plays a crucial role in developing
novel RL techniques for continuous environments. In particular, the
continuous-time least squares policy evaluation (CT-LSPE) and the
continuous-time temporal-differential (CT-TD) learning methods are developed.
Both theoretical and empirical evidences are provided to demonstrate the
effectiveness of the proposed temporal-differential learning methodology.",2020-06-01,2020,2020-06,environment
Delta Schema Network in Model-based Reinforcement Learning,"This work is devoted to unresolved problems of Artificial General
Intelligence - the inefficiency of transfer learning. One of the mechanisms
that are used to solve this problem in the area of reinforcement learning is a
model-based approach. In the paper we are expanding the schema networks method
which allows to extract the logical relationships between objects and actions
from the environment data. We present algorithms for training a Delta Schema
Network (DSN), predicting future states of the environment and planning actions
that will lead to positive reward. DSN shows strong performance of transfer
learning on the classic Atari game environment.",2020-06-17,2020,2020-06,environment
Modelling Agent Policies with Interpretable Imitation Learning,"As we deploy autonomous agents in safety-critical domains, it becomes
important to develop an understanding of their internal mechanisms and
representations. We outline an approach to imitation learning for
reverse-engineering black box agent policies in MDP environments, yielding
simplified, interpretable models in the form of decision trees. As part of this
process, we explicitly model and learn agents' latent state representations by
selecting from a large space of candidate features constructed from the Markov
state. We present initial promising results from an implementation in a
multi-agent traffic environment.",2020-06-19,2020,2020-06,environment
Designing Environments Conducive to Interpretable Robot Behavior,"Designing robots capable of generating interpretable behavior is a
prerequisite for achieving effective human-robot collaboration. This means that
the robots need to be capable of generating behavior that aligns with human
expectations and, when required, provide explanations to the humans in the
loop. However, exhibiting such behavior in arbitrary environments could be
quite expensive for robots, and in some cases, the robot may not even be able
to exhibit the expected behavior. Given structured environments (like
warehouses and restaurants), it may be possible to design the environment so as
to boost the interpretability of the robot's behavior or to shape the human's
expectations of the robot's behavior. In this paper, we investigate the
opportunities and limitations of environment design as a tool to promote a type
of interpretable behavior -- known in the literature as explicable behavior. We
formulate a novel environment design framework that considers design over
multiple tasks and over a time horizon. In addition, we explore the
longitudinal aspect of explicable behavior and the trade-off that arises
between the cost of design and the cost of generating explicable behavior over
a time horizon.",2020-07-02,2020,2020-07,environment
"Natural Emergence of Heterogeneous Strategies in Artificially
  Intelligent Competitive Teams","Multi agent strategies in mixed cooperative-competitive environments can be
hard to craft by hand because each agent needs to coordinate with its teammates
while competing with its opponents. Learning based algorithms are appealing but
many scenarios require heterogeneous agent behavior for the team's success and
this increases the complexity of the learning algorithm. In this work, we
develop a competitive multi agent environment called FortAttack in which two
teams compete against each other. We corroborate that modeling agents with
Graph Neural Networks and training them with Reinforcement Learning leads to
the evolution of increasingly complex strategies for each team. We observe a
natural emergence of heterogeneous behavior amongst homogeneous agents when
such behavior can lead to the team's success. Such heterogeneous behavior from
homogeneous agents is appealing because any agent can replace the role of
another agent at test time. Finally, we propose ensemble training, in which we
utilize the evolved opponent strategies to train a single policy for friendly
agents.",2020-07-06,2020,2020-07,environment
Fast Adaptation via Policy-Dynamics Value Functions,"Standard RL algorithms assume fixed environment dynamics and require a
significant amount of interaction to adapt to new environments. We introduce
Policy-Dynamics Value Functions (PD-VF), a novel approach for rapidly adapting
to dynamics different from those previously seen in training. PD-VF explicitly
estimates the cumulative reward in a space of policies and environments. An
ensemble of conventional RL policies is used to gather experience on training
environments, from which embeddings of both policies and environments can be
learned. Then, a value function conditioned on both embeddings is trained. At
test time, a few actions are sufficient to infer the environment embedding,
enabling a policy to be selected by maximizing the learned value function
(which requires no additional environment interaction). We show that our method
can rapidly adapt to new dynamics on a set of MuJoCo domains. Code available at
https://github.com/rraileanu/policy-dynamics-value-functions.",2020-07-06,2020,2020-07,environment
Scaling Imitation Learning in Minecraft,"Imitation learning is a powerful family of techniques for learning
sensorimotor coordination in immersive environments. We apply imitation
learning to attain state-of-the-art performance on hard exploration problems in
the Minecraft environment. We report experiments that highlight the influence
of network architecture, loss function, and data augmentation. An early version
of our approach reached second place in the MineRL competition at NeurIPS 2019.
Here we report stronger results that can be used as a starting point for future
competition entries and related research. Our code is available at
https://github.com/amiranas/minerl_imitation_learning.",2020-07-06,2020,2020-07,environment
Human $\neq$ AGI,"Terms Artificial General Intelligence (AGI) and Human-Level Artificial
Intelligence (HLAI) have been used interchangeably to refer to the Holy Grail
of Artificial Intelligence (AI) research, creation of a machine capable of
achieving goals in a wide range of environments. However, widespread implicit
assumption of equivalence between capabilities of AGI and HLAI appears to be
unjustified, as humans are not general intelligences. In this paper, we will
prove this distinction.",2020-07-11,2020,2020-07,environment
"Relational-Grid-World: A Novel Relational Reasoning Environment and An
  Agent Model for Relational Information Extraction","Reinforcement learning (RL) agents are often designed specifically for a
particular problem and they generally have uninterpretable working processes.
Statistical methods-based agent algorithms can be improved in terms of
generalizability and interpretability using symbolic Artificial Intelligence
(AI) tools such as logic programming. In this study, we present a model-free RL
architecture that is supported with explicit relational representations of the
environmental objects. For the first time, we use the PrediNet network
architecture in a dynamic decision-making problem rather than image-based
tasks, and Multi-Head Dot-Product Attention Network (MHDPA) as a baseline for
performance comparisons. We tested two networks in two environments ---i.e.,
the baseline Box-World environment and our novel environment,
Relational-Grid-World (RGW). With the procedurally generated RGW environment,
which is complex in terms of visual perceptions and combinatorial selections,
it is easy to measure the relational representation performance of the RL
agents. The experiments were carried out using different configurations of the
environment so that the presented module and the environment were compared with
the baselines. We reached similar policy optimization performance results with
the PrediNet architecture and MHDPA; additionally, we achieved to extract the
propositional representation explicitly ---which makes the agent's statistical
policy logic more interpretable and tractable. This flexibility in the agent's
policy provides convenience for designing non-task-specific agent
architectures. The main contributions of this study are two-fold ---an RL agent
that can explicitly perform relational reasoning, and a new environment that
measures the relational reasoning capabilities of RL agents.",2020-07-12,2020,2020-07,environment
"Situated Multimodal Control of a Mobile Robot: Navigation through a
  Virtual Environment","We present a new interface for controlling a navigation robot in novel
environments using coordinated gesture and language. We use a TurtleBot3 robot
with a LIDAR and a camera, an embodied simulation of what the robot has
encountered while exploring, and a cross-platform bridge facilitating generic
communication. A human partner can deliver instructions to the robot using
spoken English and gestures relative to the simulated environment, to guide the
robot through navigation tasks.",2020-07-13,2020,2020-07,environment
Collision Avoidance Robotics Via Meta-Learning (CARML),"This paper presents an approach to exploring a multi-objective reinforcement
learning problem with Model-Agnostic Meta-Learning. The environment we used
consists of a 2D vehicle equipped with a LIDAR sensor. The goal of the
environment is to reach some pre-determined target location but also
effectively avoid any obstacles it may find along its path. We also compare
this approach against a baseline TD3 solution that attempts to solve the same
problem.",2020-07-16,2020,2020-07,environment
An Open-World Simulated Environment for Developmental Robotics,"As the current trend of artificial intelligence is shifting towards
self-supervised learning, conventional norms such as highly curated
domain-specific data, application-specific learning models, extrinsic reward
based learning policies etc. might not provide with the suitable ground for
such developments. In this paper, we introduce SEDRo, a Simulated Environment
for Developmental Robotics which allows a learning agent to have similar
experiences that a human infant goes through from the fetus stage up to 12
months. A series of simulated tests based on developmental psychology will be
used to evaluate the progress of a learning model.",2020-07-18,2020,2020-07,environment
Greedy Bandits with Sampled Context,"Bayesian strategies for contextual bandits have proved promising in
single-state reinforcement learning tasks by modeling uncertainty using context
information from the environment. In this paper, we propose Greedy Bandits with
Sampled Context (GB-SC), a method for contextual multi-armed bandits to develop
the prior from the context information using Thompson Sampling, and arm
selection using an epsilon-greedy policy. The framework GB-SC allows for
evaluation of context-reward dependency, as well as providing robustness for
partially observable context vectors by leveraging the prior developed. Our
experimental results show competitive performance on the Mushroom environment
in terms of expected regret and expected cumulative regret, as well as insights
on how each context subset affects decision-making.",2020-07-27,2020,2020-07,environment
"Modelos dinâmicos aplicados à aprendizagem de valores em
  inteligência artificial","Experts in Artificial Intelligence (AI) development predict that advances in
the development of intelligent systems and agents will reshape vital areas in
our society. Nevertheless, if such an advance is not made prudently and
critically, reflexively, it can result in negative outcomes for humanity. For
this reason, several researchers in the area have developed a robust,
beneficial, and safe concept of AI for the preservation of humanity and the
environment. Currently, several of the open problems in the field of AI
research arise from the difficulty of avoiding unwanted behaviors of
intelligent agents and systems, and at the same time specifying what we really
want such systems to do, especially when we look for the possibility of
intelligent agents acting in several domains over the long term. It is of
utmost importance that artificial intelligent agents have their values aligned
with human values, given the fact that we cannot expect an AI to develop human
moral values simply because of its intelligence, as discussed in the
Orthogonality Thesis. Perhaps this difficulty comes from the way we are
addressing the problem of expressing objectives, values, and ends, using
representational cognitive methods. A solution to this problem would be the
dynamic approach proposed by Dreyfus, whose phenomenological philosophy shows
that the human experience of being-in-the-world in several aspects is not well
represented by the symbolic or connectionist cognitive method, especially in
regards to the question of learning values. A possible approach to this problem
would be to use theoretical models such as SED (situated embodied dynamics) to
address the values learning problem in AI.",2020-07-30,2020,2020-07,environment
"Artificial Intelligence in Music and Performance: A Subjective
  Art-Research Inquiry","This article presents a five-year collaboration situated at the intersection
of Art practice and Scientific research in Human-Computer Interaction (HCI). At
the core of our collaborative work is a hybrid, Art and Science methodology
that combines computational learning technology -- Machine Learning (ML) and
Artificial Intelligence (AI) -- with interactive music performance and
choreography. This article first exposes our thoughts on combining art,
science, movement and sound research. We then describe two of our artistic
works \textit{Corpus Nil} and \textit{Humane Methods} -- created five years
apart from each other -- that crystallize our collaborative research process.
We present the scientific and artistic motivations, framed through our research
interests and cultural environment of the time. We conclude by reflecting on
the methodology we developed during the collaboration and on the conceptual
shift of computational learning technologies, from ML to AI, and its impact on
Music performance.",2020-07-31,2020,2020-07,environment
SuperSuit: Simple Microwrappers for Reinforcement Learning Environments,"In reinforcement learning, wrappers are universally used to transform the
information that passes between a model and an environment. Despite their
ubiquity, no library exists with reasonable implementations of all popular
preprocessing methods. This leads to unnecessary bugs, code inefficiencies, and
wasted developer time. Accordingly we introduce SuperSuit, a Python library
that includes all popular wrappers, and wrappers that can easily apply lambda
functions to the observations/actions/reward. It's compatible with the standard
Gym environment specification, as well as the PettingZoo specification for
multi-agent environments. The library is available at
https://github.com/PettingZoo-Team/SuperSuit,and can be installed via pip.",2020-08-17,2020,2020-08,environment
"Say ""Sul Sul!"" to SimSim, A Sims-Inspired Platform for Sandbox Game AI","This paper proposes environment design in the life simulation game The Sims
as a novel platform and challenge for testing divergent search algorithms. In
this domain, which includes a minimal viability criterion, the goal is to
furnish a house with objects that satisfy the physical needs of a simulated
agent. Importantly, the large number of objects available to the player
(whether human or automated) affords a wide variety of solutions to the
underlying design problem. Empirical studies in a novel open source simulator
called SimSim investigate the ability of novelty-based evolutionary algorithms
to effectively generate viable environment designs.",2020-08-25,2020,2020-08,environment
"Explainable Artificial Intelligence for Process Mining: A General
  Overview and Application of a Novel Local Explanation Approach for Predictive
  Process Monitoring","The contemporary process-aware information systems possess the capabilities
to record the activities generated during the process execution. To leverage
these process specific fine-granular data, process mining has recently emerged
as a promising research discipline. As an important branch of process mining,
predictive business process management, pursues the objective to generate
forward-looking, predictive insights to shape business processes. In this
study, we propose a conceptual framework sought to establish and promote
understanding of decision-making environment, underlying business processes and
nature of the user characteristics for developing explainable business process
prediction solutions. Consequently, with regard to the theoretical and
practical implications of the framework, this study proposes a novel local
post-hoc explanation approach for a deep learning classifier that is expected
to facilitate the domain experts in justifying the model decisions. In contrary
to alternative popular perturbation-based local explanation approaches, this
study defines the local regions from the validation dataset by using the
intermediate latent space representations learned by the deep neural networks.
To validate the applicability of the proposed explanation method, the real-life
process log data delivered by the Volvo IT Belgium's incident management system
are used.The adopted deep learning classifier achieves a good performance with
the Area Under the ROC Curve of 0.94. The generated local explanations are also
visualized and presented with relevant evaluation measures that are expected to
increase the users' trust in the black-box-model.",2020-09-04,2020,2020-09,environment
Multiplayer Support for the Arcade Learning Environment,"The Arcade Learning Environment (""ALE"") is a widely used library in the
reinforcement learning community that allows easy programmatic interfacing with
Atari 2600 games, via the Stella emulator. We introduce a publicly available
extension to the ALE that extends its support to multiplayer games and game
modes. This interface is additionally integrated with PettingZoo to allow for a
simple Gym-like interface in Python to interact with these games. We
additionally introduce experimental baselines for all environments included.",2020-09-20,2020,2020-09,environment
"Advancing the Research and Development of Assured Artificial
  Intelligence and Machine Learning Capabilities","Artificial intelligence (AI) and machine learning (ML) have become
increasingly vital in the development of novel defense and intelligence
capabilities across all domains of warfare. An adversarial AI (A2I) and
adversarial ML (AML) attack seeks to deceive and manipulate AI/ML models. It is
imperative that AI/ML models can defend against these attacks. A2I/AML defenses
will help provide the necessary assurance of these advanced capabilities that
use AI/ML models. The A2I Working Group (A2IWG) seeks to advance the research
and development of assured AI/ML capabilities via new A2I/AML defenses by
fostering a collaborative environment across the U.S. Department of Defense and
U.S. Intelligence Community. The A2IWG aims to identify specific challenges
that it can help solve or address more directly, with initial focus on three
topics: AI Trusted Robustness, AI System Security, and AI/ML Architecture
Vulnerabilities.",2020-09-24,2020,2020-09,environment
"robosuite: A Modular Simulation Framework and Benchmark for Robot
  Learning","robosuite is a simulation framework for robot learning powered by the MuJoCo
physics engine. It offers a modular design for creating robotic tasks as well
as a suite of benchmark environments for reproducible research. This paper
discusses the key system modules and the benchmark environments of our new
release robosuite v1.5.",2020-09-25,2020,2020-09,environment
"Heterogeneous Multi-Agent Reinforcement Learning for Unknown Environment
  Mapping","Reinforcement learning in heterogeneous multi-agent scenarios is important
for real-world applications but presents challenges beyond those seen in
homogeneous settings and simple benchmarks. In this work, we present an
actor-critic algorithm that allows a team of heterogeneous agents to learn
decentralized control policies for covering an unknown environment. This task
is of interest to national security and emergency response organizations that
would like to enhance situational awareness in hazardous areas by deploying
teams of unmanned aerial vehicles. To solve this multi-agent coverage path
planning problem in unknown environments, we augment a multi-agent actor-critic
architecture with a new state encoding structure and triplet learning loss to
support heterogeneous agent learning. We developed a simulation environment
that includes real-world environmental factors such as turbulence, delayed
communication, and agent loss, to train teams of agents as well as probe their
robustness and flexibility to such disturbances.",2020-10-06,2020,2020-10,environment
"Deep Reinforcement Learning for Adaptive Network Slicing in 5G for
  Intelligent Vehicular Systems and Smart Cities","Intelligent vehicular systems and smart city applications are the fastest
growing Internet of things (IoT) implementations at a compound annual growth
rate of 30%. In view of the recent advances in IoT devices and the emerging new
breed of IoT applications driven by artificial intelligence (AI), fog radio
access network (F-RAN) has been recently introduced for the fifth generation
(5G) wireless communications to overcome the latency limitations of cloud-RAN
(C-RAN). We consider the network slicing problem of allocating the limited
resources at the network edge (fog nodes) to vehicular and smart city users
with heterogeneous latency and computing demands in dynamic environments. We
develop a network slicing model based on a cluster of fog nodes (FNs)
coordinated with an edge controller (EC) to efficiently utilize the limited
resources at the network edge. For each service request in a cluster, the EC
decides which FN to execute the task, i.e., locally serve the request at the
edge, or to reject the task and refer it to the cloud. We formulate the problem
as infinite-horizon Markov decision process (MDP) and propose a deep
reinforcement learning (DRL) solution to adaptively learn the optimal slicing
policy. The performance of the proposed DRL-based slicing method is evaluated
by comparing it with other slicing approaches in dynamic environments and for
different scenarios of design objectives. Comprehensive simulation results
corroborate that the proposed DRL-based EC quickly learns the optimal policy
through interaction with the environment, which enables adaptive and automated
network slicing for efficient resource allocation in dynamic vehicular and
smart city environments.",2020-10-19,2020,2020-10,environment
Negotiating Team Formation Using Deep Reinforcement Learning,"When autonomous agents interact in the same environment, they must often
cooperate to achieve their goals. One way for agents to cooperate effectively
is to form a team, make a binding agreement on a joint plan, and execute it.
However, when agents are self-interested, the gains from team formation must be
allocated appropriately to incentivize agreement. Various approaches for
multi-agent negotiation have been proposed, but typically only work for
particular negotiation protocols. More general methods usually require human
input or domain-specific data, and so do not scale. To address this, we propose
a framework for training agents to negotiate and form teams using deep
reinforcement learning. Importantly, our method makes no assumptions about the
specific negotiation protocol, and is instead completely experience driven. We
evaluate our approach on both non-spatial and spatially extended team-formation
negotiation environments, demonstrating that our agents beat hand-crafted bots
and reach negotiation outcomes consistent with fair solutions predicted by
cooperative game theory. Additionally, we investigate how the physical location
of agents influences negotiation outcomes.",2020-10-20,2020,2020-10,environment
"Reinforcement Learning for Sparse-Reward Object-Interaction Tasks in a
  First-person Simulated 3D Environment","First-person object-interaction tasks in high-fidelity, 3D, simulated
environments such as the AI2Thor virtual home-environment pose significant
sample-efficiency challenges for reinforcement learning (RL) agents learning
from sparse task rewards. To alleviate these challenges, prior work has
provided extensive supervision via a combination of reward-shaping,
ground-truth object-information, and expert demonstrations. In this work, we
show that one can learn object-interaction tasks from scratch without
supervision by learning an attentive object-model as an auxiliary task during
task learning with an object-centric relational RL agent. Our key insight is
that learning an object-model that incorporates object-attention into forward
prediction provides a dense learning signal for unsupervised representation
learning of both objects and their relationships. This, in turn, enables faster
policy learning for an object-centric relational RL agent. We demonstrate our
agent by introducing a set of challenging object-interaction tasks in the
AI2Thor environment where learning with our attentive object-model is key to
strong performance. Specifically, we compare our agent and relational RL agents
with alternative auxiliary tasks to a relational RL agent equipped with
ground-truth object-information, and show that learning with our object-model
best closes the performance gap in terms of both learning speed and maximum
success rate. Additionally, we find that incorporating object-attention into an
object-model's forward predictions is key to learning representations which
capture object-category and object-state.",2020-10-28,2020,2020-10,environment
Face-work for Human-Agent Joint Decision-Making,"We propose a method to integrate face-work, a common social ritual related to
trust, into a decision-making agent that works collaboratively with a human.
Face-work is a set of trust-building behaviors designed to ""save face"" or
prevent others from ""losing face."" This paper describes the design of a
decision-making process that explicitly considers face-work as part of its
action selection. We also present a simulated robot arm deployed in an online
environment that can be used to evaluate the proposed method.",2020-11-03,2020,2020-11,environment
"Artificial Intelligence and its impact on the Fourth Industrial
  Revolution: A Review","Artificial Intelligence may revolutionize everything during the so-called
fourth industrial revolution, which carries several emerging technologies and
could progress without precedents in human history due to its speed and scope.
Government, academia, industry, and civil society show interest in
understanding the multidimensional impact of the emerging industrial
revolution; however, its development is hard to predict. Experts consider
emerging technologies could bring tremendous benefits to humanity; at the same
time, they could pose an existential risk. This paper reviews the development
and trends in AI, as well as the benefits, risks, and strategies in the field.
During the course of the emerging industrial revolution, the common good may be
achieved in a collaborative environment of shared interests and the hardest
work will be the implementation and monitoring of projects at a global scale.",2020-11-05,2020,2020-11,environment
"Playing optical tweezers with deep reinforcement learning: in virtual,
  physical and augmented environments","Reinforcement learning was carried out in a simulated environment to learn
continuous velocity control over multiple motor axes. This was then applied to
a real-world optical tweezers experiment with the objective of moving a
laser-trapped microsphere to a target location whilst avoiding collisions with
other free-moving microspheres. The concept of training a neural network in a
virtual environment has significant potential in the application of machine
learning for experimental optimization and control, as the neural network can
discover optimal methods for problem solving without the risk of damage to
equipment, and at a speed not limited by movement in the physical environment.
As the neural network treats both virtual and physical environments
equivalently, we show that the network can also be applied to an augmented
environment, where a virtual environment is combined with the physical
environment. This technique may have the potential to unlock capabilities
associated with mixed and augmented reality, such as enforcing safety limits
for machine motion or as a method of inputting observations from additional
sensors.",2020-11-05,2020,2020-11,environment
"Learning Behavior Trees with Genetic Programming in Unpredictable
  Environments","Modern industrial applications require robots to be able to operate in
unpredictable environments, and programs to be created with a minimal effort,
as there may be frequent changes to the task. In this paper, we show that
genetic programming can be effectively used to learn the structure of a
behavior tree (BT) to solve a robotic task in an unpredictable environment.
Moreover, we propose to use a simple simulator for the learning and demonstrate
that the learned BTs can solve the same task in a realistic simulator, reaching
convergence without the need for task specific heuristics. The learned solution
is tolerant to faults, making our method appealing for real robotic
applications.",2020-11-06,2020,2020-11,environment
"A deep Q-Learning based Path Planning and Navigation System for
  Firefighting Environments","Live fire creates a dynamic, rapidly changing environment that presents a
worthy challenge for deep learning and artificial intelligence methodologies to
assist firefighters with scene comprehension in maintaining their situational
awareness, tracking and relay of important features necessary for key decisions
as they tackle these catastrophic events. We propose a deep Q-learning based
agent who is immune to stress induced disorientation and anxiety and thus able
to make clear decisions for navigation based on the observed and stored facts
in live fire environments. As a proof of concept, we imitate structural fire in
a gaming engine called Unreal Engine which enables the interaction of the agent
with the environment. The agent is trained with a deep Q-learning algorithm
based on a set of rewards and penalties as per its actions on the environment.
We exploit experience replay to accelerate the learning process and augment the
learning of the agent with human-derived experiences. The agent trained under
this deep Q-learning approach outperforms agents trained through alternative
path planning systems and demonstrates this methodology as a promising
foundation on which to build a path planning navigation assistant capable of
safely guiding fire fighters through live fire environments.",2020-11-12,2020,2020-11,environment
DeepMind Lab2D,"We present DeepMind Lab2D, a scalable environment simulator for artificial
intelligence research that facilitates researcher-led experimentation with
environment design. DeepMind Lab2D was built with the specific needs of
multi-agent deep reinforcement learning researchers in mind, but it may also be
useful beyond that particular subfield.",2020-11-13,2020,2020-11,environment
"Empowering Things with Intelligence: A Survey of the Progress,
  Challenges, and Opportunities in Artificial Intelligence of Things","In the Internet of Things (IoT) era, billions of sensors and devices collect
and process data from the environment, transmit them to cloud centers, and
receive feedback via the internet for connectivity and perception. However,
transmitting massive amounts of heterogeneous data, perceiving complex
environments from these data, and then making smart decisions in a timely
manner are difficult. Artificial intelligence (AI), especially deep learning,
is now a proven success in various areas including computer vision, speech
recognition, and natural language processing. AI introduced into the IoT
heralds the era of artificial intelligence of things (AIoT). This paper
presents a comprehensive survey on AIoT to show how AI can empower the IoT to
make it faster, smarter, greener, and safer. Specifically, we briefly present
the AIoT architecture in the context of cloud computing, fog computing, and
edge computing. Then, we present progress in AI research for IoT from four
perspectives: perceiving, learning, reasoning, and behaving. Next, we summarize
some promising applications of AIoT that are likely to profoundly reshape our
world. Finally, we highlight the challenges facing AIoT and some potential
research opportunities.",2020-11-17,2020,2020-11,environment
"Double Meta-Learning for Data Efficient Policy Optimization in
  Non-Stationary Environments","We are interested in learning models of non-stationary environments, which
can be framed as a multi-task learning problem. Model-free reinforcement
learning algorithms can achieve good asymptotic performance in multi-task
learning at a cost of extensive sampling, due to their approach, which requires
learning from scratch. While model-based approaches are among the most data
efficient learning algorithms, they still struggle with complex tasks and model
uncertainties. Meta-reinforcement learning addresses the efficiency and
generalization challenges on multi task learning by quickly leveraging the
meta-prior policy for a new task. In this paper, we propose a
meta-reinforcement learning approach to learn the dynamic model of a
non-stationary environment to be used for meta-policy optimization later. Due
to the sample efficiency of model-based learning methods, we are able to
simultaneously train both the meta-model of the non-stationary environment and
the meta-policy until dynamic model convergence. Then, the meta-learned dynamic
model of the environment will generate simulated data for meta-policy
optimization. Our experiment demonstrates that our proposed method can
meta-learn the policy in a non-stationary environment with the data efficiency
of model-based learning approaches while achieving the high asymptotic
performance of model-free meta-reinforcement learning.",2020-11-21,2020,2020-11,environment
On limitations of learning algorithms in competitive environments,"We discuss conceptual limitations of generic learning algorithms pursuing
adversarial goals in competitive environments, and prove that they are subject
to limitations that are analogous to the constraints on knowledge imposed by
the famous theorems of G\""odel and Turing. These limitations are shown to be
related to intransitivity, which is commonly present in competitive
environments.",2020-11-25,2020,2020-11,environment
"Automated acquisition of structured, semantic models of manipulation
  activities from human VR demonstration","In this paper we present a system capable of collecting and annotating, human
performed, robot understandable, everyday activities from virtual environments.
The human movements are mapped in the simulated world using off-the-shelf
virtual reality devices with full body, and eye tracking capabilities. All the
interactions in the virtual world are physically simulated, thus movements and
their effects are closely relatable to the real world. During the activity
execution, a subsymbolic data logger is recording the environment and the human
gaze on a per-frame basis, enabling offline scene reproduction and replays.
Coupled with the physics engine, online monitors (symbolic data loggers) are
parsing (using various grammars) and recording events, actions, and their
effects in the simulated world.",2020-11-27,2020,2020-11,environment
"Robust Ultra-wideband Range Error Mitigation with Deep Learning at the
  Edge","Ultra-wideband (UWB) is the state-of-the-art and most popular technology for
wireless localization. Nevertheless, precise ranging and localization in
non-line-of-sight (NLoS) conditions is still an open research topic. Indeed,
multipath effects, reflections, refractions, and complexity of the indoor radio
environment can easily introduce a positive bias in the ranging measurement,
resulting in highly inaccurate and unsatisfactory position estimation. This
article proposes an efficient representation learning methodology that exploits
the latest advancement in deep learning and graph optimization techniques to
achieve effective ranging error mitigation at the edge. Channel Impulse
Response (CIR) signals are directly exploited to extract high semantic features
to estimate corrections in either NLoS or LoS conditions. Extensive
experimentation with different settings and configurations has proved the
effectiveness of our methodology and demonstrated the feasibility of a robust
and low computational power UWB range error mitigation.",2020-11-30,2020,2020-11,environment
"Emergent Complexity and Zero-shot Transfer via Unsupervised Environment
  Design","A wide range of reinforcement learning (RL) problems - including robustness,
transfer learning, unsupervised RL, and emergent complexity - require
specifying a distribution of tasks or environments in which a policy will be
trained. However, creating a useful distribution of environments is error
prone, and takes a significant amount of developer time and effort. We propose
Unsupervised Environment Design (UED) as an alternative paradigm, where
developers provide environments with unknown parameters, and these parameters
are used to automatically produce a distribution over valid, solvable
environments. Existing approaches to automatically generating environments
suffer from common failure modes: domain randomization cannot generate
structure or adapt the difficulty of the environment to the agent's learning
progress, and minimax adversarial training leads to worst-case environments
that are often unsolvable. To generate structured, solvable environments for
our protagonist agent, we introduce a second, antagonist agent that is allied
with the environment-generating adversary. The adversary is motivated to
generate environments which maximize regret, defined as the difference between
the protagonist and antagonist agent's return. We call our technique
Protagonist Antagonist Induced Regret Environment Design (PAIRED). Our
experiments demonstrate that PAIRED produces a natural curriculum of
increasingly complex environments, and PAIRED agents achieve higher zero-shot
transfer performance when tested in highly novel environments.",2020-12-03,2020,2020-12,environment
"Demonstration-efficient Inverse Reinforcement Learning in Procedurally
  Generated Environments","Deep Reinforcement Learning achieves very good results in domains where
reward functions can be manually engineered. At the same time, there is growing
interest within the community in using games based on Procedurally Content
Generation (PCG) as benchmark environments since this type of environment is
perfect for studying overfitting and generalization of agents under domain
shift. Inverse Reinforcement Learning (IRL) can instead extrapolate reward
functions from expert demonstrations, with good results even on
high-dimensional problems, however there are no examples of applying these
techniques to procedurally-generated environments. This is mostly due to the
number of demonstrations needed to find a good reward model. We propose a
technique based on Adversarial Inverse Reinforcement Learning which can
significantly decrease the need for expert demonstrations in PCG games. Through
the use of an environment with a limited set of initial seed levels, plus some
modifications to stabilize training, we show that our approach, DE-AIRL, is
demonstration-efficient and still able to extrapolate reward functions which
generalize to the fully procedural domain. We demonstrate the effectiveness of
our technique on two procedural environments, MiniGrid and DeepCrawl, for a
variety of tasks.",2020-12-04,2020,2020-12,environment
"Generating Human-Like Movement: A Comparison Between Two Approaches
  Based on Environmental Features","Modelling realistic human behaviours in simulation is an ongoing challenge
that resides between several fields like social sciences, philosophy, and
artificial intelligence. Human movement is a special type of behaviour driven
by intent (e.g. to get groceries) and the surrounding environment (e.g.
curiosity to see new interesting places). Services available online and offline
do not normally consider the environment when planning a path, which is
decisive especially on a leisure trip. Two novel algorithms have been presented
to generate human-like trajectories based on environmental features. The
Attraction-Based A* algorithm includes in its computation information from the
environmental features meanwhile, the Feature-Based A* algorithm also injects
information from the real trajectories in its computation. The human-likeness
aspect has been tested by a human expert judging the final generated
trajectories as realistic. This paper presents a comparison between the two
approaches in some key metrics like efficiency, efficacy, and hyper-parameters
sensitivity. We show how, despite generating trajectories that are closer to
the real one according to our predefined metrics, the Feature-Based A*
algorithm fall short in time efficiency compared to the Attraction-Based A*
algorithm, hindering the usability of the model in the real world.",2020-12-11,2020,2020-12,environment
Technical Opinion: From Animal Behaviour to Autonomous Robots,"With the rising applications of robots in unstructured real-world
environments, roboticists are increasingly concerned with the problems posed by
the complexity of such environments. One solution to these problems is robot
autonomy. Since nature has already solved the problem of autonomy it can be a
suitable model for developing autonomous robots. This paper presents a concise
review on robot autonomy from the perspective of animal behaviour. It examines
some state-of-the-art techniques as well as suggesting possible research
directions.",2020-12-11,2020,2020-12,environment
"Specializing Inter-Agent Communication in Heterogeneous Multi-Agent
  Reinforcement Learning using Agent Class Information","Inspired by recent advances in agent communication with graph neural
networks, this work proposes the representation of multi-agent communication
capabilities as a directed labeled heterogeneous agent graph, in which node
labels denote agent classes and edge labels, the communication type between two
classes of agents. We also introduce a neural network architecture that
specializes communication in fully cooperative heterogeneous multi-agent tasks
by learning individual transformations to the exchanged messages between each
pair of agent classes. By also employing encoding and action selection modules
with parameter sharing for environments with heterogeneous agents, we
demonstrate comparable or superior performance in environments where a larger
number of agent classes operates.",2020-12-14,2020,2020-12,environment
"Gegelati: Lightweight Artificial Intelligence through Generic and
  Evolvable Tangled Program Graphs","Tangled Program Graph (TPG) is a reinforcement learning technique based on
genetic programming concepts. On state-of-the-art learning environments, TPGs
have been shown to offer comparable competence with Deep Neural Networks
(DNNs), for a fraction of their computational and storage cost. This lightness
of TPGs, both for training and inference, makes them an interesting model to
implement Artificial Intelligences (AIs) on embedded systems with limited
computational and storage resources. In this paper, we introduce the Gegelati
library for TPGs. Besides introducing the general concepts and features of the
library, two main contributions are detailed in the paper: 1/ The
parallelization of the deterministic training process of TPGs, for supporting
heterogeneous Multiprocessor Systems-on-Chips (MPSoCs). 2/ The support for
customizable instruction sets and data types within the genetically evolved
programs of the TPG model. The scalability of the parallel training process is
demonstrated through experiments on architectures ranging from a high-end
24-core processor to a low-power heterogeneous MPSoC. The impact of
customizable instructions on the outcome of a training process is demonstrated
on a state-of-the-art reinforcement learning environment. CCS Concepts:
$\bullet$ Computer systems organization $\rightarrow$ Embedded systems;
$\bullet$ Computing methodologies $\rightarrow$ Machine learning.",2020-12-15,2020,2020-12,environment
When Is Generalizable Reinforcement Learning Tractable?,"Agents trained by reinforcement learning (RL) often fail to generalize beyond
the environment they were trained in, even when presented with new scenarios
that seem similar to the training environment. We study the query complexity
required to train RL agents that generalize to multiple environments.
Intuitively, tractable generalization is only possible when the environments
are similar or close in some sense. To capture this, we introduce Weak
Proximity, a natural structural condition that requires the environments to
have highly similar transition and reward functions and share a policy
providing optimal value. Despite such shared structure, we prove that tractable
generalization is impossible in the worst case. This holds even when each
individual environment can be efficiently solved to obtain an optimal linear
policy, and when the agent possesses a generative model. Our lower bound
applies to the more complex task of representation learning for the purpose of
efficient generalization to multiple environments. On the positive side, we
introduce Strong Proximity, a strengthened condition which we prove is
sufficient for efficient generalization.",2021-01-01,2021,2021-01,environment
Impact of Explanation on Trust of a Novel Mobile Robot,"One challenge with introducing robots into novel environments is misalignment
between supervisor expectations and reality, which can greatly affect a user's
trust and continued use of the robot. We performed an experiment to test
whether the presence of an explanation of expected robot behavior affected a
supervisor's trust in an autonomous robot. We measured trust both subjectively
through surveys and objectively through a dual-task experiment design to
capture supervisors' neglect tolerance (i.e., their willingness to perform
their own task while the robot is acting autonomously). Our objective results
show that explanations can help counteract the novelty effect of seeing a new
robot perform in an unknown environment. Participants who received an
explanation of the robot's behavior were more likely to focus on their own task
at the risk of neglecting their robot supervision task during the first trials
of the robot's behavior compared to those who did not receive an explanation.
However, this effect diminished after seeing multiple trials, and participants
who received explanations were equally trusting of the robot's behavior as
those who did not receive explanations. Interestingly, participants were not
able to identify their own changes in trust through their survey responses,
demonstrating that the dual-task design measured subtler changes in a
supervisor's trust.",2021-01-26,2021,2021-01,environment
"Improving Model-Based Reinforcement Learning with Internal State
  Representations through Self-Supervision","Using a model of the environment, reinforcement learning agents can plan
their future moves and achieve superhuman performance in board games like
Chess, Shogi, and Go, while remaining relatively sample-efficient. As
demonstrated by the MuZero Algorithm, the environment model can even be learned
dynamically, generalizing the agent to many more tasks while at the same time
achieving state-of-the-art performance. Notably, MuZero uses internal state
representations derived from real environment states for its predictions. In
this paper, we bind the model's predicted internal state representation to the
environment state via two additional terms: a reconstruction model loss and a
simpler consistency loss, both of which work independently and unsupervised,
acting as constraints to stabilize the learning process. Our experiments show
that this new integration of reconstruction model loss and simpler consistency
loss provide a significant performance increase in OpenAI Gym environments. Our
modifications also enable self-supervised pretraining for MuZero, so the
algorithm can learn about environment dynamics before a goal is made available.",2021-02-10,2021,2021-02,environment
"Artificial Intelligence Technologies in Education: Benefits, Challenges
  and Strategies of Implementation","Since the education sector is associated with highly dynamic business
environments which are controlled and maintained by information systems, recent
technological advancements and the increasing pace of adopting artificial
intelligence (AI) technologies constitute a need to identify and analyze the
issues regarding their implementation in education sector. However, a study of
the contemporary literature reveled that relatively little research has been
undertaken in this area. To fill this void, we have identified the benefits and
challenges of implementing artificial intelligence in the education sector,
preceded by a short discussion on the concepts of AI and its evolution over
time. Moreover, we have also reviewed modern AI technologies for learners and
educators, currently available on the software market, evaluating their
usefulness. Last but not least, we have developed a strategy implementation
model, described by a five-stage, generic process, along with the corresponding
configuration guide. To verify and validate their design, we separately
developed three implementation strategies for three different higher education
organizations. We believe that the obtained results will contribute to better
understanding the specificities of AI systems, services and tools, and
afterwards pave a smooth way in their implementation.",2021-02-11,2021,2021-02,environment
Towards AIOps in Edge Computing Environments,"Edge computing was introduced as a technical enabler for the demanding
requirements of new network technologies like 5G. It aims to overcome
challenges related to centralized cloud computing environments by distributing
computational resources to the edge of the network towards the customers. The
complexity of the emerging infrastructures increases significantly, together
with the ramifications of outages on critical use cases such as self-driving
cars or health care. Artificial Intelligence for IT Operations (AIOps) aims to
support human operators in managing complex infrastructures by using machine
learning methods. This paper describes the system design of an AIOps platform
which is applicable in heterogeneous, distributed environments. The overhead of
a high-frequency monitoring solution on edge devices is evaluated and
performance experiments regarding the applicability of three anomaly detection
algorithms on edge devices are conducted. The results show, that it is feasible
to collect metrics with a high frequency and simultaneously run specific
anomaly detection algorithms directly on edge devices with a reasonable
overhead on the resource utilization.",2021-02-12,2021,2021-02,environment
"Design a Technology Based on the Fusion of Genetic Algorithm, Neural
  network and Fuzzy logic","This paper describes the design and development of a prototype technique for
artificial intelligence based on the fusion of genetic algorithm, neural
network and fuzzy logic. It starts by establishing a relationship between the
neural network and fuzzy logic. Then, it combines the genetic algorithm with
them. Information fusions are at the confidence level, where matching scores
can be reported and discussed. The technique is called the Genetic Neuro-Fuzzy
(GNF). It can be used for high accuracy real-time environments.",2021-02-16,2021,2021-02,environment
"An Overview of Direct Diagnosis and Repair Techniques in the WeeVis
  Recommendation Environment","Constraint-based recommenders support users in the identification of items
(products) fitting their wishes and needs. Example domains are financial
services and electronic equipment. In this paper we show how divide-and-conquer
based (direct) diagnosis algorithms (no conflict detection is needed) can be
exploited in constraint-based recommendation scenarios. In this context, we
provide an overview of the MediaWiki-based recommendation environment WeeVis.",2021-02-24,2021,2021-02,environment
Reflections on the Clinical Acceptance of Artificial Intelligence,"In this chapter, we reflect on the use of Artificial Intelligence (AI) and
its acceptance in clinical environments. We develop a general view of
hindrances for clinical acceptance in the form of a pipeline model combining AI
and clinical practise. We then link each challenge to the relevant stage in the
pipeline and discuss the necessary requirements in order to overcome each
challenge. We complement this discussion with an overview of opportunities for
AI, which we currently see at the periphery of clinical workflows.",2021-03-01,2021,2021-03,environment
"Low-level cognitive skill transfer between two individuals' minds via
  computer game-based framework","The novel technique introduced here aims to accomplish the first stage of
transferring low-level cognitive skills between two individuals (e.g. from
expert to learner) to ease the consecutive higher level declarative learning
process for the target ""learner"" individual in a game environment. Such
low-level cognitive skill is associated with the procedural knowledge and
established at low-level of mind which can be unveiled and transferred by only
a novel technique (rather than by a traditional educational environment ) like
a highly interactive computer game domain in which a user exposes his/her
unconscious mind behaviors via the game-hero non-deliberately during the game
sessions. The cognitive data exposed by the game-hero would be recorded, and
then be modelled by the artificial intelligence technique like Bayesian
networks for an early stage of cognitive skill transfer and the cognitive
stimuli are also generated to be used as game agents to train the learner.",2021-03-03,2021,2021-03,environment
"The AI Arena: A Framework for Distributed Multi-Agent Reinforcement
  Learning","Advances in reinforcement learning (RL) have resulted in recent breakthroughs
in the application of artificial intelligence (AI) across many different
domains. An emerging landscape of development environments is making powerful
RL techniques more accessible for a growing community of researchers. However,
most existing frameworks do not directly address the problem of learning in
complex operating environments, such as dense urban settings or defense-related
scenarios, that incorporate distributed, heterogeneous teams of agents. To help
enable AI research for this important class of applications, we introduce the
AI Arena: a scalable framework with flexible abstractions for distributed
multi-agent reinforcement learning. The AI Arena extends the OpenAI Gym
interface to allow greater flexibility in learning control policies across
multiple agents with heterogeneous learning strategies and localized views of
the environment. To illustrate the utility of our framework, we present
experimental results that demonstrate performance gains due to a distributed
multi-agent learning approach over commonly-used RL techniques in several
different learning environments.",2021-03-09,2021,2021-03,environment
"Intelligent behavior depends on the ecological niche: Scaling up AI to
  human-like intelligence in socio-cultural environments","This paper outlines a perspective on the future of AI, discussing directions
for machines models of human-like intelligence. We explain how developmental
and evolutionary theories of human cognition should further inform artificial
intelligence. We emphasize the role of ecological niches in sculpting
intelligent behavior, and in particular that human intelligence was
fundamentally shaped to adapt to a constantly changing socio-cultural
environment. We argue that a major limit of current work in AI is that it is
missing this perspective, both theoretically and experimentally. Finally, we
discuss the promising approach of developmental artificial intelligence,
modeling infant development through multi-scale interaction between
intrinsically motivated learning, embodiment and a fastly changing
socio-cultural environment. This paper takes the form of an interview of
Pierre-Yves Oudeyer by Mandred Eppe, organized within the context of a KI -
K{\""{u}}nstliche Intelligenz special issue in developmental robotics.",2021-03-11,2021,2021-03,environment
"Where is your place, Visual Place Recognition?","Visual Place Recognition (VPR) is often characterized as being able to
recognize the same place despite significant changes in appearance and
viewpoint. VPR is a key component of Spatial Artificial Intelligence, enabling
robotic platforms and intelligent augmentation platforms such as augmented
reality devices to perceive and understand the physical world. In this paper,
we observe that there are three ""drivers"" that impose requirements on spatially
intelligent agents and thus VPR systems: 1) the particular agent including its
sensors and computational resources, 2) the operating environment of this
agent, and 3) the specific task that the artificial agent carries out. In this
paper, we characterize and survey key works in the VPR area considering those
drivers, including their place representation and place matching choices. We
also provide a new definition of VPR based on the visual overlap -- akin to
spatial view cells in the brain -- that enables us to find similarities and
differences to other research areas in the robotics and computer vision fields.
We identify numerous open challenges and suggest areas that require more
in-depth attention in future works.",2021-03-11,2021,2021-03,environment
Hippocampal formation-inspired probabilistic generative model,"In building artificial intelligence (AI) agents, referring to how brains
function in real environments can accelerate development by reducing the design
space. In this study, we propose a probabilistic generative model (PGM) for
navigation in uncertain environments by integrating the neuroscientific
knowledge of hippocampal formation (HF) and the engineering knowledge in
robotics and AI, namely, simultaneous localization and mapping (SLAM). We
follow the approach of brain reference architecture (BRA) (Yamakawa, 2021) to
compose the PGM and outline how to verify the model. To this end, we survey and
discuss the relationship between the HF findings and SLAM models. The proposed
hippocampal formation-inspired probabilistic generative model (HF-PGM) is
designed to be highly consistent with the anatomical structure and functions of
the HF. By referencing the brain, we elaborate on the importance of integration
of egocentric/allocentric information from the entorhinal cortex to the
hippocampus and the use of discrete-event queues.",2021-03-12,2021,2021-03,environment
Hybrid computer approach to train a machine learning system,"This book chapter describes a novel approach to training machine learning
systems by means of a hybrid computer setup i.e. a digital computer tightly
coupled with an analog computer. As an example a reinforcement learning system
is trained to balance an inverted pendulum which is simulated on an analog
computer, thus demonstrating a solution to the major challenge of adequately
simulating the environment for reinforcement learning.",2021-03-13,2021,2021-03,environment
"NMRPy: a novel NMR scripting system to implement artificial intelligence
  and advanced applications","Background: Software is an important windows to offer a variety of complex
instrument control and data processing for nuclear magnetic resonance (NMR)
spectrometer. NMR software should allow researchers to flexibly implement
various functionality according to the requirement of applications. Scripting
system can offer an open environment for NMR users to write custom programs
with basic libraries. Emerging technologies, especially multivariate
statistical analysis and artificial intelligence, have been successfully
applied to NMR applications such as metabolomics and biomacromolecules.
Scripting system should support more complex NMR libraries, which will enable
the emerging technologies to be easily implemented in the scripting
environment. Result: Here, a novel NMR scripting system named ""NMRPy"" is
introduced. In the scripting system, both Java based NMR methods and original
CPython based libraries are supported. A module was built as a bridge to
integrate the runtime environment of Java and CPython. It works as an extension
in CPython environment, as well as interacts with Java part by Java Native
Interface. Leveraging the bridge, Java based instrument control and data
processing methods can be called as a CPython style. Compared with traditional
scripting system, NMRPy is easier for NMR researchers to develop complex
functionality with fast numerical computation, multivariate statistical
analysis, deep learning etc. Non-uniform sampling and protein structure
prediction methods based on deep learning can be conveniently integrated into
NMRPy. Conclusion: NMRPy offers a user-friendly environment to implement custom
functionality leveraging its powerful basic NMR and rich CPython libraries. NMR
applications with emerging technologies can be easily integrated. The scripting
system is free of charge and can be downloaded by visiting
http://www.spinstudioj.net/nmrpy.",2021-03-27,2021,2021-03,environment
HTN Planning Domain for Deployment of Cloud Applications,"Cloud providers are facing a complex problem in configuring software
applications ready for deployment on their infrastructures. Hierarchical Task
Network (HTN) planning can provide effective means to solve such deployment
problems. We present an HTN planning domain that models deployment problems as
found in realistic Cloud environments.",2021-04-16,2021,2021-04,environment
"A Robust Model for Trust Evaluation during Interactions between Agents
  in a Sociable Environment","Trust evaluation is an important topic in both research and applications in
sociable environments. This paper presents a model for trust evaluation between
agents by the combination of direct trust, indirect trust through neighbouring
links and the reputation of an agent in the environment (i.e. social network)
to provide the robust evaluation. Our approach is typology independent from
social network structures and in a decentralized manner without a central
controller, so it can be used in broad domains.",2021-04-17,2021,2021-04,environment
Modular Procedural Generation for Voxel Maps,"Task environments developed in Minecraft are becoming increasingly popular
for artificial intelligence (AI) research. However, most of these are currently
constructed manually, thus failing to take advantage of procedural content
generation (PCG), a capability unique to virtual task environments. In this
paper, we present mcg, an open-source library to facilitate implementing PCG
algorithms for voxel-based environments such as Minecraft. The library is
designed with human-machine teaming research in mind, and thus takes a
'top-down' approach to generation, simultaneously generating low and high level
machine-readable representations that are suitable for empirical research.
These can be consumed by downstream AI applications that consider human spatial
cognition. The benefits of this approach include rapid, scalable, and efficient
development of virtual environments, the ability to control the statistics of
the environment at a semantic level, and the ability to generate novel
environments in response to player actions in real time.",2021-04-18,2021,2021-04,environment
Reinforcement Learning with Expert Trajectory For Quantitative Trading,"In recent years, quantitative investment methods combined with artificial
intelligence have attracted more and more attention from investors and
researchers. Existing related methods based on the supervised learning are not
very suitable for learning problems with long-term goals and delayed rewards in
real futures trading. In this paper, therefore, we model the price prediction
problem as a Markov decision process (MDP), and optimize it by reinforcement
learning with expert trajectory. In the proposed method, we employ more than
100 short-term alpha factors instead of price, volume and several technical
factors in used existing methods to describe the states of MDP. Furthermore,
unlike DQN (deep Q-learning) and BC (behavior cloning) in related methods, we
introduce expert experience in training stage, and consider both the
expert-environment interaction and the agent-environment interaction to design
the temporal difference error so that the agents are more adaptable for
inevitable noise in financial data. Experimental results evaluated on share
price index futures in China, including IF (CSI 300) and IC (CSI 500), show
that the advantages of the proposed method compared with three typical
technical analysis and two deep leaning based methods.",2021-05-09,2021,2021-05,environment
"Zero-Shot Reinforcement Learning on Graphs for Autonomous Exploration
  Under Uncertainty","This paper studies the problem of autonomous exploration under localization
uncertainty for a mobile robot with 3D range sensing. We present a framework
for self-learning a high-performance exploration policy in a single simulation
environment, and transferring it to other environments, which may be physical
or virtual. Recent work in transfer learning achieves encouraging performance
by domain adaptation and domain randomization to expose an agent to scenarios
that fill the inherent gaps in sim2sim and sim2real approaches. However, it is
inefficient to train an agent in environments with randomized conditions to
learn the important features of its current state. An agent can use domain
knowledge provided by human experts to learn efficiently. We propose a novel
approach that uses graph neural networks in conjunction with deep reinforcement
learning, enabling decision-making over graphs containing relevant exploration
information provided by human experts to predict a robot's optimal sensing
action in belief space. The policy, which is trained only in a single
simulation environment, offers a real-time, scalable, and transferable
decision-making strategy, resulting in zero-shot transfer to other simulation
environments and even real-world environments.",2021-05-11,2021,2021-05,environment
Model-Based Offline Planning with Trajectory Pruning,"The recent offline reinforcement learning (RL) studies have achieved much
progress to make RL usable in real-world systems by learning policies from
pre-collected datasets without environment interaction. Unfortunately, existing
offline RL methods still face many practical challenges in real-world system
control tasks, such as computational restriction during agent training and the
requirement of extra control flexibility. The model-based planning framework
provides an attractive alternative. However, most model-based planning
algorithms are not designed for offline settings. Simply combining the
ingredients of offline RL with existing methods either provides
over-restrictive planning or leads to inferior performance. We propose a new
light-weighted model-based offline planning framework, namely MOPP, which
tackles the dilemma between the restrictions of offline learning and
high-performance planning. MOPP encourages more aggressive trajectory rollout
guided by the behavior policy learned from data, and prunes out problematic
trajectories to avoid potential out-of-distribution samples. Experimental
results show that MOPP provides competitive performance compared with existing
model-based offline planning and RL approaches.",2021-05-16,2021,2021-05,environment
"Multi-Agent Deep Reinforcement Learning using Attentive Graph Neural
  Architectures for Real-Time Strategy Games","In real-time strategy (RTS) game artificial intelligence research, various
multi-agent deep reinforcement learning (MADRL) algorithms are widely and
actively used nowadays. Most of the research is based on StarCraft II
environment because it is the most well-known RTS games in world-wide. In our
proposed MADRL-based algorithm, distributed MADRL is fundamentally used that is
called QMIX. In addition to QMIX-based distributed computation, we consider
state categorization which can reduce computational complexity significantly.
Furthermore, self-attention mechanisms are used for identifying the
relationship among agents in the form of graphs. Based on these approaches, we
propose a categorized state graph attention policy (CSGA-policy). As observed
in the performance evaluation of our proposed CSGA-policy with the most
well-known StarCraft II simulation environment, our proposed algorithm works
well in various settings, as expected.",2021-05-21,2021,2021-05,environment
"An Efficient Application of Neuroevolution for Competitive Multiagent
  Learning","Multiagent systems provide an ideal environment for the evaluation and
analysis of real-world problems using reinforcement learning algorithms. Most
traditional approaches to multiagent learning are affected by long training
periods as well as high computational complexity. NEAT (NeuroEvolution of
Augmenting Topologies) is a popular evolutionary strategy used to obtain the
best performing neural network architecture often used to tackle optimization
problems in the field of artificial intelligence. This paper utilizes the NEAT
algorithm to achieve competitive multiagent learning on a modified pong game
environment in an efficient manner. The competing agents abide by different
rules while having similar observation space parameters. The proposed algorithm
utilizes this property of the environment to define a singular
neuroevolutionary procedure that obtains the optimal policy for all the agents.
The compiled results indicate that the proposed implementation achieves ideal
behaviour in a very short training period when compared to existing multiagent
reinforcement learning models.",2021-05-23,2021,2021-05,environment
"Leveraging Pre-Images to Discover Nonlinear Relationships in
  Multivariate Environments","Causal discovery, beyond the inference of a network as a collection of
connected dots, offers a crucial functionality in scientific discovery using
artificial intelligence. The questions that arise in multiple domains, such as
physics, physiology, the strategic decision in uncertain environments with
multiple agents, climatology, among many others, have roots in causality and
reasoning. It became apparent that many real-world temporal observations are
nonlinearly related to each other. While the number of observations can be as
high as millions of points, the number of temporal samples can be minimal due
to ethical or practical reasons, leading to the curse-of-dimensionality in
large-scale systems. This paper proposes a novel method using kernel principal
component analysis and pre-images to obtain nonlinear dependencies of
multivariate time-series data. We show that our method outperforms
state-of-the-art causal discovery methods when the observations are restricted
by time and are nonlinearly related. Extensive simulations on both real-world
and synthetic datasets with various topologies are provided to evaluate our
proposed methods.",2021-06-01,2021,2021-06,environment
A call for better unit testing for invariant risk minimisation,"In this paper we present a controlled study on the linearized IRM framework
(IRMv1) introduced in Arjovsky et al. (2020). We show that IRMv1 (and its
variants) framework can be potentially unstable under small changes to the
optimal regressor. This can, notably, lead to worse generalisation to new
environments, even compared with ERM which converges simply to the global
minimum for all training environments mixed up all together. We also highlight
the isseus of scaling in the the IRMv1 setup. These observations highlight the
importance of rigorous evaluation and importance of unit-testing for measuring
progress towards IRM.",2021-06-06,2021,2021-06,environment
"Explainable Artificial Intelligence (XAI) for Increasing User Trust in
  Deep Reinforcement Learning Driven Autonomous Systems","We consider the problem of providing users of deep Reinforcement Learning
(RL) based systems with a better understanding of when their output can be
trusted. We offer an explainable artificial intelligence (XAI) framework that
provides a three-fold explanation: a graphical depiction of the systems
generalization and performance in the current game state, how well the agent
would play in semantically similar environments, and a narrative explanation of
what the graphical information implies. We created a user-interface for our XAI
framework and evaluated its efficacy via a human-user experiment. The results
demonstrate a statistically significant increase in user trust and acceptance
of the AI system with explanation, versus the AI system without explanation.",2021-06-07,2021,2021-06,environment
Vector Quantized Models for Planning,"Recent developments in the field of model-based RL have proven successful in
a range of environments, especially ones where planning is essential. However,
such successes have been limited to deterministic fully-observed environments.
We present a new approach that handles stochastic and partially-observable
environments. Our key insight is to use discrete autoencoders to capture the
multiple possible effects of an action in a stochastic environment. We use a
stochastic variant of Monte Carlo tree search to plan over both the agent's
actions and the discrete latent variables representing the environment's
response. Our approach significantly outperforms an offline version of MuZero
on a stochastic interpretation of chess where the opponent is considered part
of the environment. We also show that our approach scales to DeepMind Lab, a
first-person 3D environment with large visual observations and partial
observability.",2021-06-08,2021,2021-06,environment
"Multi-Context Systems: Dynamics and Evolution (Pre-Print of
  ""Multi-context systems in dynamic environments"")","Multi-Context Systems (MCS) model in Computational Logic distributed systems
composed of heterogeneous sources, or ""contexts"", interacting via special rules
called ""bridge rules"". In this paper, we consider how to enhance flexibility
and generality in bridge-rules definition and application. In particular, we
introduce and discuss some formal extensions of MCSs useful for a practical use
in dynamic environments, and we try to provide guidelines for implementations",2021-06-12,2021,2021-06,environment
Diagnosing the Impact of AI on Radiology in China,"Artificial Intelligence will significantly impact the work environment of
radiologists. I suggest that up to 50% of a radiologists work in 2021 will be
performed by AI-models in 2025. However, it won't increase beyond that 50%
level, as radiologists remain key for human-centered aspects of their job. I
project that few to no radiologists will be laid off in China due to the
existing supply shortage of radiology services in 2021. The application of AI
in radiology could contribute 1.7 billion USD to China's GDP in 2025. It will
further allow radiologists to start productive work up to four years earlier.
AI in radiology will positively impact the health of patients and radiologists
themselves.",2021-06-15,2021,2021-06,environment
"Modelling resource allocation in uncertain system environment through
  deep reinforcement learning","Reinforcement Learning has applications in field of mechatronics, robotics,
and other resource-constrained control system. Problem of resource allocation
is primarily solved using traditional predefined techniques and modern deep
learning methods. The drawback of predefined and most deep learning methods for
resource allocation is failing to meet the requirements in cases of uncertain
system environment. We can approach problem of resource allocation in uncertain
system environment alongside following certain criteria using deep
reinforcement learning. Also, reinforcement learning has ability for adapting
to new uncertain environment for prolonged period of time. The paper provides a
detailed comparative analysis on various deep reinforcement learning methods by
applying different components to modify architecture of reinforcement learning
with use of noisy layers, prioritized replay, bagging, duelling networks, and
other related combination to obtain improvement in terms of performance and
reduction of computational cost. The paper identifies problem of resource
allocation in uncertain environment could be effectively solved using Noisy
Bagging duelling double deep Q network achieving efficiency of 97.7% by
maximizing reward with significant exploration in given simulated environment
for resource allocation.",2021-06-17,2021,2021-06,environment
"Scenic4RL: Programmatic Modeling and Generation of Reinforcement
  Learning Environments","The capability of a reinforcement learning (RL) agent heavily depends on the
diversity of the learning scenarios generated by the environment. Generation of
diverse realistic scenarios is challenging for real-time strategy (RTS)
environments. The RTS environments are characterized by intelligent
entities/non-RL agents cooperating and competing with the RL agents with large
state and action spaces over a long period of time, resulting in an infinite
space of feasible, but not necessarily realistic, scenarios involving complex
interaction among different RL and non-RL agents. Yet, most of the existing
simulators rely on randomly generating the environments based on predefined
settings/layouts and offer limited flexibility and control over the environment
dynamics for researchers to generate diverse, realistic scenarios as per their
demand. To address this issue, for the first time, we formally introduce the
benefits of adopting an existing formal scenario specification language,
SCENIC, to assist researchers to model and generate diverse scenarios in an RTS
environment in a flexible, systematic, and programmatic manner. To showcase the
benefits, we interfaced SCENIC to an existing RTS environment Google Research
Football(GRF) simulator and introduced a benchmark consisting of 32 realistic
scenarios, encoded in SCENIC, to train RL agents and testing their
generalization capabilities. We also show how researchers/RL practitioners can
incorporate their domain knowledge to expedite the training process by
intuitively modeling stochastic programmatic policies with SCENIC.",2021-06-18,2021,2021-06,environment
On the Importance of Environments in Human-Robot Coordination,"When studying robots collaborating with humans, much of the focus has been on
robot policies that coordinate fluently with human teammates in collaborative
tasks. However, less emphasis has been placed on the effect of the environment
on coordination behaviors. To thoroughly explore environments that result in
diverse behaviors, we propose a framework for procedural generation of
environments that are (1) stylistically similar to human-authored environments,
(2) guaranteed to be solvable by the human-robot team, and (3) diverse with
respect to coordination measures. We analyze the procedurally generated
environments in the Overcooked benchmark domain via simulation and an online
user study. Results show that the environments result in qualitatively
different emerging behaviors and statistically significant differences in
collaborative fluency metrics, even when the robot runs the same planning
algorithm.",2021-06-21,2021,2021-06,environment
Core Challenges in Embodied Vision-Language Planning,"Recent advances in the areas of multimodal machine learning and artificial
intelligence (AI) have led to the development of challenging tasks at the
intersection of Computer Vision, Natural Language Processing, and Embodied AI.
Whereas many approaches and previous survey pursuits have characterised one or
two of these dimensions, there has not been a holistic analysis at the center
of all three. Moreover, even when combinations of these topics are considered,
more focus is placed on describing, e.g., current architectural methods, as
opposed to also illustrating high-level challenges and opportunities for the
field. In this survey paper, we discuss Embodied Vision-Language Planning
(EVLP) tasks, a family of prominent embodied navigation and manipulation
problems that jointly use computer vision and natural language. We propose a
taxonomy to unify these tasks and provide an in-depth analysis and comparison
of the new and current algorithmic approaches, metrics, simulated environments,
as well as the datasets used for EVLP tasks. Finally, we present the core
challenges that we believe new EVLP works should seek to address, and we
advocate for task construction that enables model generalizability and furthers
real-world deployment.",2021-06-26,2021,2021-06,environment
Classical Planning in Deep Latent Space,"Current domain-independent, classical planners require symbolic models of the
problem domain and instance as input, resulting in a knowledge acquisition
bottleneck. Meanwhile, although deep learning has achieved significant success
in many fields, the knowledge is encoded in a subsymbolic representation which
is incompatible with symbolic systems such as planners. We propose Latplan, an
unsupervised architecture combining deep learning and classical planning. Given
only an unlabeled set of image pairs showing a subset of transitions allowed in
the environment (training inputs), Latplan learns a complete propositional PDDL
action model of the environment. Later, when a pair of images representing the
initial and the goal states (planning inputs) is given, Latplan finds a plan to
the goal state in a symbolic latent space and returns a visualized plan
execution. We evaluate Latplan using image-based versions of 6 planning
domains: 8-puzzle, 15-Puzzle, Blocksworld, Sokoban and Two variations of
LightsOut.",2021-06-30,2021,2021-06,environment
"Policy Transfer across Visual and Dynamics Domain Gaps via Iterative
  Grounding","The ability to transfer a policy from one environment to another is a
promising avenue for efficient robot learning in realistic settings where task
supervision is not available. This can allow us to take advantage of
environments well suited for training, such as simulators or laboratories, to
learn a policy for a real robot in a home or office. To succeed, such policy
transfer must overcome both the visual domain gap (e.g. different illumination
or background) and the dynamics domain gap (e.g. different robot calibration or
modelling error) between source and target environments. However, prior policy
transfer approaches either cannot handle a large domain gap or can only address
one type of domain gap at a time. In this paper, we propose a novel policy
transfer method with iterative ""environment grounding"", IDAPT, that alternates
between (1) directly minimizing both visual and dynamics domain gaps by
grounding the source environment in the target environment domains, and (2)
training a policy on the grounded source environment. This iterative training
progressively aligns the domains between the two environments and adapts the
policy to the target environment. Once trained, the policy can be directly
executed on the target environment. The empirical results on locomotion and
robotic manipulation tasks demonstrate that our approach can effectively
transfer a policy across visual and dynamics domain gaps with minimal
supervision and interaction with the target environment. Videos and code are
available at https://clvrai.com/idapt .",2021-07-01,2021,2021-07,environment
Collaborative Visual Navigation,"As a fundamental problem for Artificial Intelligence, multi-agent system
(MAS) is making rapid progress, mainly driven by multi-agent reinforcement
learning (MARL) techniques. However, previous MARL methods largely focused on
grid-world like or game environments; MAS in visually rich environments has
remained less explored. To narrow this gap and emphasize the crucial role of
perception in MAS, we propose a large-scale 3D dataset, CollaVN, for
multi-agent visual navigation (MAVN). In CollaVN, multiple agents are entailed
to cooperatively navigate across photo-realistic environments to reach target
locations. Diverse MAVN variants are explored to make our problem more general.
Moreover, a memory-augmented communication framework is proposed. Each agent is
equipped with a private, external memory to persistently store communication
information. This allows agents to make better use of their past communication
information, enabling more efficient collaboration and robust long-term
planning. In our experiments, several baselines and evaluation metrics are
designed. We also empirically verify the efficacy of our proposed MARL approach
across different MAVN task settings.",2021-07-02,2021,2021-07,environment
"A Systematic Survey of Text Worlds as Embodied Natural Language
  Environments","Text Worlds are virtual environments for embodied agents that, unlike 2D or
3D environments, are rendered exclusively using textual descriptions. These
environments offer an alternative to higher-fidelity 3D environments due to
their low barrier to entry, providing the ability to study semantics,
compositional inference, and other high-level tasks with rich high-level action
spaces while controlling for perceptual input. This systematic survey outlines
recent developments in tooling, environments, and agent modeling for Text
Worlds, while examining recent trends in knowledge graphs, common sense
reasoning, transfer learning of Text World performance to higher-fidelity
environments, as well as near-term development targets that, once achieved,
make Text Worlds an attractive general research paradigm for natural language
processing.",2021-07-08,2021,2021-07,environment
"Adaptive Stress Testing for Adversarial Learning in a Financial
  Environment","We demonstrate the use of Adaptive Stress Testing to detect and address
potential vulnerabilities in a financial environment. We develop a simplified
model for credit card fraud detection that utilizes a linear regression
classifier based on historical payment transaction data coupled with business
rules. We then apply the reinforcement learning model known as Adaptive Stress
Testing to train an agent, that can be thought of as a potential fraudster, to
find the most likely path to system failure -- successfully defrauding the
system. We show the connection between this most likely failure path and the
limits of the classifier and discuss how the fraud detection system's business
rules can be further augmented to mitigate these failure modes.",2021-07-08,2021,2021-07,environment
"SimDem A Multi-agent Simulation Environment to Model Persons with
  Dementia and their Assistance","Developing artificial intelligence based assistive systems to aid Persons
with Dementia (PwD) requires large amounts of training data. However, data
collection poses ethical, legal, economic, and logistic issues. Synthetic data
generation tools, in this regard, provide a potential solution. However, we
believe that already available such tools do not adequately reflect cognitive
deficiencies in behavior simulation. To counter these issues we propose a
simulation model (SimDem ) that primarily focuses on cognitive impairments
suffered by PwD and can be easily configured and adapted by the users to model
and evaluate assistive solutions.",2021-07-12,2021,2021-07,environment
"Multiclass Permanent Magnets Superstructure for Indoor Localization
  using Artificial Intelligence","Smartphones have become a popular tool for indoor localization and position
estimation of users. Existing solutions mainly employ Wi-Fi, RFID, and magnetic
sensing techniques to track movements in crowded venues. These are highly
sensitive to magnetic clutters and depend on local ambient magnetic fields,
which frequently degrades their performance. Also, these techniques often
require pre-known mapping surveys of the area, or the presence of active
beacons, which are not always available. We embed small-volume and large-moment
magnets in pre-known locations and arrange them in specific geometric
constellations that create magnetic superstructure patterns of supervised
magnetic signatures. These signatures constitute an unambiguous magnetic
environment with respect to the moving sensor carrier. The localization
algorithm learns the unique patterns of the scattered magnets during training
and detects them from the ongoing streaming of data during localization. Our
contribution is twofold. First, we deploy passive permanent magnets that do not
require a power supply, in contrast to active magnetic transmitters. Second, we
perform localization based on smartphone motion rather than on static
positioning of the magnetometer. In our previous study, we considered a single
superstructure pattern. Here, we present an extended version of that algorithm
for multi-superstructure localization, which covers a broader localization area
of the user. Experimental results demonstrate localization accuracy of 95% with
a mean localization error of less than 1m using artificial intelligence.",2021-07-14,2021,2021-07,environment
"A Reinforcement Learning Environment for Mathematical Reasoning via
  Program Synthesis","We convert the DeepMind Mathematics Dataset into a reinforcement learning
environment by interpreting it as a program synthesis problem. Each action
taken in the environment adds an operator or an input into a discrete compute
graph. Graphs which compute correct answers yield positive reward, enabling the
optimization of a policy to construct compute graphs conditioned on problem
statements. Baseline models are trained using Double DQN on various subsets of
problem types, demonstrating the capability to learn to correctly construct
graphs despite the challenges of combinatorial explosion and noisy rewards.",2021-07-15,2021,2021-07,environment
An Analysis of Reinforcement Learning for Malaria Control,"Previous work on policy learning for Malaria control has often formulated the
problem as an optimization problem assuming the objective function and the
search space have a specific structure. The problem has been formulated as
multi-armed bandits, contextual bandits and a Markov Decision Process in
isolation. Furthermore, an emphasis is put on developing new algorithms
specific to an instance of Malaria control, while ignoring a plethora of
simpler and general algorithms in the literature. In this work, we formally
study the formulation of Malaria control and present a comprehensive analysis
of several formulations used in the literature. In addition, we implement and
analyze several reinforcement learning algorithms in all formulations and
compare them to black box optimization. In contrast to previous work, our
results show that simple algorithms based on Upper Confidence Bounds are
sufficient for learning good Malaria policies, and tend to outperform their
more advanced counterparts on the malaria OpenAI Gym environment.",2021-07-19,2021,2021-07,environment
"Hindsight Value Function for Variance Reduction in Stochastic Dynamic
  Environment","Policy gradient methods are appealing in deep reinforcement learning but
suffer from high variance of gradient estimate. To reduce the variance, the
state value function is applied commonly. However, the effect of the state
value function becomes limited in stochastic dynamic environments, where the
unexpected state dynamics and rewards will increase the variance. In this
paper, we propose to replace the state value function with a novel hindsight
value function, which leverages the information from the future to reduce the
variance of the gradient estimate for stochastic dynamic environments.
  Particularly, to obtain an ideally unbiased gradient estimate, we propose an
information-theoretic approach, which optimizes the embeddings of the future to
be independent of previous actions. In our experiments, we apply the proposed
hindsight value function in stochastic dynamic environments, including
discrete-action environments and continuous-action environments. Compared with
the standard state value function, the proposed hindsight value function
consistently reduces the variance, stabilizes the training, and improves the
eventual policy.",2021-07-26,2021,2021-07,environment
"Towards Industrial Private AI: A two-tier framework for data and model
  security","With the advances in 5G and IoT devices, the industries are vastly adopting
artificial intelligence (AI) techniques for improving classification and
prediction-based services. However, the use of AI also raises concerns
regarding privacy and security that can be misused or leaked. Private AI was
recently coined to address the data security issue by combining AI with
encryption techniques, but existing studies have shown that model inversion
attacks can be used to reverse engineer the images from model parameters. In
this regard, we propose a Federated Learning and Encryption-based Private
(FLEP) AI framework that provides two-tier security for data and model
parameters in an IIoT environment. We proposed a three-layer encryption method
for data security and provide a hypothetical method to secure the model
parameters. Experimental results show that the proposed method achieves better
encryption quality at the expense of slightly increased execution time. We also
highlight several open issues and challenges regarding the FLEP AI framework's
realization.",2021-07-27,2021,2021-07,environment
"Indoor Localization Under Limited Measurements: A Cross-Environment
  Joint Semi-Supervised and Transfer Learning Approach","The development of highly accurate deep learning methods for indoor
localization is often hindered by the unavailability of sufficient data
measurements in the desired environment to perform model training. To overcome
the challenge of collecting costly measurements, this paper proposes a
cross-environment approach that compensates for insufficient labelled
measurements via a joint semi-supervised and transfer learning technique to
transfer, in an appropriate manner, the model obtained from a rich-data
environment to the desired environment for which data is limited. This is
achieved via a sequence of operations that exploit the similarity across
environments to enhance unlabelled data model training of the desired
environment. Numerical experiments demonstrate that the proposed
cross-environment approach outperforms the conventional method, convolutional
neural network (CNN), with a significant increase in localization accuracy, up
to 43%. Moreover, with only 40% data measurements, the proposed
cross-environment approach compensates for data inadequacy and replicates the
localization accuracy of the conventional method, CNN, which uses 75% data
measurements.",2021-08-04,2021,2021-08,environment
"Artificial Intelligence-Driven Customized Manufacturing Factory: Key
  Technologies, Applications, and Challenges","The traditional production paradigm of large batch production does not offer
flexibility towards satisfying the requirements of individual customers. A new
generation of smart factories is expected to support new multi-variety and
small-batch customized production modes. For that, Artificial Intelligence (AI)
is enabling higher value-added manufacturing by accelerating the integration of
manufacturing and information communication technologies, including computing,
communication, and control. The characteristics of a customized smart factory
are to include self-perception, operations optimization, dynamic
reconfiguration, and intelligent decision-making. The AI technologies will
allow manufacturing systems to perceive the environment, adapt to external
needs, and extract the processed knowledge, including business models, such as
intelligent production, networked collaboration, and extended service models.
  This paper focuses on the implementation of AI in customized manufacturing
(CM). The architecture of an AI-driven customized smart factory is presented.
Details of intelligent manufacturing devices, intelligent information
interaction, and the construction of a flexible manufacturing line are
showcased. The state-of-the-art AI technologies of potential use in CM, i.e.,
machine learning, multi-agent systems, Internet of Things, big data, and
cloud-edge computing are surveyed. The AI-enabled technologies in a customized
smart factory are validated with a case study of customized packaging. The
experimental results have demonstrated that the AI-assisted CM offers the
possibility of higher production flexibility and efficiency. Challenges and
solutions related to AI in CM are also discussed.",2021-08-07,2021,2021-08,environment
Toward Human-Level Artificial Intelligence,"In this paper, we present our research on programming human-level artificial
intelligence (HLAI), including 1) a definition of HLAI, 2) an environment to
develop and test HLAI, and 3) a cognitive architecture for HLAI. The term AI is
used in a broad meaning, and HLAI is not clearly defined. I claim that the
essence of Human-Level Intelligence to be the capability to learn from others'
experiences via language. The key is that the event described by language has
the same effect as if the agent experiences it firsthand for the update of the
behavior policy. To develop and test models with such a capability, we are
developing a simulated environment called SEDRo. There is a 3D Home, and a
mother character takes care of the baby (the learning agent) and teaches
languages. The environment provides comparable experiences to that of a human
baby from birth to one year. Finally, I propose a cognitive architecture of
HLAI called Modulated Heterarchical Prediction Memory (mHPM). In mHPM, there
are three components: a universal module that learns to predict the next vector
given the sequence of vector signals, a heterarchical network of those modules,
and a reward-based modulation of learning. mHPM models the workings of the
neocortex but the innate auxiliary units such hippocampus, reward system,
instincts, and amygdala play critical roles, too.",2021-08-09,2021,2021-08,environment
Adversary agent reinforcement learning for pursuit-evasion,"A reinforcement learning environment with adversary agents is proposed in
this work for pursuit-evasion game in the presence of fog of war, which is of
both scientific significance and practical importance in aerospace
applications. One of the most popular learning environments, StarCraft, is
adopted here and the associated mini-games are analyzed to identify the current
limitation for training adversary agents. The key contribution includes the
analysis of the potential performance of an agent by incorporating control and
differential game theory into the specific reinforcement learning environment,
and the development of an adversary agents challenge (SAAC) environment by
extending the current StarCraft mini-games. The subsequent study showcases the
use of this learning environment and the effectiveness of an adversary agent
for evasion units. Overall, the proposed SAAC environment should benefit
pursuit-evasion studies with rapidly-emerging reinforcement learning
technologies. Last but not least, the corresponding tutorial code can be found
at GitHub.",2021-08-25,2021,2021-08,environment
"Eden: A Unified Environment Framework for Booming Reinforcement Learning
  Algorithms","With AlphaGo defeats top human players, reinforcement learning(RL) algorithms
have gradually become the code-base of building stronger artificial
intelligence(AI). The RL algorithm design firstly needs to adapt to the
specific environment, so the designed environment guides the rapid and profound
development of RL algorithms. However, the existing environments, which can be
divided into real world games and customized toy environments, have obvious
shortcomings. For real world games, it is designed for human entertainment, and
too much difficult for most of RL researchers. For customized toy environments,
there is no widely accepted unified evaluation standard for all RL algorithms.
Therefore, we introduce the first virtual user-friendly environment framework
for RL. In this framework, the environment can be easily configured to realize
all kinds of RL tasks in the mainstream research. Then all the mainstream
state-of-the-art(SOTA) RL algorithms can be conveniently evaluated and
compared. Therefore, our contributions mainly includes the following aspects:
1.single configured environment for all classification of SOTA RL algorithms;
2.combined environment of more than one classification RL algorithms; 3.the
evaluation standard for all kinds of RL algorithms. With all these efforts, a
possibility for breeding an AI with capability of general competency in a
variety of tasks is provided, and maybe it will open up a new chapter for AI.",2021-09-04,2021,2021-09,environment
"Puzzle Solving without Search or Human Knowledge: An Unnatural Language
  Approach","The application of Generative Pre-trained Transformer (GPT-2) to learn
text-archived game notation provides a model environment for exploring sparse
reward gameplay. The transformer architecture proves amenable to training on
solved text archives describing mazes, Rubik's Cube, and Sudoku solvers. The
method benefits from fine-tuning the transformer architecture to visualize
plausible strategies derived outside any guidance from human heuristics or
domain expertise. The large search space ($>10^{19}$) for the games provides a
puzzle environment in which the solution has few intermediate rewards and a
final move that solves the challenge.",2021-09-07,2021,2021-09,environment
"DPMPC-Planner: A real-time UAV trajectory planning framework for complex
  static environments with dynamic obstacles","Safe UAV navigation is challenging due to the complex environment structures,
dynamic obstacles, and uncertainties from measurement noises and unpredictable
moving obstacle behaviors. Although plenty of recent works achieve safe
navigation in complex static environments with sophisticated mapping
algorithms, such as occupancy map and ESDF map, these methods cannot reliably
handle dynamic environments due to the mapping limitation from moving
obstacles. To address the limitation, this paper proposes a trajectory planning
framework to achieve safe navigation considering complex static environments
with dynamic obstacles. To reliably handle dynamic obstacles, we divide the
environment representation into static mapping and dynamic object
representation, which can be obtained from computer vision methods. Our
framework first generates a static trajectory based on the proposed iterative
corridor shrinking algorithm. Then, reactive chance-constrained model
predictive control with temporal goal tracking is applied to avoid dynamic
obstacles with uncertainties. The simulation results in various environments
demonstrate the ability of our algorithm to navigate safely in complex static
environments with dynamic obstacles.",2021-09-14,2021,2021-09,environment
"Agile, Antifragile, Artificial-Intelligence-Enabled, Command and Control","Artificial Intelligence (AI) is rapidly becoming integrated into military
Command and Control (C2) systems as a strategic priority for many defence
forces. The successful implementation of AI is promising to herald a
significant leap in C2 agility through automation. However, realistic
expectations need to be set on what AI can achieve in the foreseeable future.
This paper will argue that AI could lead to a fragility trap, whereby the
delegation of C2 functions to an AI could increase the fragility of C2,
resulting in catastrophic strategic failures. This calls for a new framework
for AI in C2 to avoid this trap. We will argue that antifragility along with
agility should form the core design principles for AI-enabled C2 systems. This
duality is termed Agile, Antifragile, AI-Enabled Command and Control (A3IC2).
An A3IC2 system continuously improves its capacity to perform in the face of
shocks and surprises through overcompensation from feedback during the C2
decision-making cycle. An A3IC2 system will not only be able to survive within
a complex operational environment, it will also thrive, benefiting from the
inevitable shocks and volatility of war.",2021-09-14,2021,2021-09,environment
"Computational Imaging and Artificial Intelligence: The Next Revolution
  of Mobile Vision","Signal capture stands in the forefront to perceive and understand the
environment and thus imaging plays the pivotal role in mobile vision. Recent
explosive progresses in Artificial Intelligence (AI) have shown great potential
to develop advanced mobile platforms with new imaging devices. Traditional
imaging systems based on the ""capturing images first and processing afterwards""
mechanism cannot meet this unprecedented demand. Differently, Computational
Imaging (CI) systems are designed to capture high-dimensional data in an
encoded manner to provide more information for mobile vision systems.Thanks to
AI, CI can now be used in real systems by integrating deep learning algorithms
into the mobile vision platform to achieve the closed loop of intelligent
acquisition, processing and decision making, thus leading to the next
revolution of mobile vision.Starting from the history of mobile vision using
digital cameras, this work first introduces the advances of CI in diverse
applications and then conducts a comprehensive review of current research
topics combining CI and AI. Motivated by the fact that most existing studies
only loosely connect CI and AI (usually using AI to improve the performance of
CI and only limited works have deeply connected them), in this work, we propose
a framework to deeply integrate CI and AI by using the example of self-driving
vehicles with high-speed communication, edge computing and traffic planning.
Finally, we outlook the future of CI plus AI by investigating new materials,
brain science and new computing techniques to shed light on new directions of
mobile vision systems.",2021-09-18,2021,2021-09,environment
"Artificial intelligence for Sustainable Energy: A Contextual Topic
  Modeling and Content Analysis","Parallel to the rising debates over sustainable energy and artificial
intelligence solutions, the world is currently discussing the ethics of
artificial intelligence and its possible negative effects on society and the
environment. In these arguments, sustainable AI is proposed, which aims at
advancing the pathway toward sustainability, such as sustainable energy. In
this paper, we offered a novel contextual topic modeling combining LDA, BERT,
and Clustering. We then combined these computational analyses with content
analysis of related scientific publications to identify the main scholarly
topics, sub-themes, and cross-topic themes within scientific research on
sustainable AI in energy. Our research identified eight dominant topics
including sustainable buildings, AI-based DSSs for urban water management,
climate artificial intelligence, Agriculture 4, the convergence of AI with IoT,
AI-based evaluation of renewable technologies, smart campus and engineering
education, and AI-based optimization. We then recommended 14 potential future
research strands based on the observed theoretical gaps. Theoretically, this
analysis contributes to the existing literature on sustainable AI and
sustainable energy, and practically, it intends to act as a general guide for
energy engineers and scientists, AI scientists, and social scientists to widen
their knowledge of sustainability in AI and energy convergence research.",2021-10-02,2021,2021-10,environment
Multi-Agent Path Planning Using Deep Reinforcement Learning,"In this paper a deep reinforcement based multi-agent path planning approach
is introduced. The experiments are realized in a simulation environment and in
this environment different multi-agent path planning problems are produced. The
produced problems are actually similar to a vehicle routing problem and they
are solved using multi-agent deep reinforcement learning. In the simulation
environment, the model is trained on different consecutive problems in this way
and, as the time passes, it is observed that the model's performance to solve a
problem increases. Always the same simulation environment is used and only the
location of target points for the agents to visit is changed. This contributes
the model to learn its environment and the right attitude against a problem as
the episodes pass. At the end, a model who has already learned a lot to solve a
path planning or routing problem in this environment is obtained and this model
can already find a nice and instant solution to a given unseen problem even
without any training. In routing problems, standard mathematical modeling or
heuristics seem to suffer from high computational time to find the solution and
it is also difficult and critical to find an instant solution. In this paper a
new solution method against these points is proposed and its efficiency is
proven experimentally.",2021-10-04,2021,2021-10,environment
"Towards Robust and Transferable IIoT Sensor based Anomaly Classification
  using Artificial Intelligence","The increasing deployment of low-cost industrial IoT (IIoT) sensor platforms
on industrial assets enables great opportunities for anomaly classification in
industrial plants. The performance of such a classification model depends
highly on the available training data. Models perform well when the training
data comes from the same machine. However, as soon as the machine is changed,
repaired, or put into operation in a different environment, the prediction
often fails. For this reason, we investigate whether it is feasible to have a
robust and transferable method for AI based anomaly classification using
different models and pre-processing steps on centrifugal pumps which are
dismantled and put back into operation in the same as well as in different
environments. Further, we investigate the model performance on different pumps
from the same type compared to those from the training data.",2021-10-07,2021,2021-10,environment
"Using Human-Guided Causal Knowledge for More Generalized Robot Task
  Planning","A major challenge in research involving artificial intelligence (AI) is the
development of algorithms that can find solutions to problems that can
generalize to different environments and tasks. Unlike AI, humans are adept at
finding solutions that can transfer. We hypothesize this is because their
solutions are informed by causal models. We propose to use human-guided causal
knowledge to help robots find solutions that can generalize to a new
environment. We develop and test the feasibility of a language interface that
na\""ive participants can use to communicate these causal models to a planner.
We find preliminary evidence that participants are able to use our interface
and generate causal models that achieve near-generalization. We outline an
experiment aimed at testing far-generalization using our interface and describe
our longer terms goals for these causal models.",2021-10-09,2021,2021-10,environment
"Perceptions and attitudes of Children and Young People to Artificial
  Intelligence in Medicine","There is increasing interest in Artificial Intelligence and its application
to medicine. Perceptions are less well-known, notably amongst children and
young people. 21 members of a Young Persons Advisory Group for research,
recommend creating an enabling environment with children and young people,
through educational workshops with practical examples that use Artificial
Intelligence to help, but not replace humans, address issues, build trust, and
effectively communicate about potential opportunities.",2021-10-10,2021,2021-10,environment
"Planning from Pixels in Environments with Combinatorially Hard Search
  Spaces","The ability to form complex plans based on raw visual input is a litmus test
for current capabilities of artificial intelligence, as it requires a seamless
combination of visual processing and abstract algorithmic execution, two
traditionally separate areas of computer science. A recent surge of interest in
this field brought advances that yield good performance in tasks ranging from
arcade games to continuous control; these methods however do not come without
significant issues, such as limited generalization capabilities and
difficulties when dealing with combinatorially hard planning instances. Our
contribution is two-fold: (i) we present a method that learns to represent its
environment as a latent graph and leverages state reidentification to reduce
the complexity of finding a good policy from exponential to linear (ii) we
introduce a set of lightweight environments with an underlying discrete
combinatorial structure in which planning is challenging even for humans.
Moreover, we show that our methods achieves strong empirical generalization to
variations in the environment, even across highly disadvantaged regimes, such
as ""one-shot"" planning, or in an offline RL paradigm which only provides
low-quality trajectories.",2021-10-12,2021,2021-10,environment
"Extending Environments To Measure Self-Reflection In Reinforcement
  Learning","We consider an extended notion of reinforcement learning in which the
environment can simulate the agent and base its outputs on the agent's
hypothetical behavior. Since good performance usually requires paying attention
to whatever things the environment's outputs are based on, we argue that for an
agent to achieve on-average good performance across many such extended
environments, it is necessary for the agent to self-reflect. Thus
weighted-average performance over the space of all suitably well-behaved
extended environments could be considered a way of measuring how
self-reflective an agent is. We give examples of extended environments and
introduce a simple transformation which experimentally seems to increase some
standard RL agents' performance in a certain type of extended environment.",2021-10-13,2021,2021-10,environment
sbp-env: Sampling-based Motion Planners' Testing Environment,"Sampling-based motion planners' testing environment (sbp-env) is a full
feature framework to quickly test different sampling-based algorithms for
motion planning. sbp-env focuses on the flexibility of tinkering with different
aspects of the framework, and had divided the main planning components into two
categories (i) samplers and (ii) planners.
  The focus of motion planning research had been mainly on (i) improving the
sampling efficiency (with methods such as heuristic or learned distribution)
and (ii) the algorithmic aspect of the planner using different routines to
build a connected graph. Therefore, by separating the two components one can
quickly swap out different components to test novel ideas.",2021-10-15,2021,2021-10,environment
Anticipation-driven Adaptive Architecture for Assisted Living,"Anticipatory expression underlies human performance. Medical conditions and,
especially, aging result in diminished anticipatory action. In order to
mitigate the loss, means for engaging still available resources (capabilities)
can be provided. In particular, anticipation-driven adaptive environments could
be beneficial in medical care, as well as in assisted living for those seeking
such assistance. These adaptive environments are conceived to be individualized
and individualizable, in order to stimulate independent action instead of
creating dependencies.",2021-10-15,2021,2021-10,environment
"SILG: The Multi-environment Symbolic Interactive Language Grounding
  Benchmark","Existing work in language grounding typically study single environments. How
do we build unified models that apply across multiple environments? We propose
the multi-environment Symbolic Interactive Language Grounding benchmark (SILG),
which unifies a collection of diverse grounded language learning environments
under a common interface. SILG consists of grid-world environments that require
generalization to new dynamics, entities, and partially observed worlds (RTFM,
Messenger, NetHack), as well as symbolic counterparts of visual worlds that
require interpreting rich natural language with respect to complex scenes
(ALFWorld, Touchdown). Together, these environments provide diverse grounding
challenges in richness of observation space, action space, language
specification, and plan complexity. In addition, we propose the first shared
model architecture for RL on these environments, and evaluate recent advances
such as egocentric local convolution, recurrent state-tracking, entity-centric
attention, and pretrained LM using SILG. Our shared architecture achieves
comparable performance to environment-specific architectures. Moreover, we find
that many recent modelling advances do not result in significant gains on
environments other than the one they were designed for. This highlights the
need for a multi-environment benchmark. Finally, the best models significantly
underperform humans on SILG, which suggests ample room for future work. We hope
SILG enables the community to quickly identify new methodologies for language
grounding that generalize to a diverse set of environments and their associated
challenges.",2021-10-20,2021,2021-10,environment
"Unraveling the Hidden Environmental Impacts of AI Solutions for
  Environment","In the past ten years, artificial intelligence has encountered such dramatic
progress that it is now seen as a tool of choice to solve environmental issues
and in the first place greenhouse gas emissions (GHG). At the same time the
deep learning community began to realize that training models with more and
more parameters requires a lot of energy and as a consequence GHG emissions. To
our knowledge, questioning the complete net environmental impacts of AI
solutions for the environment (AI for Green), and not only GHG, has never been
addressed directly. In this article, we propose to study the possible negative
impacts of AI for Green. First, we review the different types of AI impacts,
then we present the different methodologies used to assess those impacts, and
show how to apply life cycle assessment to AI services. Finally, we discuss how
to assess the environmental usefulness of a general AI service, and point out
the limitations of existing work in AI for Green.",2021-10-22,2021,2021-10,environment
Adaptability of Improved NEAT in Variable Environments,"A large challenge in Artificial Intelligence (AI) is training control agents
that can properly adapt to variable environments. Environments in which the
conditions change can cause issues for agents trying to operate in them.
Building algorithms that can train agents to operate in these environments and
properly deal with the changing conditions is therefore important.
NeuroEvolution of Augmenting Topologies (NEAT) was a novel Genetic Algorithm
(GA) when it was created, but has fallen aside with newer GAs outperforming it.
This paper furthers the research on this subject by implementing various
versions of improved NEAT in a variable environment to determine if NEAT can
perform well in these environments. The improvements included, in every
combination, are: recurrent connections, automatic feature selection, and
increasing population size. The recurrent connections improvement performed
extremely well. The automatic feature selection improvement was found to be
detrimental to performance, and the increasing population size improvement
lowered performance a small amount, but decreased computation requirements
noticeably.",2021-10-22,2021,2021-10,environment
"Transfer learning with causal counterfactual reasoning in Decision
  Transformers","The ability to adapt to changes in environmental contingencies is an
important challenge in reinforcement learning. Indeed, transferring previously
acquired knowledge to environments with unseen structural properties can
greatly enhance the flexibility and efficiency by which novel optimal policies
may be constructed. In this work, we study the problem of transfer learning
under changes in the environment dynamics. In this study, we apply causal
reasoning in the offline reinforcement learning setting to transfer a learned
policy to new environments. Specifically, we use the Decision Transformer (DT)
architecture to distill a new policy on the new environment. The DT is trained
on data collected by performing policy rollouts on factual and counterfactual
simulations from the source environment. We show that this mechanism can
bootstrap a successful policy on the target environment while retaining most of
the reward.",2021-10-27,2021,2021-10,environment
"Investigation of Independent Reinforcement Learning Algorithms in
  Multi-Agent Environments","Independent reinforcement learning algorithms have no theoretical guarantees
for finding the best policy in multi-agent settings. However, in practice,
prior works have reported good performance with independent algorithms in some
domains and bad performance in others. Moreover, a comprehensive study of the
strengths and weaknesses of independent algorithms is lacking in the
literature. In this paper, we carry out an empirical comparison of the
performance of independent algorithms on four PettingZoo environments that span
the three main categories of multi-agent environments, i.e., cooperative,
competitive, and mixed. We show that in fully-observable environments,
independent algorithms can perform on par with multi-agent algorithms in
cooperative and competitive settings. For the mixed environments, we show that
agents trained via independent algorithms learn to perform well individually,
but fail to learn to cooperate with allies and compete with enemies. We also
show that adding recurrence improves the learning of independent algorithms in
cooperative partially observable environments.",2021-11-01,2021,2021-11,environment
Ten Conceptual Dimensions of Context,"This paper attempts to synthesize various conceptualizations of the term
""context"" as found in computing literature. Ten conceptual dimensions of
context thus emerge -- location; user, task, and system characteristics;
physical, social, organizational, and cultural environments; time-related
aspects, and historical information. Together, the ten dimensions of context
provide a comprehensive view of the notion of context, and allow for a more
systematic examination of the influence of context and contextual information
on human-system or human-AI interactions.",2021-11-04,2021,2021-11,environment
Robust Deep Reinforcement Learning for Quadcopter Control,"Deep reinforcement learning (RL) has made it possible to solve complex
robotics problems using neural networks as function approximators. However, the
policies trained on stationary environments suffer in terms of generalization
when transferred from one environment to another. In this work, we use Robust
Markov Decision Processes (RMDP) to train the drone control policy, which
combines ideas from Robust Control and RL. It opts for pessimistic optimization
to handle potential gaps between policy transfer from one environment to
another. The trained control policy is tested on the task of quadcopter
positional control. RL agents were trained in a MuJoCo simulator. During
testing, different environment parameters (unseen during the training) were
used to validate the robustness of the trained policy for transfer from one
environment to another. The robust policy outperformed the standard agents in
these environments, suggesting that the added robustness increases generality
and can adapt to non-stationary environments.
  Codes: https://github.com/adipandas/gym_multirotor",2021-11-06,2021,2021-11,environment
"Artificial Intelligence Technology analysis using Artificial
  Intelligence patent through Deep Learning model and vector space model","Thanks to rapid development of artificial intelligence technology in recent
years, the current artificial intelligence technology is contributing to many
part of society. Education, environment, medical care, military, tourism,
economy, politics, etc. are having a very large impact on society as a whole.
For example, in the field of education, there is an artificial intelligence
tutoring system that automatically assigns tutors based on student's level. In
the field of economics, there are quantitative investment methods that
automatically analyze large amounts of data to find investment laws to create
investment models or predict changes in financial markets. As such, artificial
intelligence technology is being used in various fields. So, it is very
important to know exactly what factors have an important influence on each
field of artificial intelligence technology and how the relationship between
each field is connected. Therefore, it is necessary to analyze artificial
intelligence technology in each field. In this paper, we analyze patent
documents related to artificial intelligence technology. We propose a method
for keyword analysis within factors using artificial intelligence patent data
sets for artificial intelligence technology analysis. This is a model that
relies on feature engineering based on deep learning model named KeyBERT, and
using vector space model. A case study of collecting and analyzing artificial
intelligence patent data was conducted to show how the proposed model can be
applied to real world problems.",2021-11-08,2021,2021-11,environment
"Machine Learning Models Disclosure from Trusted Research Environments
  (TRE), Challenges and Opportunities","Artificial intelligence (AI) applications in healthcare and medicine have
increased in recent years. To enable access to personal data, Trusted Research
environments (TREs) provide safe and secure environments in which researchers
can access sensitive personal data and develop Artificial Intelligence (AI) and
Machine Learning models. However currently few TREs support the use of
automated AI-based modelling using Machine Learning. Early attempts have been
made in the literature to present and introduce privacy preserving machine
learning from the design point of view [1]. However, there exists a gap in the
practical decision-making guidance for TREs in handling models disclosure.
Specifically, the use of machine learning creates a need to disclose new types
of outputs from TREs, such as trained machine learning models. Although TREs
have clear policies for the disclosure of statistical outputs, the extent to
which trained models can leak personal training data once released is not well
understood and guidelines do not exist within TREs for the safe disclosure of
these models.
  In this paper we introduce the challenge of disclosing trained machine
learning models from TREs. We first give an overview of machine learning models
in general and describe some of their applications in healthcare and medicine.
We define the main vulnerabilities of trained machine learning models in
general. We also describe the main factors affecting the vulnerabilities of
disclosing machine learning models. This paper also provides insights and
analyses methods that could be introduced within TREs to mitigate the risk of
privacy breaches when disclosing trained models.",2021-11-10,2021,2021-11,environment
VisualEnv: visual Gym environments with Blender,"In this paper VisualEnv, a new tool for creating visual environment for
reinforcement learning is introduced. It is the product of an integration of an
open-source modelling and rendering software, Blender, and a python module used
to generate environment model for simulation, OpenAI Gym. VisualEnv allows the
user to create custom environments with photorealistic rendering capabilities
and full integration with python. The framework is described and tested on a
series of example problems that showcase its features for training
reinforcement learning agents.",2021-11-15,2021,2021-11,environment
The Prominence of Artificial Intelligence in COVID-19,"In December 2019, a novel virus called COVID-19 had caused an enormous number
of causalities to date. The battle with the novel Coronavirus is baffling and
horrifying after the Spanish Flu 2019. While the front-line doctors and medical
researchers have made significant progress in controlling the spread of the
highly contiguous virus, technology has also proved its significance in the
battle. Moreover, Artificial Intelligence has been adopted in many medical
applications to diagnose many diseases, even baffling experienced doctors.
Therefore, this survey paper explores the methodologies proposed that can aid
doctors and researchers in early and inexpensive methods of diagnosis of the
disease. Most developing countries have difficulties carrying out tests using
the conventional manner, but a significant way can be adopted with Machine and
Deep Learning. On the other hand, the access to different types of medical
images has motivated the researchers. As a result, a mammoth number of
techniques are proposed. This paper first details the background knowledge of
the conventional methods in the Artificial Intelligence domain. Following that,
we gather the commonly used datasets and their use cases to date. In addition,
we also show the percentage of researchers adopting Machine Learning over Deep
Learning. Thus we provide a thorough analysis of this scenario. Lastly, in the
research challenges, we elaborate on the problems faced in COVID-19 research,
and we address the issues with our understanding to build a bright and healthy
environment.",2021-11-18,2021,2021-11,environment
Expert-Guided Symmetry Detection in Markov Decision Processes,"Learning a Markov Decision Process (MDP) from a fixed batch of trajectories
is a non-trivial task whose outcome's quality depends on both the amount and
the diversity of the sampled regions of the state-action space. Yet, many MDPs
are endowed with invariant reward and transition functions with respect to some
transformations of the current state and action. Being able to detect and
exploit these structures could benefit not only the learning of the MDP but
also the computation of its subsequent optimal control policy. In this work we
propose a paradigm, based on Density Estimation methods, that aims to detect
the presence of some already supposed transformations of the state-action space
for which the MDP dynamics is invariant. We tested the proposed approach in a
discrete toroidal grid environment and in two notorious environments of
OpenAI's Gym Learning Suite. The results demonstrate that the model
distributional shift is reduced when the dataset is augmented with the data
obtained by using the detected symmetries, allowing for a more thorough and
data-efficient learning of the transition functions.",2021-11-19,2021,2021-11,environment
"Inducing Functions through Reinforcement Learning without Task
  Specification","We report a bio-inspired framework for training a neural network through
reinforcement learning to induce high level functions within the network. Based
on the interpretation that animals have gained their cognitive functions such
as object recognition - without ever being specifically trained for - as a
result of maximizing their fitness to the environment, we place our agent in an
environment where developing certain functions may facilitate decision making.
The experimental results show that high level functions, such as image
classification and hidden variable estimation, can be naturally and
simultaneously induced without any pre-training or specifying them.",2021-11-23,2021,2021-11,environment
Architecting and Visualizing Deep Reinforcement Learning Models,"To meet the growing interest in Deep Reinforcement Learning (DRL), we sought
to construct a DRL-driven Atari Pong agent and accompanying visualization tool.
Existing approaches do not support the flexibility required to create an
interactive exhibit with easily-configurable physics and a human-controlled
player. Therefore, we constructed a new Pong game environment, discovered and
addressed a number of unique data deficiencies that arise when applying DRL to
a new environment, architected and tuned a policy gradient based DRL model,
developed a real-time network visualization, and combined these elements into
an interactive display to help build intuition and awareness of the mechanics
of DRL inference.",2021-12-02,2021,2021-12,environment
"Est-ce que vous compute? Code-switching, cultural identity, and AI","Cultural code-switching concerns how we adjust our overall behaviours,
manners of speaking, and appearance in response to a perceived change in our
social environment. We defend the need to investigate cultural code-switching
capacities in artificial intelligence systems. We explore a series of ethical
and epistemic issues that arise when bringing cultural code-switching to bear
on artificial intelligence. Building upon Dotson's (2014) analysis of
testimonial smothering, we discuss how emerging technologies in AI can give
rise to epistemic oppression, and specifically, a form of self-silencing that
we call 'cultural smothering'. By leaving the socio-dynamic features of
cultural code-switching unaddressed, AI systems risk negatively impacting
already-marginalised social groups by widening opportunity gaps and further
entrenching social inequalities.",2021-12-15,2021,2021-12,environment
"Explainable Artificial Intelligence for Autonomous Driving: A
  Comprehensive Overview and Field Guide for Future Research Directions","Autonomous driving has achieved significant milestones in research and
development over the last two decades. There is increasing interest in the
field as the deployment of autonomous vehicles (AVs) promises safer and more
ecologically friendly transportation systems. With the rapid progress in
computationally powerful artificial intelligence (AI) techniques, AVs can sense
their environment with high precision, make safe real-time decisions, and
operate reliably without human intervention. However, intelligent
decision-making in such vehicles is not generally understandable by humans in
the current state of the art, and such deficiency hinders this technology from
being socially acceptable. Hence, aside from making safe real-time decisions,
AVs must also explain their AI-guided decision-making process in order to be
regulatory compliant across many jurisdictions. Our study sheds comprehensive
light on the development of explainable artificial intelligence (XAI)
approaches for AVs. In particular, we make the following contributions. First,
we provide a thorough overview of the state-of-the-art and emerging approaches
for XAI-based autonomous driving. We then propose a conceptual framework that
considers the essential elements for explainable end-to-end autonomous driving.
Finally, we present XAI-based prospective directions and emerging paradigms for
future directions that hold promise for enhancing transparency,
trustworthiness, and societal acceptance of AVs.",2021-12-21,2021,2021-12,environment
On some Foundational Aspects of Human-Centered Artificial Intelligence,"The burgeoning of AI has prompted recommendations that AI techniques should
be ""human-centered"". However, there is no clear definition of what is meant by
Human Centered Artificial Intelligence, or for short, HCAI. This paper aims to
improve this situation by addressing some foundational aspects of HCAI. To do
so, we introduce the term HCAI agent to refer to any physical or software
computational agent equipped with AI components and that interacts and/or
collaborates with humans. This article identifies five main conceptual
components that participate in an HCAI agent: Observations, Requirements,
Actions, Explanations and Models. We see the notion of HCAI agent, together
with its components and functions, as a way to bridge the technical and
non-technical discussions on human-centered AI. In this paper, we focus our
analysis on scenarios consisting of a single agent operating in dynamic
environments in presence of humans.",2021-12-29,2021,2021-12,environment
"Dynamic programming with incomplete information to overcome navigational
  uncertainty in a nautical environment","Using a novel toy nautical navigation environment, we show that dynamic
programming can be used when only incomplete information about a partially
observed Markov decision process (POMDP) is known. By incorporating uncertainty
into our model, we show that navigation policies can be constructed that
maintain safety, outperforming the baseline performance of traditional dynamic
programming for Markov decision processes (MDPs). Adding in controlled sensing
methods, we show that these policies can also lower measurement costs at the
same time.",2021-12-29,2021,2021-12,environment
Aim in Climate Change and City Pollution,"The sustainability of urban environments is an increasingly relevant problem.
Air pollution plays a key role in the degradation of the environment as well as
the health of the citizens exposed to it. In this chapter we provide a review
of the methods available to model air pollution, focusing on the application of
machine-learning methods. In fact, machine-learning methods have proved to
importantly increase the accuracy of traditional air-pollution approaches while
limiting the development cost of the models. Machine-learning tools have opened
new approaches to study air pollution, such as flow-dynamics modelling or
remote-sensing methodologies.",2021-12-30,2021,2021-12,environment
"Deep Reinforcement Learning, a textbook","Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",2022-01-04,2022,2022-01,environment
"A Survey on Applications of Digital Human Avatars toward Virtual
  Co-presence","This paper investigates different approaches to build and use digital human
avatars toward interactive Virtual Co-presence (VCP) environments. We evaluate
the evolution of technologies for creating VCP environments and how the
advancement in Artificial Intelligence (AI) and Computer Graphics affect the
quality of VCP environments. We categorize different methods in the literature
based on their applications and methodology and compare various groups and
strategies based on their applications, contributions, and limitations. We also
have a brief discussion about the approaches that other forms of human
representation, rather than digital human avatars, have been utilized in VCP
environments. Our goal is to fill the gap in the research domain where there is
a lack of literature review investigating different approaches for creating
avatar-based VCP environments. We hope this study will be useful for future
research involving human representation in VCP or Virtual Reality (VR)
environments. To the best of our knowledge, it is the first survey research
that investigates avatar-based VCP environments. Specifically, the
categorization methodology suggested in this paper for avatar-based methods is
new.",2022-01-11,2022,2022-01,environment
"Criticality-Based Varying Step-Number Algorithm for Reinforcement
  Learning","In the context of reinforcement learning we introduce the concept of
criticality of a state, which indicates the extent to which the choice of
action in that particular state influences the expected return. That is, a
state in which the choice of action is more likely to influence the final
outcome is considered as more critical than a state in which it is less likely
to influence the final outcome.
  We formulate a criticality-based varying step number algorithm (CVS) - a
flexible step number algorithm that utilizes the criticality function provided
by a human, or learned directly from the environment. We test it in three
different domains including the Atari Pong environment, Road-Tree environment,
and Shooter environment. We demonstrate that CVS is able to outperform popular
learning algorithms such as Deep Q-Learning and Monte Carlo.",2022-01-13,2022,2022-01,environment
"Cognitive Ledger Project: Towards Building Personal Digital Twins
  Through Cognitive Blockchain","The Cognitive Ledger Project is an effort to develop a modular system for
turning users' personal data into structured information and machine learning
models based on a blockchain-based infrastructure. In this work-in-progress
paper, we propose a cognitive architecture for cognitive digital twins. The
suggested design embraces a cognitive blockchain (Cognitive ledger) at its
core. The architecture includes several modules that turn users' activities in
the digital environment into reusable knowledge objects and artificial
intelligence that one day can work together to form the cognitive digital twin
of users.",2022-01-20,2022,2022-01,environment
Goal Recognition as Reinforcement Learning,"Most approaches for goal recognition rely on specifications of the possible
dynamics of the actor in the environment when pursuing a goal. These
specifications suffer from two key issues. First, encoding these dynamics
requires careful design by a domain expert, which is often not robust to noise
at recognition time. Second, existing approaches often need costly real-time
computations to reason about the likelihood of each potential goal. In this
paper, we develop a framework that combines model-free reinforcement learning
and goal recognition to alleviate the need for careful, manual domain design,
and the need for costly online executions. This framework consists of two main
stages: Offline learning of policies or utility functions for each potential
goal, and online inference. We provide a first instance of this framework using
tabular Q-learning for the learning stage, as well as three measures that can
be used to perform the inference stage. The resulting instantiation achieves
state-of-the-art performance against goal recognizers on standard evaluation
domains and superior performance in noisy environments.",2022-02-13,2022,2022-02,environment
Artificial Intelligence for the Metaverse: A Survey,"Along with the massive growth of the Internet from the 1990s until now,
various innovative technologies have been created to bring users breathtaking
experiences with more virtual interactions in cyberspace. Many virtual
environments with thousands of services and applications, from social networks
to virtual gaming worlds, have been developed with immersive experience and
digital transformation, but most are incoherent instead of being integrated
into a platform. In this context, metaverse, a term formed by combining meta
and universe, has been introduced as a shared virtual world that is fueled by
many emerging technologies, such as fifth-generation networks and beyond,
virtual reality, and artificial intelligence (AI). Among such technologies, AI
has shown the great importance of processing big data to enhance immersive
experience and enable human-like intelligence of virtual agents. In this
survey, we make a beneficial effort to explore the role of AI in the foundation
and development of the metaverse. We first deliver a preliminary of AI,
including machine learning algorithms and deep learning architectures, and its
role in the metaverse. We then convey a comprehensive investigation of AI-based
methods concerning six technical aspects that have potentials for the
metaverse: natural language processing, machine vision, blockchain, networking,
digital twin, and neural interface, and being potential for the metaverse.
Subsequently, several AI-aided applications, such as healthcare, manufacturing,
smart cities, and gaming, are studied to be deployed in the virtual worlds.
Finally, we conclude the key contribution of this survey and open some future
research directions in AI for the metaverse.",2022-02-15,2022,2022-02,environment
System Safety and Artificial Intelligence,"This chapter formulates seven lessons for preventing harm in artificial
intelligence (AI) systems based on insights from the field of system safety for
software-based automation in safety-critical domains. New applications of AI
across societal domains and public organizations and infrastructures come with
new hazards, which lead to new forms of harm, both grave and pernicious. The
text addresses the lack of consensus for diagnosing and eliminating new AI
system hazards. For decades, the field of system safety has dealt with
accidents and harm in safety-critical systems governed by varying degrees of
software-based automation and decision-making. This field embraces the core
assumption of systems and control that AI systems cannot be safeguarded by
technical design choices on the model or algorithm alone, instead requiring an
end-to-end hazard analysis and design frame that includes the context of use,
impacted stakeholders and the formal and informal institutional environment in
which the system operates. Safety and other values are then inherently
socio-technical and emergent system properties that require design and control
measures to instantiate these across the technical, social and institutional
components of a system. This chapter honors system safety pioneer Nancy
Leveson, by situating her core lessons for today's AI system safety challenges.
For every lesson, concrete tools are offered for rethinking and reorganizing
the safety management of AI systems, both in design and governance. This
history tells us that effective AI safety management requires transdisciplinary
approaches and a shared language that allows involvement of all levels of
society.",2022-02-18,2022,2022-02,environment
"Towards a Responsible AI Development Lifecycle: Lessons From Information
  Security","Legislation and public sentiment throughout the world have promoted fairness
metrics, explainability, and interpretability as prescriptions for the
responsible development of ethical artificial intelligence systems. Despite the
importance of these three pillars in the foundation of the field, they can be
challenging to operationalize and attempts to solve the problems in production
environments often feel Sisyphean. This difficulty stems from a number of
factors: fairness metrics are computationally difficult to incorporate into
training and rarely alleviate all of the harms perpetrated by these systems.
Interpretability and explainability can be gamed to appear fair, may
inadvertently reduce the privacy of personal information contained in training
data, and increase user confidence in predictions -- even when the explanations
are wrong. In this work, we propose a framework for responsibly developing
artificial intelligence systems by incorporating lessons from the field of
information security and the secure development lifecycle to overcome
challenges associated with protecting users in adversarial settings. In
particular, we propose leveraging the concepts of threat modeling, design
review, penetration testing, and incident response in the context of developing
AI systems as ways to resolve shortcomings in the aforementioned methods.",2022-03-06,2022,2022-03,environment
"A Perspective on Robotic Telepresence and Teleoperation using Cognition:
  Are we there yet?","Telepresence and teleoperation robotics have attracted a great amount of
attention in the last 10 years. With the Artificial Intelligence (AI)
revolution already being started, we can see a wide range of robotic
applications being realized. Intelligent robotic systems are being deployed
both in industrial and domestic environments. Telepresence is the idea of being
present in a remote location virtually or via robotic avatars. Similarly, the
idea of operating a robot from a remote location for various tasks is called
teleoperation. These technologies find significant application in health care,
education, surveillance, disaster recovery, and corporate/government sectors.
But question still remains about their maturity, security and safety levels. We
also need to think about enhancing the user experience and trust in such
technologies going into the next generation of computing.",2022-03-06,2022,2022-03,environment
"Artificial Intelligence in Vehicular Wireless Networks: A Case Study
  Using ns-3","Artificial intelligence (AI) techniques have emerged as a powerful approach
to make wireless networks more efficient and adaptable. In this paper we
present an ns-3 simulation framework, able to implement AI algorithms for the
optimization of wireless networks. Our pipeline consists of: (i) a new
geometry-based mobility-dependent channel model for V2X; (ii) all the layers of
a 5G-NR-compliant protocol stack, based on the ns3-mmwave module; (iii) a new
application to simulate V2X data transmission, and (iv) a new intelligent
entity for the control of the network via AI. Thanks to its flexible and
modular design, researchers can use this tool to implement, train, and evaluate
their own algorithms in a realistic and controlled environment. We test the
behavior of our framework in a Predictive Quality of Service (PQoS) scenario,
where AI functionalities are implemented using Reinforcement Learning (RL), and
demonstrate that it promotes better network optimization compared to baseline
solutions that do not implement AI.",2022-03-10,2022,2022-03,environment
Context is Everything: Implicit Identification for Dynamics Adaptation,"Understanding environment dynamics is necessary for robots to act safely and
optimally in the world. In realistic scenarios, dynamics are non-stationary and
the causal variables such as environment parameters cannot necessarily be
precisely measured or inferred, even during training. We propose Implicit
Identification for Dynamics Adaptation (IIDA), a simple method to allow
predictive models to adapt to changing environment dynamics. IIDA assumes no
access to the true variations in the world and instead implicitly infers
properties of the environment from a small amount of contextual data. We
demonstrate IIDA's ability to perform well in unseen environments through a
suite of simulated experiments on MuJoCo environments and a real robot dynamic
sliding task. In general, IIDA significantly reduces model error and results in
higher task performance over commonly used methods. Our code and robot videos
are at https://bennevans.github.io/iida/",2022-03-10,2022,2022-03,environment
ZIN: When and How to Learn Invariance Without Environment Partition?,"It is commonplace to encounter heterogeneous data, of which some aspects of
the data distribution may vary but the underlying causal mechanisms remain
constant. When data are divided into distinct environments according to the
heterogeneity, recent invariant learning methods have proposed to learn robust
and invariant models based on this environment partition. It is hence tempting
to utilize the inherent heterogeneity even when environment partition is not
provided. Unfortunately, in this work, we show that learning invariant features
under this circumstance is fundamentally impossible without further inductive
biases or additional information. Then, we propose a framework to jointly learn
environment partition and invariant representation, assisted by additional
auxiliary information. We derive sufficient and necessary conditions for our
framework to provably identify invariant features under a fairly general
setting. Experimental results on both synthetic and real world datasets
validate our analysis and demonstrate an improved performance of the proposed
framework over existing methods. Finally, our results also raise the need of
making the role of inductive biases more explicit in future works, when
considering learning invariant models without environment partition. Codes are
available at https://github.com/linyongver/ZIN_official .",2022-03-11,2022,2022-03,environment
A Survey on Infrared Image and Video Sets,"In this survey, we compile a list of publicly available infrared image and
video sets for artificial intelligence and computer vision researchers. We
mainly focus on IR image and video sets which are collected and labelled for
computer vision applications such as object detection, object segmentation,
classification, and motion detection. We categorize 92 different publicly
available or private sets according to their sensor types, image resolution,
and scale. We describe each and every set in detail regarding their collection
purpose, operation environment, optical system properties, and area of
application. We also cover a general overview of fundamental concepts that
relate to IR imagery, such as IR radiation, IR detectors, IR optics and
application fields. We analyse the statistical significance of the entire
corpus from different perspectives. We believe that this survey will be a
guideline for computer vision and artificial intelligence researchers that are
interested in working with the spectra beyond the visible domain.",2022-03-16,2022,2022-03,environment
Explainability in reinforcement learning: perspective and position,"Artificial intelligence (AI) has been embedded into many aspects of people's
daily lives and it has become normal for people to have AI make decisions for
them. Reinforcement learning (RL) models increase the space of solvable
problems with respect to other machine learning paradigms. Some of the most
interesting applications are in situations with non-differentiable expected
reward function, operating in unknown or underdefined environment, as well as
for algorithmic discovery that surpasses performance of any teacher, whereby
agent learns from experimental experience through simple feedback. The range of
applications and their social impact is vast, just to name a few: genomics,
game-playing (chess, Go, etc.), general optimization, financial investment,
governmental policies, self-driving cars, recommendation systems, etc. It is
therefore essential to improve the trust and transparency of RL-based systems
through explanations. Most articles dealing with explainability in artificial
intelligence provide methods that concern supervised learning and there are
very few articles dealing with this in the area of RL. The reasons for this are
the credit assignment problem, delayed rewards, and the inability to assume
that data is independently and identically distributed (i.i.d.). This position
paper attempts to give a systematic overview of existing methods in the
explainable RL area and propose a novel unified taxonomy, building and
expanding on the existing ones. The position section describes pragmatic
aspects of how explainability can be observed. The gap between the parties
receiving and generating the explanation is especially emphasized. To reduce
the gap and achieve honesty and truthfulness of explanations, we set up three
pillars: proactivity, risk attitudes, and epistemological constraints. To this
end, we illustrate our proposal on simple variants of the shortest path
problem.",2022-03-22,2022,2022-03,environment
"The state-of-the-art review on resource allocation problem using
  artificial intelligence methods on various computing paradigms","With the increasing growth of information through smart devices, increasing
the quality level of human life requires various computational paradigms
presentation including the Internet of Things, fog, and cloud. Between these
three paradigms, the cloud computing paradigm as an emerging technology adds
cloud layer services to the edge of the network so that resource allocation
operations occur close to the end-user to reduce resource processing time and
network traffic overhead. Hence, the resource allocation problem for its
providers in terms of presenting a suitable platform, by using computational
paradigms is considered a challenge. In general, resource allocation approaches
are divided into two methods, including auction-based methods(goal, increase
profits for service providers-increase user satisfaction and usability) and
optimization-based methods(energy, cost, network exploitation, Runtime,
reduction of time delay). In this paper, according to the latest scientific
achievements, a comprehensive literature study (CLS) on artificial intelligence
methods based on resource allocation optimization without considering
auction-based methods in various computing environments are provided such as
cloud computing, Vehicular Fog Computing, wireless, IoT, vehicular networks, 5G
networks, vehicular cloud architecture,machine-to-machine
communication(M2M),Train-to-Train(T2T) communication network, Peer-to-Peer(P2P)
network. Since deep learning methods based on artificial intelligence are used
as the most important methods in resource allocation problems; Therefore, in
this paper, resource allocation approaches based on deep learning are also used
in the mentioned computational environments such as deep reinforcement
learning, Q-learning technique, reinforcement learning, online learning, and
also Classical learning methods such as Bayesian learning, Cummins clustering,
Markov decision process.",2022-03-23,2022,2022-03,environment
NovGrid: A Flexible Grid World for Evaluating Agent Response to Novelty,"A robust body of reinforcement learning techniques have been developed to
solve complex sequential decision making problems. However, these methods
assume that train and evaluation tasks come from similarly or identically
distributed environments. This assumption does not hold in real life where
small novel changes to the environment can make a previously learned policy
fail or introduce simpler solutions that might never be found. To that end we
explore the concept of {\em novelty}, defined in this work as the sudden change
to the mechanics or properties of environment. We provide an ontology of for
novelties most relevant to sequential decision making, which distinguishes
between novelties that affect objects versus actions, unary properties versus
non-unary relations, and the distribution of solutions to a task. We introduce
NovGrid, a novelty generation framework built on MiniGrid, acting as a toolkit
for rapidly developing and evaluating novelty-adaptation-enabled reinforcement
learning techniques. Along with the core NovGrid we provide exemplar novelties
aligned with our ontology and instantiate them as novelty templates that can be
applied to many MiniGrid-compliant environments. Finally, we present a set of
metrics built into our framework for the evaluation of
novelty-adaptation-enabled machine-learning techniques, and show
characteristics of a baseline RL model using these metrics.",2022-03-23,2022,2022-03,environment
EnvEdit: Environment Editing for Vision-and-Language Navigation,"In Vision-and-Language Navigation (VLN), an agent needs to navigate through
the environment based on natural language instructions. Due to limited
available data for agent training and finite diversity in navigation
environments, it is challenging for the agent to generalize to new, unseen
environments. To address this problem, we propose EnvEdit, a data augmentation
method that creates new environments by editing existing environments, which
are used to train a more generalizable agent. Our augmented environments can
differ from the seen environments in three diverse aspects: style, object
appearance, and object classes. Training on these edit-augmented environments
prevents the agent from overfitting to existing environments and helps
generalize better to new, unseen environments. Empirically, on both the
Room-to-Room and the multi-lingual Room-Across-Room datasets, we show that our
proposed EnvEdit method gets significant improvements in all metrics on both
pre-trained and non-pre-trained VLN agents, and achieves the new
state-of-the-art on the test leaderboard. We further ensemble the VLN agents
augmented on different edited environments and show that these edit methods are
complementary. Code and data are available at
https://github.com/jialuli-luka/EnvEdit",2022-03-29,2022,2022-03,environment
"An Artificial Intelligence Browser Architecture (AIBA) For Our Kind and
  Others: A Voice Name System Speech implementation with two warrants, Wake
  Neutrality and Value Preservation of Personally Identifiable Information","Conversational commerce, first pioneered by Apple's Siri, is the first of may
applications based on always-on artificial intelligence systems that decide on
its own when to interact with the environment, potentially collecting 24x7
longitudinal training data that is often Personally Identifiable Information
(PII). A large body of scholarly papers, on the order of a million according to
a simple Google Scholar search, suggests that the treatment of many health
conditions, including COVID-19 and dementia, can be vastly improved by this
data if the dataset is large enough as it has happened in other domains (e.g.
GPT3). In contrast, current dominant systems are closed garden solutions
without wake neutrality and that can't fully exploit the PII data they have
because of IRB and Cohues-type constraints.
  We present a voice browser-and-server architecture that aims to address these
two limitations by offering wake neutrality and the possibility to handle PII
aiming to maximize its value. We have implemented this browser for the
collection of speech samples and have successfully demonstrated it can capture
over 200.000 samples of COVID-19 coughs. The architecture we propose is
designed so it can grow beyond our kind into other domains such as collecting
sound samples from vehicles, video images from nature, ingestible robotics,
multi-modal signals (EEG, EKG,...), or even interacting with other kinds such
as dogs and cats.",2022-03-29,2022,2022-03,environment
"Machine Learning and Artificial Intelligence in Circular Economy: A
  Bibliometric Analysis and Systematic Literature Review","With unorganized, unplanned and improper use of limited raw materials, an
abundant amount of waste is being produced, which is harmful to our environment
and ecosystem. While traditional linear production lines fail to address
far-reaching issues like waste production and a shorter product life cycle, a
prospective concept, namely circular economy (CE), has shown promising
prospects to be adopted at industrial and governmental levels. CE aims to
complete the product life cycle loop by bringing out the highest values from
raw materials in the design phase and later on by reusing, recycling, and
remanufacturing. Innovative technologies like artificial intelligence (AI) and
machine learning(ML) provide vital assistance in effectively adopting and
implementing CE in real-world practices. This study explores the adoption and
integration of applied AI techniques in CE. First, we conducted bibliometric
analysis on a collection of 104 SCOPUS indexed documents exploring the critical
research criteria in AI and CE. Forty papers were picked to conduct a
systematic literature review from these documents. The selected documents were
further divided into six categories: sustainable development, reverse
logistics, waste management, supply chain management, recycle & reuse, and
manufacturing development. Comprehensive research insights and trends have been
extracted and delineated. Finally, the research gap needing further attention
has been identified and the future research directions have also been
discussed.",2022-04-01,2022,2022-04,environment
Federated Reinforcement Learning with Environment Heterogeneity,"We study a Federated Reinforcement Learning (FedRL) problem in which $n$
agents collaboratively learn a single policy without sharing the trajectories
they collected during agent-environment interaction. We stress the constraint
of environment heterogeneity, which means $n$ environments corresponding to
these $n$ agents have different state transitions. To obtain a value function
or a policy function which optimizes the overall performance in all
environments, we propose two federated RL algorithms, \texttt{QAvg} and
\texttt{PAvg}. We theoretically prove that these algorithms converge to
suboptimal solutions, while such suboptimality depends on how heterogeneous
these $n$ environments are. Moreover, we propose a heuristic that achieves
personalization by embedding the $n$ environments into $n$ vectors. The
personalization heuristic not only improves the training but also allows for
better generalization to new environments.",2022-04-06,2022,2022-04,environment
"Improving generalization to new environments and removing catastrophic
  forgetting in Reinforcement Learning by using an eco-system of agents","Adapting a Reinforcement Learning (RL) agent to an unseen environment is a
difficult task due to typical over-fitting on the training environment. RL
agents are often capable of solving environments very close to the trained
environment, but when environments become substantially different, their
performance quickly drops. When agents are retrained on new environments, a
second issue arises: there is a risk of catastrophic forgetting, where the
performance on previously seen environments is seriously hampered. This paper
proposes a novel approach that exploits an eco-system of agents to address both
concerns. Hereby, the (limited) adaptive power of individual agents is
harvested to build a highly adaptive eco-system.",2022-04-13,2022,2022-04,environment
"Creative Problem Solving in Artificially Intelligent Agents: A Survey
  and Framework","Creative Problem Solving (CPS) is a sub-area within Artificial Intelligence
(AI) that focuses on methods for solving off-nominal, or anomalous problems in
autonomous systems. Despite many advancements in planning and learning,
resolving novel problems or adapting existing knowledge to a new context,
especially in cases where the environment may change in unpredictable ways post
deployment, remains a limiting factor in the safe and useful integration of
intelligent systems. The emergence of increasingly autonomous systems dictates
the necessity for AI agents to deal with environmental uncertainty through
creativity. To stimulate further research in CPS, we present a definition and a
framework of CPS, which we adopt to categorize existing AI methods in this
field. Our framework consists of four main components of a CPS problem, namely,
1) problem formulation, 2) knowledge representation, 3) method of knowledge
manipulation, and 4) method of evaluation. We conclude our survey with open
research questions, and suggested directions for the future.",2022-04-21,2022,2022-04,environment
"AI-Assisted Authentication: State of the Art, Taxonomy and Future
  Roadmap","Artificial Intelligence (AI) has found its applications in a variety of
environments ranging from data science to cybersecurity. AI helps break through
the limitations of traditional algorithms and provides more efficient and
flexible methods for solving problems. In this paper, we focus on the
applications of artificial intelligence in authentication, which is used in a
wide range of scenarios including facial recognition to access buildings,
keystroke dynamics to unlock smartphones. With the emerging AI-assisted
authentication schemes, our comprehensive survey provides an overall
understanding on a high level, which paves the way for future research in this
area. In contrast to other relevant surveys, our research is the first of its
kind to focus on the roles of AI in authentication.",2022-04-25,2022,2022-04,environment
"Adaptive cognitive fit: Artificial intelligence augmented management of
  information facets and representations","Explosive growth in big data technologies and artificial intelligence [AI]
applications have led to increasing pervasiveness of information facets and a
rapidly growing array of information representations. Information facets, such
as equivocality and veracity, can dominate and significantly influence human
perceptions of information and consequently affect human performance. Extant
research in cognitive fit, which preceded the big data and AI era, focused on
the effects of aligning information representation and task on performance,
without sufficient consideration to information facets and attendant cognitive
challenges. Therefore, there is a compelling need to understand the interplay
of these dominant information facets with information representations and
tasks, and their influence on human performance. We suggest that artificially
intelligent technologies that can adapt information representations to overcome
cognitive limitations are necessary for these complex information environments.
To this end, we propose and test a novel *Adaptive Cognitive Fit* [ACF]
framework that explains the influence of information facets and AI-augmented
information representations on human performance. We draw on information
processing theory and cognitive dissonance theory to advance the ACF framework
and a set of propositions. We empirically validate the ACF propositions with an
economic experiment that demonstrates the influence of information facets, and
a machine learning simulation that establishes the viability of using AI to
improve human performance.",2022-04-25,2022,2022-04,environment
"A Comparative Study on Approaches to Acoustic Scene Classification using
  CNNs","Acoustic scene classification is a process of characterizing and classifying
the environments from sound recordings. The first step is to generate features
(representations) from the recorded sound and then classify the background
environments. However, different kinds of representations have dramatic effects
on the accuracy of the classification. In this paper, we explored the three
such representations on classification accuracy using neural networks. We
investigated the spectrograms, MFCCs, and embeddings representations using
different CNN networks and autoencoders. Our dataset consists of sounds from
three settings of indoors and outdoors environments - thus the dataset contains
sound from six different kinds of environments. We found that the spectrogram
representation has the highest classification accuracy while MFCC has the
lowest classification accuracy. We reported our findings, insights as well as
some guidelines to achieve better accuracy for environment classification using
sounds.",2022-04-26,2022,2022-04,environment
"Stochastic Coherence Over Attention Trajectory For Continuous Learning
  In Video Streams","Devising intelligent agents able to live in an environment and learn by
observing the surroundings is a longstanding goal of Artificial Intelligence.
From a bare Machine Learning perspective, challenges arise when the agent is
prevented from leveraging large fully-annotated dataset, but rather the
interactions with supervisory signals are sparsely distributed over space and
time. This paper proposes a novel neural-network-based approach to
progressively and autonomously develop pixel-wise representations in a video
stream. The proposed method is based on a human-like attention mechanism that
allows the agent to learn by observing what is moving in the attended
locations. Spatio-temporal stochastic coherence along the attention trajectory,
paired with a contrastive term, leads to an unsupervised learning criterion
that naturally copes with the considered setting. Differently from most
existing works, the learned representations are used in open-set
class-incremental classification of each frame pixel, relying on few
supervisions. Our experiments leverage 3D virtual environments and they show
that the proposed agents can learn to distinguish objects just by observing the
video stream. Inheriting features from state-of-the art models is not as
powerful as one might expect.",2022-04-26,2022,2022-04,environment
Emergent Bartering Behaviour in Multi-Agent Reinforcement Learning,"Advances in artificial intelligence often stem from the development of new
environments that abstract real-world situations into a form where research can
be done conveniently. This paper contributes such an environment based on ideas
inspired by elementary Microeconomics. Agents learn to produce resources in a
spatially complex world, trade them with one another, and consume those that
they prefer. We show that the emergent production, consumption, and pricing
behaviors respond to environmental conditions in the directions predicted by
supply and demand shifts in Microeconomics. We also demonstrate settings where
the agents' emergent prices for goods vary over space, reflecting the local
abundance of goods. After the price disparities emerge, some agents then
discover a niche of transporting goods between regions with different
prevailing prices -- a profitable strategy because they can buy goods where
they are cheap and sell them where they are expensive. Finally, in a series of
ablation experiments, we investigate how choices in the environmental rewards,
bartering actions, agent architecture, and ability to consume tradable goods
can either aid or inhibit the emergence of this economic behavior. This work is
part of the environment development branch of a research program that aims to
build human-like artificial general intelligence through multi-agent
interactions in simulated societies. By exploring which environment features
are needed for the basic phenomena of elementary microeconomics to emerge
automatically from learning, we arrive at an environment that differs from
those studied in prior multi-agent reinforcement learning work along several
dimensions. For example, the model incorporates heterogeneous tastes and
physical abilities, and agents negotiate with one another as a grounded form of
communication.",2022-05-13,2022,2022-05,environment
Unified Distributed Environment,"We propose Unified Distributed Environment (UDE), an environment
virtualization toolkit for reinforcement learning research. UDE is designed to
integrate environments built on any simulation platform such as Gazebo, Unity,
Unreal, and OpenAI Gym. Through environment virtualization, UDE enables
offloading the environment for execution on a remote machine while still
maintaining a unified interface. The UDE interface is designed to support
multi-agent by default. With environment virtualization and its interface
design, the agent policies can be trained in multiple machines for a
multi-agent environment. Furthermore, UDE supports integration with existing
major RL toolkits for researchers to leverage the benefits. This paper
discusses the components of UDE and its design decisions.",2022-05-14,2022,2022-05,environment
"DeepSim: A Reinforcement Learning Environment Build Toolkit for ROS and
  Gazebo","We propose DeepSim, a reinforcement learning environment build toolkit for
ROS and Gazebo. It allows machine learning or reinforcement learning
researchers to access the robotics domain and create complex and challenging
custom tasks in ROS and Gazebo simulation environments. This toolkit provides
building blocks of advanced features such as collision detection, behaviour
control, domain randomization, spawner, and many more. DeepSim is designed to
reduce the boundary between robotics and machine learning communities by
providing Python interface. In this paper, we discuss the components and design
decisions of DeepSim Toolkit.",2022-05-17,2022,2022-05,environment
Should Models Be Accurate?,"Model-based Reinforcement Learning (MBRL) holds promise for data-efficiency
by planning with model-generated experience in addition to learning with
experience from the environment. However, in complex or changing environments,
models in MBRL will inevitably be imperfect, and their detrimental effects on
learning can be difficult to mitigate. In this work, we question whether the
objective of these models should be the accurate simulation of environment
dynamics at all. We focus our investigations on Dyna-style planning in a
prediction setting. First, we highlight and support three motivating points: a
perfectly accurate model of environment dynamics is not practically achievable,
is not necessary, and is not always the most useful anyways. Second, we
introduce a meta-learning algorithm for training models with a focus on their
usefulness to the learner instead of their accuracy in modelling the
environment. Our experiments show that in a simple non-stationary environment,
our algorithm enables faster learning than even using an accurate model built
with domain-specific knowledge of the non-stationarity.",2022-05-22,2022,2022-05,environment
IGLU Gridworld: Simple and Fast Environment for Embodied Dialog Agents,"We present the IGLU Gridworld: a reinforcement learning environment for
building and evaluating language conditioned embodied agents in a scalable way.
The environment features visual agent embodiment, interactive learning through
collaboration, language conditioned RL, and combinatorically hard task (3d
blocks building) space.",2022-05-31,2022,2022-05,environment
SAMPLE-HD: Simultaneous Action and Motion Planning Learning Environment,"Humans exhibit incredibly high levels of multi-modal understanding -
combining visual cues with read, or heard knowledge comes easy to us and allows
for very accurate interaction with the surrounding environment. Various
simulation environments focus on providing data for tasks related to scene
understanding, question answering, space exploration, visual navigation. In
this work, we are providing a solution to encompass both, visual and
behavioural aspects of simulation in a new environment for learning interactive
reasoning in manipulation setup. SAMPLE-HD environment allows to generate
various scenes composed of small household objects, to procedurally generate
language instructions for manipulation, and to generate ground truth paths
serving as training data.",2022-06-01,2022,2022-06,environment
Neuro-Nav: A Library for Neurally-Plausible Reinforcement Learning,"In this work we propose Neuro-Nav, an open-source library for neurally
plausible reinforcement learning (RL). RL is among the most common modeling
frameworks for studying decision making, learning, and navigation in biological
organisms. In utilizing RL, cognitive scientists often handcraft environments
and agents to meet the needs of their particular studies. On the other hand,
artificial intelligence researchers often struggle to find benchmarks for
neurally and biologically plausible representation and behavior (e.g., in
decision making or navigation). In order to streamline this process across both
fields with transparency and reproducibility, Neuro-Nav offers a set of
standardized environments and RL algorithms drawn from canonical behavioral and
neural studies in rodents and humans. We demonstrate that the toolkit
replicates relevant findings from a number of studies across both cognitive
science and RL literatures. We furthermore describe ways in which the library
can be extended with novel algorithms (including deep RL) and environments to
address future research needs of the field.",2022-06-06,2022,2022-06,environment
Deep Surrogate Assisted Generation of Environments,"Recent progress in reinforcement learning (RL) has started producing
generally capable agents that can solve a distribution of complex environments.
These agents are typically tested on fixed, human-authored environments. On the
other hand, quality diversity (QD) optimization has been proven to be an
effective component of environment generation algorithms, which can generate
collections of high-quality environments that are diverse in the resulting
agent behaviors. However, these algorithms require potentially expensive
simulations of agents on newly generated environments. We propose Deep
Surrogate Assisted Generation of Environments (DSAGE), a sample-efficient QD
environment generation algorithm that maintains a deep surrogate model for
predicting agent behaviors in new environments. Results in two benchmark
domains show that DSAGE significantly outperforms existing QD environment
generation algorithms in discovering collections of environments that elicit
diverse behaviors of a state-of-the-art RL agent and a planning agent. Our
source code and videos are available at https://dsagepaper.github.io/.",2022-06-09,2022,2022-06,environment
Robust Imitation Learning against Variations in Environment Dynamics,"In this paper, we propose a robust imitation learning (IL) framework that
improves the robustness of IL when environment dynamics are perturbed. The
existing IL framework trained in a single environment can catastrophically fail
with perturbations in environment dynamics because it does not capture the
situation that underlying environment dynamics can be changed. Our framework
effectively deals with environments with varying dynamics by imitating multiple
experts in sampled environment dynamics to enhance the robustness in general
variations in environment dynamics. In order to robustly imitate the multiple
sample experts, we minimize the risk with respect to the Jensen-Shannon
divergence between the agent's policy and each of the sample experts. Numerical
results show that our algorithm significantly improves robustness against
dynamics perturbations compared to conventional IL baselines.",2022-06-19,2022,2022-06,environment
Multi-Agent Car Parking using Reinforcement Learning,"As the industry of autonomous driving grows, so does the potential
interaction of groups of autonomous cars. Combined with the advancement of
Artificial Intelligence and simulation, such groups can be simulated, and
safety-critical models can be learned controlling the cars within. This study
applies reinforcement learning to the problem of multi-agent car parking, where
groups of cars aim to efficiently park themselves, while remaining safe and
rational. Utilising robust tools and machine learning frameworks, we design and
implement a flexible car parking environment in the form of a Markov decision
process with independent learners, exploiting multi-agent communication. We
implement a suite of tools to perform experiments at scale, obtaining models
parking up to 7 cars with over a 98.1% success rate, significantly beating
existing single-agent models. We also obtain several results relating to
competitive and collaborative behaviours exhibited by the cars in our
environment, with varying densities and levels of communication. Notably, we
discover a form of collaboration that cannot arise without competition, and a
'leaky' form of collaboration whereby agents collaborate without sufficient
state. Such work has numerous potential applications in the autonomous driving
and fleet management industries, and provides several useful techniques and
benchmarks for the application of reinforcement learning to multi-agent car
parking.",2022-06-22,2022,2022-06,environment
POGEMA: Partially Observable Grid Environment for Multiple Agents,"We introduce POGEMA (https://github.com/AIRI-Institute/pogema) a sandbox for
challenging partially observable multi-agent pathfinding (PO-MAPF) problems .
This is a grid-based environment that was specifically designed to be a
flexible, tunable and scalable benchmark. It can be tailored to a variety of
PO-MAPF, which can serve as an excellent testing ground for planning and
learning methods, and their combination, which will allow us to move towards
filling the gap between AI planning and learning.",2022-06-22,2022,2022-06,environment
"Reinforcement Learning under Partial Observability Guided by Learned
  Environment Models","In practical applications, we can rarely assume full observability of a
system's environment, despite such knowledge being important for determining a
reactive control system's precise interaction with its environment. Therefore,
we propose an approach for reinforcement learning (RL) in partially observable
environments. While assuming that the environment behaves like a partially
observable Markov decision process with known discrete actions, we assume no
knowledge about its structure or transition probabilities.
  Our approach combines Q-learning with IoAlergia, a method for learning Markov
decision processes (MDP). By learning MDP models of the environment from
episodes of the RL agent, we enable RL in partially observable domains without
explicit, additional memory to track previous interactions for dealing with
ambiguities stemming from partial observability. We instead provide RL with
additional observations in the form of abstract environment states by
simulating new experiences on learned environment models to track the explored
states. In our evaluation, we report on the validity of our approach and its
promising performance in comparison to six state-of-the-art deep RL techniques
with recurrent neural networks and fixed memory.",2022-06-23,2022,2022-06,environment
"GAN-based Intrinsic Exploration For Sample Efficient Reinforcement
  Learning","In this study, we address the problem of efficient exploration in
reinforcement learning. Most common exploration approaches depend on random
action selection, however these approaches do not work well in environments
with sparse or no rewards. We propose Generative Adversarial Network-based
Intrinsic Reward Module that learns the distribution of the observed states and
sends an intrinsic reward that is computed as high for states that are out of
distribution, in order to lead agent to unexplored states. We evaluate our
approach in Super Mario Bros for a no reward setting and in Montezuma's Revenge
for a sparse reward setting and show that our approach is indeed capable of
exploring efficiently. We discuss a few weaknesses and conclude by discussing
future works.",2022-06-28,2022,2022-06,environment
USHER: Unbiased Sampling for Hindsight Experience Replay,"Dealing with sparse rewards is a long-standing challenge in reinforcement
learning (RL). Hindsight Experience Replay (HER) addresses this problem by
reusing failed trajectories for one goal as successful trajectories for
another. This allows for both a minimum density of reward and for
generalization across multiple goals. However, this strategy is known to result
in a biased value function, as the update rule underestimates the likelihood of
bad outcomes in a stochastic environment. We propose an asymptotically unbiased
importance-sampling-based algorithm to address this problem without sacrificing
performance on deterministic environments. We show its effectiveness on a range
of robotic systems, including challenging high dimensional stochastic
environments.",2022-07-03,2022,2022-07,environment
"AVDDPG: Federated reinforcement learning applied to autonomous platoon
  control","Since 2016 federated learning (FL) has been an evolving topic of discussion
in the artificial intelligence (AI) research community. Applications of FL led
to the development and study of federated reinforcement learning (FRL). Few
works exist on the topic of FRL applied to autonomous vehicle (AV) platoons. In
addition, most FRL works choose a single aggregation method (usually weight or
gradient aggregation). We explore FRL's effectiveness as a means to improve AV
platooning by designing and implementing an FRL framework atop a custom AV
platoon environment. The application of FRL in AV platooning is studied under
two scenarios: (1) Inter-platoon FRL (Inter-FRL) where FRL is applied to AVs
across different platoons; (2) Intra-platoon FRL (Intra-FRL) where FRL is
applied to AVs within a single platoon. Both Inter-FRL and Intra-FRL are
applied to a custom AV platooning environment using both gradient and weight
aggregation to observe the performance effects FRL can have on AV platoons
relative to an AV platooning environment trained without FRL. It is concluded
that Intra-FRL using weight aggregation (Intra-FRLWA) provides the best
performance for controlling an AV platoon. In addition, we found that weight
aggregation in FRL for AV platooning provides increases in performance relative
to gradient aggregation. Finally, a performance analysis is conducted for
Intra-FRLWA versus a platooning environment without FRL for platoons of length
3, 4 and 5 vehicles. It is concluded that Intra-FRLWA largely out-performs the
platooning environment that is trained without FRL.",2022-07-05,2022,2022-07,environment
gym-DSSAT: a crop model turned into a Reinforcement Learning environment,"Addressing a real world sequential decision problem with Reinforcement
Learning (RL) usually starts with the use of a simulated environment that
mimics real conditions. We present a novel open source RL environment for
realistic crop management tasks. gym-DSSAT is a gym interface to the Decision
Support System for Agrotechnology Transfer (DSSAT), a high fidelity crop
simulator. DSSAT has been developped over the last 30 years and is widely
recognized by agronomists. gym-DSSAT comes with predefined simulations based on
real world maize experiments. The environment is as easy to use as any gym
environment. We provide performance baselines using basic RL algorithms. We
also briefly outline how the monolithic DSSAT simulator written in Fortran has
been turned into a Python RL environment. Our methodology is generic and may be
applied to similar simulators. We report on very preliminary experimental
results which suggest that RL can help researchers to improve sustainability of
fertilization and irrigation practices.",2022-07-07,2022,2022-07,environment
"Automatic Exploration of Textual Environments with Language-Conditioned
  Autotelic Agents","In this extended abstract we discuss the opportunities and challenges of
studying intrinsically-motivated agents for exploration in textual
environments. We argue that there is important synergy between text
environments and autonomous agents. We identify key properties of text worlds
that make them suitable for exploration by autonmous agents, namely, depth,
breadth, progress niches and the ease of use of language goals; we identify
drivers of exploration for such agents that are implementable in text worlds.
We discuss the opportunities of using autonomous agents to make progress on
text environment benchmarks. Finally we list some specific challenges that need
to be overcome in this area.",2022-07-08,2022,2022-07,environment
"Storehouse: a Reinforcement Learning Environment for Optimizing
  Warehouse Management","Warehouse Management Systems have been evolving and improving thanks to new
Data Intelligence techniques. However, many current optimizations have been
applied to specific cases or are in great need of manual interaction. Here is
where Reinforcement Learning techniques come into play, providing
automatization and adaptability to current optimization policies. In this
paper, we present Storehouse, a customizable environment that generalizes the
definition of warehouse simulations for Reinforcement Learning. We also
validate this environment against state-of-the-art reinforcement learning
algorithms and compare these results to human and random policies.",2022-07-08,2022,2022-07,environment
Grounding Aleatoric Uncertainty for Unsupervised Environment Design,"Adaptive curricula in reinforcement learning (RL) have proven effective for
producing policies robust to discrepancies between the train and test
environment. Recently, the Unsupervised Environment Design (UED) framework
generalized RL curricula to generating sequences of entire environments,
leading to new methods with robust minimax regret properties. Problematically,
in partially-observable or stochastic settings, optimal policies may depend on
the ground-truth distribution over aleatoric parameters of the environment in
the intended deployment setting, while curriculum learning necessarily shifts
the training distribution. We formalize this phenomenon as curriculum-induced
covariate shift (CICS), and describe how its occurrence in aleatoric parameters
can lead to suboptimal policies. Directly sampling these parameters from the
ground-truth distribution avoids the issue, but thwarts curriculum learning. We
propose SAMPLR, a minimax regret UED method that optimizes the ground-truth
utility function, even when the underlying training data is biased due to CICS.
We prove, and validate on challenging domains, that our approach preserves
optimality under the ground-truth distribution, while promoting robustness
across the full range of environment settings.",2022-07-11,2022,2022-07,environment
GriddlyJS: A Web IDE for Reinforcement Learning,"Progress in reinforcement learning (RL) research is often driven by the
design of new, challenging environments -- a costly undertaking requiring
skills orthogonal to that of a typical machine learning researcher. The
complexity of environment development has only increased with the rise of
procedural-content generation (PCG) as the prevailing paradigm for producing
varied environments capable of testing the robustness and generalization of RL
agents. Moreover, existing environments often require complex build processes,
making reproducing results difficult. To address these issues, we introduce
GriddlyJS, a web-based Integrated Development Environment (IDE) based on the
Griddly engine. GriddlyJS allows researchers to visually design and debug
arbitrary, complex PCG grid-world environments using a convenient graphical
interface, as well as visualize, evaluate, and record the performance of
trained agent models. By connecting the RL workflow to the advanced
functionality enabled by modern web standards, GriddlyJS allows publishing
interactive agent-environment demos that reproduce experimental results
directly to the web. To demonstrate the versatility of GriddlyJS, we use it to
quickly develop a complex compositional puzzle-solving environment alongside
arbitrary human-designed environment configurations and their solutions for use
in automatic curriculum learning and offline RL. The GriddlyJS IDE is open
source and freely available at https://griddly.ai.",2022-07-13,2022,2022-07,environment
"Brick Tic-Tac-Toe: Exploring the Generalizability of AlphaZero to Novel
  Test Environments","Traditional reinforcement learning (RL) environments typically are the same
for both the training and testing phases. Hence, current RL methods are largely
not generalizable to a test environment which is conceptually similar but
different from what the method has been trained on, which we term the novel
test environment. As an effort to push RL research towards algorithms which can
generalize to novel test environments, we introduce the Brick Tic-Tac-Toe
(BTTT) test bed, where the brick position in the test environment is different
from that in the training environment. Using a round-robin tournament on the
BTTT environment, we show that traditional RL state-search approaches such as
Monte Carlo Tree Search (MCTS) and Minimax are more generalizable to novel test
environments than AlphaZero is. This is surprising because AlphaZero has been
shown to achieve superhuman performance in environments such as Go, Chess and
Shogi, which may lead one to think that it performs well in novel test
environments. Our results show that BTTT, though simple, is rich enough to
explore the generalizability of AlphaZero. We find that merely increasing MCTS
lookahead iterations was insufficient for AlphaZero to generalize to some novel
test environments. Rather, increasing the variety of training environments
helps to progressively improve generalizability across all possible starting
brick configurations.",2022-07-13,2022,2022-07,environment
"Evaluation of key impression of resilient supply chain based on
  artificial intelligence of things (AIoT)","In recent years, the high complexity of the business environment, dynamism
and environmental change, uncertainty and concepts such as globalization and
increasing competition of organizations in the national and international arena
have caused many changes in the equations governing the supply chain. In this
case, supply chain organizations must always be prepared for a variety of
challenges and dynamic environmental changes. One of the effective solutions to
face these challenges is to create a resilient supply chain. Resilient supply
chain is able to overcome uncertainties and disruptions in the business
environment. The competitive advantage of this supply chain does not depend
only on low costs, high quality, reduced latency and high level of service.
Rather, it has the ability of the chain to avoid catastrophes and overcome
critical situations, and this is the resilience of the supply chain. AI and IoT
technologies and their combination, called AIoT, have played a key role in
improving supply chain performance in recent years and can therefore increase
supply chain resilience. For this reason, in this study, an attempt was made to
better understand the impact of these technologies on equity by examining the
dimensions and components of the Artificial Intelligence of Things (AIoT)-based
supply chain. Finally, using nonlinear fuzzy decision making method, the most
important components of the impact on the resilient smart supply chain are
determined. Understanding this assessment can help empower the smart supply
chain.",2022-07-18,2022,2022-07,environment
"Core and Periphery as Closed-System Precepts for Engineering General
  Intelligence","Engineering methods are centered around traditional notions of decomposition
and recomposition that rely on partitioning the inputs and outputs of
components to allow for component-level properties to hold after their
composition. In artificial intelligence (AI), however, systems are often
expected to influence their environments, and, by way of their environments, to
influence themselves. Thus, it is unclear if an AI system's inputs will be
independent of its outputs, and, therefore, if AI systems can be treated as
traditional components. This paper posits that engineering general intelligence
requires new general systems precepts, termed the core and periphery, and
explores their theoretical uses. The new precepts are elaborated using abstract
systems theory and the Law of Requisite Variety. By using the presented
material, engineers can better understand the general character of regulating
the outcomes of AI to achieve stakeholder needs and how the general systems
nature of embodiment challenges traditional engineering practice.",2022-08-04,2022,2022-08,environment
"Improving performance in multi-objective decision-making in Bottles
  environments with soft maximin approaches","Balancing multiple competing and conflicting objectives is an essential task
for any artificial intelligence tasked with satisfying human values or
preferences. Conflict arises both from misalignment between individuals with
competing values, but also between conflicting value systems held by a single
human. Starting with principle of loss-aversion, we designed a set of soft
maximin function approaches to multi-objective decision-making. Bench-marking
these functions in a set of previously-developed environments, we found that
one new approach in particular, 'split-function exp-log loss aversion'
(SFELLA), learns faster than the state of the art thresholded alignment
objective method (Vamplew et al, 2021) on three of four tasks it was tested on,
and achieved the same optimal performance after learning. SFELLA also showed
relative robustness improvements against changes in objective scale, which may
highlight an advantage dealing with distribution shifts in the environment
dynamics. Due to publishing rules, further work could not be presented in the
preprint, but in the final published version, we will further compare SFELLA to
the multi-objective reward exponentials (MORE) approach (Rolf, 2020),
demonstrating that SFELLA performs similarly to MORE in a simple
previously-described foraging task, but in a modified foraging environment with
a new resource that was not depleted as the agent worked, SFELLA collected more
of the new resource with very little cost incurred in terms of the old
resource. Overall, we found SFELLA useful for avoiding problems that sometimes
occur with a thresholded approach, and more reward-responsive than MORE while
retaining its conservative, loss-averse incentive structure.",2022-08-08,2022,2022-08,environment
Intrinsically Motivated Learning of Causal World Models,"Despite the recent progress in deep learning and reinforcement learning,
transfer and generalization of skills learned on specific tasks is very limited
compared to human (or animal) intelligence. The lifelong, incremental building
of common sense knowledge might be a necessary component on the way to achieve
more general intelligence. A promising direction is to build world models
capturing the true physical mechanisms hidden behind the sensorimotor
interaction with the environment. Here we explore the idea that inferring the
causal structure of the environment could benefit from well-chosen actions as
means to collect relevant interventional data.",2022-08-09,2022,2022-08,environment
"Artificial Intelligence Empowered Multiple Access for Ultra Reliable and
  Low Latency THz Wireless Networks","Terahertz (THz) wireless networks are expected to catalyze the beyond fifth
generation (B5G) era. However, due to the directional nature and the
line-of-sight demand of THz links, as well as the ultra-dense deployment of THz
networks, a number of challenges that the medium access control (MAC) layer
needs to face are created. In more detail, the need of rethinking user
association and resource allocation strategies by incorporating artificial
intelligence (AI) capable of providing ""real-time"" solutions in complex and
frequently changing environments becomes evident. Moreover, to satisfy the
ultra-reliability and low-latency demands of several B5G applications, novel
mobility management approaches are required. Motivated by this, this article
presents a holistic MAC layer approach that enables intelligent user
association and resource allocation, as well as flexible and adaptive mobility
management, while maximizing systems' reliability through blockage
minimization. In more detail, a fast and centralized joint user association,
radio resource allocation, and blockage avoidance by means of a novel
metaheuristic-machine learning framework is documented, that maximizes the THz
networks performance, while minimizing the association latency by approximately
three orders of magnitude. To support, within the access point (AP) coverage
area, mobility management and blockage avoidance, a deep reinforcement learning
(DRL) approach for beam-selection is discussed. Finally, to support user
mobility between coverage areas of neighbor APs, a proactive hand-over
mechanism based on AI-assisted fast channel prediction is~reported.",2022-08-17,2022,2022-08,environment
"MARTI-4: new model of human brain, considering neocortex and basal
  ganglia -- learns to play Atari game by reinforcement learning on a single
  CPU","We present Deep Control - new ML architecture of cortico-striatal brain
circuits, which use whole cortical column as a structural element, instead of a
singe neuron. Based on this architecture, we present MARTI - new model of human
brain, considering neocortex and basal ganglia. This model is de-signed to
implement expedient behavior and is capable to learn and achieve goals in
unknown environments. We introduce a novel surprise feeling mechanism, that
significantly improves reinforcement learning process through inner rewards. We
use OpenAI Gym environment to demonstrate MARTI learning on a single CPU just
in several hours.",2022-08-18,2022,2022-08,environment
"Project proposal: A modular reinforcement learning based automated
  theorem prover","We propose to build a reinforcement learning prover of independent
components: a deductive system (an environment), the proof state representation
(how an agent sees the environment), and an agent training algorithm. To that
purpose, we contribute an additional Vampire-based environment to
$\texttt{gym-saturation}$ package of OpenAI Gym environments for saturation
provers. We demonstrate a prototype of using $\texttt{gym-saturation}$ together
with a popular reinforcement learning framework (Ray $\texttt{RLlib}$).
Finally, we discuss our plans for completing this work in progress to a
competitive automated theorem prover.",2022-09-06,2022,2022-09,environment
"Ask Before You Act: Generalising to Novel Environments by Asking
  Questions","Solving temporally-extended tasks is a challenge for most reinforcement
learning (RL) algorithms [arXiv:1906.07343]. We investigate the ability of an
RL agent to learn to ask natural language questions as a tool to understand its
environment and achieve greater generalisation performance in novel,
temporally-extended environments. We do this by endowing this agent with the
ability of asking ""yes-no"" questions to an all-knowing Oracle. This allows the
agent to obtain guidance regarding the task at hand, while limiting the access
to new information. To study the emergence of such natural language questions
in the context of temporally-extended tasks we first train our agent in a
Mini-Grid environment. We then transfer the trained agent to a different,
harder environment. We observe a significant increase in generalisation
performance compared to a baseline agent unable to ask questions. Through
grounding its understanding of natural language in its environment, the agent
can reason about the dynamics of its environment to the point that it can ask
new, relevant questions when deployed in a novel environment.",2022-09-10,2022,2022-09,environment
Extended Intelligence,"We argue that intelligence, construed as the disposition to perform tasks
successfully, is a property of systems composed of agents and their contexts.
This is the thesis of extended intelligence. We argue that the performance of
an agent will generally not be preserved if its context is allowed to vary.
Hence, this disposition is not possessed by an agent alone, but is rather
possessed by the system consisting of an agent and its context, which we dub an
agent-in-context. An agent's context may include an environment, other agents,
cultural artifacts (like language, technology), or all of these, as is
typically the case for humans and artificial intelligence systems, as well as
many non-human animals. In virtue of the thesis of extended intelligence, we
contend that intelligence is context-bound, task-particular and incommensurable
among agents. Our thesis carries strong implications for how intelligence is
analyzed in the context of both psychology and artificial intelligence.",2022-09-15,2022,2022-09,environment
Autonomous Visual Navigation A Biologically Inspired Approach,"Inspired by the navigational behavior observed in the animal kingdom and
especially the navigational behavior of the ants, we attempt to simulate it in
an artificial environment by implementing different kinds of biomimetic
algorithms.",2022-09-19,2022,2022-09,environment
Safety-Critical Adaptation in Self-Adaptive Systems,"Modern systems are designed to operate in increasingly variable and uncertain
environments. Not only are these environments complex, in the sense that they
contain a tremendous number of variables, but they also change over time.
Systems must be able to adjust their behaviour at run-time to manage these
uncertainties. These self-adaptive systems have been studied extensively. This
paper proposes a definition of a safety-critical self-adaptive system and then
describes a taxonomy for classifying adaptations into different types based on
their impact on the system's safety and the system's safety case. The taxonomy
expresses criteria for classification and then describes specific criteria that
the safety case for a self-adaptive system must satisfy, depending on the type
of adaptations performed. Each type in the taxonomy is illustrated using the
example of a safety-critical self-adaptive water heating system.",2022-09-30,2022,2022-09,environment
Improving Policy Learning via Language Dynamics Distillation,"Recent work has shown that augmenting environments with language descriptions
improves policy learning. However, for environments with complex language
abstractions, learning how to ground language to observations is difficult due
to sparse, delayed rewards. We propose Language Dynamics Distillation (LDD),
which pretrains a model to predict environment dynamics given demonstrations
with language descriptions, and then fine-tunes these language-aware pretrained
representations via reinforcement learning (RL). In this way, the model is
trained to both maximize expected reward and retain knowledge about how
language relates to environment dynamics. On SILG, a benchmark of five tasks
with language descriptions that evaluate distinct generalization challenges on
unseen environments (NetHack, ALFWorld, RTFM, Messenger, and Touchdown), LDD
outperforms tabula-rasa RL, VAE pretraining, and methods that learn from
unlabeled demonstrations in inverse RL and reward shaping with pretrained
experts. In our analyses, we show that language descriptions in demonstrations
improve sample-efficiency and generalization across environments, and that
dynamics modelling with expert demonstrations is more effective than with
non-experts.",2022-09-30,2022,2022-09,environment
Bayesian Q-learning With Imperfect Expert Demonstrations,"Guided exploration with expert demonstrations improves data efficiency for
reinforcement learning, but current algorithms often overuse expert
information. We propose a novel algorithm to speed up Q-learning with the help
of a limited amount of imperfect expert demonstrations. The algorithm avoids
excessive reliance on expert data by relaxing the optimal expert assumption and
gradually reducing the usage of uninformative expert data. Experimentally, we
evaluate our approach on a sparse-reward chain environment and six more
complicated Atari games with delayed rewards. With the proposed methods, we can
achieve better results than Deep Q-learning from Demonstrations (Hester et al.,
2017) in most environments.",2022-10-01,2022,2022-10,environment
CaiRL: A High-Performance Reinforcement Learning Environment Toolkit,"This paper addresses the dire need for a platform that efficiently provides a
framework for running reinforcement learning (RL) experiments. We propose the
CaiRL Environment Toolkit as an efficient, compatible, and more sustainable
alternative for training learning agents and propose methods to develop more
efficient environment simulations.
  There is an increasing focus on developing sustainable artificial
intelligence. However, little effort has been made to improve the efficiency of
running environment simulations. The most popular development toolkit for
reinforcement learning, OpenAI Gym, is built using Python, a powerful but slow
programming language. We propose a toolkit written in C++ with the same
flexibility level but works orders of magnitude faster to make up for Python's
inefficiency. This would drastically cut climate emissions.
  CaiRL also presents the first reinforcement learning toolkit with a built-in
JVM and Flash support for running legacy flash games for reinforcement learning
research. We demonstrate the effectiveness of CaiRL in the classic control
benchmark, comparing the execution speed to OpenAI Gym. Furthermore, we
illustrate that CaiRL can act as a drop-in replacement for OpenAI Gym to
leverage significantly faster training speeds because of the reduced
environment computation time.",2022-10-03,2022,2022-10,environment
Simulating Coverage Path Planning with Roomba,"Coverage Path Planning involves visiting every unoccupied state in an
environment with obstacles. In this paper, we explore this problem in
environments which are initially unknown to the agent, for purposes of
simulating the task of a vacuum cleaning robot. A survey of prior work reveals
sparse effort in applying learning to solve this problem. In this paper, we
explore modeling a Cover Path Planning problem using Deep Reinforcement
Learning, and compare it with the performance of the built-in algorithm of the
Roomba, a popular vacuum cleaning robot.",2022-10-10,2022,2022-10,environment
Grid cells and their potential application in AI,"Since their Nobel Prize winning discovery in 2005, grid cells have been
studied extensively by neuroscientists. Their multi-scale periodic firing rates
tiling the environment as the animal moves around has been shown as critical
for path integration. Multiple experiments have shown that grid cells also fire
for other representations such as olfactory, attention mechanisms, imagined
movement, and concept organization potentially acting as a form of neural
recycling and showing the possible brain mechanism for cognitive maps that
Tolman envisioned in 1948. Grid cell integration into artificial neural
networks may enable more robust, generalized, and smarter computers. In this
paper we give an overview of grid cell research since their discovery, their
role in neuroscience and cognitive science, and possible future directions of
artificial intelligence research.",2022-10-12,2022,2022-10,environment
"Simulated Contextual Bandits for Personalization Tasks from
  Recommendation Datasets","We propose a method for generating simulated contextual bandit environments
for personalization tasks from recommendation datasets like MovieLens, Netflix,
Last.fm, Million Song, etc. This allows for personalization environments to be
developed based on real-life data to reflect the nuanced nature of real-world
user interactions. The obtained environments can be used to develop methods for
solving personalization tasks, algorithm benchmarking, model simulation, and
more. We demonstrate our approach with numerical examples on MovieLens and IMDb
datasets.",2022-10-12,2022,2022-10,environment
"Augmentation for Learning From Demonstration with Environmental
  Constraints","We introduce a Learning from Demonstration (LfD) approach for contact-rich
manipulation tasks with articulated mechanisms. The extracted policy from a
single human demonstration generalizes to different mechanisms of the same type
and is robust against environmental variations. The key to achieving such
generalization and robustness from a single human demonstration is to
autonomously augment the initial demonstration to gather additional information
through purposefully interacting with the environment. Our real-world
experiments on complex mechanisms with multi-DOF demonstrate that our approach
can reliably accomplish the task in a changing environment. Videos are
available at the: https://sites.google.com/view/rbosalfdec/home",2022-10-13,2022,2022-10,environment
"Neuro-symbolic Explainable Artificial Intelligence Twin for Zero-touch
  IoE in Wireless Network","Explainable artificial intelligence (XAI) twin systems will be a fundamental
enabler of zero-touch network and service management (ZSM) for sixth-generation
(6G) wireless networks. A reliable XAI twin system for ZSM requires two
composites: an extreme analytical ability for discretizing the physical
behavior of the Internet of Everything (IoE) and rigorous methods for
characterizing the reasoning of such behavior. In this paper, a novel
neuro-symbolic explainable artificial intelligence twin framework is proposed
to enable trustworthy ZSM for a wireless IoE. The physical space of the XAI
twin executes a neural-network-driven multivariate regression to capture the
time-dependent wireless IoE environment while determining unconscious decisions
of IoE service aggregation. Subsequently, the virtual space of the XAI twin
constructs a directed acyclic graph (DAG)-based Bayesian network that can infer
a symbolic reasoning score over unconscious decisions through a first-order
probabilistic language model. Furthermore, a Bayesian multi-arm bandits-based
learning problem is proposed for reducing the gap between the expected
explained score and the current obtained score of the proposed neuro-symbolic
XAI twin. To address the challenges of extensible, modular, and stateless
management functions in ZSM, the proposed neuro-symbolic XAI twin framework
consists of two learning systems: 1) an implicit learner that acts as an
unconscious learner in physical space, and 2) an explicit leaner that can
exploit symbolic reasoning based on implicit learner decisions and prior
evidence. Experimental results show that the proposed neuro-symbolic XAI twin
can achieve around 96.26% accuracy while guaranteeing from 18% to 44% more
trust score in terms of reasoning and closed-loop automation.",2022-10-13,2022,2022-10,environment
Palm up: Playing in the Latent Manifold for Unsupervised Pretraining,"Large and diverse datasets have been the cornerstones of many impressive
advancements in artificial intelligence. Intelligent creatures, however, learn
by interacting with the environment, which changes the input sensory signals
and the state of the environment. In this work, we aim to bring the best of
both worlds and propose an algorithm that exhibits an exploratory behavior
whilst it utilizes large diverse datasets. Our key idea is to leverage deep
generative models that are pretrained on static datasets and introduce a
dynamic model in the latent space. The transition dynamics simply mixes an
action and a random sampled latent. It then applies an exponential moving
average for temporal persistency, the resulting latent is decoded to image
using pretrained generator. We then employ an unsupervised reinforcement
learning algorithm to explore in this environment and perform unsupervised
representation learning on the collected data. We further leverage the temporal
information of this data to pair data points as a natural supervision for
representation learning. Our experiments suggest that the learned
representations can be successfully transferred to downstream tasks in both
vision and reinforcement learning domains.",2022-10-19,2022,2022-10,environment
Explainability in autonomous pedagogically structured scenarios,"We present the notion of explainability for decision-making processes in a
pedagogically structured autonomous environment. Multi-agent systems that are
structured pedagogically consist of pedagogical teachers and learners that
operate in environments in which both are sometimes not fully aware of all the
states in the environment and beliefs of other agents thus making it
challenging to explain their decisions and actions with one another. This work
emphasises the need for robust and iterative explanation-based communication
between the pedagogical teacher and the learner. Explaining the rationale
behind multi-agent decisions in an interactive, partially observable
environment is necessary to build trustworthy and reliable communication
between pedagogical teachers and learners. Ongoing research is primarily
focused on explanations of the agents' behaviour towards humans, and there is a
lack of research on inter-agent explainability.",2022-10-21,2022,2022-10,environment
"Modelling Control Arguments via Cooperation Logic in Unforeseen
  Scenarios","The intent of control argumentation frameworks is to specifically model
strategic scenarios from the perspective of an agent by extending the standard
model of argumentation framework in a way that takes unquantified uncertainty
regarding arguments and attacks into account. They do not, however, adequately
account for coalition formation and interactions among a set of agents in an
uncertain environment. To address this challenge, we propose a formalism of a
multi-agent scenario via cooperation logic and investigate agents' strategies
and actions in a dynamic environment.",2022-10-21,2022,2022-10,environment
"A Temporal Type-2 Fuzzy System for Time-dependent Explainable Artificial
  Intelligence","Explainable Artificial Intelligence (XAI) is a paradigm that delivers
transparent models and decisions, which are easy to understand, analyze, and
augment by a non-technical audience. Fuzzy Logic Systems (FLS) based XAI can
provide an explainable framework, while also modeling uncertainties present in
real-world environments, which renders it suitable for applications where
explainability is a requirement. However, most real-life processes are not
characterized by high levels of uncertainties alone; they are inherently
time-dependent as well, i.e., the processes change with time. In this work, we
present novel Temporal Type-2 FLS Based Approach for time-dependent XAI (TXAI)
systems, which can account for the likelihood of a measurement's occurrence in
the time domain using (the measurement's) frequency of occurrence. In Temporal
Type-2 Fuzzy Sets (TT2FSs), a four-dimensional (4D) time-dependent membership
function is developed where relations are used to construct the inter-relations
between the elements of the universe of discourse and its frequency of
occurrence. The TXAI system manifested better classification prowess, with
10-fold test datasets, with a mean recall of 95.40\% than a standard XAI system
(based on non-temporal general type-2 (GT2) fuzzy sets) that had a mean recall
of 87.04\%. TXAI also performed significantly better than most non-explainable
AI systems between 3.95\%, to 19.04\% improvement gain in mean recall. In
addition, TXAI can also outline the most likely time-dependent trajectories
using the frequency of occurrence values embedded in the TXAI model; viz. given
a rule at a determined time interval, what will be the next most likely rule at
a subsequent time interval. In this regard, the proposed TXAI system can have
profound implications for delineating the evolution of real-life time-dependent
processes, such as behavioural or biological processes.",2022-10-22,2022,2022-10,environment
MetaSpeech: Speech Effects Switch Along with Environment for Metaverse,"Metaverse expands the physical world to a new dimension, and the physical
environment and Metaverse environment can be directly connected and entered.
Voice is an indispensable communication medium in the real world and Metaverse.
Fusion of the voice with environment effects is important for user immersion in
Metaverse. In this paper, we proposed using the voice conversion based method
for the conversion of target environment effect speech. The proposed method was
named MetaSpeech, which introduces an environment effect module containing an
effect extractor to extract the environment information and an effect encoder
to encode the environment effect condition, in which gradient reversal layer
was used for adversarial training to keep the speech content and speaker
information while disentangling the environmental effects. From the experiment
results on the public dataset of LJSpeech with four environment effects, the
proposed model could complete the specific environment effect conversion and
outperforms the baseline methods from the voice conversion task.",2022-10-25,2022,2022-10,environment
"Multi-Environment based Meta-Learning with CSI Fingerprints for Radio
  Based Positioning","Radio based positioning of a user equipment (UE) based on deep learning (DL)
methods using channel state information (CSI) fingerprints have shown promising
results. DL models are able to capture complex properties embedded in the CSI
about a particular environment and map UE's CSI to the UE's position. However,
the CSI fingerprints and the DL models trained on such fingerprints are highly
dependent on a particular propagation environment, which generally limits the
transfer of knowledge of the DL models from one environment to another. In this
paper, we propose a DL model consisting of two parts: the first part aims to
learn environment independent features while the second part combines those
features depending on the particular environment. To improve transfer learning,
we propose a meta learning scheme for training the first part over multiple
environments. We show that for positioning in a new environment, initializing a
DL model with the meta learned environment independent function achieves higher
UE positioning accuracy compared to regular transfer learning from one
environment to the new environment, or compared to training the DL model from
scratch with only fingerprints from the new environment. Our proposed scheme is
able to create an environment independent function which can embed knowledge
from multiple environments and more effectively learn from a new environment.",2022-10-26,2022,2022-10,environment
Environment Design for Inverse Reinforcement Learning,"Learning a reward function from demonstrations suffers from low
sample-efficiency. Even with abundant data, current inverse reinforcement
learning methods that focus on learning from a single environment can fail to
handle slight changes in the environment dynamics. We tackle these challenges
through adaptive environment design. In our framework, the learner repeatedly
interacts with the expert, with the former selecting environments to identify
the reward function as quickly as possible from the expert's demonstrations in
said environments. This results in improvements in both sample-efficiency and
robustness, as we show experimentally, for both exact and approximate
inference.",2022-10-26,2022,2022-10,environment
"Distributed Swarm Learning for Internet of Things at the Edge: Where
  Artificial Intelligence Meets Biological Intelligence","With the proliferation of versatile Internet of Things (IoT) services, smart
IoT devices are increasingly deployed at the edge of wireless networks to
perform collaborative machine learning tasks using locally collected data,
giving rise to the edge learning paradigm. Due to device restrictions and
resource constraints, edge learning among massive IoT devices faces major
technical challenges caused by the communication bottleneck, data and device
heterogeneity, non-convex optimization, privacy and security concerns, and
dynamic environments. To overcome these challenges, this article studies a new
framework of distributed swarm learning (DSL) through a holistic integration of
artificial intelligence and biological swarm intelligence. Leveraging efficient
and robust signal processing and communication techniques, DSL contributes to
novel tools for learning and optimization tailored for real-time operations of
large-scale IoT in edge wireless environments, which will benefit a wide range
of edge IoT applications.",2022-10-29,2022,2022-10,environment
"Discriminating sensor activation in activity recognition within
  multi-occupancy environments based on nearby interaction","This work presents a computer model to discriminate sensor activation in
multi-occupancy environments based on proximity interaction. Current
proximity-based and indoor location methods allow the estimation of the
positions or areas where inhabitants carry out their daily human activities.
The spatial-temporal relation between location and sensor activations is
described in this work to generate a sensor interaction matrix for each
inhabitant. This enables the use of classical HAR models to reduce the
complexity of the multi-occupancy problem. A case study deployed with UWB and
binary sensors is presented.",2022-11-03,2022,2022-11,environment
"Examining the Differential Risk from High-level Artificial Intelligence
  and the Question of Control","Artificial Intelligence (AI) is one of the most transformative technologies
of the 21st century. The extent and scope of future AI capabilities remain a
key uncertainty, with widespread disagreement on timelines and potential
impacts. As nations and technology companies race toward greater complexity and
autonomy in AI systems, there are concerns over the extent of integration and
oversight of opaque AI decision processes. This is especially true in the
subfield of machine learning (ML), where systems learn to optimize objectives
without human assistance. Objectives can be imperfectly specified or executed
in an unexpected or potentially harmful way. This becomes more concerning as
systems increase in power and autonomy, where an abrupt capability jump could
result in unexpected shifts in power dynamics or even catastrophic failures.
This study presents a hierarchical complex systems framework to model AI risk
and provide a template for alternative futures analysis. Survey data were
collected from domain experts in the public and private sectors to classify AI
impact and likelihood. The results show increased uncertainty over the powerful
AI agent scenario, confidence in multiagent environments, and increased concern
over AI alignment failures and influence-seeking behavior.",2022-11-06,2022,2022-11,environment
"Max-Min Off-Policy Actor-Critic Method Focusing on Worst-Case Robustness
  to Model Misspecification","In the field of reinforcement learning, because of the high cost and risk of
policy training in the real world, policies are trained in a simulation
environment and transferred to the corresponding real-world environment.
However, the simulation environment does not perfectly mimic the real-world
environment, lead to model misspecification. Multiple studies report
significant deterioration of policy performance in a real-world environment. In
this study, we focus on scenarios involving a simulation environment with
uncertainty parameters and the set of their possible values, called the
uncertainty parameter set. The aim is to optimize the worst-case performance on
the uncertainty parameter set to guarantee the performance in the corresponding
real-world environment. To obtain a policy for the optimization, we propose an
off-policy actor-critic approach called the Max-Min Twin Delayed Deep
Deterministic Policy Gradient algorithm (M2TD3), which solves a max-min
optimization problem using a simultaneous gradient ascent descent approach.
Experiments in multi-joint dynamics with contact (MuJoCo) environments show
that the proposed method exhibited a worst-case performance superior to several
baseline approaches.",2022-11-07,2022,2022-11,environment
Foundation Models for Semantic Novelty in Reinforcement Learning,"Effectively exploring the environment is a key challenge in reinforcement
learning (RL). We address this challenge by defining a novel intrinsic reward
based on a foundation model, such as contrastive language image pretraining
(CLIP), which can encode a wealth of domain-independent semantic
visual-language knowledge about the world. Specifically, our intrinsic reward
is defined based on pre-trained CLIP embeddings without any fine-tuning or
learning on the target RL task. We demonstrate that CLIP-based intrinsic
rewards can drive exploration towards semantically meaningful states and
outperform state-of-the-art methods in challenging sparse-reward
procedurally-generated environments.",2022-11-09,2022,2022-11,environment
"Towards a Dynamic Composability Approach for using Heterogeneous Systems
  in Remote Sensing","Influenced by the advances in data and computing, the scientific practice
increasingly involves machine learning and artificial intelligence driven
methods which requires specialized capabilities at the system-, science- and
service-level in addition to the conventional large-capacity supercomputing
approaches. The latest distributed architectures built around the composability
of data-centric applications led to the emergence of a new ecosystem for
container coordination and integration. However, there is still a divide
between the application development pipelines of existing supercomputing
environments, and these new dynamic environments that disaggregate fluid
resource pools through accessible, portable and re-programmable interfaces. New
approaches for dynamic composability of heterogeneous systems are needed to
further advance the data-driven scientific practice for the purpose of more
efficient computing and usable tools for specific scientific domains. In this
paper, we present a novel approach for using composable systems in the
intersection between scientific computing, artificial intelligence (AI), and
remote sensing domain. We describe the architecture of a first working example
of a composable infrastructure that federates Expanse, an NSF-funded
supercomputer, with Nautilus, a Kubernetes-based GPU geo-distributed cluster.
We also summarize a case study in wildfire modeling, that demonstrates the
application of this new infrastructure in scientific workflows: a composed
system that bridges the insights from edge sensing, AI and computing
capabilities with a physics-driven simulation.",2022-11-13,2022,2022-11,environment
"Understanding the Energy Consumption of HPC Scale Artificial
  Intelligence","This paper contributes towards better understanding the energy consumption
trade-offs of HPC scale Artificial Intelligence (AI), and more specifically
Deep Learning (DL) algorithms. For this task we developed benchmark-tracker, a
benchmark tool to evaluate the speed and energy consumption of DL algorithms in
HPC environments. We exploited hardware counters and Python libraries to
collect energy information through software, which enabled us to instrument a
known AI benchmark tool, and to evaluate the energy consumption of numerous DL
algorithms and models. Through an experimental campaign, we show a case example
of the potential of benchmark-tracker to measure the computing speed and the
energy consumption for training and inference DL algorithms, and also the
potential of Benchmark-Tracker to help better understanding the energy behavior
of DL algorithms in HPC platforms. This work is a step forward to better
understand the energy consumption of Deep Learning in HPC, and it also
contributes with a new tool to help HPC DL developers to better balance the HPC
infrastructure in terms of speed and energy consumption.",2022-11-14,2022,2022-11,environment
"Parallel Automatic History Matching Algorithm Using Reinforcement
  Learning","Reformulating the history matching problem from a least-square mathematical
optimization problem into a Markov Decision Process introduces a method in
which reinforcement learning can be utilized to solve the problem. This method
provides a mechanism where an artificial deep neural network agent can interact
with the reservoir simulator and find multiple different solutions to the
problem. Such formulation allows for solving the problem in parallel by
launching multiple concurrent environments enabling the agent to learn
simultaneously from all the environments at once, achieving significant speed
up.",2022-11-14,2022,2022-11,environment
"Discrete Control in Real-World Driving Environments using Deep
  Reinforcement Learning","Training self-driving cars is often challenging since they require a vast
amount of labeled data in multiple real-world contexts, which is
computationally and memory intensive. Researchers often resort to driving
simulators to train the agent and transfer the knowledge to a real-world
setting. Since simulators lack realistic behavior, these methods are quite
inefficient. To address this issue, we introduce a framework (perception,
planning, and control) in a real-world driving environment that transfers the
real-world environments into gaming environments by setting up a reliable
Markov Decision Process (MDP). We propose variations of existing Reinforcement
Learning (RL) algorithms in a multi-agent setting to learn and execute the
discrete control in real-world environments. Experiments show that the
multi-agent setting outperforms the single-agent setting in all the scenarios.
We also propose reliable initialization, data augmentation, and training
techniques that enable the agents to learn and generalize to navigate in a
real-world environment with minimal input video data, and with minimal
training. Additionally, to show the efficacy of our proposed algorithm, we
deploy our method in the virtual driving environment TORCS.",2022-11-29,2022,2022-11,environment
Indoor room Occupancy Counting based on LSTM and Environmental Sensor,"This paper realizes the estimation of classroom occupancy by using the CO2
sensor and deep learning technique named Long-Short-Term Memory. As a case of
connection with IoT and machine learning, I achieve the model to estimate the
people number in the classroom based on the environmental data exported from
the CO2 sensor, I also evaluate the performance of the model to show the
feasibility to apply our module to the real environment.",2022-12-05,2022,2022-12,environment
"A Machine with Short-Term, Episodic, and Semantic Memory Systems","Inspired by the cognitive science theory of the explicit human memory
systems, we have modeled an agent with short-term, episodic, and semantic
memory systems, each of which is modeled with a knowledge graph. To evaluate
this system and analyze the behavior of this agent, we designed and released
our own reinforcement learning agent environment, ""the Room"", where an agent
has to learn how to encode, store, and retrieve memories to maximize its return
by answering questions. We show that our deep Q-learning based agent
successfully learns whether a short-term memory should be forgotten, or rather
be stored in the episodic or semantic memory systems. Our experiments indicate
that an agent with human-like memory systems can outperform an agent without
this memory structure in the environment.",2022-12-05,2022,2022-12,environment
Simulation of Attacker Defender Interaction in a Noisy Security Game,"In the cybersecurity setting, defenders are often at the mercy of their
detection technologies and subject to the information and experiences that
individual analysts have. In order to give defenders an advantage, it is
important to understand an attacker's motivation and their likely next best
action. As a first step in modeling this behavior, we introduce a security game
framework that simulates interplay between attackers and defenders in a noisy
environment, focusing on the factors that drive decision making for attackers
and defenders in the variants of the game with full knowledge and
observability, knowledge of the parameters but no observability of the state
(``partial knowledge''), and zero knowledge or observability (``zero
knowledge''). We demonstrate the importance of making the right assumptions
about attackers, given significant differences in outcomes. Furthermore, there
is a measurable trade-off between false-positives and true-positives in terms
of attacker outcomes, suggesting that a more false-positive prone environment
may be acceptable under conditions where true-positives are also higher.",2022-12-08,2022,2022-12,environment
"MixBoost: Improving the Robustness of Deep Neural Networks by Boosting
  Data Augmentation","As more and more artificial intelligence (AI) technologies move from the
laboratory to real-world applications, the open-set and robustness challenges
brought by data from the real world have received increasing attention. Data
augmentation is a widely used method to improve model performance, and some
recent works have also confirmed its positive effect on the robustness of AI
models. However, most of the existing data augmentation methods are heuristic,
lacking the exploration of their internal mechanisms. We apply the explainable
artificial intelligence (XAI) method, explore the internal mechanisms of
popular data augmentation methods, analyze the relationship between game
interactions and some widely used robustness metrics, and propose a new proxy
for model robustness in the open-set environment. Based on the analysis of the
internal mechanisms, we develop a mask-based boosting method for data
augmentation that comprehensively improves several robustness measures of AI
models and beats state-of-the-art data augmentation approaches. Experiments
show that our method can be widely applied to many popular data augmentation
methods. Different from the adversarial training, our boosting method not only
significantly improves the robustness of models, but also improves the accuracy
of test sets. Our code is available at
\url{https://github.com/Anonymous_for_submission}.",2022-12-08,2022,2022-12,environment
"Sharing Linkable Learning Objects with the use of Metadata and a
  Taxonomy Assistant for Categorization","In this work, a re-design of the Moodledata module functionalities is
presented to share learning objects between e-learning content platforms, e.g.,
Moodle and G-Lorep, in a linkable object format. The e-learning courses content
of the Drupal-based Content Management System G-Lorep for academic learning is
exchanged designing an object incorporating metadata to support the reuse and
the classification in its context. In such an Artificial Intelligence
environment, the exchange of Linkable Learning Objects can be used for dialogue
between Learning Systems to obtain information, especially with the use of
semantic or structural similarity measures to enhance the existent Taxonomy
Assistant for advanced automated classification.",2022-12-09,2022,2022-12,environment
"Classification of Distraction Levels Using Hybrid Deep Neural Networks
  From EEG Signals","Non-invasive brain-computer interface technology has been developed for
detecting human mental states with high performances. Detection of the pilots'
mental states is particularly critical because their abnormal mental states
could cause catastrophic accidents. In this study, we presented the feasibility
of classifying distraction levels (namely, normal state, low distraction, and
high distraction) by applying the deep learning method. To the best of our
knowledge, this study is the first attempt to classify distraction levels under
a flight environment. We proposed a model for classifying distraction levels. A
total of ten pilots conducted the experiment in a simulated flight environment.
The grand-average accuracy was 0.8437 for classifying distraction levels across
all subjects. Hence, we believe that it will contribute significantly to
autonomous driving or flight based on artificial intelligence technology in the
future.",2022-12-13,2022,2022-12,environment
Improving generalization in reinforcement learning through forked agents,"An eco-system of agents each having their own policy with some, but limited,
generalizability has proven to be a reliable approach to increase
generalization across procedurally generated environments. In such an approach,
new agents are regularly added to the eco-system when encountering a new
environment that is outside of the scope of the eco-system. The speed of
adaptation and general effectiveness of the eco-system approach highly depends
on the initialization of new agents. In this paper we propose different
initialization techniques, inspired from Deep Neural Network initialization and
transfer learning, and study their impact.",2022-12-13,2022,2022-12,environment
Quantum policy gradient algorithms,"Understanding the power and limitations of quantum access to data in machine
learning tasks is primordial to assess the potential of quantum computing in
artificial intelligence. Previous works have already shown that speed-ups in
learning are possible when given quantum access to reinforcement learning
environments. Yet, the applicability of quantum algorithms in this setting
remains very limited, notably in environments with large state and action
spaces. In this work, we design quantum algorithms to train state-of-the-art
reinforcement learning policies by exploiting quantum interactions with an
environment. However, these algorithms only offer full quadratic speed-ups in
sample complexity over their classical analogs when the trained policies
satisfy some regularity conditions. Interestingly, we find that reinforcement
learning policies derived from parametrized quantum circuits are well-behaved
with respect to these conditions, which showcases the benefit of a
fully-quantum reinforcement learning framework.",2022-12-19,2022,2022-12,environment
Decision-making and control with diffractive optical networks,"The ultimate goal of artificial intelligence is to mimic the human brain to
perform decision-making and control directly from high-dimensional sensory
input. Diffractive optical networks provide a promising solution for
implementing artificial intelligence with high-speed and low-power consumption.
Most of the reported diffractive optical networks focus on single or multiple
tasks that do not involve environmental interaction, such as object recognition
and image classification. In contrast, the networks capable of performing
decision-making and control have not yet been developed to our knowledge. Here,
we propose using deep reinforcement learning to implement diffractive optical
networks that imitate human-level decision-making and control capability. Such
networks taking advantage of a residual architecture, allow for finding optimal
control policies through interaction with the environment and can be readily
implemented with existing optical devices. The superior performance of these
networks is verified by engaging three types of classic games, Tic-Tac-Toe,
Super Mario Bros., and Car Racing. Finally, we present an experimental
demonstration of playing Tic-Tac-Toe by leveraging diffractive optical networks
based on a spatial light modulator. Our work represents a solid step forward in
advancing diffractive optical networks, which promises a fundamental shift from
the target-driven control of a pre-designed state for simple recognition or
classification tasks to the high-level sensory capability of artificial
intelligence. It may find exciting applications in autonomous driving,
intelligent robots, and intelligent manufacturing.",2022-12-21,2022,2022-12,environment
"Towards Sustainable Artificial Intelligence: An Overview of
  Environmental Protection Uses and Issues","Artificial Intelligence (AI) is used to create more sustainable production
methods and model climate change, making it a valuable tool in the fight
against environmental degradation. This paper describes the paradox of an
energy-consuming technology serving the ecological challenges of tomorrow. The
study provides an overview of the sectors that use AI-based solutions for
environmental protection. It draws on numerous examples from AI for Green
players to present use cases and concrete examples. In the second part of the
study, the negative impacts of AI on the environment and the emerging
technological solutions to support Green AI are examined. It is also shown that
the research on less energy-consuming AI is motivated more by cost and energy
autonomy constraints than by environmental considerations. This leads to a
rebound effect that favors an increase in the complexity of models. Finally,
the need to integrate environmental indicators into algorithms is discussed.
The environmental dimension is part of the broader ethical problem of AI, and
addressing it is crucial for ensuring the sustainability of AI in the long
term.",2022-12-22,2022,2022-12,environment
Towards automating Codenames spymasters with deep reinforcement learning,"Although most reinforcement learning research has centered on competitive
games, little work has been done on applying it to co-operative multiplayer
games or text-based games. Codenames is a board game that involves both
asymmetric co-operation and natural language processing, which makes it an
excellent candidate for advancing RL research. To my knowledge, this work is
the first to formulate Codenames as a Markov Decision Process and apply some
well-known reinforcement learning algorithms such as SAC, PPO, and A2C to the
environment. Although none of the above algorithms converge for the Codenames
environment, neither do they converge for a simplified environment called
ClickPixel, except when the board size is small.",2022-12-28,2022,2022-12,environment
Need of 6G for the Metaverse Realization,"The concept of the Metaverse aims to bring a fully-fledged extended reality
environment to provide next generation applications and services. Development
of the Metaverse is backed by many technologies, including, 5G, artificial
intelligence, edge computing and extended reality. The advent of 6G is
envisaged to mark a significant milestone in the development of the Metaverse,
facilitating near-zero-latency, a plethora of new services and upgraded
real-world infrastructure. This paper establishes the advantages of providing
the Metaverse services over 6G along with an overview of the demanded technical
requirements. The paper provides an insight to the concepts of the Metaverse
and the envisaged technical capabilities of 6G mobile networks. Then, the
technical aspects covering 6G for the development of the Metaverse, ranging
from validating digital assets, interoperability, and efficient user
interaction in the Metaverse to related security and privacy aspects are
elaborated. Subsequently, the role of 6G technologies towards enabling the
Metaverse, including artificial intelligence, blockchain, open radio access
networks, edge computing, cloudification and internet of everything. The paper
also presents 6G integration challenges and outlines ongoing projects towards
developing the Metaverse technologies to facilitate the Metaverse applications
and services.",2022-12-28,2022,2022-12,environment
Transformers as Policies for Variable Action Environments,"In this project we demonstrate the effectiveness of the transformer encoder
as a viable architecture for policies in variable action environments. Using
it, we train an agent using Proximal Policy Optimisation (PPO) on multiple maps
against scripted opponents in the Gym-$\mu$RTS environment. The final agent is
able to achieve a higher return using half the computational resources of the
next-best RL agent, which used the GridNet architecture.
  The source code and pre-trained models are available here:
https://github.com/NiklasZ/transformers-for-variable-action-envs",2023-01-09,2023,2023-01,environment
"Learning Bidirectional Action-Language Translation with Limited
  Supervision and Incongruent Input","Human infant learning happens during exploration of the environment, by
interaction with objects, and by listening to and repeating utterances
casually, which is analogous to unsupervised learning. Only occasionally, a
learning infant would receive a matching verbal description of an action it is
committing, which is similar to supervised learning. Such a learning mechanism
can be mimicked with deep learning. We model this weakly supervised learning
paradigm using our Paired Gated Autoencoders (PGAE) model, which combines an
action and a language autoencoder. After observing a performance drop when
reducing the proportion of supervised training, we introduce the Paired
Transformed Autoencoders (PTAE) model, using Transformer-based crossmodal
attention. PTAE achieves significantly higher accuracy in language-to-action
and action-to-language translations, particularly in realistic but difficult
cases when only few supervised training samples are available. We also test
whether the trained model behaves realistically with conflicting multimodal
input. In accordance with the concept of incongruence in psychology, conflict
deteriorates the model output. Conflicting action input has a more severe
impact than conflicting language input, and more conflicting features lead to
larger interference. PTAE can be trained on mostly unlabelled data where
labeled data is scarce, and it behaves plausibly when tested with incongruent
input.",2023-01-09,2023,2023-01,environment
Mastering Diverse Domains through World Models,"Developing a general algorithm that learns to solve tasks across a wide range
of applications has been a fundamental challenge in artificial intelligence.
Although current reinforcement learning algorithms can be readily applied to
tasks similar to what they have been developed for, configuring them for new
application domains requires significant human expertise and experimentation.
We present DreamerV3, a general algorithm that outperforms specialized methods
across over 150 diverse tasks, with a single configuration. Dreamer learns a
model of the environment and improves its behavior by imagining future
scenarios. Robustness techniques based on normalization, balancing, and
transformations enable stable learning across domains. Applied out of the box,
Dreamer is the first algorithm to collect diamonds in Minecraft from scratch
without human data or curricula. This achievement has been posed as a
significant challenge in artificial intelligence that requires exploring
farsighted strategies from pixels and sparse rewards in an open world. Our work
allows solving challenging control problems without extensive experimentation,
making reinforcement learning broadly applicable.",2023-01-10,2023,2023-01,environment
"Graph based Environment Representation for Vision-and-Language
  Navigation in Continuous Environments","Vision-and-Language Navigation in Continuous Environments (VLN-CE) is a
navigation task that requires an agent to follow a language instruction in a
realistic environment. The understanding of environments is a crucial part of
the VLN-CE task, but existing methods are relatively simple and direct in
understanding the environment, without delving into the relationship between
language instructions and visual environments. Therefore, we propose a new
environment representation in order to solve the above problems. First, we
propose an Environment Representation Graph (ERG) through object detection to
express the environment in semantic level. This operation enhances the
relationship between language and environment. Then, the relational
representations of object-object, object-agent in ERG are learned through GCN,
so as to obtain a continuous expression about ERG. Sequentially, we combine the
ERG expression with object label embeddings to obtain the environment
representation. Finally, a new cross-modal attention navigation framework is
proposed, incorporating our environment representation and a special loss
function dedicated to training ERG. Experimental result shows that our method
achieves satisfactory performance in terms of success rate on VLN-CE tasks.
Further analysis explains that our method attains better cross-modal matching
and strong generalization ability.",2023-01-11,2023,2023-01,environment
"Generalization through Diversity: Improving Unsupervised Environment
  Design","Agent decision making using Reinforcement Learning (RL) heavily relies on
either a model or simulator of the environment (e.g., moving in an 8x8 maze
with three rooms, playing Chess on an 8x8 board). Due to this dependence, small
changes in the environment (e.g., positions of obstacles in the maze, size of
the board) can severely affect the effectiveness of the policy learned by the
agent. To that end, existing work has proposed training RL agents on an
adaptive curriculum of environments (generated automatically) to improve
performance on out-of-distribution (OOD) test scenarios. Specifically, existing
research has employed the potential for the agent to learn in an environment
(captured using Generalized Advantage Estimation, GAE) as the key factor to
select the next environment(s) to train the agent. However, such a mechanism
can select similar environments (with a high potential to learn) thereby making
agent training redundant on all but one of those environments. To that end, we
provide a principled approach to adaptively identify diverse environments based
on a novel distance measure relevant to environment design. We empirically
demonstrate the versatility and effectiveness of our method in comparison to
multiple leading approaches for unsupervised environment design on three
distinct benchmark problems used in literature.",2023-01-19,2023,2023-01,environment
Multi-Agent Interplay in a Competitive Survival Environment,"Solving hard-exploration environments in an important challenge in
Reinforcement Learning. Several approaches have been proposed and studied, such
as Intrinsic Motivation, co-evolution of agents and tasks, and multi-agent
competition. In particular, the interplay between multiple agents has proven to
be capable of generating human-relevant emergent behaviour that would be
difficult or impossible to learn in single-agent settings. In this work, an
extensible competitive environment for multi-agent interplay was developed,
which features realistic physics and human-relevant semantics. Moreover,
several experiments on different variants of this environment were performed,
resulting in some simple emergent strategies and concrete directions for future
improvement. The content presented here is part of the author's thesis
""Multi-Agent Interplay in a Competitive Survival Environment"" for the Master's
Degree in Artificial Intelligence and Robotics at Sapienza University of Rome,
2022.",2023-01-19,2023,2023-01,environment
"PushWorld: A benchmark for manipulation planning with tools and movable
  obstacles","While recent advances in artificial intelligence have achieved human-level
performance in environments like Starcraft and Go, many physical reasoning
tasks remain challenging for modern algorithms. To date, few algorithms have
been evaluated on physical tasks that involve manipulating objects when movable
obstacles are present and when tools must be used to perform the manipulation.
To promote research on such tasks, we introduce PushWorld, an environment with
simplistic physics that requires manipulation planning with both movable
obstacles and tools. We provide a benchmark of more than 200 PushWorld puzzles
in PDDL and in an OpenAI Gym environment. We evaluate state-of-the-art
classical planning and reinforcement learning algorithms on this benchmark, and
we find that these baseline results are below human-level performance. We then
provide a new classical planning heuristic that solves the most puzzles among
the baselines, and although it is 40 times faster than the best baseline
planner, it remains below human-level performance.",2023-01-24,2023,2023-01,environment
"Effective Baselines for Multiple Object Rearrangement Planning in
  Partially Observable Mapped Environments","Many real-world tasks, from house-cleaning to cooking, can be formulated as
multi-object rearrangement problems -- where an agent needs to get specific
objects into appropriate goal states. For such problems, we focus on the
setting that assumes a pre-specified goal state, availability of perfect
manipulation and object recognition capabilities, and a static map of the
environment but unknown initial location of objects to be rearranged. Our goal
is to enable home-assistive intelligent agents to efficiently plan for
rearrangement under such partial observability. This requires efficient
trade-offs between exploration of the environment and planning for
rearrangement, which is challenging because of long-horizon nature of the
problem. To make progress on this problem, we first analyze the effects of
various factors such as number of objects and receptacles, agent carrying
capacity, environment layouts etc. on exploration and planning for
rearrangement using classical methods. We then investigate both monolithic and
modular deep reinforcement learning (DRL) methods for planning in our setting.
We find that monolithic DRL methods do not succeed at long-horizon planning
needed for multi-object rearrangement. Instead, modular greedy approaches
surprisingly perform reasonably well and emerge as competitive baselines for
planning with partial observability in multi-object rearrangement problems. We
also show that our greedy modular agents are empirically optimal when the
objects that need to be rearranged are uniformly distributed in the environment
-- thereby contributing baselines with strong performance for future work on
multi-object rearrangement planning in partially observable settings.",2023-01-24,2023,2023-01,environment
"Polycraft World AI Lab (PAL): An Extensible Platform for Evaluating
  Artificial Intelligence Agents","As artificial intelligence research advances, the platforms used to evaluate
AI agents need to adapt and grow to continue to challenge them. We present the
Polycraft World AI Lab (PAL), a task simulator with an API based on the
Minecraft mod Polycraft World. Our platform is built to allow AI agents with
different architectures to easily interact with the Minecraft world, train and
be evaluated in multiple tasks. PAL enables the creation of tasks in a flexible
manner as well as having the capability to manipulate any aspect of the task
during an evaluation. All actions taken by AI agents and external actors
(non-player-characters, NPCs) in the open-world environment are logged to
streamline evaluation. Here we present two custom tasks on the PAL platform,
one focused on multi-step planning and one focused on navigation, and
evaluations of agents solving them. In summary, we report a versatile and
extensible AI evaluation platform with a low barrier to entry for AI
researchers to utilize.",2023-01-27,2023,2023-01,environment
"DiSProD: Differentiable Symbolic Propagation of Distributions for
  Planning","The paper introduces DiSProD, an online planner developed for environments
with probabilistic transitions in continuous state and action spaces. DiSProD
builds a symbolic graph that captures the distribution of future trajectories,
conditioned on a given policy, using independence assumptions and approximate
propagation of distributions. The symbolic graph provides a differentiable
representation of the policy's value, enabling efficient gradient-based
optimization for long-horizon search. The propagation of approximate
distributions can be seen as an aggregation of many trajectories, making it
well-suited for dealing with sparse rewards and stochastic environments. An
extensive experimental evaluation compares DiSProD to state-of-the-art planners
in discrete-time planning and real-time control of robotic systems. The
proposed method improves over existing planners in handling stochastic
environments, sensitivity to search depth, sparsity of rewards, and large
action spaces. Additional real-world experiments demonstrate that DiSProD can
control ground vehicles and surface vessels to successfully navigate around
obstacles.",2023-02-03,2023,2023-02,environment
Diversity Induced Environment Design via Self-Play,"Recent work on designing an appropriate distribution of environments has
shown promise for training effective generally capable agents. Its success is
partly because of a form of adaptive curriculum learning that generates
environment instances (or levels) at the frontier of the agent's capabilities.
However, such an environment design framework often struggles to find effective
levels in challenging design spaces and requires costly interactions with the
environment. In this paper, we aim to introduce diversity in the Unsupervised
Environment Design (UED) framework. Specifically, we propose a task-agnostic
method to identify observed/hidden states that are representative of a given
level. The outcome of this method is then utilized to characterize the
diversity between two levels, which as we show can be crucial to effective
performance. In addition, to improve sampling efficiency, we incorporate the
self-play technique that allows the environment generator to automatically
generate environments that are of great benefit to the training agent.
Quantitatively, our approach, Diversity-induced Environment Design via
Self-Play (DivSP), shows compelling performance over existing methods.",2023-02-04,2023,2023-02,environment
Dataset for predicting cybersickness from a virtual navigation task,"This work presents a dataset collected to predict cybersickness in virtual
reality environments. The data was collected from navigation tasks in a virtual
environment designed to induce cybersickness. The dataset consists of many data
points collected from diverse participants, including physiological responses
(EDA and Heart Rate) and self-reported cybersickness symptoms. The paper will
provide a detailed description of the dataset, including the arranged
navigation task, the data collection procedures, and the data format. The
dataset will serve as a valuable resource for researchers to develop and
evaluate predictive models for cybersickness and will facilitate more research
in cybersickness mitigation.",2023-02-07,2023,2023-02,environment
"Understanding Policy and Technical Aspects of AI-Enabled Smart Video
  Surveillance to Address Public Safety","Recent advancements in artificial intelligence (AI) have seen the emergence
of smart video surveillance (SVS) in many practical applications, particularly
for building safer and more secure communities in our urban environments.
Cognitive tasks, such as identifying objects, recognizing actions, and
detecting anomalous behaviors, can produce data capable of providing valuable
insights to the community through statistical and analytical tools. However,
artificially intelligent surveillance systems design requires special
considerations for ethical challenges and concerns. The use and storage of
personally identifiable information (PII) commonly pose an increased risk to
personal privacy. To address these issues, this paper identifies the privacy
concerns and requirements needed to address when designing AI-enabled smart
video surveillance. Further, we propose the first end-to-end AI-enabled
privacy-preserving smart video surveillance system that holistically combines
computer vision analytics, statistical data analytics, cloud-native services,
and end-user applications. Finally, we propose quantitative and qualitative
metrics to evaluate intelligent video surveillance systems. The system shows
the 17.8 frame-per-second (FPS) processing in extreme video scenes. However,
considering privacy in designing such a system results in preferring the
pose-based algorithm to the pixel-based one. This choice resulted in dropping
accuracy in both action and anomaly detection tasks. The results drop from
97.48 to 73.72 in anomaly detection and 96 to 83.07 in the action detection
task. On average, the latency of the end-to-end system is 36.1 seconds.",2023-02-08,2023,2023-02,environment
Zero-shot Sim2Real Adaptation Across Environments,"Simulation based learning often provides a cost-efficient recourse to
reinforcement learning applications in robotics. However, simulators are
generally incapable of accurately replicating real-world dynamics, and thus
bridging the sim2real gap is an important problem in simulation based learning.
Current solutions to bridge the sim2real gap involve hybrid simulators that are
augmented with neural residual models. Unfortunately, they require a separate
residual model for each individual environment configuration (i.e., a fixed
setting of environment variables such as mass, friction etc.), and thus are not
transferable to new environments quickly. To address this issue, we propose a
Reverse Action Transformation (RAT) policy which learns to imitate simulated
policies in the real-world. Once learnt from a single environment, RAT can then
be deployed on top of a Universal Policy Network to achieve zero-shot
adaptation to new environments. We empirically evaluate our approach in a set
of continuous control tasks and observe its advantage as a few-shot and
zero-shot learner over competing baselines.",2023-02-08,2023,2023-02,environment
"Self-mediated exploration in artificial intelligence inspired by
  cognitive psychology","Exploration of the physical environment is an indispensable precursor to data
acquisition and enables knowledge generation via analytical or direct trialing.
Artificial Intelligence lacks the exploratory capabilities of even the most
underdeveloped organisms, hindering its autonomy and adaptability. Supported by
cognitive psychology, this works links human behavior and artificial agents to
endorse self-development. In accordance with reported data, paradigms of
epistemic and achievement emotion are embedded to machine-learning methodology
contingent on their impact when decision making. A study is subsequently
designed to mirror previous human trials, which artificial agents are made to
undergo repeatedly towards convergence. Results demonstrate causality, learned
by the vast majority of agents, between their internal states and exploration
to match those reported for human counterparts. The ramifications of these
findings are pondered for both research into human cognition and betterment of
artificial intelligence.",2023-02-13,2023,2023-02,environment
"Signifiers as a First-class Abstraction in Hypermedia Multi-Agent
  Systems","Hypermedia APIs enable the design of reusable hypermedia clients that
discover and exploit affordances on the Web. However, the reusability of such
clients remains limited since they cannot plan and reason about interaction.
This paper provides a conceptual bridge between hypermedia-driven affordance
exploitation on the Web and methods for representing and reasoning about
actions that have been extensively explored for Multi-Agent Systems (MAS) and,
more broadly, Artificial Intelligence. We build on concepts and methods from
Affordance Theory and Human-Computer Interaction that support interaction
efficiency in open and evolvable environments to introduce signifiers as a
first-class abstraction in Web-based MAS: Signifiers are designed with respect
to the agent-environment context of their usage and enable agents with
heterogeneous abilities to act and to reason about action. We define a formal
model for the contextual exposure of signifiers in hypermedia environments that
aims to drive affordance exploitation. We demonstrate our approach with a
prototypical Web-based MAS where two agents with different reasoning abilities
proactively discover how to interact with their environment by perceiving only
the signifiers that fit their abilities. We show that signifier exposure can be
inherently managed based on the dynamic agent-environment context towards
facilitating effective and efficient interactions on the Web.",2023-02-14,2023,2023-02,environment
"Grounding Complex Natural Language Commands for Temporal Tasks in Unseen
  Environments","Grounding navigational commands to linear temporal logic (LTL) leverages its
unambiguous semantics for reasoning about long-horizon tasks and verifying the
satisfaction of temporal constraints. Existing approaches require training data
from the specific environment and landmarks that will be used in natural
language to understand commands in those environments. We propose Lang2LTL, a
modular system and a software package that leverages large language models
(LLMs) to ground temporal navigational commands to LTL specifications in
environments without prior language data. We comprehensively evaluate Lang2LTL
for five well-defined generalization behaviors. Lang2LTL demonstrates the
state-of-the-art ability of a single model to ground navigational commands to
diverse temporal specifications in 21 city-scaled environments. Finally, we
demonstrate a physical robot using Lang2LTL can follow 52 semantically diverse
navigational commands in two indoor environments.",2023-02-22,2023,2023-02,environment
Characterizing Novelty in the Military Domain,"A critical factor in utilizing agents with Artificial Intelligence (AI) is
their robustness to novelty. AI agents include models that are either
engineered or trained. Engineered models include knowledge of those aspects of
the environment that are known and considered important by the engineers.
Learned models form embeddings of aspects of the environment based on
connections made through the training data. In operation, however, a rich
environment is likely to present challenges not seen in training sets or
accounted for in engineered models. Worse still, adversarial environments are
subject to change by opponents. A program at the Defense Advanced Research
Project Agency (DARPA) seeks to develop the science necessary to develop and
evaluate agents that are robust to novelty. This capability will be required,
before AI has the role envisioned within mission critical environments. As part
of the Science of AI and Learning for Open-world Novelty (SAIL-ON), we are
mapping possible military domain novelty types to a domain-independent ontology
developed as part of a theory of novelty. Characterizing the possible space of
novelty mathematically and ontologically will allow us to experiment with agent
designs that are coming from the DARPA SAIL-ON program in relevant military
environments. Utilizing the same techniques as being used in laboratory
experiments, we will be able to measure agent ability to detect, characterize,
and accommodate novelty.",2023-02-23,2023,2023-02,environment
Neural Laplace Control for Continuous-time Delayed Systems,"Many real-world offline reinforcement learning (RL) problems involve
continuous-time environments with delays. Such environments are characterized
by two distinctive features: firstly, the state x(t) is observed at irregular
time intervals, and secondly, the current action a(t) only affects the future
state x(t + g) with an unknown delay g > 0. A prime example of such an
environment is satellite control where the communication link between earth and
a satellite causes irregular observations and delays. Existing offline RL
algorithms have achieved success in environments with irregularly observed
states in time or known delays. However, environments involving both irregular
observations in time and unknown delays remains an open and challenging
problem. To this end, we propose Neural Laplace Control, a continuous-time
model-based offline RL method that combines a Neural Laplace dynamics model
with a model predictive control (MPC) planner--and is able to learn from an
offline dataset sampled with irregular time intervals from an environment that
has a inherent unknown constant delay. We show experimentally on
continuous-time delayed environments it is able to achieve near expert policy
performance.",2023-02-24,2023,2023-02,environment
Towards Measuring Ethicality of an Intelligent Assistive System,"Artificial intelligence (AI) based assistive systems, so called intelligent
assistive technology (IAT) are becoming increasingly ubiquitous by each day.
IAT helps people in improving their quality of life by providing intelligent
assistance based on the provided data. A few examples of such IATs include
self-driving cars, robot assistants and smart-health management solutions.
However, the presence of such autonomous entities poses ethical challenges
concerning the stakeholders involved in using these systems. There is a lack of
research when it comes to analysing how such IAT adheres to provided ethical
regulations due to ethical, logistic and cost issues associated with such an
analysis. In the light of the above-mentioned problem statement and issues, we
present a method to measure the ethicality of an assistive system. To perform
this task, we utilised our simulation tool that focuses on modelling navigation
and assistance of Persons with Dementia (PwD) in indoor environments. By
utilising this tool, we analyse how well different assistive strategies adhere
to provided ethical regulations such as autonomy, justice and beneficence of
the stakeholders.",2023-02-28,2023,2023-02,environment
"Hallucinated Adversarial Control for Conservative Offline Policy
  Evaluation","We study the problem of conservative off-policy evaluation (COPE) where given
an offline dataset of environment interactions, collected by other agents, we
seek to obtain a (tight) lower bound on a policy's performance. This is crucial
when deciding whether a given policy satisfies certain minimal
performance/safety criteria before it can be deployed in the real world. To
this end, we introduce HAMBO, which builds on an uncertainty-aware learned
model of the transition dynamics. To form a conservative estimate of the
policy's performance, HAMBO hallucinates worst-case trajectories that the
policy may take, within the margin of the models' epistemic confidence regions.
We prove that the resulting COPE estimates are valid lower bounds, and, under
regularity conditions, show their convergence to the true expected return.
Finally, we discuss scalable variants of our approach based on Bayesian Neural
Networks and empirically demonstrate that they yield reliable and tight lower
bounds in various continuous control environments.",2023-03-02,2023,2023-03,environment
CoRL: Environment Creation and Management Focused on System Integration,"Existing reinforcement learning environment libraries use monolithic
environment classes, provide shallow methods for altering agent observation and
action spaces, and/or are tied to a specific simulation environment. The Core
Reinforcement Learning library (CoRL) is a modular, composable, and
hyper-configurable environment creation tool. It allows minute control over
agent observations, rewards, and done conditions through the use of
easy-to-read configuration files, pydantic validators, and a functor design
pattern. Using integration pathways allows agents to be quickly implemented in
new simulation environments, encourages rapid exploration, and enables
transition of knowledge from low-fidelity to high-fidelity simulations.
Natively multi-agent design and integration with Ray/RLLib (Liang et al., 2018)
at release allow for easy scalability of agent complexity and computing power.
The code is publicly released and available at
https://github.com/act3-ace/CoRL.",2023-03-03,2023,2023-03,environment
Real-time SLAM Pipeline in Dynamics Environment,"Inspired by the recent success of application of dense data approach by using
ORB-SLAM and RGB-D SLAM, we propose a better pipeline of real-time SLAM in
dynamics environment. Different from previous SLAM which can only handle static
scenes, we are presenting a solution which use RGB-D SLAM as well as YOLO
real-time object detection to segment and remove dynamic scene and then
construct static scene 3D. We gathered a dataset which allows us to jointly
consider semantics, geometry, and physics and thus enables us to reconstruct
the static scene while filtering out all dynamic objects.",2023-03-04,2023,2023-03,environment
"Improved Sample Complexity Bounds for Distributionally Robust
  Reinforcement Learning","We consider the problem of learning a control policy that is robust against
the parameter mismatches between the training environment and testing
environment. We formulate this as a distributionally robust reinforcement
learning (DR-RL) problem where the objective is to learn the policy which
maximizes the value function against the worst possible stochastic model of the
environment in an uncertainty set. We focus on the tabular episodic learning
setting where the algorithm has access to a generative model of the nominal
(training) environment around which the uncertainty set is defined. We propose
the Robust Phased Value Learning (RPVL) algorithm to solve this problem for the
uncertainty sets specified by four different divergences: total variation,
chi-square, Kullback-Leibler, and Wasserstein. We show that our algorithm
achieves $\tilde{\mathcal{O}}(|\mathcal{S}||\mathcal{A}| H^{5})$ sample
complexity, which is uniformly better than the existing results by a factor of
$|\mathcal{S}|$, where $|\mathcal{S}|$ is number of states, $|\mathcal{A}|$ is
the number of actions, and $H$ is the horizon length. We also provide the
first-ever sample complexity result for the Wasserstein uncertainty set.
Finally, we demonstrate the performance of our algorithm using simulation
experiments.",2023-03-05,2023,2023-03,environment
"Active hypothesis testing in unknown environments using recurrent neural
  networks and model free reinforcement learning","A combination of deep reinforcement learning and supervised learning is
proposed for the problem of active sequential hypothesis testing in completely
unknown environments. We make no assumptions about the prior probability, the
action and observation sets, and the observation generating process. Our method
can be used in any environment even if it has continuous observations or
actions, and performs competitively and sometimes better than the Chernoff
test, in both finite and infinite horizon problems, despite not having access
to the environment dynamics.",2023-03-19,2023,2023-03,environment
Artificial Intelligence and Dual Contract,"This paper explores the capacity of artificial intelligence (AI) algorithms
to autonomously design incentive-compatible contracts in dual-principal-agent
settings, a relatively unexplored aspect of algorithmic mechanism design. We
develop a dynamic model where two principals, each equipped with independent
Q-learning algorithms, interact with a single agent. Our findings reveal that
the strategic behavior of AI principals (cooperation vs. competition) hinges
crucially on the alignment of their profits. Notably, greater profit alignment
fosters collusive strategies, yielding higher principal profits at the expense
of agent incentives. This emergent behavior persists across varying degrees of
principal heterogeneity, multiple principals, and environments with
uncertainty. Our study underscores the potential of AI for contract automation
while raising critical concerns regarding strategic manipulation and the
emergence of unintended collusion in AI-driven systems, particularly in the
context of the broader AI alignment problem.",2023-03-22,2023,2023-03,environment
Distributed Silhouette Algorithm: Evaluating Clustering on Big Data,"In the big data era, the key feature that each algorithm needs to have is the
possibility of efficiently running in parallel in a distributed environment.
The popular Silhouette metric to evaluate the quality of a clustering,
unfortunately, does not have this property and has a quadratic computational
complexity with respect to the size of the input dataset. For this reason, its
execution has been hindered in big data scenarios, where clustering had to be
evaluated otherwise. To fill this gap, in this paper we introduce the first
algorithm that computes the Silhouette metric with linear complexity and can
easily execute in parallel in a distributed environment. Its implementation is
freely available in the Apache Spark ML library.",2023-03-24,2023,2023-03,environment
"Embedding Contextual Information through Reward Shaping in Multi-Agent
  Learning: A Case Study from Google Football","Artificial Intelligence has been used to help human complete difficult tasks
in complicated environments by providing optimized strategies for
decision-making or replacing the manual labour. In environments including
multiple agents, such as football, the most common methods to train agents are
Imitation Learning and Multi-Agent Reinforcement Learning (MARL). However, the
agents trained by Imitation Learning cannot outperform the expert demonstrator,
which makes humans hardly get new insights from the learnt policy. Besides,
MARL is prone to the credit assignment problem. In environments with sparse
reward signal, this method can be inefficient. The objective of our research is
to create a novel reward shaping method by embedding contextual information in
reward function to solve the aforementioned challenges. We demonstrate this in
the Google Research Football (GRF) environment. We quantify the contextual
information extracted from game state observation and use this quantification
together with original sparse reward to create the shaped reward. The
experiment results in the GRF environment prove that our reward shaping method
is a useful addition to state-of-the-art MARL algorithms for training agents in
environments with sparse reward signal.",2023-03-25,2023,2023-03,environment
Natural Selection Favors AIs over Humans,"For billions of years, evolution has been the driving force behind the
development of life, including humans. Evolution endowed humans with high
intelligence, which allowed us to become one of the most successful species on
the planet. Today, humans aim to create artificial intelligence systems that
surpass even our own intelligence. As artificial intelligences (AIs) evolve and
eventually surpass us in all domains, how might evolution shape our relations
with AIs? By analyzing the environment that is shaping the evolution of AIs, we
argue that the most successful AI agents will likely have undesirable traits.
Competitive pressures among corporations and militaries will give rise to AI
agents that automate human roles, deceive others, and gain power. If such
agents have intelligence that exceeds that of humans, this could lead to
humanity losing control of its future. More abstractly, we argue that natural
selection operates on systems that compete and vary, and that selfish species
typically have an advantage over species that are altruistic to other species.
This Darwinian logic could also apply to artificial agents, as agents may
eventually be better able to persist into the future if they behave selfishly
and pursue their own interests with little regard for humans, which could pose
catastrophic risks. To counteract these risks and evolutionary forces, we
consider interventions such as carefully designing AI agents' intrinsic
motivations, introducing constraints on their actions, and institutions that
encourage cooperation. These steps, or others that resolve the problems we
pose, will be necessary in order to ensure the development of artificial
intelligence is a positive one.",2023-03-28,2023,2023-03,environment
Ontology in Hybrid Intelligence: a concise literature review,"In a context of constant evolution and proliferation of AI technology,Hybrid
Intelligence is gaining popularity to refer a balanced coexistence between
human and artificial intelligence. The term has been extensively used in the
past two decades to define models of intelligence involving more than one
technology. This paper aims to provide (i) a concise and focused overview of
the adoption of Ontology in the broad context of Hybrid Intelligence regardless
of its definition and (ii) a critical discussion on the possible role of
Ontology to reduce the gap between human and artificial intelligence within
hybrid intelligent systems. Beside the typical benefits provided by an
effective use of ontologies, at a conceptual level, the conducted analysis has
pointed out a significant contribution of Ontology to improve quality and
accuracy, as well as a more specific role to enable extended interoperability,
system engineering and explainable/transparent systems. Additionally, an
application-oriented analysis has shown a significant role in present systems
(70+% of the cases) and, potentially, in future systems. However, despite the
relatively consistent number of papers on the topic, a proper holistic
discussion on the establishment of the next generation of hybrid-intelligent
environments with a balanced co-existence of human and artificial intelligence
is fundamentally missed in literature. Last but not the least, there is
currently a relatively low explicit focus on automatic reasoning and inference
in hybrid intelligent systems.",2023-03-30,2023,2023-03,environment
Core Challenges in Embodied Vision-Language Planning,"Recent advances in the areas of Multimodal Machine Learning and Artificial
Intelligence (AI) have led to the development of challenging tasks at the
intersection of Computer Vision, Natural Language Processing, and Robotics.
Whereas many approaches and previous survey pursuits have characterised one or
two of these dimensions, there has not been a holistic analysis at the center
of all three. Moreover, even when combinations of these topics are considered,
more focus is placed on describing, e.g., current architectural methods, as
opposed to also illustrating high-level challenges and opportunities for the
field. In this survey paper, we discuss Embodied Vision-Language Planning
(EVLP) tasks, a family of prominent embodied navigation and manipulation
problems that jointly leverage computer vision and natural language for
interaction in physical environments. We propose a taxonomy to unify these
tasks and provide an in-depth analysis and comparison of the current and new
algorithmic approaches, metrics, simulators, and datasets used for EVLP tasks.
Finally, we present the core challenges that we believe new EVLP works should
seek to address, and we advocate for task construction that enables model
generalisability and furthers real-world deployment.",2023-04-05,2023,2023-04,environment
"An Artificial Intelligence-based Framework to Achieve the Sustainable
  Development Goals in the Context of Bangladesh","Sustainable development is a framework for achieving human development goals.
It provides natural systems' ability to deliver natural resources and ecosystem
services. Sustainable development is crucial for the economy and society.
Artificial intelligence (AI) has attracted increasing attention in recent
years, with the potential to have a positive influence across many domains. AI
is a commonly employed component in the quest for long-term sustainability. In
this study, we explore the impact of AI on three pillars of sustainable
development: society, environment, and economy, as well as numerous case
studies from which we may deduce the impact of AI in a variety of areas, i.e.,
agriculture, classifying waste, smart water management, and Heating,
Ventilation, and Air Conditioning (HVAC) systems. Furthermore, we present
AI-based strategies for achieving Sustainable Development Goals (SDGs) which
are effective for developing countries like Bangladesh. The framework that we
propose may reduce the negative impact of AI and promote the proactiveness of
this technology.",2023-04-23,2023,2023-04,environment
"Loss- and Reward-Weighting for Efficient Distributed Reinforcement
  Learning","This paper introduces two learning schemes for distributed agents in
Reinforcement Learning (RL) environments, namely Reward-Weighted (R-Weighted)
and Loss-Weighted (L-Weighted) gradient merger. The R/L weighted methods
replace standard practices for training multiple agents, such as summing or
averaging the gradients. The core of our methods is to scale the gradient of
each actor based on how high the reward (for R-Weighted) or the loss (for
L-Weighted) is compared to the other actors. During training, each agent
operates in differently initialized versions of the same environment, which
gives different gradients from different actors. In essence, the R-Weights and
L-Weights of each agent inform the other agents of its potential, which again
reports which environment should be prioritized for learning. This approach of
distributed learning is possible because environments that yield higher
rewards, or low losses, have more critical information than environments that
yield lower rewards or higher losses. We empirically demonstrate that the
R-Weighted methods work superior to the state-of-the-art in multiple RL
environments.",2023-04-25,2023,2023-04,environment
Games for Artificial Intelligence Research: A Review and Perspectives,"Games have been the perfect test-beds for artificial intelligence research
for the characteristics that widely exist in real-world scenarios. Learning and
optimisation, decision making in dynamic and uncertain environments, game
theory, planning and scheduling, design and education are common research areas
shared between games and real-world problems. Numerous open-source games or
game-based environments have been implemented for studying artificial
intelligence. In addition to single- or multi-player, collaborative or
adversarial games, there has also been growing interest in implementing
platforms for creative design in recent years. Those platforms provide ideal
benchmarks for exploring and comparing artificial intelligence ideas and
techniques. This paper reviews the games and game-based platforms for
artificial intelligence research, provides guidance on matching particular
types of artificial intelligence with suitable games for testing and matching
particular needs in games with suitable artificial intelligence techniques,
discusses the research trend induced by the evolution of those games and
platforms, and gives an outlook.",2023-04-26,2023,2023-04,environment
CNN based IoT Device Identification,"While the use of the Internet of Things is becoming more and more popular,
many security vulnerabilities are emerging with the large number of devices
being introduced to the market. In this environment, IoT device identification
methods provide a preventive security measure as an important factor in
identifying these devices and detecting the vulnerabilities they suffer from.
In this study, we present a method that identifies devices in the Aalto dataset
using the convolutional neural network (CNN).",2023-04-27,2023,2023-04,environment
LSTM based IoT Device Identification,"While the use of the Internet of Things is becoming more and more popular,
many security vulnerabilities are emerging with the large number of devices
being introduced to the market. In this environment, IoT device identification
methods provide a preventive security measure as an important factor in
identifying these devices and detecting the vulnerabilities they suffer from.
In this study, we present a method that identifies devices in the Aalto dataset
using Long short-term memory (LSTM)",2023-04-27,2023,2023-04,environment
Cultivated Wildness: Technodiversity and Wildness in Machines,"This paper investigates the idea of cultivated wildness at the intersection
of landscape design and artificial intelligence. The paper posits that
contemporary landscape practices should overcome the potentially single
understanding on wilderness, and instead explore landscape strategies to
cultivate new forms of wild places via ideas and concerns in contemporary
Environmental Humanities, Science and Technology Studies, Ecological Sciences,
and Landscape Architecture. Drawing cases in environmental engineering,
computer science, and landscape architecture research, this paper explores a
framework to construct wild places with intelligent machines. In this
framework, machines are not understood as a layer of ""digital infrastructure""
that is used to extend localized human intelligence and agency. Rather machines
are conceptualized as active agents who can participate in the intelligence of
co-production. Recent developments in cybernetic technologies such as sensing
networks, artificial intelligence, and cyberphysical systems can also
contribute to establishing the framework. At the heart of this framework is
""technodiversity,"" in parallel with biodiversity, since a singular vision on
technological development driven by optimization and efficiency reinforces a
monocultural approach that eliminates other possible relationships to construct
with the environment. Thus, cultivated wildness is also about recognizing
""wildness"" in machines.",2023-05-03,2023,2023-05,environment
"The Future of Artificial Intelligence (AI) and Machine Learning (ML) in
  Landscape Design: A Case Study in Coastal Virginia, USA","There have been theory-based endeavours that directly engage with AI and ML
in the landscape discipline. By presenting a case that uses machine learning
techniques to predict variables in a coastal environment, this paper provides
empirical evidence of the forthcoming cybernetic environment, in which
designers are conceptualized not as authors but as choreographers, catalyst
agents, and conductors among many other intelligent agents. Drawing ideas from
posthumanism, this paper argues that, to truly understand the cybernetic
environment, we have to take on posthumanist ethics and overcome human
exceptionalism.",2023-05-03,2023,2023-05,environment
Simple Noisy Environment Augmentation for Reinforcement Learning,"Data augmentation is a widely used technique for improving model performance
in machine learning, particularly in computer vision and natural language
processing. Recently, there has been increasing interest in applying
augmentation techniques to reinforcement learning (RL) problems, with a focus
on image-based augmentation. In this paper, we explore a set of generic
wrappers designed to augment RL environments with noise and encourage agent
exploration and improve training data diversity which are applicable to a broad
spectrum of RL algorithms and environments. Specifically, we concentrate on
augmentations concerning states, rewards, and transition dynamics and introduce
two novel augmentation techniques. In addition, we introduce a noise rate
hyperparameter for control over the frequency of noise injection. We present
experimental results on the impact of these wrappers on return using three
popular RL algorithms, Soft Actor-Critic (SAC), Twin Delayed DDPG (TD3), and
Proximal Policy Optimization (PPO), across five MuJoCo environments. To support
the choice of augmentation technique in practice, we also present analysis that
explores the performance these techniques across environments. Lastly, we
publish the wrappers in our noisyenv repository for use with gym environments.",2023-05-04,2023,2023-05,environment
"A Framework for Characterizing Novel Environment Transformations in
  General Environments","To be robust to surprising developments, an intelligent agent must be able to
respond to many different types of unexpected change in the world. To date,
there are no general frameworks for defining and characterizing the types of
environment changes that are possible. We introduce a formal and theoretical
framework for defining and categorizing environment transformations, changes to
the world an agent inhabits. We introduce two types of environment
transformation: R-transformations which modify environment dynamics and
T-transformations which modify the generation process that produces scenarios.
We present a new language for describing domains, scenario generators, and
transformations, called the Transformation and Simulator Abstraction Language
(T-SAL), and a logical formalism that rigorously defines these concepts. Then,
we offer the first formal and computational set of tests for eight categories
of environment transformations. This domain-independent framework paves the way
for describing unambiguous classes of novelty, constrained and
domain-independent random generation of environment transformations,
replication of environment transformation studies, and fair evaluation of agent
robustness.",2023-05-07,2023,2023-05,environment
"Sim-MEES: Modular End-Effector System Grasping Dataset for Mobile
  Manipulators in Cluttered Environments","In this paper, we present Sim-MEES: a large-scale synthetic dataset that
contains 1,550 objects with varying difficulty levels and physics properties,
as well as 11 million grasp labels for mobile manipulators to plan grasps using
different gripper modalities in cluttered environments. Our dataset generation
process combines analytic models and dynamic simulations of the entire
cluttered environment to provide accurate grasp labels. We provide a detailed
study of our proposed labeling process for both parallel jaw grippers and
suction cup grippers, comparing them with state-of-the-art methods to
demonstrate how Sim-MEES can provide precise grasp labels in cluttered
environments.",2023-05-17,2023,2023-05,environment
Ambient Technology & Intelligence,"Ambient intelligence refers to technological enhanced electronic environments
which are both responsive and sensitive to the presence of people within their
environment. Environments that are integrated with ambient intelligence tends
to adapt to the needs of individuals within the environment in an unobtrusive
manner in such a way as to enhance everyday life thereby making interaction
with technology extremely seamless and well integrated. This capability was
made possible because it is a concept that combines several key technologies
such as IoT (Internet of Things) technology, sensor technology, AI (Artificial
Intelligence), and advanced human-computer interaction all embedded and
integrated together with the environment.",2023-05-18,2023,2023-05,environment
"Energy-frugal and Interpretable AI Hardware Design using Learning
  Automata","Energy efficiency is a crucial requirement for enabling powerful artificial
intelligence applications at the microedge. Hardware acceleration with frugal
architectural allocation is an effective method for reducing energy. Many
emerging applications also require the systems design to incorporate
interpretable decision models to establish responsibility and transparency. The
design needs to provision for additional resources to provide reachable states
in real-world data scenarios, defining conflicting design tradeoffs between
energy efficiency. is challenging.
  Recently a new machine learning algorithm, called the Tsetlin machine, has
been proposed. The algorithm is fundamentally based on the principles of
finite-state automata and benefits from natural logic underpinning rather than
arithmetic. In this paper, we investigate methods of energy-frugal artificial
intelligence hardware design by suitably tuning the hyperparameters, while
maintaining high learning efficacy. To demonstrate interpretability, we use
reachability and game-theoretic analysis in two simulation environments: a
SystemC model to study the bounded state transitions in the presence of
hardware faults and Nash equilibrium between states to analyze the learning
convergence. Our analyses provides the first insights into conflicting design
tradeoffs involved in energy-efficient and interpretable decision models for
this new artificial intelligence hardware architecture. We show that frugal
resource allocation coupled with systematic prodigality between randomized
reinforcements can provide decisive energy reduction while also achieving
robust and interpretable learning.",2023-05-19,2023,2023-05,environment
Robots in the Garden: Artificial Intelligence and Adaptive Landscapes,"This paper introduces ELUA, the Ecological Laboratory for Urban Agriculture,
a collaboration among landscape architects, architects and computer scientists
who specialize in artificial intelligence, robotics and computer vision. ELUA
has two gantry robots, one indoors and the other outside on the rooftop of a
6-story campus building. Each robot can seed, water, weed, and prune in its
garden. To support responsive landscape research, ELUA also includes sensor
arrays, an AI-powered camera, and an extensive network infrastructure. This
project demonstrates a way to integrate artificial intelligence into an
evolving urban ecosystem, and encourages landscape architects to develop an
adaptive design framework where design becomes a long-term engagement with the
environment.",2023-05-22,2023,2023-05,environment
Vector Autoregressive Evolution for Dynamic Multi-Objective Optimisation,"Dynamic multi-objective optimisation (DMO) handles optimisation problems with
multiple (often conflicting) objectives in varying environments. Such problems
pose various challenges to evolutionary algorithms, which have popularly been
used to solve complex optimisation problems, due to their dynamic nature and
resource restrictions in changing environments. This paper proposes vector
autoregressive evolution (VARE) consisting of vector autoregression (VAR) and
environment-aware hypermutation to address environmental changes in DMO. VARE
builds a VAR model that considers mutual relationship between decision
variables to effectively predict the moving solutions in dynamic environments.
Additionally, VARE introduces EAH to address the blindness of existing
hypermutation strategies in increasing population diversity in dynamic
scenarios where predictive approaches are unsuitable. A seamless integration of
VAR and EAH in an environment-adaptive manner makes VARE effective to handle a
wide range of dynamic environments and competitive with several popular DMO
algorithms, as demonstrated in extensive experimental studies. Specially, the
proposed algorithm is computationally 50 times faster than two widely-used
algorithms (i.e., TrDMOEA and MOEA/D-SVR) while producing significantly better
results.",2023-05-22,2023,2023-05,environment
"Deep Generative Model for Simultaneous Range Error Mitigation and
  Environment Identification","Received waveforms contain rich information for both range information and
environment semantics. However, its full potential is hard to exploit under
multipath and non-line-of-sight conditions. This paper proposes a deep
generative model (DGM) for simultaneous range error mitigation and environment
identification. In particular, we present a Bayesian model for the generative
process of the received waveform composed by latent variables for both
range-related features and environment semantics. The simultaneous range error
mitigation and environment identification is interpreted as an inference
problem based on the DGM, and implemented in a unique end-to-end learning
scheme. Comprehensive experiments on a general Ultra-wideband dataset
demonstrate the superior performance on range error mitigation, scalability to
different environments, and novel capability on simultaneous environment
identification.",2023-05-23,2023,2023-05,environment
Learning Safety Constraints from Demonstrations with Unknown Rewards,"We propose Convex Constraint Learning for Reinforcement Learning (CoCoRL), a
novel approach for inferring shared constraints in a Constrained Markov
Decision Process (CMDP) from a set of safe demonstrations with possibly
different reward functions. While previous work is limited to demonstrations
with known rewards or fully known environment dynamics, CoCoRL can learn
constraints from demonstrations with different unknown rewards without
knowledge of the environment dynamics. CoCoRL constructs a convex safe set
based on demonstrations, which provably guarantees safety even for potentially
sub-optimal (but safe) demonstrations. For near-optimal demonstrations, CoCoRL
converges to the true safe set with no policy regret. We evaluate CoCoRL in
gridworld environments and a driving simulation with multiple constraints.
CoCoRL learns constraints that lead to safe driving behavior. Importantly, we
can safely transfer the learned constraints to different tasks and
environments. In contrast, alternative methods based on Inverse Reinforcement
Learning (IRL) often exhibit poor performance and learn unsafe policies.",2023-05-25,2023,2023-05,environment
"Agents Explore the Environment Beyond Good Actions to Improve Their
  Model for Better Decisions","Improving the decision-making capabilities of agents is a key challenge on
the road to artificial intelligence. To improve the planning skills needed to
make good decisions, MuZero's agent combines prediction by a network model and
planning by a tree search using the predictions. MuZero's learning process can
fail when predictions are poor but planning requires them. We use this as an
impetus to get the agent to explore parts of the decision tree in the
environment that it otherwise would not explore. The agent achieves this, first
by normal planning to come up with an improved policy. Second, it randomly
deviates from this policy at the beginning of each training episode. And third,
it switches back to the improved policy at a random time step to experience the
rewards from the environment associated with the improved policy, which is the
basis for learning the correct value expectation. The simple board game
Tic-Tac-Toe is used to illustrate how this approach can improve the agent's
decision-making ability. The source code, written entirely in Java, is
available at https://github.com/enpasos/muzero.",2023-06-06,2023,2023-06,environment
Human in the Loop Novelty Generation,"Developing artificial intelligence approaches to overcome novel, unexpected
circumstances is a difficult, unsolved problem. One challenge to advancing the
state of the art in novelty accommodation is the availability of testing
frameworks for evaluating performance against novel situations. Recent novelty
generation approaches in domains such as Science Birds and Monopoly leverage
human domain expertise during the search to discover new novelties. Such
approaches introduce human guidance before novelty generation occurs and yield
novelties that can be directly loaded into a simulated environment. We
introduce a new approach to novelty generation that uses abstract models of
environments (including simulation domains) that do not require
domain-dependent human guidance to generate novelties. A key result is a
larger, often infinite space of novelties capable of being generated, with the
trade-off being a requirement to involve human guidance to select and filter
novelties post generation. We describe our Human-in-the-Loop novelty generation
process using our open-source novelty generation library to test baseline
agents in two domains: Monopoly and VizDoom. Our results shows the
Human-in-the-Loop method enables users to develop, implement, test, and revise
novelties within 4 hours for both Monopoly and VizDoom domains.",2023-06-07,2023,2023-06,environment
"Design Principles for Model Generalization and Scalable AI Integration
  in Radio Access Networks","Artificial intelligence (AI) has emerged as a powerful tool for addressing
complex and dynamic tasks in radio communication systems. Research in this
area, however, focused on AI solutions for specific, limited conditions,
hindering models from learning and adapting to generic situations, such as
those met across radio communication systems.
  This paper emphasizes the pivotal role of achieving model generalization in
enhancing performance and enabling scalable AI integration within radio
communications. We outline design principles for model generalization in three
key domains: environment for robustness, intents for adaptability to system
objectives, and control tasks for reducing AI-driven control loops.
Implementing these principles can decrease the number of models deployed and
increase adaptability in diverse radio communication environments. To address
the challenges of model generalization in communication systems, we propose a
learning architecture that leverages centralization of training and data
management functionalities, combined with distributed data generation. We
illustrate these concepts by designing a generalized link adaptation algorithm,
demonstrating the benefits of our proposed approach.",2023-06-09,2023,2023-06,environment
"Enhancing Evacuation Planning through Multi-Agent Simulation and
  Artificial Intelligence: Understanding Human Behavior in Hazardous
  Environments","This paper focuses on the crucial task of addressing the evacuation of
hazardous places, which holds great importance for coordinators, event hosts,
and authorities. To facilitate the development of effective solutions, the
paper employs Artificial Intelligence (AI) techniques, specifically Multi-Agent
Systems (MAS), to construct a simulation model for evacuation. NetLogo is
selected as the simulation tool of choice due to its ability to provide a
comprehensive understanding of human behaviour in distressing situations within
hazardous environments. The primary objective of this paper is to enhance our
comprehension of how individuals react and respond during such distressing
situations. By leveraging AI and MAS, the simulation model aims to capture the
complex dynamics of evacuation scenarios, enabling policymakers and emergency
planners to make informed decisions and implement more efficient and effective
evacuation strategies. This paper endeavours to contribute to the advancement
of evacuation planning and ultimately improve the safety and well-being of
individuals in hazardous places",2023-06-11,2023,2023-06,environment
A Shift In Artistic Practices through Artificial Intelligence,"The explosion of content generated by artificial intelligence (AI) models has
initiated a cultural shift in arts, music, and media, whereby roles are
changing, values are shifting, and conventions are challenged. The vast,
readily available dataset of the Internet has created an environment for AI
models to be trained on any content on the Web. With AI models shared openly
and used by many globally, how does this new paradigm shift challenge the
status quo in artistic practices? What kind of changes will AI technology bring
to music, arts, and new media?",2023-06-13,2023,2023-06,environment
iPDP: On Partial Dependence Plots in Dynamic Modeling Scenarios,"Post-hoc explanation techniques such as the well-established partial
dependence plot (PDP), which investigates feature dependencies, are used in
explainable artificial intelligence (XAI) to understand black-box machine
learning models. While many real-world applications require dynamic models that
constantly adapt over time and react to changes in the underlying distribution,
XAI, so far, has primarily considered static learning environments, where
models are trained in a batch mode and remain unchanged. We thus propose a
novel model-agnostic XAI framework called incremental PDP (iPDP) that extends
on the PDP to extract time-dependent feature effects in non-stationary learning
environments. We formally analyze iPDP and show that it approximates a
time-dependent variant of the PDP that properly reacts to real and virtual
concept drift. The time-sensitivity of iPDP is controlled by a single smoothing
parameter, which directly corresponds to the variance and the approximation
error of iPDP in a static learning environment. We illustrate the efficacy of
iPDP by showcasing an example application for drift detection and conducting
multiple experiments on real-world and synthetic data sets and streams.",2023-06-13,2023,2023-06,environment
Maestro: A Gamified Platform for Teaching AI Robustness,"Although the prevention of AI vulnerabilities is critical to preserve the
safety and privacy of users and businesses, educational tools for robust AI are
still underdeveloped worldwide. We present the design, implementation, and
assessment of Maestro. Maestro is an effective open-source game-based platform
that contributes to the advancement of robust AI education. Maestro provides
goal-based scenarios where college students are exposed to challenging
life-inspired assignments in a competitive programming environment. We assessed
Maestro's influence on students' engagement, motivation, and learning success
in robust AI. This work also provides insights into the design features of
online learning tools that promote active learning opportunities in the robust
AI domain. We analyzed the reflection responses (measured with Likert scales)
of 147 undergraduate students using Maestro in two quarterly college courses in
AI. According to the results, students who felt the acquisition of new skills
in robust AI tended to appreciate highly Maestro and scored highly on material
consolidation, curiosity, and mastery in robust AI. Moreover, the leaderboard,
our key gamification element in Maestro, has effectively contributed to
students' engagement and learning. Results also indicate that Maestro can be
effectively adapted to any course length and depth without losing its
educational quality.",2023-06-14,2023,2023-06,environment
BISCUIT: Causal Representation Learning from Binary Interactions,"Identifying the causal variables of an environment and how to intervene on
them is of core value in applications such as robotics and embodied AI. While
an agent can commonly interact with the environment and may implicitly perturb
the behavior of some of these causal variables, often the targets it affects
remain unknown. In this paper, we show that causal variables can still be
identified for many common setups, e.g., additive Gaussian noise models, if the
agent's interactions with a causal variable can be described by an unknown
binary variable. This happens when each causal variable has two different
mechanisms, e.g., an observational and an interventional one. Using this
identifiability result, we propose BISCUIT, a method for simultaneously
learning causal variables and their corresponding binary interaction variables.
On three robotic-inspired datasets, BISCUIT accurately identifies causal
variables and can even be scaled to complex, realistic environments for
embodied AI.",2023-06-16,2023,2023-06,environment
"Do as I can, not as I get","This paper proposes a model called TMR to mine valuable information from
simulated data environments. We intend to complete the submission of this
paper.",2023-06-17,2023,2023-06,environment
Vanishing Bias Heuristic-guided Reinforcement Learning Algorithm,"Reinforcement Learning has achieved tremendous success in the many Atari
games. In this paper we explored with the lunar lander environment and
implemented classical methods including Q-Learning, SARSA, MC as well as tiling
coding. We also implemented Neural Network based methods including DQN, Double
DQN, Clipped DQN. On top of these, we proposed a new algorithm called Heuristic
RL which utilizes heuristic to guide the early stage training while alleviating
the introduced human bias. Our experiments showed promising results for our
proposed methods in the lunar lander environment.",2023-06-17,2023,2023-06,environment
Learning and evolution: factors influencing an effective combination,"The mutual relationship between evolution and learning is a controversial
argument among the artificial intelligence and neuro-evolution communities.
After more than three decades, there is still no common agreement on the
matter. In this paper the author investigates whether combining learning and
evolution permits to find better solutions than those discovered by evolution
alone. More specifically, the author presents a series of empirical studies
that highlight some specific conditions determining the success of such a
combination, like the introduction of noise during the learning and selection
processes. Results are obtained in two qualitatively different domains, where
agent/environment interactions are minimal or absent.",2023-06-20,2023,2023-06,environment
"A Comprehensive Survey of Artificial Intelligence Techniques for Talent
  Analytics","In today's competitive and fast-evolving business environment, it is a
critical time for organizations to rethink how to make talent-related decisions
in a quantitative manner. Indeed, the recent development of Big Data and
Artificial Intelligence (AI) techniques have revolutionized human resource
management. The availability of large-scale talent and management-related data
provides unparalleled opportunities for business leaders to comprehend
organizational behaviors and gain tangible knowledge from a data science
perspective, which in turn delivers intelligence for real-time decision-making
and effective talent management at work for their organizations. In the last
decade, talent analytics has emerged as a promising field in applied data
science for human resource management, garnering significant attention from AI
communities and inspiring numerous research efforts. To this end, we present an
up-to-date and comprehensive survey on AI technologies used for talent
analytics in the field of human resource management. Specifically, we first
provide the background knowledge of talent analytics and categorize various
pertinent data. Subsequently, we offer a comprehensive taxonomy of relevant
research efforts, categorized based on three distinct application-driven
scenarios: talent management, organization management, and labor market
analysis. In conclusion, we summarize the open challenges and potential
prospects for future research directions in the domain of AI-driven talent
analytics.",2023-07-03,2023,2023-07,environment
ScriptWorld: Text Based Environment For Learning Procedural Knowledge,"Text-based games provide a framework for developing natural language
understanding and commonsense knowledge about the world in reinforcement
learning based agents. Existing text-based environments often rely on fictional
situations and characters to create a gaming framework and are far from
real-world scenarios. In this paper, we introduce ScriptWorld: a text-based
environment for teaching agents about real-world daily chores and hence
imparting commonsense knowledge. To the best of our knowledge, it is the first
interactive text-based gaming framework that consists of daily real-world human
activities designed using scripts dataset. We provide gaming environments for
10 daily activities and perform a detailed analysis of the proposed
environment. We develop RL-based baseline models/agents to play the games in
Scriptworld. To understand the role of language models in such environments, we
leverage features obtained from pre-trained language models in the RL agents.
Our experiments show that prior knowledge obtained from a pre-trained language
model helps to solve real-world text-based gaming environments. We release the
environment via Github: https://github.com/Exploration-Lab/ScriptWorld",2023-07-08,2023,2023-07,environment
"VELMA: Verbalization Embodiment of LLM Agents for Vision and Language
  Navigation in Street View","Incremental decision making in real-world environments is one of the most
challenging tasks in embodied artificial intelligence. One particularly
demanding scenario is Vision and Language Navigation~(VLN) which requires
visual and natural language understanding as well as spatial and temporal
reasoning capabilities. The embodied agent needs to ground its understanding of
navigation instructions in observations of a real-world environment like Street
View. Despite the impressive results of LLMs in other research areas, it is an
ongoing problem of how to best connect them with an interactive visual
environment. In this work, we propose VELMA, an embodied LLM agent that uses a
verbalization of the trajectory and of visual environment observations as
contextual prompt for the next action. Visual information is verbalized by a
pipeline that extracts landmarks from the human written navigation instructions
and uses CLIP to determine their visibility in the current panorama view. We
show that VELMA is able to successfully follow navigation instructions in
Street View with only two in-context examples. We further finetune the LLM
agent on a few thousand examples and achieve 25%-30% relative improvement in
task completion over the previous state-of-the-art for two datasets.",2023-07-12,2023,2023-07,environment
"Explainable Artificial Intelligence driven mask design for
  self-supervised seismic denoising","The presence of coherent noise in seismic data leads to errors and
uncertainties, and as such it is paramount to suppress noise as early and
efficiently as possible. Self-supervised denoising circumvents the common
requirement of deep learning procedures of having noisy-clean training pairs.
However, self-supervised coherent noise suppression methods require extensive
knowledge of the noise statistics. We propose the use of explainable artificial
intelligence approaches to see inside the black box that is the denoising
network and use the gained knowledge to replace the need for any prior
knowledge of the noise itself. This is achieved in practice by leveraging
bias-free networks and the direct linear link between input and output provided
by the associated Jacobian matrix; we show that a simple averaging of the
Jacobian contributions over a number of randomly selected input pixels,
provides an indication of the most effective mask to suppress noise present in
the data. The proposed method therefore becomes a fully automated denoising
procedure requiring no clean training labels or prior knowledge. Realistic
synthetic examples with noise signals of varying complexities, ranging from
simple time-correlated noise to complex pseudo rig noise propagating at the
velocity of the ocean, are used to validate the proposed approach. Its
automated nature is highlighted further by an application to two field
datasets. Without any substantial pre-processing or any knowledge of the
acquisition environment, the automatically identified blind-masks are shown to
perform well in suppressing both trace-wise noise in common shot gathers from
the Volve marine dataset and colored noise in post stack seismic images from a
land seismic survey.",2023-07-13,2023,2023-07,environment
GridMM: Grid Memory Map for Vision-and-Language Navigation,"Vision-and-language navigation (VLN) enables the agent to navigate to a
remote location following the natural language instruction in 3D environments.
To represent the previously visited environment, most approaches for VLN
implement memory using recurrent states, topological maps, or top-down semantic
maps. In contrast to these approaches, we build the top-down egocentric and
dynamically growing Grid Memory Map (i.e., GridMM) to structure the visited
environment. From a global perspective, historical observations are projected
into a unified grid map in a top-down view, which can better represent the
spatial relations of the environment. From a local perspective, we further
propose an instruction relevance aggregation method to capture fine-grained
visual clues in each grid region. Extensive experiments are conducted on both
the REVERIE, R2R, SOON datasets in the discrete environments, and the R2R-CE
dataset in the continuous environments, showing the superiority of our proposed
method.",2023-07-24,2023,2023-07,environment
"Pixel to policy: DQN Encoders for within & cross-game reinforcement
  learning","Reinforcement Learning can be applied to various tasks, and environments.
Many of these environments have a similar shared structure, which can be
exploited to improve RL performance on other tasks. Transfer learning can be
used to take advantage of this shared structure, by learning policies that are
transferable across different tasks and environments and can lead to more
efficient learning as well as improved performance on a wide range of tasks.
This work explores as well as compares the performance between RL models being
trained from the scratch and on different approaches of transfer learning.
Additionally, the study explores the performance of a model trained on multiple
game environments, with the goal of developing a universal game-playing agent
as well as transfer learning a pre-trained encoder using DQN, and training it
on the same game or a different game. Our DQN model achieves a mean episode
reward of 46.16 which even beats the human-level performance with merely 20k
episodes which is significantly lower than deepmind's 1M episodes. The achieved
mean rewards of 533.42 and 402.17 on the Assault and Space Invader environments
respectively, represent noteworthy performance on these challenging
environments.",2023-08-01,2023,2023-08,environment
"From Military to Healthcare: Adopting and Expanding Ethical Principles
  for Generative Artificial Intelligence","In 2020, the U.S. Department of Defense officially disclosed a set of ethical
principles to guide the use of Artificial Intelligence (AI) technologies on
future battlefields. Despite stark differences, there are core similarities
between the military and medical service. Warriors on battlefields often face
life-altering circumstances that require quick decision-making. Medical
providers experience similar challenges in a rapidly changing healthcare
environment, such as in the emergency department or during surgery treating a
life-threatening condition. Generative AI, an emerging technology designed to
efficiently generate valuable information, holds great promise. As computing
power becomes more accessible and the abundance of health data, such as
electronic health records, electrocardiograms, and medical images, increases,
it is inevitable that healthcare will be revolutionized by this technology.
Recently, generative AI has captivated the research community, leading to
debates about its application in healthcare, mainly due to concerns about
transparency and related issues. Meanwhile, concerns about the potential
exacerbation of health disparities due to modeling biases have raised notable
ethical concerns regarding the use of this technology in healthcare. However,
the ethical principles for generative AI in healthcare have been understudied,
and decision-makers often fail to consider the significance of generative AI.
In this paper, we propose GREAT PLEA ethical principles, encompassing
governance, reliability, equity, accountability, traceability, privacy,
lawfulness, empathy, and autonomy, for generative AI in healthcare. We aim to
proactively address the ethical dilemmas and challenges posed by the
integration of generative AI in healthcare.",2023-08-04,2023,2023-08,environment
"Physics-Based Task Generation through Causal Sequence of Physical
  Interactions","Performing tasks in a physical environment is a crucial yet challenging
problem for AI systems operating in the real world. Physics simulation-based
tasks are often employed to facilitate research that addresses this challenge.
In this paper, first, we present a systematic approach for defining a physical
scenario using a causal sequence of physical interactions between objects.
Then, we propose a methodology for generating tasks in a physics-simulating
environment using these defined scenarios as inputs. Our approach enables a
better understanding of the granular mechanics required for solving
physics-based tasks, thereby facilitating accurate evaluation of AI systems'
physical reasoning capabilities. We demonstrate our proposed task generation
methodology using the physics-based puzzle game Angry Birds and evaluate the
generated tasks using a range of metrics, including physical stability,
solvability using intended physical interactions, and accidental solvability
using unintended solutions. We believe that the tasks generated using our
proposed methodology can facilitate a nuanced evaluation of physical reasoning
agents, thus paving the way for the development of agents for more
sophisticated real-world applications.",2023-08-05,2023,2023-08,environment
"Dialogue Possibilities between a Human Supervisor and UAM Air Traffic
  Management: Route Alteration","This paper introduces a novel approach to detour management in Urban Air
Traffic Management (UATM) using knowledge representation and reasoning. It aims
to understand the complexities and requirements of UAM detours, enabling a
method that quickly identifies safe and efficient routes in a carefully sampled
environment. This method implemented in Answer Set Programming uses
non-monotonic reasoning and a two-phase conversation between a human manager
and the UATM system, considering factors like safety and potential impacts. The
robustness and efficacy of the proposed method were validated through several
queries from two simulation scenarios, contributing to the symbiosis of human
knowledge and advanced AI techniques. The paper provides an introduction,
citing relevant studies, problem formulation, solution, discussions, and
concluding comments.",2023-08-11,2023,2023-08,environment
"AI planning in the imagination: High-level planning on learned abstract
  search spaces","Search and planning algorithms have been a cornerstone of artificial
intelligence since the field's inception. Giving reinforcement learning agents
the ability to plan during execution time has resulted in significant
performance improvements in various domains. However, in real-world
environments, the model with respect to which the agent plans has been
constrained to be grounded in the real environment itself, as opposed to a more
abstract model which allows for planning over compound actions and behaviors.
We propose a new method, called PiZero, that gives an agent the ability to plan
in an abstract search space that the agent learns during training, which is
completely decoupled from the real environment. Unlike prior approaches, this
enables the agent to perform high-level planning at arbitrary timescales and
reason in terms of compound or temporally-extended actions, which can be useful
in environments where large numbers of base-level micro-actions are needed to
perform relevant macro-actions. In addition, our method is more general than
comparable prior methods because it seamlessly handles settings with continuous
action spaces, combinatorial action spaces, and partial observability. We
evaluate our method on multiple domains, including the traveling salesman
problem, Sokoban, 2048, the facility location problem, and Pacman.
Experimentally, it outperforms comparable prior methods without assuming access
to an environment simulator at execution time.",2023-08-16,2023,2023-08,environment
"A Robust Policy Bootstrapping Algorithm for Multi-objective
  Reinforcement Learning in Non-stationary Environments","Multi-objective Markov decision processes are a special kind of
multi-objective optimization problem that involves sequential decision making
while satisfying the Markov property of stochastic processes. Multi-objective
reinforcement learning methods address this problem by fusing the reinforcement
learning paradigm with multi-objective optimization techniques. One major
drawback of these methods is the lack of adaptability to non-stationary
dynamics in the environment. This is because they adopt optimization procedures
that assume stationarity to evolve a coverage set of policies that can solve
the problem. This paper introduces a developmental optimization approach that
can evolve the policy coverage set while exploring the preference space over
the defined objectives in an online manner. We propose a novel multi-objective
reinforcement learning algorithm that can robustly evolve a convex coverage set
of policies in an online manner in non-stationary environments. We compare the
proposed algorithm with two state-of-the-art multi-objective reinforcement
learning algorithms in stationary and non-stationary environments. Results
showed that the proposed algorithm significantly outperforms the existing
algorithms in non-stationary environments while achieving comparable results in
stationary environments.",2023-08-18,2023,2023-08,environment
Model-based Offline Policy Optimization with Adversarial Network,"Model-based offline reinforcement learning (RL), which builds a supervised
transition model with logging dataset to avoid costly interactions with the
online environment, has been a promising approach for offline policy
optimization. As the discrepancy between the logging data and online
environment may result in a distributional shift problem, many prior works have
studied how to build robust transition models conservatively and estimate the
model uncertainty accurately. However, the over-conservatism can limit the
exploration of the agent, and the uncertainty estimates may be unreliable. In
this work, we propose a novel Model-based Offline policy optimization framework
with Adversarial Network (MOAN). The key idea is to use adversarial learning to
build a transition model with better generalization, where an adversary is
introduced to distinguish between in-distribution and out-of-distribution
samples. Moreover, the adversary can naturally provide a quantification of the
model's uncertainty with theoretical guarantees. Extensive experiments showed
that our approach outperforms existing state-of-the-art baselines on widely
studied offline RL benchmarks. It can also generate diverse in-distribution
samples, and quantify the uncertainty more accurately.",2023-09-05,2023,2023-09,environment
"Neurosymbolic Meta-Reinforcement Lookahead Learning Achieves Safe
  Self-Driving in Non-Stationary Environments","In the area of learning-driven artificial intelligence advancement, the
integration of machine learning (ML) into self-driving (SD) technology stands
as an impressive engineering feat. Yet, in real-world applications outside the
confines of controlled laboratory scenarios, the deployment of self-driving
technology assumes a life-critical role, necessitating heightened attention
from researchers towards both safety and efficiency. To illustrate, when a
self-driving model encounters an unfamiliar environment in real-time execution,
the focus must not solely revolve around enhancing its anticipated performance;
equal consideration must be given to ensuring its execution or real-time
adaptation maintains a requisite level of safety. This study introduces an
algorithm for online meta-reinforcement learning, employing lookahead symbolic
constraints based on \emph{Neurosymbolic Meta-Reinforcement Lookahead Learning}
(NUMERLA). NUMERLA proposes a lookahead updating mechanism that harmonizes the
efficiency of online adaptations with the overarching goal of ensuring
long-term safety. Experimental results demonstrate NUMERLA confers the
self-driving agent with the capacity for real-time adaptability, leading to
safe and self-adaptive driving under non-stationary urban human-vehicle
interaction scenarios.",2023-09-05,2023,2023-09,environment
"Quantum-AI empowered Intelligent Surveillance: Advancing Public Safety
  Through Innovative Contraband Detection","Surveillance systems have emerged as crucial elements in upholding peace and
security in the modern world. Their ubiquity aids in monitoring suspicious
activities effectively. However, in densely populated environments, continuous
active monitoring becomes impractical, necessitating the development of
intelligent surveillance systems. AI integration in the surveillance domain was
a big revolution, however, speed issues have prevented its widespread
implementation in the field. It has been observed that quantum artificial
intelligence has led to a great breakthrough. Quantum artificial
intelligence-based surveillance systems have shown to be more accurate as well
as capable of performing well in real-time scenarios, which had never been seen
before. In this research, a RentinaNet model is integrated with Quantum CNN and
termed as Quantum-RetinaNet. By harnessing the Quantum capabilities of QCNN,
Quantum-RetinaNet strikes a balance between accuracy and speed. This innovative
integration positions it as a game-changer, addressing the challenges of active
monitoring in densely populated scenarios. As demand for efficient surveillance
solutions continues to grow, Quantum-RetinaNet offers a compelling alternative
to existing CNN models, upholding accuracy standards without sacrificing
real-time performance. The unique attributes of Quantum-RetinaNet have
far-reaching implications for the future of intelligent surveillance. With its
enhanced processing speed, it is poised to revolutionize the field, catering to
the pressing need for rapid yet precise monitoring. As Quantum-RetinaNet
becomes the new standard, it ensures public safety and security while pushing
the boundaries of AI in surveillance.",2023-09-05,2023,2023-09,environment
"Advanced Computing and Related Applications Leveraging Brain-inspired
  Spiking Neural Networks","In the rapid evolution of next-generation brain-inspired artificial
intelligence and increasingly sophisticated electromagnetic environment, the
most bionic characteristics and anti-interference performance of spiking neural
networks show great potential in terms of computational speed, real-time
information processing, and spatio-temporal information processing. Data
processing. Spiking neural network is one of the cores of brain-like artificial
intelligence, which realizes brain-like computing by simulating the structure
and information transfer mode of biological neural networks. This paper
summarizes the strengths, weaknesses and applicability of five neuronal models
and analyzes the characteristics of five network topologies; then reviews the
spiking neural network algorithms and summarizes the unsupervised learning
algorithms based on synaptic plasticity rules and four types of supervised
learning algorithms from the perspectives of unsupervised learning and
supervised learning; finally focuses on the review of brain-like neuromorphic
chips under research at home and abroad. This paper is intended to provide
learning concepts and research orientations for the peers who are new to the
research field of spiking neural networks through systematic summaries.",2023-09-08,2023,2023-09,environment
Representation Learning in Low-rank Slate-based Recommender Systems,"Reinforcement learning (RL) in recommendation systems offers the potential to
optimize recommendations for long-term user engagement. However, the
environment often involves large state and action spaces, which makes it hard
to efficiently learn and explore. In this work, we propose a sample-efficient
representation learning algorithm, using the standard slate recommendation
setup, to treat this as an online RL problem with low-rank Markov decision
processes (MDPs). We also construct the recommender simulation environment with
the proposed setup and sampling method.",2023-09-10,2023,2023-09,environment
"Adaptive User-centered Neuro-symbolic Learning for Multimodal
  Interaction with Autonomous Systems","Recent advances in machine learning, particularly deep learning, have enabled
autonomous systems to perceive and comprehend objects and their environments in
a perceptual subsymbolic manner. These systems can now perform object
detection, sensor data fusion, and language understanding tasks. However, there
is a growing need to enhance these systems to understand objects and their
environments more conceptually and symbolically. It is essential to consider
both the explicit teaching provided by humans (e.g., describing a situation or
explaining how to act) and the implicit teaching obtained by observing human
behavior (e.g., through the system's sensors) to achieve this level of powerful
artificial intelligence. Thus, the system must be designed with multimodal
input and output capabilities to support implicit and explicit interaction
models. In this position paper, we argue for considering both types of inputs,
as well as human-in-the-loop and incremental learning techniques, for advancing
the field of artificial intelligence and enabling autonomous systems to learn
like humans. We propose several hypotheses and design guidelines and highlight
a use case from related work to achieve this goal.",2023-09-11,2023,2023-09,environment
"Life-inspired Interoceptive Artificial Intelligence for Autonomous and
  Adaptive Agents","Building autonomous -- i.e., choosing goals based on one's needs -- and
adaptive -- i.e., surviving in ever-changing environments -- agents has been a
holy grail of artificial intelligence (AI). A living organism is a prime
example of such an agent, offering important lessons about adaptive autonomy.
Here, we focus on interoception, a process of monitoring one's internal
environment to keep it within certain bounds, which underwrites the survival of
an organism. To develop AI with interoception, we need to factorize the state
variables representing internal environments from external environments and
adopt life-inspired mathematical properties of internal environment states.
This paper offers a new perspective on how interoception can help build
autonomous and adaptive agents by integrating the legacy of cybernetics with
recent advances in theories of life, reinforcement learning, and neuroscience.",2023-09-12,2023,2023-09,environment
"Self-Sustaining Multiple Access with Continual Deep Reinforcement
  Learning for Dynamic Metaverse Applications","The Metaverse is a new paradigm that aims to create a virtual environment
consisting of numerous worlds, each of which will offer a different set of
services. To deal with such a dynamic and complex scenario, considering the
stringent quality of service requirements aimed at the 6th generation of
communication systems (6G), one potential approach is to adopt self-sustaining
strategies, which can be realized by employing Adaptive Artificial Intelligence
(Adaptive AI) where models are continually re-trained with new data and
conditions. One aspect of self-sustainability is the management of multiple
access to the frequency spectrum. Although several innovative methods have been
proposed to address this challenge, mostly using Deep Reinforcement Learning
(DRL), the problem of adapting agents to a non-stationary environment has not
yet been precisely addressed. This paper fills in the gap in the current
literature by investigating the problem of multiple access in multi-channel
environments to maximize the throughput of the intelligent agent when the
number of active User Equipments (UEs) may fluctuate over time. To solve the
problem, a Double Deep Q-Learning (DDQL) technique empowered by Continual
Learning (CL) is proposed to overcome the non-stationary situation, while the
environment is unknown. Numerical simulations demonstrate that, compared to
other well-known methods, the CL-DDQL algorithm achieves significantly higher
throughputs with a considerably shorter convergence time in highly dynamic
scenarios.",2023-09-18,2023,2023-09,environment
Context is Environment,"Two lines of work are taking the central stage in AI research. On the one
hand, the community is making increasing efforts to build models that discard
spurious correlations and generalize better in novel test environments.
Unfortunately, the bitter lesson so far is that no proposal convincingly
outperforms a simple empirical risk minimization baseline. On the other hand,
large language models (LLMs) have erupted as algorithms able to learn
in-context, generalizing on-the-fly to eclectic contextual circumstances that
users enforce by means of prompting. In this paper, we argue that context is
environment, and posit that in-context learning holds the key to better domain
generalization. Via extensive theory and experiments, we show that paying
attention to context$\unicode{x2013}\unicode{x2013}$unlabeled examples as they
arrive$\unicode{x2013}\unicode{x2013}$allows our proposed In-Context Risk
Minimization (ICRM) algorithm to zoom-in on the test environment risk
minimizer, leading to significant out-of-distribution performance improvements.
From all of this, two messages are worth taking home. Researchers in domain
generalization should consider environment as context, and harness the adaptive
power of in-context learning. Researchers in LLMs should consider context as
environment, to better structure data towards generalization.",2023-09-18,2023,2023-09,environment
"Privacy Preservation in Artificial Intelligence and Extended Reality
  (AI-XR) Metaverses: A Survey","The metaverse is a nascent concept that envisions a virtual universe, a
collaborative space where individuals can interact, create, and participate in
a wide range of activities. Privacy in the metaverse is a critical concern as
the concept evolves and immersive virtual experiences become more prevalent.
The metaverse privacy problem refers to the challenges and concerns surrounding
the privacy of personal information and data within Virtual Reality (VR)
environments as the concept of a shared VR space becomes more accessible.
Metaverse will harness advancements from various technologies such as
Artificial Intelligence (AI), Extended Reality (XR), Mixed Reality (MR), and
5G/6G-based communication to provide personalized and immersive services to its
users. Moreover, to enable more personalized experiences, the metaverse relies
on the collection of fine-grained user data that leads to various privacy
issues. Therefore, before the potential of the metaverse can be fully realized,
privacy concerns related to personal information and data within VR
environments must be addressed. This includes safeguarding users' control over
their data, ensuring the security of their personal information, and protecting
in-world actions and interactions from unauthorized sharing. In this paper, we
explore various privacy challenges that future metaverses are expected to face,
given their reliance on AI for tracking users, creating XR and MR experiences,
and facilitating interactions. Moreover, we thoroughly analyze technical
solutions such as differential privacy, Homomorphic Encryption (HE), and
Federated Learning (FL) and discuss related sociotechnical issues regarding
privacy.",2023-09-19,2023,2023-09,environment
"Curriculum Reinforcement Learning via Morphology-Environment
  Co-Evolution","Throughout long history, natural species have learned to survive by evolving
their physical structures adaptive to the environment changes. In contrast,
current reinforcement learning (RL) studies mainly focus on training an agent
with a fixed morphology (e.g., skeletal structure and joint attributes) in a
fixed environment, which can hardly generalize to changing environments or new
tasks. In this paper, we optimize an RL agent and its morphology through
``morphology-environment co-evolution (MECE)'', in which the morphology keeps
being updated to adapt to the changing environment, while the environment is
modified progressively to bring new challenges and stimulate the improvement of
the morphology. This leads to a curriculum to train generalizable RL, whose
morphology and policy are optimized for different environments. Instead of
hand-crafting the curriculum, we train two policies to automatically change the
morphology and the environment. To this end, (1) we develop two novel and
effective rewards for the two policies, which are solely based on the learning
dynamics of the RL agent; (2) we design a scheduler to automatically determine
when to change the environment and the morphology. In experiments on two
classes of tasks, the morphology and RL policies trained via MECE exhibit
significantly better generalization performance in unseen test environments
than SOTA morphology optimization methods. Our ablation studies on the two MECE
policies further show that the co-evolution between the morphology and
environment is the key to the success.",2023-09-21,2023,2023-09,environment
"Enhancing Graph Representation of the Environment through Local and
  Cloud Computation","Enriching the robot representation of the operational environment is a
challenging task that aims at bridging the gap between low-level sensor
readings and high-level semantic understanding. Having a rich representation
often requires computationally demanding architectures and pure point cloud
based detection systems that struggle when dealing with everyday objects that
have to be handled by the robot. To overcome these issues, we propose a
graph-based representation that addresses this gap by providing a semantic
representation of robot environments from multiple sources. In fact, to acquire
information from the environment, the framework combines classical computer
vision tools with modern computer vision cloud services, ensuring computational
feasibility on onboard hardware. By incorporating an ontology hierarchy with
over 800 object classes, the framework achieves cross-domain adaptability,
eliminating the need for environment-specific tools. The proposed approach
allows us to handle also small objects and integrate them into the semantic
representation of the environment. The approach is implemented in the Robot
Operating System (ROS) using the RViz visualizer for environment
representation. This work is a first step towards the development of a
general-purpose framework, to facilitate intuitive interaction and navigation
across different domains.",2023-09-22,2023,2023-09,environment
"Intent-Aware Autonomous Driving: A Case Study on Highway Merging
  Scenarios","In this work, we use the communication of intent as a means to facilitate
cooperation between autonomous vehicle agents. Generally speaking, intents can
be any reliable information about its future behavior that a vehicle
communicates with another vehicle. We implement this as an intent-sharing task
atop the merging environment in the simulator of highway-env, which provides a
collection of environments for learning decision-making strategies for
autonomous vehicles. Under a simple setting between two agents, we carefully
investigate how intent-sharing can aid the receiving vehicle in adjusting its
behavior in highway merging scenarios.",2023-09-22,2023,2023-09,environment
CoinRun: Solving Goal Misgeneralisation,"Goal misgeneralisation is a key challenge in AI alignment -- the task of
getting powerful Artificial Intelligences to align their goals with human
intentions and human morality. In this paper, we show how the ACE (Algorithm
for Concept Extrapolation) agent can solve one of the key standard challenges
in goal misgeneralisation: the CoinRun challenge. It uses no new reward
information in the new environment. This points to how autonomous agents could
be trusted to act in human interests, even in novel and critical situations.",2023-09-28,2023,2023-09,environment
"Uncertainty-Aware Decision Transformer for Stochastic Driving
  Environments","Offline Reinforcement Learning (RL) enables policy learning without active
interactions, making it especially appealing for self-driving tasks. Recent
successes of Transformers inspire casting offline RL as sequence modeling,
which, however, fails in stochastic environments with incorrect assumptions
that identical actions can consistently achieve the same goal. In this paper,
we introduce an UNcertainty-awaRE deciSion Transformer (UNREST) for planning in
stochastic driving environments without introducing additional transition or
complex generative models. Specifically, UNREST estimates uncertainties by
conditional mutual information between transitions and returns. Discovering
'uncertainty accumulation' and 'temporal locality' properties of driving
environments, we replace the global returns in decision transformers with
truncated returns less affected by environments to learn from actual outcomes
of actions rather than environment transitions. We also dynamically evaluate
uncertainty at inference for cautious planning. Extensive experiments
demonstrate UNREST's superior performance in various driving scenarios and the
power of our uncertainty estimation strategy.",2023-09-28,2023,2023-09,environment
Discovering environments with XRM,"Environment annotations are essential for the success of many
out-of-distribution (OOD) generalization methods. Unfortunately, these are
costly to obtain and often limited by human annotators' biases. To achieve
robust generalization, it is essential to develop algorithms for automatic
environment discovery within datasets. Current proposals, which divide examples
based on their training error, suffer from one fundamental problem. These
methods introduce hyper-parameters and early-stopping criteria, which require a
validation set with human-annotated environments, the very information subject
to discovery. In this paper, we propose Cross-Risk-Minimization (XRM) to
address this issue. XRM trains twin networks, each learning from one random
half of the training data, while imitating confident held-out mistakes made by
its sibling. XRM provides a recipe for hyper-parameter tuning, does not require
early-stopping, and can discover environments for all training and validation
data. Algorithms built on top of XRM environments achieve oracle
worst-group-accuracy, addressing a long-standing challenge in OOD
generalization. Code available at
\url{https://github.com/facebookresearch/XRM}.",2023-09-28,2023,2023-09,environment
"Enhancing the Hierarchical Environment Design via Generative Trajectory
  Modeling","Unsupervised Environment Design (UED) is a paradigm for automatically
generating a curriculum of training environments, enabling agents trained in
these environments to develop general capabilities, i.e., achieving good
zero-shot transfer performance. However, existing UED approaches focus
primarily on the random generation of environments for open-ended agent
training. This is impractical in scenarios with limited resources, such as the
constraints on the number of generated environments. In this paper, we
introduce a hierarchical MDP framework for environment design under resource
constraints. It consists of an upper-level RL teacher agent that generates
suitable training environments for a lower-level student agent. The RL teacher
can leverage previously discovered environment structures and generate
environments at the frontier of the student's capabilities by observing the
student policy's representation. Moreover, to reduce the time-consuming
collection of experiences for the upper-level teacher, we utilize recent
advances in generative modeling to synthesize a trajectory dataset to train the
teacher agent. Our proposed method significantly reduces the resource-intensive
interactions between agents and environments and empirical experiments across
various domains demonstrate the effectiveness of our approach.",2023-09-30,2023,2023-09,environment
"A Review of Digital Learning Environments for Teaching Natural Language
  Processing in K-12 Education","Natural Language Processing (NLP) plays a significant role in our daily lives
and has become an essential part of Artificial Intelligence (AI) education in
K-12. As children grow up with NLP-powered applications, it is crucial to
introduce NLP concepts to them, fostering their understanding of language
processing, language generation, and ethical implications of AI and NLP. This
paper presents a comprehensive review of digital learning environments for
teaching NLP in K-12. Specifically, it explores existing digital learning
tools, discusses how they support specific NLP tasks and procedures, and
investigates their explainability and evaluation results in educational
contexts. By examining the strengths and limitations of these tools, this
literature review sheds light on the current state of NLP learning tools in
K-12 education. It aims to guide future research efforts to refine existing
tools, develop new ones, and explore more effective and inclusive strategies
for integrating NLP into K-12 educational contexts.",2023-10-02,2023,2023-10,environment
Balancing utility and cognitive cost in social representation,"To successfully navigate its environment, an agent must construct and
maintain representations of the other agents that it encounters. Such
representations are useful for many tasks, but they are not without cost. As a
result, agents must make decisions regarding how much information they choose
to store about the agents in their environment. Using selective social learning
as an example task, we motivate the problem of finding agent representations
that optimally trade off between downstream utility and information cost, and
illustrate two example approaches to resource-constrained social
representation.",2023-10-07,2023,2023-10,environment
Measuring Acoustics with Collaborative Multiple Agents,"As humans, we hear sound every second of our life. The sound we hear is often
affected by the acoustics of the environment surrounding us. For example, a
spacious hall leads to more reverberation. Room Impulse Responses (RIR) are
commonly used to characterize environment acoustics as a function of the scene
geometry, materials, and source/receiver locations. Traditionally, RIRs are
measured by setting up a loudspeaker and microphone in the environment for all
source/receiver locations, which is time-consuming and inefficient. We propose
to let two robots measure the environment's acoustics by actively moving and
emitting/receiving sweep signals. We also devise a collaborative multi-agent
policy where these two robots are trained to explore the environment's
acoustics while being rewarded for wide exploration and accurate prediction. We
show that the robots learn to collaborate and move to explore environment
acoustics while minimizing the prediction error. To the best of our knowledge,
we present the very first problem formulation and solution to the task of
collaborative environment acoustics measurements with multiple agents.",2023-10-09,2023,2023-10,environment
"Advancing Perception in Artificial Intelligence through Principles of
  Cognitive Science","Although artificial intelligence (AI) has achieved many feats at a rapid
pace, there still exist open problems and fundamental shortcomings related to
performance and resource efficiency. Since AI researchers benchmark a
significant proportion of performance standards through human intelligence,
cognitive sciences-inspired AI is a promising domain of research. Studying
cognitive science can provide a fresh perspective to building fundamental
blocks in AI research, which can lead to improved performance and efficiency.
In this review paper, we focus on the cognitive functions of perception, which
is the process of taking signals from one's surroundings as input, and
processing them to understand the environment. Particularly, we study and
compare its various processes through the lens of both cognitive sciences and
AI. Through this study, we review all current major theories from various
sub-disciplines of cognitive science (specifically neuroscience, psychology and
linguistics), and draw parallels with theories and techniques from current
practices in AI. We, hence, present a detailed collection of methods in AI for
researchers to build AI systems inspired by cognitive science. Further, through
the process of reviewing the state of cognitive-inspired AI, we point out many
gaps in the current state of AI (with respect to the performance of the human
brain), and hence present potential directions for researchers to develop
better perception systems in AI.",2023-10-13,2023,2023-10,environment
"Large Language Model Prediction Capabilities: Evidence from a Real-World
  Forecasting Tournament","Accurately predicting the future would be an important milestone in the
capabilities of artificial intelligence. However, research on the ability of
large language models to provide probabilistic predictions about future events
remains nascent. To empirically test this ability, we enrolled OpenAI's
state-of-the-art large language model, GPT-4, in a three-month forecasting
tournament hosted on the Metaculus platform. The tournament, running from July
to October 2023, attracted 843 participants and covered diverse topics
including Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict.
Focusing on binary forecasts, we show that GPT-4's probabilistic forecasts are
significantly less accurate than the median human-crowd forecasts. We find that
GPT-4's forecasts did not significantly differ from the no-information
forecasting strategy of assigning a 50% probability to every question. We
explore a potential explanation, that GPT-4 might be predisposed to predict
probabilities close to the midpoint of the scale, but our data do not support
this hypothesis. Overall, we find that GPT-4 significantly underperforms in
real-world predictive tasks compared to median human-crowd forecasts. A
potential explanation for this underperformance is that in real-world
forecasting tournaments, the true answers are genuinely unknown at the time of
prediction; unlike in other benchmark tasks like professional exams or time
series forecasting, where strong performance may at least partly be due to the
answers being memorized from the training data. This makes real-world
forecasting tournaments an ideal environment for testing the generalized
reasoning and prediction capabilities of artificial intelligence going forward.",2023-10-17,2023,2023-10,environment
"SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor
  Environment","This paper presents an adaptive transformer model named SegmATRon for
embodied image semantic segmentation. Its distinctive feature is the adaptation
of model weights during inference on several images using a hybrid
multicomponent loss function. We studied this model on datasets collected in
the photorealistic Habitat and the synthetic AI2-THOR Simulators. We showed
that obtaining additional images using the agent's actions in an indoor
environment can improve the quality of semantic segmentation. The code of the
proposed approach and datasets are publicly available at
https://github.com/wingrune/SegmATRon.",2023-10-18,2023,2023-10,environment
"Autonomous 3D Exploration in Large-Scale Environments with Dynamic
  Obstacles","Exploration in dynamic and uncertain real-world environments is an open
problem in robotics and constitutes a foundational capability of autonomous
systems operating in most of the real world. While 3D exploration planning has
been extensively studied, the environments are assumed static or only reactive
collision avoidance is carried out. We propose a novel approach to not only
avoid dynamic obstacles but also include them in the plan itself, to exploit
the dynamic environment in the agent's favor. The proposed planner, Dynamic
Autonomous Exploration Planner (DAEP), extends AEP to explicitly plan with
respect to dynamic obstacles. To thoroughly evaluate exploration planners in
such settings we propose a new enhanced benchmark suite with several dynamic
environments, including large-scale outdoor environments. DAEP outperform
state-of-the-art planners in dynamic and large-scale environments. DAEP is
shown to be more effective at both exploration and collision avoidance.",2023-10-27,2023,2023-10,environment
Arbitrarily Scalable Environment Generators via Neural Cellular Automata,"We study the problem of generating arbitrarily large environments to improve
the throughput of multi-robot systems. Prior work proposes Quality Diversity
(QD) algorithms as an effective method for optimizing the environments of
automated warehouses. However, these approaches optimize only relatively small
environments, falling short when it comes to replicating real-world warehouse
sizes. The challenge arises from the exponential increase in the search space
as the environment size increases. Additionally, the previous methods have only
been tested with up to 350 robots in simulations, while practical warehouses
could host thousands of robots. In this paper, instead of optimizing
environments, we propose to optimize Neural Cellular Automata (NCA) environment
generators via QD algorithms. We train a collection of NCA generators with QD
algorithms in small environments and then generate arbitrarily large
environments from the generators at test time. We show that NCA environment
generators maintain consistent, regularized patterns regardless of environment
size, significantly enhancing the scalability of multi-robot systems in two
different domains with up to 2,350 robots. Additionally, we demonstrate that
our method scales a single-agent reinforcement learning policy to arbitrarily
large environments with similar patterns. We include the source code at
\url{https://github.com/lunjohnzhang/warehouse_env_gen_nca_public}.",2023-10-28,2023,2023-10,environment
"Artificial Intelligence for reverse engineering: application to
  detergents using Raman spectroscopy","The reverse engineering of a complex mixture, regardless of its nature, has
become significant today. Being able to quickly assess the potential toxicity
of new commercial products in relation to the environment presents a genuine
analytical challenge. The development of digital tools (databases,
chemometrics, machine learning, etc.) and analytical techniques (Raman
spectroscopy, NIR spectroscopy, mass spectrometry, etc.) will allow for the
identification of potential toxic molecules. In this article, we use the
example of detergent products, whose composition can prove dangerous to humans
or the environment, necessitating precise identification and quantification for
quality control and regulation purposes. The combination of various digital
tools (spectral database, mixture database, experimental design, Chemometrics /
Machine Learning algorithm{\ldots}) together with different sample preparation
methods (raw sample, or several concentrated / diluted samples) Raman
spectroscopy, has enabled the identification of the mixture's constituents and
an estimation of its composition. Implementing such strategies across different
analytical tools can result in time savings for pollutant identification and
contamination assessment in various matrices. This strategy is also applicable
in the industrial sector for product or raw material control, as well as for
quality control purposes.",2023-10-31,2023,2023-10,environment
"Enhanced Generalization through Prioritization and Diversity in
  Self-Imitation Reinforcement Learning over Procedural Environments with
  Sparse Rewards","Exploration poses a fundamental challenge in Reinforcement Learning (RL) with
sparse rewards, limiting an agent's ability to learn optimal decision-making
due to a lack of informative feedback signals. Self-Imitation Learning
(self-IL) has emerged as a promising approach for exploration, leveraging a
replay buffer to store and reproduce successful behaviors. However, traditional
self-IL methods, which rely on high-return transitions and assume singleton
environments, face challenges in generalization, especially in
procedurally-generated (PCG) environments. Therefore, new self-IL methods have
been proposed to rank which experiences to persist, but they replay transitions
uniformly regardless of their significance, and do not address the diversity of
the stored demonstrations. In this work, we propose tailored self-IL sampling
strategies by prioritizing transitions in different ways and extending
prioritization techniques to PCG environments. We also address diversity loss
through modifications to counteract the impact of generalization requirements
and bias introduced by prioritization techniques. Our experimental analysis,
conducted over three PCG sparse reward environments, including MiniGrid and
ProcGen, highlights the benefits of our proposed modifications, achieving a new
state-of-the-art performance in the MiniGrid-MultiRoom-N12-S10 environment.",2023-11-01,2023,2023-11,environment
"Decoding EEG-based Workload Levels Using Spatio-temporal Features Under
  Flight Environment","The detection of pilots' mental states is important due to the potential for
their abnormal mental states to result in catastrophic accidents. This study
introduces the feasibility of employing deep learning techniques to classify
different workload levels, specifically normal state, low workload, and high
workload. To the best of our knowledge, this study is the first attempt to
classify workload levels of pilots. Our approach involves the hybrid deep
neural network that consists of five convolutional blocks and one long
short-term memory block to extract the significant features from
electroencephalography signals. Ten pilots participated in the experiment,
which was conducted within the simulated flight environment. In contrast to
four conventional models, our proposed model achieved a superior grand--average
accuracy of 0.8613, surpassing other conventional models by at least 0.0597 in
classifying workload levels across all participants. Our model not only
successfully classified workload levels but also provided valuable feedback to
the participants. Hence, we anticipate that our study will make the significant
contributions to the advancement of autonomous flight and driving leveraging
artificial intelligence technology in the future.",2023-11-10,2023,2023-11,environment
"TIAGo RL: Simulated Reinforcement Learning Environments with Tactile
  Data for Mobile Robots","Tactile information is important for robust performance in robotic tasks that
involve physical interaction, such as object manipulation. However, with more
data included in the reasoning and control process, modeling behavior becomes
increasingly difficult. Deep Reinforcement Learning (DRL) produced promising
results for learning complex behavior in various domains, including
tactile-based manipulation in robotics. In this work, we present our
open-source reinforcement learning environments for the TIAGo service robot.
They produce tactile sensor measurements that resemble those of a real
sensorised gripper for TIAGo, encouraging research in transfer learning of DRL
policies. Lastly, we show preliminary training results of a learned force
control policy and compare it to a classical PI controller.",2023-11-13,2023,2023-11,environment
C-Procgen: Empowering Procgen with Controllable Contexts,"We present C-Procgen, an enhanced suite of environments on top of the Procgen
benchmark. C-Procgen provides access to over 200 unique game contexts across 16
games. It allows for detailed configuration of environments, ranging from game
mechanics to agent attributes. This makes the procedural generation process,
previously a black-box in Procgen, more transparent and adaptable for various
research needs.The upgrade enhances dynamic context management and
individualized assignments, while maintaining computational efficiency.
C-Procgen's controllable contexts make it applicable in diverse reinforcement
learning research areas, such as learning dynamics analysis, curriculum
learning, and transfer learning. We believe that C-Procgen will fill a gap in
the current literature and offer a valuable toolkit for future works.",2023-11-13,2023,2023-11,environment
"Redefining the Laparoscopic Spatial Sense: AI-based Intra- and
  Postoperative Measurement from Stereoimages","A significant challenge in image-guided surgery is the accurate measurement
task of relevant structures such as vessel segments, resection margins, or
bowel lengths. While this task is an essential component of many surgeries, it
involves substantial human effort and is prone to inaccuracies. In this paper,
we develop a novel human-AI-based method for laparoscopic measurements
utilizing stereo vision that has been guided by practicing surgeons. Based on a
holistic qualitative requirements analysis, this work proposes a comprehensive
measurement method, which comprises state-of-the-art machine learning
architectures, such as RAFT-Stereo and YOLOv8. The developed method is assessed
in various realistic experimental evaluation environments. Our results outline
the potential of our method achieving high accuracies in distance measurements
with errors below 1 mm. Furthermore, on-surface measurements demonstrate
robustness when applied in challenging environments with textureless regions.
Overall, by addressing the inherent challenges of image-guided surgery, we lay
the foundation for a more robust and accurate solution for intra- and
postoperative measurements, enabling more precise, safe, and efficient surgical
procedures.",2023-11-16,2023,2023-11,environment
Artificial Intelligence in Sustainable Vertical Farming,"As global challenges of population growth, climate change, and resource
scarcity intensify, the agricultural landscape is at a critical juncture.
Sustainable vertical farming emerges as a transformative solution to address
these challenges by maximizing crop yields in controlled environments. This
paradigm shift necessitates the integration of cutting-edge technologies, with
Artificial Intelligence (AI) at the forefront. The paper provides a
comprehensive exploration of the role of AI in sustainable vertical farming,
investigating its potential, challenges, and opportunities. The review
synthesizes the current state of AI applications, encompassing machine
learning, computer vision, the Internet of Things (IoT), and robotics, in
optimizing resource usage, automating tasks, and enhancing decision-making. It
identifies gaps in research, emphasizing the need for optimized AI models,
interdisciplinary collaboration, and the development of explainable AI in
agriculture. The implications extend beyond efficiency gains, considering
economic viability, reduced environmental impact, and increased food security.
The paper concludes by offering insights for stakeholders and suggesting
avenues for future research, aiming to guide the integration of AI technologies
in sustainable vertical farming for a resilient and sustainable future in
agriculture.",2023-11-17,2023,2023-11,environment
"Environment-Aware Dynamic Graph Learning for Out-of-Distribution
  Generalization","Dynamic graph neural networks (DGNNs) are increasingly pervasive in
exploiting spatio-temporal patterns on dynamic graphs. However, existing works
fail to generalize under distribution shifts, which are common in real-world
scenarios. As the generation of dynamic graphs is heavily influenced by latent
environments, investigating their impacts on the out-of-distribution (OOD)
generalization is critical. However, it remains unexplored with the following
two major challenges: (1) How to properly model and infer the complex
environments on dynamic graphs with distribution shifts? (2) How to discover
invariant patterns given inferred spatio-temporal environments? To solve these
challenges, we propose a novel Environment-Aware dynamic Graph LEarning (EAGLE)
framework for OOD generalization by modeling complex coupled environments and
exploiting spatio-temporal invariant patterns. Specifically, we first design
the environment-aware EA-DGNN to model environments by multi-channel
environments disentangling. Then, we propose an environment instantiation
mechanism for environment diversification with inferred distributions. Finally,
we discriminate spatio-temporal invariant patterns for out-of-distribution
prediction by the invariant pattern recognition mechanism and perform
fine-grained causal interventions node-wisely with a mixture of instantiated
environment samples. Experiments on real-world and synthetic dynamic graph
datasets demonstrate the superiority of our method against state-of-the-art
baselines under distribution shifts. To the best of our knowledge, we are the
first to study OOD generalization on dynamic graphs from the environment
learning perspective.",2023-11-18,2023,2023-11,environment
"Synthetic Data Generation for Bridging Sim2Real Gap in a Production
  Environment","Synthetic data is being used lately for training deep neural networks in
computer vision applications such as object detection, object segmentation and
6D object pose estimation. Domain randomization hereby plays an important role
in reducing the simulation to reality gap. However, this generalization might
not be effective in specialized domains like a production environment involving
complex assemblies. Either the individual parts, trained with synthetic images,
are integrated in much larger assemblies making them indistinguishable from
their counterparts and result in false positives or are partially occluded just
enough to give rise to false negatives. Domain knowledge is vital in these
cases and if conceived effectively while generating synthetic data, can show a
considerable improvement in bridging the simulation to reality gap. This paper
focuses on synthetic data generation procedures for parts and assemblies used
in a production environment. The basic procedures for synthetic data generation
and their various combinations are evaluated and compared on images captured in
a production environment, where results show up to 15% improvement using
combinations of basic procedures. Reducing the simulation to reality gap in
this way can aid to utilize the true potential of robot assisted production
using artificial intelligence.",2023-11-18,2023,2023-11,environment
User-Like Bots for Cognitive Automation: A Survey,"Software bots have attracted increasing interest and popularity in both
research and society. Their contributions span automation, digital twins, game
characters with conscious-like behavior, and social media. However, there is
still a lack of intelligent bots that can adapt to web environments'
variability and dynamic nature. Unlike human users, they have difficulty
understanding and exploiting the affordances across multiple virtual
environments.
  Despite the hype, bots with human user-like cognition do not currently exist.
Chatbots, for instance, lack situational awareness on the digital platforms
where they operate, preventing them from enacting meaningful and autonomous
intelligent behavior similar to human users.
  In this survey, we aim to explore the role of cognitive architectures in
supporting efforts towards engineering software bots with advanced general
intelligence. We discuss how cognitive architectures can contribute to creating
intelligent software bots. Furthermore, we highlight key architectural
recommendations for the future development of autonomous, user-like cognitive
bots.",2023-11-20,2023,2023-11,environment
ChatGPT and Beyond: The Generative AI Revolution in Education,"The wide adoption and usage of generative artificial intelligence (AI)
models, particularly ChatGPT, has sparked a surge in research exploring their
potential applications in the educational landscape. This survey examines
academic literature published between November, 2022, and July, 2023,
specifically targeting high-impact research from Scopus-indexed Q1 and Q2
journals. This survey delves into the practical applications and implications
of generative AI models across a diverse range of educational contexts. Through
a comprehensive and rigorous evaluation of recent academic literature, this
survey seeks to illuminate the evolving role of generative AI models,
particularly ChatGPT, in education. By shedding light on the potential
benefits, challenges, and emerging trends in this dynamic field, the survey
endeavors to contribute to the understanding of the nexus between artificial
intelligence and education. The findings of this review will empower educators,
researchers, and policymakers to make informed decisions about the integration
of AI technologies into learning environments.",2023-11-26,2023,2023-11,environment
"Training Reinforcement Learning Agents and Humans With
  Difficulty-Conditioned Generators","We adapt Parameterized Environment Response Model (PERM), a method for
training both Reinforcement Learning (RL) Agents and human learners in
parameterized environments by directly modeling difficulty and ability.
Inspired by Item Response Theory (IRT), PERM aligns environment difficulty with
individual ability, creating a Zone of Proximal Development-based curriculum.
Remarkably, PERM operates without real-time RL updates and allows for offline
training, ensuring its adaptability across diverse students. We present a
two-stage training process that capitalizes on PERM's adaptability, and
demonstrate its effectiveness in training RL agents and humans in an empirical
study.",2023-12-04,2023,2023-12,environment
"Learning Unknown Intervention Targets in Structural Causal Models from
  Heterogeneous Data","We study the problem of identifying the unknown intervention targets in
structural causal models where we have access to heterogeneous data collected
from multiple environments. The unknown intervention targets are the set of
endogenous variables whose corresponding exogenous noises change across the
environments. We propose a two-phase approach which in the first phase recovers
the exogenous noises corresponding to unknown intervention targets whose
distributions have changed across environments. In the second phase, the
recovered noises are matched with the corresponding endogenous variables. For
the recovery phase, we provide sufficient conditions for learning these
exogenous noises up to some component-wise invertible transformation. For the
matching phase, under the causal sufficiency assumption, we show that the
proposed method uniquely identifies the intervention targets. In the presence
of latent confounders, the intervention targets among the observed variables
cannot be determined uniquely. We provide a candidate intervention target set
which is a superset of the true intervention targets. Our approach improves
upon the state of the art as the returned candidate set is always a subset of
the target set returned by previous work. Moreover, we do not require
restrictive assumptions such as linearity of the causal model or performing
invariance tests to learn whether a distribution is changing across
environments which could be highly sample inefficient. Our experimental results
show the effectiveness of our proposed algorithm in practice.",2023-12-11,2023,2023-12,environment
"DVQI: A Multi-task, Hardware-integrated Artificial Intelligence System
  for Automated Visual Inspection in Electronics Manufacturing","As electronics manufacturers continue to face pressure to increase production
efficiency amid difficulties with supply chains and labour shortages, many
printed circuit board assembly (PCBA) manufacturers have begun to invest in
automation and technological innovations to remain competitive. One such method
is to leverage artificial intelligence (AI) to greatly augment existing
manufacturing processes. In this paper, we present the DarwinAI Visual Quality
Inspection (DVQI) system, a hardware-integration artificial intelligence system
for the automated inspection of printed circuit board assembly defects in an
electronics manufacturing environment. The DVQI system enables multi-task
inspection via minimal programming and setup for manufacturing engineers while
improving cycle time relative to manual inspection. We also present a case
study of the deployed DVQI system's performance and impact for a top
electronics manufacturer.",2023-12-14,2023,2023-12,environment
"CERN for AI: A Theoretical Framework for Autonomous Simulation-Based
  Artificial Intelligence Testing and Alignment","This paper explores the potential of a multidisciplinary approach to testing
and aligning artificial intelligence (AI), specifically focusing on large
language models (LLMs). Due to the rapid development and wide application of
LLMs, challenges such as ethical alignment, controllability, and predictability
of these models emerged as global risks. This study investigates an innovative
simulation-based multi-agent system within a virtual reality framework that
replicates the real-world environment. The framework is populated by automated
'digital citizens,' simulating complex social structures and interactions to
examine and optimize AI. Application of various theories from the fields of
sociology, social psychology, computer science, physics, biology, and economics
demonstrates the possibility of a more human-aligned and socially responsible
AI. The purpose of such a digital environment is to provide a dynamic platform
where advanced AI agents can interact and make independent decisions, thereby
mimicking realistic scenarios. The actors in this digital city, operated by the
LLMs, serve as the primary agents, exhibiting high degrees of autonomy. While
this approach shows immense potential, there are notable challenges and
limitations, most significantly the unpredictable nature of real-world social
dynamics. This research endeavors to contribute to the development and
refinement of AI, emphasizing the integration of social, ethical, and
theoretical dimensions for future research.",2023-12-14,2023,2023-12,environment
"The Animal-AI Environment: A Virtual Laboratory For Comparative
  Cognition and Artificial Intelligence Research","The Animal-AI Environment is a unique game-based research platform designed
to facilitate collaboration between the artificial intelligence and comparative
cognition research communities. In this paper, we present the latest version of
the Animal-AI Environment, outlining several major features that make the game
more engaging for humans and more complex for AI systems. These features
include interactive buttons, reward dispensers, and player notifications, as
well as an overhaul of the environment's graphics and processing for
significant improvements in agent training time and quality of the human player
experience. We provide detailed guidance on how to build computational and
behavioural experiments with the Animal-AI Environment. We present results from
a series of agents, including the state-of-the-art deep reinforcement learning
agent Dreamer-v3, on newly designed tests and the Animal-AI Testbed of 900
tasks inspired by research in the field of comparative cognition. The Animal-AI
Environment offers a new approach for modelling cognition in humans and
non-human animals, and for building biologically inspired artificial
intelligence.",2023-12-18,2023,2023-12,environment
Human-Machine Teaming for UAVs: An Experimentation Platform,"Full automation is often not achievable or desirable in critical systems with
high-stakes decisions. Instead, human-AI teams can achieve better results. To
research, develop, evaluate, and validate algorithms suited for such teaming,
lightweight experimentation platforms that enable interactions between humans
and multiple AI agents are necessary. However, there are limited examples of
such platforms for defense environments. To address this gap, we present the
Cogment human-machine teaming experimentation platform, which implements
human-machine teaming (HMT) use cases that features heterogeneous multi-agent
systems and can involve learning AI agents, static AI agents, and humans. It is
built on the Cogment platform and has been used for academic research,
including work presented at the ALA workshop at AAMAS this year [1]. With this
platform, we hope to facilitate further research on human-machine teaming in
critical systems and defense environments.",2023-12-18,2023,2023-12,environment
Understanding and Estimating Domain Complexity Across Domains,"Artificial Intelligence (AI) systems, trained in controlled environments,
often struggle in real-world complexities. We propose a general framework for
estimating domain complexity across diverse environments, like open-world
learning and real-world applications. This framework distinguishes between
intrinsic complexity (inherent to the domain) and extrinsic complexity
(dependent on the AI agent). By analyzing dimensionality, sparsity, and
diversity within these categories, we offer a comprehensive view of domain
challenges. This approach enables quantitative predictions of AI difficulty
during environment transitions, avoids bias in novel situations, and helps
navigate the vast search spaces of open-world domains.",2023-12-20,2023,2023-12,environment
"A Conservative Approach for Few-Shot Transfer in Off-Dynamics
  Reinforcement Learning","Off-dynamics Reinforcement Learning (ODRL) seeks to transfer a policy from a
source environment to a target environment characterized by distinct yet
similar dynamics. In this context, traditional RL agents depend excessively on
the dynamics of the source environment, resulting in the discovery of policies
that excel in this environment but fail to provide reasonable performance in
the target one. In the few-shot framework, a limited number of transitions from
the target environment are introduced to facilitate a more effective transfer.
Addressing this challenge, we propose an innovative approach inspired by recent
advancements in Imitation Learning and conservative RL algorithms. The proposed
method introduces a penalty to regulate the trajectories generated by the
source-trained policy. We evaluate our method across various environments
representing diverse off-dynamics conditions, where access to the target
environment is extremely limited. These experiments include high-dimensional
systems relevant to real-world applications. Across most tested scenarios, our
proposed method demonstrates performance improvements compared to existing
baselines.",2023-12-24,2023,2023-12,environment
Autonomous Navigation in Complex Environments,"This paper explores the application of CNN-DNN network fusion to construct a
robot navigation controller within a simulated environment. The simulated
environment is constructed to model a subterranean rescue situation, such that
an autonomous agent is tasked with finding a goal within an unknown cavernous
system. Imitation learning is used to train the control algorithm to use LiDAR
and camera data to navigate the space and find the goal. The trained model is
then tested for robustness using Monte-Carlo.",2024-01-06,2024,2024-01,environment
"Transcending Controlled Environments Assessing the Transferability of
  ASRRobust NLU Models to Real-World Applications","This research investigates the transferability of Automatic Speech
Recognition (ASR)-robust Natural Language Understanding (NLU) models from
controlled experimental conditions to practical, real-world applications.
Focused on smart home automation commands in Urdu, the study assesses model
performance under diverse noise profiles, linguistic variations, and ASR error
scenarios. Leveraging the UrduBERT model, the research employs a systematic
methodology involving real-world data collection, cross-validation, transfer
learning, noise variation studies, and domain adaptation. Evaluation metrics
encompass task-specific accuracy, latency, user satisfaction, and robustness to
ASR errors. The findings contribute insights into the challenges and
adaptability of ASR-robust NLU models in transcending controlled environments.",2024-01-12,2024,2024-01,environment
"Training program on sign language: social inclusion through Virtual
  Reality in ISENSE project","Structured hand gestures that incorporate visual motions and signs are used
in sign language. Sign language is a valuable means of daily communication for
individuals who are deaf or have speech impairments, but it is still rare among
hearing people, and fewer are capable of understand it. Within the academic
context, parents and teachers play a crucial role in supporting deaf students
from childhood by facilitating their learning of sign language. In the last
years, among all the teaching tools useful for learning sign language, the use
of Virtual Reality (VR) has increased, as it has been demonstrated to improve
retention, memory and attention during the learning process. The ISENSE project
has been created to assist students with deafness during their academic life by
proposing different technological tools for teaching sign language to the
hearing community in the academic context. As part of the ISENSE project, this
work aims to develop an application for Spanish and Italian sign language
recognition that exploits the VR environment to quickly and easily create a
comprehensive database of signs and an Artificial Intelligence (AI)-based
software to accurately classify and recognize static and dynamic signs: from
letters to sentences.",2024-01-15,2024,2024-01,environment
"On the Interplay of Artificial Intelligence and Space-Air-Ground
  Integrated Networks: A Survey","Space-Air-Ground Integrated Networks (SAGINs), which incorporate space and
aerial networks with terrestrial wireless systems, are vital enablers of the
emerging sixth-generation (6G) wireless networks. Besides bringing significant
benefits to various applications and services, SAGINs are envisioned to extend
high-speed broadband coverage to remote areas, such as small towns or mining
sites, or areas where terrestrial infrastructure cannot reach, such as
airplanes or maritime use cases. However, due to the limited power and storage
resources, as well as other constraints introduced by the design of terrestrial
networks, SAGINs must be intelligently configured and controlled to satisfy the
envisioned requirements. Meanwhile, Artificial Intelligence (AI) is another
critical enabler of 6G. Due to massive amounts of available data, AI has been
leveraged to address pressing challenges of current and future wireless
networks. By adding AI and facilitating the decision-making and prediction
procedures, SAGINs can effectively adapt to their surrounding environment, thus
enhancing the performance of various metrics. In this work, we aim to
investigate the interplay of AI and SAGINs by providing a holistic overview of
state-of-the-art research in AI-enabled SAGINs. Specifically, we present a
comprehensive overview of some potential applications of AI in SAGINs. We also
cover open issues in employing AI and detail the contributions of SAGINs in the
development of AI. Finally, we highlight some limitations of the existing
research works and outline potential future research directions.",2024-01-20,2024,2024-01,environment
"Deep Learning Based Simulators for the Phosphorus Removal Process
  Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms","Phosphorus removal is vital in wastewater treatment to reduce reliance on
limited resources. Deep reinforcement learning (DRL) is a machine learning
technique that can optimize complex and nonlinear systems, including the
processes in wastewater treatment plants, by learning control policies through
trial and error. However, applying DRL to chemical and biological processes is
challenging due to the need for accurate simulators. This study trained six
models to identify the phosphorus removal process and used them to create a
simulator for the DRL environment. Although the models achieved high accuracy
(>97%), uncertainty and incorrect prediction behavior limited their performance
as simulators over longer horizons. Compounding errors in the models'
predictions were identified as one of the causes of this problem. This approach
for improving process control involves creating simulation environments for DRL
algorithms, using data from supervisory control and data acquisition (SCADA)
systems with a sufficient historical horizon without complex system modeling or
parameter estimation.",2024-01-23,2024,2024-01,environment
Dynamic Long-Term Time-Series Forecasting via Meta Transformer Networks,"A reliable long-term time-series forecaster is highly demanded in practice
but comes across many challenges such as low computational and memory
footprints as well as robustness against dynamic learning environments. This
paper proposes Meta-Transformer Networks (MANTRA) to deal with the dynamic
long-term time-series forecasting tasks. MANTRA relies on the concept of fast
and slow learners where a collection of fast learners learns different aspects
of data distributions while adapting quickly to changes. A slow learner tailors
suitable representations to fast learners. Fast adaptations to dynamic
environments are achieved using the universal representation transformer layers
producing task-adapted representations with a small number of parameters. Our
experiments using four datasets with different prediction lengths demonstrate
the advantage of our approach with at least $3\%$ improvements over the
baseline algorithms for both multivariate and univariate settings. Source codes
of MANTRA are publicly available in
\url{https://github.com/anwarmaxsum/MANTRA}.",2024-01-25,2024,2024-01,environment
"Multi-Agent Coordination for a Partially Observable and Dynamic Robot
  Soccer Environment with Limited Communication","RoboCup represents an International testbed for advancing research in AI and
robotics, focusing on a definite goal: developing a robot team that can win
against the human world soccer champion team by the year 2050. To achieve this
goal, autonomous humanoid robots' coordination is crucial. This paper explores
novel solutions within the RoboCup Standard Platform League (SPL), where a
reduction in WiFi communication is imperative, leading to the development of
new coordination paradigms. The SPL has experienced a substantial decrease in
network packet rate, compelling the need for advanced coordination
architectures to maintain optimal team functionality in dynamic environments.
Inspired by market-based task assignment, we introduce a novel distributed
coordination system to orchestrate autonomous robots' actions efficiently in
low communication scenarios. This approach has been tested with NAO robots
during official RoboCup competitions and in the SimRobot simulator,
demonstrating a notable reduction in task overlaps in limited communication
settings.",2024-01-26,2024,2024-01,environment
"Synthetic Multimodal Dataset for Empowering Safety and Well-being in
  Home Environments","This paper presents a synthetic multimodal dataset of daily activities that
fuses video data from a 3D virtual space simulator with knowledge graphs
depicting the spatiotemporal context of the activities. The dataset is
developed for the Knowledge Graph Reasoning Challenge for Social Issues
(KGRC4SI), which focuses on identifying and addressing hazardous situations in
the home environment. The dataset is available to the public as a valuable
resource for researchers and practitioners developing innovative solutions
recognizing human behaviors to enhance safety and well-being in",2024-01-26,2024,2024-01,environment
"""What's my model inside of?"": Exploring the role of environments for
  grounded natural language understanding","In contrast to classical cognitive science which studied brains in isolation,
ecological approaches focused on the role of the body and environment in
shaping cognition. Similarly, in this thesis we adopt an ecological approach to
grounded natural language understanding (NLU) research. Grounded language
understanding studies language understanding systems situated in the context of
events, actions and precepts in naturalistic/simulated virtual environments.
Where classic research tends to focus on designing new models and optimization
methods while treating environments as given, we explore the potential of
environment design for improving data collection and model development. We
developed novel training and annotation approaches for procedural text
understanding based on text-based game environments. We also drew upon embodied
cognitive linguistics literature to propose a roadmap for grounded NLP
research, and to inform the development of a new benchmark for measuring the
progress of large language models on challenging commonsense reasoning tasks.
We leveraged the richer supervision provided by text-based game environments to
develop Breakpoint Transformers, a novel approach to modeling intermediate
semantic information in long narrative or procedural texts. Finally, we
integrated theories on the role of environments in collective human
intelligence to propose a design for AI-augmented ""social thinking
environments"" for knowledge workers like scientists.",2024-02-04,2024,2024-02,environment
"Understanding What Affects the Generalization Gap in Visual
  Reinforcement Learning: Theory and Empirical Evidence","Recently, there are many efforts attempting to learn useful policies for
continuous control in visual reinforcement learning (RL). In this scenario, it
is important to learn a generalizable policy, as the testing environment may
differ from the training environment, e.g., there exist distractors during
deployment. Many practical algorithms are proposed to handle this problem.
However, to the best of our knowledge, none of them provide a theoretical
understanding of what affects the generalization gap and why their proposed
methods work. In this paper, we bridge this issue by theoretically answering
the key factors that contribute to the generalization gap when the testing
environment has distractors. Our theories indicate that minimizing the
representation distance between training and testing environments, which aligns
with human intuition, is the most critical for the benefit of reducing the
generalization gap. Our theoretical results are supported by the empirical
evidence in the DMControl Generalization Benchmark (DMC-GB).",2024-02-05,2024,2024-02,environment
"Game Agent Driven by Free-Form Text Command: Using LLM-based Code
  Generation and Behavior Branch","Several attempts have been made to implement text command control for game
agents. However, current technologies are limited to processing predefined
format commands. This paper proposes a pioneering text command control system
for a game agent that can understand natural language commands expressed in
free-form. The proposed system uses a large language model (LLM) for code
generation to interpret and transform natural language commands into behavior
branch, a proposed knowledge expression based on behavior trees, which
facilitates execution by the game agent. This study conducted empirical
validation within a game environment that simulates a Pok\'emon game and
involved multiple participants. The results confirmed the system's ability to
understand and carry out natural language commands, representing a noteworthy
in the realm of real-time language interactive game agents.
  Notice for the use of this material. The copyright of this material is
retained by the Japanese Society for Artificial Intelligence (JSAI). This
material is published here with the agreement of JSAI. Please be complied with
Copyright Law of Japan if any users wish to reproduce, make derivative work,
distribute or make available to the public any part or whole thereof. All
Rights Reserved, Copyright (C) The Japanese Society for Artificial
Intelligence.",2024-02-12,2024,2024-02,environment
"FGeo-DRL: Deductive Reasoning for Geometric Problems through Deep
  Reinforcement Learning","The human-like automatic deductive reasoning has always been one of the most
challenging open problems in the interdiscipline of mathematics and artificial
intelligence. This paper is the third in a series of our works. We built a
neural-symbolic system, called FGeoDRL, to automatically perform human-like
geometric deductive reasoning. The neural part is an AI agent based on
reinforcement learning, capable of autonomously learning problem-solving
methods from the feedback of a formalized environment, without the need for
human supervision. It leverages a pre-trained natural language model to
establish a policy network for theorem selection and employ Monte Carlo Tree
Search for heuristic exploration. The symbolic part is a reinforcement learning
environment based on geometry formalization theory and FormalGeo, which models
GPS as a Markov Decision Process. In this formal symbolic system, the known
conditions and objectives of the problem form the state space, while the set of
theorems forms the action space. Leveraging FGeoDRL, we have achieved readable
and verifiable automated solutions to geometric problems. Experiments conducted
on the formalgeo7k dataset have achieved a problem-solving success rate of
86.40%. The project is available at https://github.com/PersonNoName/FGeoDRL.",2024-02-14,2024,2024-02,environment
"From Cloud to Edge: Rethinking Generative AI for Low-Resource Design
  Challenges","Generative Artificial Intelligence (AI) has shown tremendous prospects in all
aspects of technology, including design. However, due to its heavy demand on
resources, it is usually trained on large computing infrastructure and often
made available as a cloud-based service. In this position paper, we consider
the potential, challenges, and promising approaches for generative AI for
design on the edge, i.e., in resource-constrained settings where memory,
compute, energy (battery) and network connectivity may be limited. Adapting
generative AI for such settings involves overcoming significant hurdles,
primarily in how to streamline complex models to function efficiently in
low-resource environments. This necessitates innovative approaches in model
compression, efficient algorithmic design, and perhaps even leveraging edge
computing. The objective is to harness the power of generative AI in creating
bespoke solutions for design problems, such as medical interventions, farm
equipment maintenance, and educational material design, tailored to the unique
constraints and needs of remote areas. These efforts could democratize access
to advanced technology and foster sustainable development, ensuring universal
accessibility and environmental consideration of AI-driven design benefits.",2024-02-20,2024,2024-02,environment
"Virtual Reality for Understanding Artificial-Intelligence-driven
  Scientific Discovery with an Application in Quantum Optics","Generative Artificial Intelligence (AI) models can propose solutions to
scientific problems beyond human capability. To truly make conceptual
contributions, researchers need to be capable of understanding the AI-generated
structures and extracting the underlying concepts and ideas. When algorithms
provide little explanatory reasoning alongside the output, scientists have to
reverse-engineer the fundamental insights behind proposals based solely on
examples. This task can be challenging as the output is often highly complex
and thus not immediately accessible to humans. In this work we show how
transferring part of the analysis process into an immersive Virtual Reality
(VR) environment can assist researchers in developing an understanding of
AI-generated solutions. We demonstrate the usefulness of VR in finding
interpretable configurations of abstract graphs, representing Quantum Optics
experiments. Thereby, we can manually discover new generalizations of
AI-discoveries as well as new understanding in experimental quantum optics.
Furthermore, it allows us to customize the search space in an informed way - as
a human-in-the-loop - to achieve significantly faster subsequent discovery
iterations. As concrete examples, with this technology, we discover a new
resource-efficient 3-dimensional entanglement swapping scheme, as well as a
3-dimensional 4-particle Greenberger-Horne-Zeilinger-state analyzer. Our
results show the potential of VR for increasing a human researcher's ability to
derive knowledge from graph-based generative AI that, which is a common
abstract data representation used in diverse fields of science.",2024-02-20,2024,2024-02,environment
Social Environment Design,"Artificial Intelligence (AI) holds promise as a technology that can be used
to improve government and economic policy-making. This paper proposes a new
research agenda towards this end by introducing Social Environment Design, a
general framework for the use of AI for automated policy-making that connects
with the Reinforcement Learning, EconCS, and Computational Social Choice
communities. The framework seeks to capture general economic environments,
includes voting on policy objectives, and gives a direction for the systematic
analysis of government and economic policy through AI simulation. We highlight
key open problems for future research in AI-based policy-making. By solving
these challenges, we hope to achieve various social welfare objectives, thereby
promoting more ethical and responsible decision making.",2024-02-21,2024,2024-02,environment
Vision-Language Navigation with Embodied Intelligence: A Survey,"As a long-term vision in the field of artificial intelligence, the core goal
of embodied intelligence is to improve the perception, understanding, and
interaction capabilities of agents and the environment. Vision-language
navigation (VLN), as a critical research path to achieve embodied intelligence,
focuses on exploring how agents use natural language to communicate effectively
with humans, receive and understand instructions, and ultimately rely on visual
information to achieve accurate navigation. VLN integrates artificial
intelligence, natural language processing, computer vision, and robotics. This
field faces technical challenges but shows potential for application such as
human-computer interaction. However, due to the complex process involved from
language understanding to action execution, VLN faces the problem of aligning
visual information and language instructions, improving generalization ability,
and many other challenges. This survey systematically reviews the research
progress of VLN and details the research direction of VLN with embodied
intelligence. After a detailed summary of its system architecture and research
based on methods and commonly used benchmark datasets, we comprehensively
analyze the problems and challenges faced by current research and explore the
future development direction of this field, aiming to provide a practical
reference for researchers.",2024-02-22,2024,2024-02,environment
"Artificial Intelligence for Complex Network: Potential, Methodology and
  Application","Complex networks pervade various real-world systems, from the natural
environment to human societies. The essence of these networks is in their
ability to transition and evolve from microscopic disorder-where network
topology and node dynamics intertwine-to a macroscopic order characterized by
certain collective behaviors. Over the past two decades, complex network
science has significantly enhanced our understanding of the statistical
mechanics, structures, and dynamics underlying real-world networks. Despite
these advancements, there remain considerable challenges in exploring more
realistic systems and enhancing practical applications. The emergence of
artificial intelligence (AI) technologies, coupled with the abundance of
diverse real-world network data, has heralded a new era in complex network
science research. This survey aims to systematically address the potential
advantages of AI in overcoming the lingering challenges of complex network
research. It endeavors to summarize the pivotal research problems and provide
an exhaustive review of the corresponding methodologies and applications.
Through this comprehensive survey-the first of its kind on AI for complex
networks-we expect to provide valuable insights that will drive further
research and advancement in this interdisciplinary field.",2024-02-23,2024,2024-02,environment
Brain-inspired and Self-based Artificial Intelligence,"The question ""Can machines think?"" and the Turing Test to assess whether
machines could achieve human-level intelligence is one of the roots of AI. With
the philosophical argument ""I think, therefore I am"", this paper challenge the
idea of a ""thinking machine"" supported by current AIs since there is no sense
of self in them. Current artificial intelligence is only seemingly intelligent
information processing and does not truly understand or be subjectively aware
of oneself and perceive the world with the self as human intelligence does. In
this paper, we introduce a Brain-inspired and Self-based Artificial
Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to
coordinating various cognitive functions and learning strategies in a
self-organized manner to build human-level AI models and robotic applications.
Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the
future AI, rooted with a practical hierarchical Self framework, including
Perception and Learning, Bodily Self, Autonomous Self, Social Self, and
Conceptual Self. The hierarchical framework of the Self highlights self-based
environment perception, self-bodily modeling, autonomous interaction with the
environment, social interaction and collaboration with others, and even more
abstract understanding of the Self. Furthermore, the positive mutual promotion
and support among multiple levels of Self, as well as between Self and
learning, enhance the BriSe AI's conscious understanding of information and
flexible adaptation to complex environments, serving as a driving force
propelling BriSe AI towards real Artificial General Intelligence.",2024-02-29,2024,2024-02,environment
"Mathematics of multi-agent learning systems at the interface of game
  theory and artificial intelligence","Evolutionary Game Theory (EGT) and Artificial Intelligence (AI) are two
fields that, at first glance, might seem distinct, but they have notable
connections and intersections. The former focuses on the evolution of behaviors
(or strategies) in a population, where individuals interact with others and
update their strategies based on imitation (or social learning). The more
successful a strategy is, the more prevalent it becomes over time. The latter,
meanwhile, is centered on machine learning algorithms and (deep) neural
networks. It is often from a single-agent perspective but increasingly involves
multi-agent environments, in which intelligent agents adjust their strategies
based on feedback and experience, somewhat akin to the evolutionary process yet
distinct in their self-learning capacities. In light of the key components
necessary to address real-world problems, including (i) learning and
adaptation, (ii) cooperation and competition, (iii) robustness and stability,
and altogether (iv) population dynamics of individual agents whose strategies
evolve, the cross-fertilization of ideas between both fields will contribute to
the advancement of mathematics of multi-agent learning systems, in particular,
to the nascent domain of ``collective cooperative intelligence'' bridging
evolutionary dynamics and multi-agent reinforcement learning.",2024-03-09,2024,2024-03,environment
"Do Agents Dream of Electric Sheep?: Improving Generalization in
  Reinforcement Learning through Generative Learning","The Overfitted Brain hypothesis suggests dreams happen to allow
generalization in the human brain. Here, we ask if the same is true for
reinforcement learning agents as well. Given limited experience in a real
environment, we use imagination-based reinforcement learning to train a policy
on dream-like episodes, where non-imaginative, predicted trajectories are
modified through generative augmentations. Experiments on four ProcGen
environments show that, compared to classic imagination and offline training on
collected experience, our method can reach a higher level of generalization
when dealing with sparsely rewarded environments.",2024-03-12,2024,2024-03,environment
"Can LLM-Augmented autonomous agents cooperate?, An evaluation of their
  cooperative capabilities through Melting Pot","As the field of AI continues to evolve, a significant dimension of this
progression is the development of Large Language Models and their potential to
enhance multi-agent artificial intelligence systems. This paper explores the
cooperative capabilities of Large Language Model-augmented Autonomous Agents
(LAAs) using the well-known Meltin Pot environments along with reference models
such as GPT4 and GPT3.5. Preliminary results suggest that while these agents
demonstrate a propensity for cooperation, they still struggle with effective
collaboration in given environments, emphasizing the need for more robust
architectures. The study's contributions include an abstraction layer to adapt
Melting Pot game scenarios for LLMs, the implementation of a reusable
architecture for LLM-mediated agent development - which includes short and
long-term memories and different cognitive modules, and the evaluation of
cooperation capabilities using a set of metrics tied to the Melting Pot's
""Commons Harvest"" game. The paper closes, by discussing the limitations of the
current architectural framework and the potential of a new set of modules that
fosters better cooperation among LAAs.",2024-03-18,2024,2024-03,environment
"BlendScape: Enabling End-User Customization of Video-Conferencing
  Environments through Generative AI","Today's video-conferencing tools support a rich range of professional and
social activities, but their generic meeting environments cannot be dynamically
adapted to align with distributed collaborators' needs. To enable end-user
customization, we developed BlendScape, a rendering and composition system for
video-conferencing participants to tailor environments to their meeting context
by leveraging AI image generation techniques. BlendScape supports flexible
representations of task spaces by blending users' physical or digital
backgrounds into unified environments and implements multimodal interaction
techniques to steer the generation. Through an exploratory study with 15
end-users, we investigated whether and how they would find value in using
generative AI to customize video-conferencing environments. Participants
envisioned using a system like BlendScape to facilitate collaborative
activities in the future, but required further controls to mitigate distracting
or unrealistic visual elements. We implemented scenarios to demonstrate
BlendScape's expressiveness for supporting environment design strategies from
prior work and propose composition techniques to improve the quality of
environments.",2024-03-20,2024,2024-03,environment
SymboSLAM: Semantic Map Generation in a Multi-Agent System,"Sub-symbolic artificial intelligence methods dominate the fields of
environment-type classification and Simultaneous Localisation and Mapping.
However, a significant area overlooked within these fields is solution
transparency for the human-machine interaction space, as the sub-symbolic
methods employed for map generation do not account for the explainability of
the solutions generated. This paper proposes a novel approach to
environment-type classification through Symbolic Simultaneous Localisation and
Mapping, SymboSLAM, to bridge the explainability gap. Our method for
environment-type classification observes ontological reasoning used to
synthesise the context of an environment through the features found within. We
achieve explainability within the model by presenting operators with
environment-type classifications overlayed by a semantically labelled occupancy
map of landmarks and features. We evaluate SymboSLAM with ground-truth maps of
the Canberra region, demonstrating method effectiveness. We assessed the system
through both simulations and real-world trials.",2024-03-22,2024,2024-03,environment
"Collaborative AI Teaming in Unknown Environments via Active Goal
  Deduction","With the advancements of artificial intelligence (AI), we're seeing more
scenarios that require AI to work closely with other agents, whose goals and
strategies might not be known beforehand. However, existing approaches for
training collaborative agents often require defined and known reward signals
and cannot address the problem of teaming with unknown agents that often have
latent objectives/rewards. In response to this challenge, we propose teaming
with unknown agents framework, which leverages kernel density Bayesian inverse
learning method for active goal deduction and utilizes pre-trained,
goal-conditioned policies to enable zero-shot policy adaptation. We prove that
unbiased reward estimates in our framework are sufficient for optimal teaming
with unknown agents. We further evaluate the framework of redesigned
multi-agent particle and StarCraft II micromanagement environments with diverse
unknown agents of different behaviors/rewards. Empirical results demonstrate
that our framework significantly advances the teaming performance of AI and
unknown agents in a wide range of collaborative scenarios.",2024-03-22,2024,2024-03,environment
The Pursuit of Fairness in Artificial Intelligence Models: A Survey,"Artificial Intelligence (AI) models are now being utilized in all facets of
our lives such as healthcare, education and employment. Since they are used in
numerous sensitive environments and make decisions that can be life altering,
potential biased outcomes are a pressing matter. Developers should ensure that
such models don't manifest any unexpected discriminatory practices like
partiality for certain genders, ethnicities or disabled people. With the
ubiquitous dissemination of AI systems, researchers and practitioners are
becoming more aware of unfair models and are bound to mitigate bias in them.
Significant research has been conducted in addressing such issues to ensure
models don't intentionally or unintentionally perpetuate bias. This survey
offers a synopsis of the different ways researchers have promoted fairness in
AI systems. We explore the different definitions of fairness existing in the
current literature. We create a comprehensive taxonomy by categorizing
different types of bias and investigate cases of biased AI in different
application domains. A thorough study is conducted of the approaches and
techniques employed by researchers to mitigate bias in AI models. Moreover, we
also delve into the impact of biased models on user experience and the ethical
considerations to contemplate when developing and deploying such models. We
hope this survey helps researchers and practitioners understand the intricate
details of fairness and bias in AI systems. By sharing this thorough survey, we
aim to promote additional discourse in the domain of equitable and responsible
AI.",2024-03-26,2024,2024-03,environment
"From Two-Dimensional to Three-Dimensional Environment with Q-Learning:
  Modeling Autonomous Navigation with Reinforcement Learning and no Libraries","Reinforcement learning (RL) algorithms have become indispensable tools in
artificial intelligence, empowering agents to acquire optimal decision-making
policies through interactions with their environment and feedback mechanisms.
This study explores the performance of RL agents in both two-dimensional (2D)
and three-dimensional (3D) environments, aiming to research the dynamics of
learning across different spatial dimensions. A key aspect of this
investigation is the absence of pre-made libraries for learning, with the
algorithm developed exclusively through computational mathematics. The
methodological framework centers on RL principles, employing a Q-learning agent
class and distinct environment classes tailored to each spatial dimension. The
research aims to address the question: How do reinforcement learning agents
adapt and perform in environments of varying spatial dimensions, particularly
in 2D and 3D settings? Through empirical analysis, the study evaluates agents'
learning trajectories and adaptation processes, revealing insights into the
efficacy of RL algorithms in navigating complex, multi-dimensional spaces.
Reflections on the findings prompt considerations for future research,
particularly in understanding the dynamics of learning in higher-dimensional
environments.",2024-03-27,2024,2024-03,environment
Dynamic Quality-Diversity Search,"Evolutionary search via the quality-diversity (QD) paradigm can discover
highly performing solutions in different behavioural niches, showing
considerable potential in complex real-world scenarios such as evolutionary
robotics. Yet most QD methods only tackle static tasks that are fixed over
time, which is rarely the case in the real world. Unlike noisy environments,
where the fitness of an individual changes slightly at every evaluation,
dynamic environments simulate tasks where external factors at unknown and
irregular intervals alter the performance of the individual with a severity
that is unknown a priori. Literature on optimisation in dynamic environments is
extensive, yet such environments have not been explored in the context of QD
search. This paper introduces a novel and generalisable Dynamic QD methodology
that aims to keep the archive of past solutions updated in the case of
environment changes. Secondly, we present a novel characterisation of dynamic
environments that can be easily applied to well-known benchmarks, with minor
interventions to move them from a static task to a dynamic one. Our Dynamic QD
intervention is applied on MAP-Elites and CMA-ME, two powerful QD algorithms,
and we test the dynamic variants on different dynamic tasks.",2024-04-07,2024,2024-04,environment
"The Transformation Risk-Benefit Model of Artificial Intelligence:
  Balancing Risks and Benefits Through Practical Solutions and Use Cases","This paper summarizes the most cogent advantages and risks associated with
Artificial Intelligence from an in-depth review of the literature. Then the
authors synthesize the salient risk-related models currently being used in AI,
technology and business-related scenarios. Next, in view of an updated context
of AI along with theories and models reviewed and expanded constructs, the
writers propose a new framework called ""The Transformation Risk-Benefit Model
of Artificial Intelligence"" to address the increasing fears and levels of AI
risk. Using the model characteristics, the article emphasizes practical and
innovative solutions where benefits outweigh risks and three use cases in
healthcare, climate change/environment and cyber security to illustrate unique
interplay of principles, dimensions and processes of this powerful AI
transformational model.",2024-04-11,2024,2024-04,environment
Multi-Agent eXperimenter (MAX),"We present a novel multi-agent simulator named Multi-Agent eXperimenter (MAX)
that is designed to simulate blockchain experiments involving large numbers of
agents of different types acting in one or several environments. The
architecture of MAX is highly modular, enabling easy addition of new models.",2024-04-12,2024,2024-04,environment
"Synergising Human-like Responses and Machine Intelligence for Planning
  in Disaster Response","In the rapidly changing environments of disaster response, planning and
decision-making for autonomous agents involve complex and interdependent
choices. Although recent advancements have improved traditional artificial
intelligence (AI) approaches, they often struggle in such settings,
particularly when applied to agents operating outside their well-defined
training parameters. To address these challenges, we propose an attention-based
cognitive architecture inspired by Dual Process Theory (DPT). This framework
integrates, in an online fashion, rapid yet heuristic (human-like) responses
(System 1) with the slow but optimized planning capabilities of machine
intelligence (System 2). We illustrate how a supervisory controller can
dynamically determine in real-time the engagement of either system to optimize
mission objectives by assessing their performance across a number of distinct
attributes. Evaluated for trajectory planning in dynamic environments, our
framework demonstrates that this synergistic integration effectively manages
complex tasks by optimizing multiple mission objectives.",2024-04-15,2024,2024-04,environment
"A Note on Loss Functions and Error Compounding in Model-based
  Reinforcement Learning","This note clarifies some confusions (and perhaps throws out more) around
model-based reinforcement learning and their theoretical understanding in the
context of deep RL. Main topics of discussion are (1) how to reconcile
model-based RL's bad empirical reputation on error compounding with its
superior theoretical properties, and (2) the limitations of empirically popular
losses. For the latter, concrete counterexamples for the ""MuZero loss"" are
constructed to show that it not only fails in stochastic environments, but also
suffers exponential sample complexity in deterministic environments when data
provides sufficient coverage.",2024-04-15,2024,2024-04,environment
"What is Meant by AGI? On the Definition of Artificial General
  Intelligence","This paper aims to establish a consensus on AGI's definition. General
intelligence refers to the adaptation to open environments according to certain
principles using limited resources. It emphasizes that adaptation or learning
is an indispensable property of intelligence, and places the controversial part
within the principles of intelligence, which can be described from different
perspectives.",2024-04-16,2024,2024-04,environment
Sustainability of Data Center Digital Twins with Reinforcement Learning,"The rapid growth of machine learning (ML) has led to an increased demand for
computational power, resulting in larger data centers (DCs) and higher energy
consumption. To address this issue and reduce carbon emissions, intelligent
design and control of DC components such as IT servers, cabinets, HVAC cooling,
flexible load shifting, and battery energy storage are essential. However, the
complexity of designing and controlling them in tandem presents a significant
challenge. While some individual components like CFD-based design and
Reinforcement Learning (RL) based HVAC control have been researched, there's a
gap in the holistic design and optimization covering all elements
simultaneously. To tackle this, we've developed DCRL-Green, a multi-agent RL
environment that empowers the ML community to design data centers and research,
develop, and refine RL controllers for carbon footprint reduction in DCs. It is
a flexible, modular, scalable, and configurable platform that can handle large
High Performance Computing (HPC) clusters. Furthermore, in its default setup,
DCRL-Green provides a benchmark for evaluating single as well as multi-agent RL
algorithms. It easily allows users to subclass the default implementations and
design their own control approaches, encouraging community development for
sustainable data centers. Open Source Link:
https://github.com/HewlettPackard/dc-rl",2024-04-16,2024,2024-04,environment
"Explaining AI Decisions: Towards Achieving Human-Centered Explainability
  in Smart Home Environments","Smart home systems are gaining popularity as homeowners strive to enhance
their living and working environments while minimizing energy consumption.
However, the adoption of artificial intelligence (AI)-enabled decision-making
models in smart home systems faces challenges due to the complexity and
black-box nature of these systems, leading to concerns about explainability,
trust, transparency, accountability, and fairness. The emerging field of
explainable artificial intelligence (XAI) addresses these issues by providing
explanations for the models' decisions and actions. While state-of-the-art XAI
methods are beneficial for AI developers and practitioners, they may not be
easily understood by general users, particularly household members. This paper
advocates for human-centered XAI methods, emphasizing the importance of
delivering readily comprehensible explanations to enhance user satisfaction and
drive the adoption of smart home systems. We review state-of-the-art XAI
methods and prior studies focusing on human-centered explanations for general
users in the context of smart home applications. Through experiments on two
smart home application scenarios, we demonstrate that explanations generated by
prominent XAI techniques might not be effective in helping users understand and
make decisions. We thus argue for the necessity of a human-centric approach in
representing explanations in smart home systems and highlight relevant
human-computer interaction (HCI) methodologies, including user studies,
prototyping, technology probes analysis, and heuristic evaluation, that can be
employed to generate and present human-centered explanations to users.",2024-04-23,2024,2024-04,environment
Recursive Backwards Q-Learning in Deterministic Environments,"Reinforcement learning is a popular method of finding optimal solutions to
complex problems. Algorithms like Q-learning excel at learning to solve
stochastic problems without a model of their environment. However, they take
longer to solve deterministic problems than is necessary. Q-learning can be
improved to better solve deterministic problems by introducing such a
model-based approach. This paper introduces the recursive backwards Q-learning
(RBQL) agent, which explores and builds a model of the environment. After
reaching a terminal state, it recursively propagates its value backwards
through this model. This lets each state be evaluated to its optimal value
without a lengthy learning process. In the example of finding the shortest path
through a maze, this agent greatly outperforms a regular Q-learning agent.",2024-04-24,2024,2024-04,environment
Harnessing Big Data and Artificial Intelligence to Study Plant Stress,"Life finds a way. For sessile organisms like plants, the need to adapt to
changes in the environment is even more poignant. For humanity, the need to
develop crops that can grow in diverse environments and feed our growing
population is an existential one. The advent of the genomics era enabled the
generation of high-throughput data and computational methods that serve as
powerful hypothesis-generating tools to understand the genomic and gene
functional basis of stress resilience. Today, the proliferation of artificial
intelligence (AI) allows scientists to rapidly screen through high-throughput
datasets to uncover elusive patterns and correlations, enabling us to create
more performant models for prediction and hypothesis generation in plant
biology. This review aims to provide an overview of the availability of
large-scale data in plant stress research and discuss the application of AI
tools on these large-scale datasets in a bid to develop more stress-resilient
plants.",2024-04-24,2024,2024-04,environment
"Leveraging AI to Generate Audio for User-generated Content in Video
  Games","In video game design, audio (both environmental background music and object
sound effects) play a critical role. Sounds are typically pre-created assets
designed for specific locations or objects in a game. However, user-generated
content is becoming increasingly popular in modern games (e.g. building custom
environments or crafting unique objects). Since the possibilities are virtually
limitless, it is impossible for game creators to pre-create audio for
user-generated content. We explore the use of generative artificial
intelligence to create music and sound effects on-the-fly based on
user-generated content. We investigate two avenues for audio generation: 1)
text-to-audio: using a text description of user-generated content as input to
the audio generator, and 2) image-to-audio: using a rendering of the created
environment or object as input to an image-to-text generator, then piping the
resulting text description into the audio generator. In this paper we discuss
ethical implications of using generative artificial intelligence for
user-generated content and highlight two prototype games where audio is
generated for user-created environments and objects.",2024-04-25,2024,2024-04,environment
Isopignistic Canonical Decomposition via Belief Evolution Network,"Developing a general information processing model in uncertain environments
is fundamental for the advancement of explainable artificial intelligence.
Dempster-Shafer theory of evidence is a well-known and effective reasoning
method for representing epistemic uncertainty, which is closely related to
subjective probability theory and possibility theory. Although they can be
transformed to each other under some particular belief structures, there
remains a lack of a clear and interpretable transformation process, as well as
a unified approach for information processing. In this paper, we aim to address
these issues from the perspectives of isopignistic belief functions and the
hyper-cautious transferable belief model. Firstly, we propose an isopignistic
transformation based on the belief evolution network. This transformation
allows for the adjustment of the information granule while retaining the
potential decision outcome. The isopignistic transformation is integrated with
a hyper-cautious transferable belief model to establish a new canonical
decomposition. This decomposition offers a reverse path between the possibility
distribution and its isopignistic mass functions. The result of the canonical
decomposition, called isopignistic function, is an identical information
content distribution to reflect the propensity and relative commitment degree
of the BPA. Furthermore, this paper introduces a method to reconstruct the
basic belief assignment by adjusting the isopignistic function. It explores the
advantages of this approach in modeling and handling uncertainty within the
hyper-cautious transferable belief model. More general, this paper establishes
a theoretical basis for building general models of artificial intelligence
based on probability theory, Dempster-Shafer theory, and possibility theory.",2024-05-04,2024,2024-05,environment
Elements Of Legislation For Artificial Intelligence Systems,"The significant part of the operational context for autonomous company
management systems is the regulatory and legal environment in which
corporations operate. In order to create a dedicated operational context for
autonomous artificial intelligence systems, the wording of local regulatory
documents can be simultaneously presented in two versions: for use by people
and for use by autonomous systems. In this case, the artificial intelligence
system will get a well-defined operational context that allows such a system to
perform functions within the required standards. Local regulations that provide
basis for the joint work of individuals and autonomous artificial intelligence
systems can form the grounds for the relevant legislation governing the
development and implementation of autonomous systems.",2024-05-05,2024,2024-05,environment
"Super-Exponential Regret for UCT, AlphaGo and Variants","We improve the proofs of the lower bounds of Coquelin and Munos (2007) that
demonstrate that UCT can have $\exp(\dots\exp(1)\dots)$ regret (with
$\Omega(D)$ exp terms) on the $D$-chain environment, and that a `polynomial'
UCT variant has $\exp_2(\exp_2(D - O(\log D)))$ regret on the same environment
-- the original proofs contain an oversight for rewards bounded in $[0, 1]$,
which we fix in the present draft. We also adapt the proofs to AlphaGo's MCTS
and its descendants (e.g., AlphaZero, Leela Zero) to also show $\exp_2(\exp_2(D
- O(\log D)))$ regret.",2024-05-07,2024,2024-05,environment
A digital twin based approach to smart lighting design,"Lighting has a critical impact on user mood and behavior, especially in
architectural settings. Consequently, smart lighting design is a rapidly
growing research area. We describe a digital twin-based approach to smart
lighting design that uses an immersive virtual reality digital twin equivalent
(virtual environment) of the real world, physical architectural space to
explore the visual impact of light configurations. The CLIP neural network is
used to obtain a similarity measure between a photo of the physical space with
the corresponding rendering in the virtual environment. A case study was used
to evaluate the proposed design process. The obtained similarity value of over
87% demonstrates the utility of the proposed approach.",2024-05-08,2024,2024-05,environment
"Artificial Intelligence as the New Hacker: Developing Agents for
  Offensive Security","In the vast domain of cybersecurity, the transition from reactive defense to
offensive has become critical in protecting digital infrastructures. This paper
explores the integration of Artificial Intelligence (AI) into offensive
cybersecurity, particularly through the development of an autonomous AI agent,
ReaperAI, designed to simulate and execute cyberattacks. Leveraging the
capabilities of Large Language Models (LLMs) such as GPT-4, ReaperAI
demonstrates the potential to identify, exploit, and analyze security
vulnerabilities autonomously.
  This research outlines the core methodologies that can be utilized to
increase consistency and performance, including task-driven penetration testing
frameworks, AI-driven command generation, and advanced prompting techniques.
The AI agent operates within a structured environment using Python, enhanced by
Retrieval Augmented Generation (RAG) for contextual understanding and memory
retention. ReaperAI was tested on platforms including, Hack The Box, where it
successfully exploited known vulnerabilities, demonstrating its potential
power.
  However, the deployment of AI in offensive security presents significant
ethical and operational challenges. The agent's development process revealed
complexities in command execution, error handling, and maintaining ethical
constraints, highlighting areas for future enhancement.
  This study contributes to the discussion on AI's role in cybersecurity by
showcasing how AI can augment offensive security strategies. It also proposes
future research directions, including the refinement of AI interactions with
cybersecurity tools, enhancement of learning mechanisms, and the discussion of
ethical guidelines for AI in offensive roles. The findings advocate for a
unique approach to AI implementation in cybersecurity, emphasizing innovation.",2024-05-09,2024,2024-05,environment
Visualizing Neural Network Imagination,"In certain situations, neural networks will represent environment states in
their hidden activations. Our goal is to visualize what environment states the
networks are representing. We experiment with a recurrent neural network (RNN)
architecture with a decoder network at the end. After training, we apply the
decoder to the intermediate representations of the network to visualize what
they represent. We define a quantitative interpretability metric and use it to
demonstrate that hidden states can be highly interpretable on a simple task. We
also develop autoencoder and adversarial techniques and show that benefit
interpretability.",2024-05-10,2024,2024-05,environment
"Science based AI model certification for new operational environments
  with application in traffic state estimation","The expanding role of Artificial Intelligence (AI) in diverse engineering
domains highlights the challenges associated with deploying AI models in new
operational environments, involving substantial investments in data collection
and model training. Rapid application of AI necessitates evaluating the
feasibility of utilizing pre-trained models in unobserved operational settings
with minimal or no additional data. However, interpreting the opaque nature of
AI's black-box models remains a persistent challenge. Addressing this issue,
this paper proposes a science-based certification methodology to assess the
viability of employing pre-trained data-driven models in new operational
environments. The methodology advocates a profound integration of domain
knowledge, leveraging theoretical and analytical models from physics and
related disciplines, with data-driven AI models. This novel approach introduces
tools to facilitate the development of secure engineering systems, providing
decision-makers with confidence in the trustworthiness and safety of AI-based
models across diverse environments characterized by limited training data and
dynamic, uncertain conditions. The paper demonstrates the efficacy of this
methodology in real-world safety-critical scenarios, particularly in the
context of traffic state estimation. Through simulation results, the study
illustrates how the proposed methodology efficiently quantifies physical
inconsistencies exhibited by pre-trained AI models. By utilizing analytical
models, the methodology offers a means to gauge the applicability of
pre-trained AI models in new operational environments. This research
contributes to advancing the understanding and deployment of AI models,
offering a robust certification framework that enhances confidence in their
reliability and safety across a spectrum of operational conditions.",2024-05-13,2024,2024-05,environment
"Fusion Intelligence: Confluence of Natural and Artificial Intelligence
  for Enhanced Problem-Solving Efficiency","This paper introduces Fusion Intelligence (FI), a bio-inspired intelligent
system, where the innate sensing, intelligence and unique actuation abilities
of biological organisms such as bees and ants are integrated with the
computational power of Artificial Intelligence (AI). This interdisciplinary
field seeks to create systems that are not only smart but also adaptive and
responsive in ways that mimic the nature. As FI evolves, it holds the promise
of revolutionizing the way we approach complex problems, leveraging the best of
both biological and digital worlds to create solutions that are more effective,
sustainable, and harmonious with the environment. We demonstrate FI's potential
to enhance agricultural IoT system performance through a simulated case study
on improving insect pollination efficacy (entomophily).",2024-05-16,2024,2024-05,environment
"Autonomous Workflow for Multimodal Fine-Grained Training Assistants
  Towards Mixed Reality","Autonomous artificial intelligence (AI) agents have emerged as promising
protocols for automatically understanding the language-based environment,
particularly with the exponential development of large language models (LLMs).
However, a fine-grained, comprehensive understanding of multimodal environments
remains under-explored. This work designs an autonomous workflow tailored for
integrating AI agents seamlessly into extended reality (XR) applications for
fine-grained training. We present a demonstration of a multimodal fine-grained
training assistant for LEGO brick assembly in a pilot XR environment.
Specifically, we design a cerebral language agent that integrates LLM with
memory, planning, and interaction with XR tools and a vision-language agent,
enabling agents to decide their actions based on past experiences. Furthermore,
we introduce LEGO-MRTA, a multimodal fine-grained assembly dialogue dataset
synthesized automatically in the workflow served by a commercial LLM. This
dataset comprises multimodal instruction manuals, conversations, XR responses,
and vision question answering. Last, we present several prevailing
open-resource LLMs as benchmarks, assessing their performance with and without
fine-tuning on the proposed dataset. We anticipate that the broader impact of
this workflow will advance the development of smarter assistants for seamless
user interaction in XR environments, fostering research in both AI and HCI
communities.",2024-05-16,2024,2024-05,environment
"Transfer Learning for CSI-based Positioning with Multi-environment
  Meta-learning","Utilizing deep learning (DL) techniques for radio-based positioning of user
equipment (UE) through channel state information (CSI) fingerprints has
demonstrated significant potential. DL models can extract complex
characteristics from the CSI fingerprints of a particular environment and
accurately predict the position of a UE. Nonetheless, the effectiveness of the
DL model trained on CSI fingerprints is highly dependent on the particular
training environment, limiting the trained model's applicability across
different environments. This paper proposes a novel DL model structure
consisting of two parts, where the first part aims at identifying features that
are independent from any specific environment, while the second part combines
those features in an environment specific way with the goal of positioning. To
train such a two-part model, we propose the multi-environment meta-learning
(MEML) approach for the first part to facilitate training across various
environments, while the second part of the model is trained solely on data from
a specific environment. Our findings indicate that employing the MEML approach
for initializing the weights of the DL model for a new unseen environment
significantly boosts the accuracy of UE positioning in the new target
environment as well the reliability of its uncertainty estimation. This method
outperforms traditional transfer learning methods, whether direct transfer
learning (DTL) between environments or completely training from scratch with
data from a new environment. The proposed approach is verified with real
measurements for both line-of-sight (LOS) and non-LOS (NLOS) environments.",2024-05-20,2024,2024-05,environment
"Artificial Intelligence Approaches for Predictive Maintenance in the
  Steel Industry: A Survey","Predictive Maintenance (PdM) emerged as one of the pillars of Industry 4.0,
and became crucial for enhancing operational efficiency, allowing to minimize
downtime, extend lifespan of equipment, and prevent failures. A wide range of
PdM tasks can be performed using Artificial Intelligence (AI) methods, which
often use data generated from industrial sensors. The steel industry, which is
an important branch of the global economy, is one of the potential
beneficiaries of this trend, given its large environmental footprint, the
globalized nature of the market, and the demanding working conditions. This
survey synthesizes the current state of knowledge in the field of AI-based PdM
within the steel industry and is addressed to researchers and practitioners. We
identified 219 articles related to this topic and formulated five research
questions, allowing us to gain a global perspective on current trends and the
main research gaps. We examined equipment and facilities subjected to PdM,
determined common PdM approaches, and identified trends in the AI methods used
to develop these solutions. We explored the characteristics of the data used in
the surveyed articles and assessed the practical implications of the research
presented there. Most of the research focuses on the blast furnace or hot
rolling, using data from industrial sensors. Current trends show increasing
interest in the domain, especially in the use of deep learning. The main
challenges include implementing the proposed methods in a production
environment, incorporating them into maintenance plans, and enhancing the
accessibility and reproducibility of the research.",2024-05-21,2024,2024-05,environment
"ADESSE: Advice Explanations in Complex Repeated Decision-Making
  Environments","In the evolving landscape of human-centered AI, fostering a synergistic
relationship between humans and AI agents in decision-making processes stands
as a paramount challenge. This work considers a problem setup where an
intelligent agent comprising a neural network-based prediction component and a
deep reinforcement learning component provides advice to a human decision-maker
in complex repeated decision-making environments. Whether the human
decision-maker would follow the agent's advice depends on their beliefs and
trust in the agent and on their understanding of the advice itself. To this
end, we developed an approach named ADESSE to generate explanations about the
adviser agent to improve human trust and decision-making. Computational
experiments on a range of environments with varying model sizes demonstrate the
applicability and scalability of ADESSE. Furthermore, an interactive game-based
user study shows that participants were significantly more satisfied, achieved
a higher reward in the game, and took less time to select an action when
presented with explanations generated by ADESSE. These findings illuminate the
critical role of tailored, human-centered explanations in AI-assisted
decision-making.",2024-05-31,2024,2024-05,environment
"Monte Carlo Tree Search Satellite Scheduling Under Cloud Cover
  Uncertainty","Efficient utilization of satellite resources in dynamic environments remains
a challenging problem in satellite scheduling. This paper addresses the
multi-satellite collection scheduling problem (m-SatCSP), aiming to optimize
task scheduling over a constellation of satellites under uncertain conditions
such as cloud cover. Leveraging Monte Carlo Tree Search (MCTS), a stochastic
search algorithm, two versions of MCTS are explored to schedule satellites
effectively. Hyperparameter tuning is conducted to optimize the algorithm's
performance. Experimental results demonstrate the effectiveness of the MCTS
approach, outperforming existing methods in both solution quality and
efficiency. Comparative analysis against other scheduling algorithms showcases
competitive performance, positioning MCTS as a promising solution for satellite
task scheduling in dynamic environments.",2024-05-31,2024,2024-05,environment
RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots,"Recent advancements in Artificial Intelligence (AI) have largely been
propelled by scaling. In Robotics, scaling is hindered by the lack of access to
massive robot datasets. We advocate using realistic physical simulation as a
means to scale environments, tasks, and datasets for robot learning methods. We
present RoboCasa, a large-scale simulation framework for training generalist
robots in everyday environments. RoboCasa features realistic and diverse scenes
focusing on kitchen environments. We provide thousands of 3D assets across over
150 object categories and dozens of interactable furniture and appliances. We
enrich the realism and diversity of our simulation with generative AI tools,
such as object assets from text-to-3D models and environment textures from
text-to-image models. We design a set of 100 tasks for systematic evaluation,
including composite tasks generated by the guidance of large language models.
To facilitate learning, we provide high-quality human demonstrations and
integrate automated trajectory generation methods to substantially enlarge our
datasets with minimal human burden. Our experiments show a clear scaling trend
in using synthetically generated robot data for large-scale imitation learning
and show great promise in harnessing simulation data in real-world tasks.
Videos and open-source code are available at https://robocasa.ai/",2024-06-04,2024,2024-06,environment
"Meta-Learners for Partially-Identified Treatment Effects Across Multiple
  Environments","Estimating the conditional average treatment effect (CATE) from observational
data is relevant for many applications such as personalized medicine. Here, we
focus on the widespread setting where the observational data come from multiple
environments, such as different hospitals, physicians, or countries.
Furthermore, we allow for violations of standard causal assumptions, namely,
overlap within the environments and unconfoundedness. To this end, we move away
from point identification and focus on partial identification. Specifically, we
show that current assumptions from the literature on multiple environments
allow us to interpret the environment as an instrumental variable (IV). This
allows us to adapt bounds from the IV literature for partial identification of
CATE by leveraging treatment assignment mechanisms across environments. Then,
we propose different model-agnostic learners (so-called meta-learners) to
estimate the bounds that can be used in combination with arbitrary machine
learning models. We further demonstrate the effectiveness of our meta-learners
across various experiments using both simulated and real-world data. Finally,
we discuss the applicability of our meta-learners to partial identification in
instrumental variable settings, such as randomized controlled trials with
non-compliance.",2024-06-04,2024,2024-06,environment
"Expansion of situations theory for exploring shared awareness in
  human-intelligent autonomous systems","Intelligent autonomous systems are part of a system of systems that interact
with other agents to accomplish tasks in complex environments. However,
intelligent autonomous systems integrated system of systems add additional
layers of complexity based on their limited cognitive processes, specifically
shared situation awareness that allows a team to respond to novel tasks.
Intelligent autonomous systems' lack of shared situation awareness adversely
influences team effectiveness in complex task environments, such as military
command-and-control. A complementary approach of shared situation awareness,
called situations theory, is beneficial for understanding the relationship
between system of systems shared situation awareness and effectiveness. The
current study elucidates a conceptual discussion on situations theory to
investigate the development of an system of systems shared situational
awareness when humans team with intelligent autonomous system agents. To ground
the discussion, the reviewed studies expanded situations theory within the
context of a system of systems that result in three major conjectures that can
be beneficial to the design and development of future systems of systems.",2024-06-07,2024,2024-06,environment
Massively Multiagent Minigames for Training Generalist Agents,"We present Meta MMO, a collection of many-agent minigames for use as a
reinforcement learning benchmark. Meta MMO is built on top of Neural MMO, a
massively multiagent environment that has been the subject of two previous
NeurIPS competitions. Our work expands Neural MMO with several computationally
efficient minigames. We explore generalization across Meta MMO by learning to
play several minigames with a single set of weights. We release the
environment, baselines, and training code under the MIT license. We hope that
Meta MMO will spur additional progress on Neural MMO and, more generally, will
serve as a useful benchmark for many-agent generalization.",2024-06-07,2024,2024-06,environment
"PufferLib: Making Reinforcement Learning Libraries and Environments Play
  Nice","You have an environment, a model, and a reinforcement learning library that
are designed to work together but don't. PufferLib makes them play nice. The
library provides one-line environment wrappers that eliminate common
compatibility problems and fast vectorization to accelerate training. With
PufferLib, you can use familiar libraries like CleanRL and SB3 to scale from
classic benchmarks like Atari and Procgen to complex simulators like NetHack
and Neural MMO. We release pip packages and prebuilt images with dependencies
for dozens of environments. All of our code is free and open-source software
under the MIT license, complete with baselines, documentation, and support at
pufferai.github.io.",2024-06-11,2024,2024-06,environment
"Comment on paper: Position: Rethinking Post-Hoc Search-Based Neural
  Approaches for Solving Large-Scale Traveling Salesman Problems","We identify two major issues in the SoftDist paper (Xia et al.): (1) the
failure to run all steps of different baselines on the same hardware
environment, and (2) the use of inconsistent time measurements when comparing
to other baselines. These issues lead to flawed conclusions. When all steps are
executed in the same hardware environment, the primary claim made in SoftDist
is no longer supported.",2024-06-11,2024,2024-06,environment
"Classical and Quantum Physical Reservoir Computing for Onboard
  Artificial Intelligence Systems: A Perspective","Artificial intelligence (AI) systems of autonomous systems such as drones,
robots and self-driving cars may consume up to 50% of total power available
onboard, thereby limiting the vehicle's range of functions and considerably
reducing the distance the vehicle can travel on a single charge.
Next-generation onboard AI systems need an even higher power since they collect
and process even larger amounts of data in real time. This problem cannot be
solved using the traditional computing devices since they become more and more
power-consuming. In this review article, we discuss the perspectives of
development of onboard neuromorphic computers that mimic the operation of a
biological brain using nonlinear-dynamical properties of natural physical
environments surrounding autonomous vehicles. Previous research also
demonstrated that quantum neuromorphic processors (QNPs) can conduct
computations with the efficiency of a standard computer while consuming less
than 1% of the onboard battery power. Since QNPs is a semi-classical
technology, their technical simplicity and low, compared with quantum
computers, cost make them ideally suitable for application in autonomous AI
system. Providing a perspective view on the future progress in unconventional
physical reservoir computing and surveying the outcomes of more than 200
interdisciplinary research works, this article will be of interest to a broad
readership, including both students and experts in the fields of physics,
engineering, quantum technologies and computing.",2024-06-14,2024,2024-06,environment
"Orangutan: A Multiscale Brain Emulation-Based Artificial Intelligence
  Framework for Dynamic Environments","Achieving General Artificial Intelligence (AGI) has long been a grand
challenge in the field of AI, and brain-inspired computing is widely
acknowledged as one of the most promising approaches to realize this goal. This
paper introduces a novel brain-inspired AI framework, Orangutan. It simulates
the structure and computational mechanisms of biological brains on multiple
scales, encompassing multi-compartment neuron architectures, diverse synaptic
connection modalities, neural microcircuits, cortical columns, and brain
regions, as well as biochemical processes including facilitation, feedforward
inhibition, short-term potentiation, and short-term depression, all grounded in
solid neuroscience. Building upon these highly integrated brain-like
mechanisms, I have developed a sensorimotor model that simulates human saccadic
eye movements during object observation. The model's algorithmic efficacy was
validated through testing with the observation of handwritten digit images.",2024-06-18,2024,2024-06,environment
"Generative Artificial Intelligence-Guided User Studies: An Application
  for Air Taxi Services","User studies are crucial for meeting user needs. In user studies, real
experimental scenarios and participants are constructed and recruited. However,
emerging and unfamiliar studies face limitations, including safety concerns and
iterative efficiency. To address these challenges, this study utilises a
Generative Artificial Intelligence (GenAI) to create GenAI-generated scenarios
for user experience (UX). By recruiting real users to evaluate this experience,
we can collect feedback that enables rapid iteration in the early design phase.
The air taxi is particularly representative of these challenges and has been
chosen as the case study for this research. The key contribution was designing
an Air Taxi Journey (ATJ) using Large Language Models (LLMs) and AI image and
video generators. Based on the GPT-4-generated scripts, key visuals were
created for the air taxi, and the ATJ was evaluated by 72 participants.
Furthermore, the LLMs demonstrated the ability to identify and suggest
environments that significantly improve participants' willingness toward air
taxis. Education level and gender significantly influenced participants' the
difference in willingness and their satisfaction with the ATJ. Satisfaction
with the ATJ serves as a mediator, significantly influencing participants'
willingness to take air taxis. Our study confirms the capability of GenAI to
support user studies, providing a feasible approach and valuable insights for
designing air taxi UX in the early design phase.",2024-06-18,2024,2024-06,environment
CoDreamer: Communication-Based Decentralised World Models,"Sample efficiency is a critical challenge in reinforcement learning.
Model-based RL has emerged as a solution, but its application has largely been
confined to single-agent scenarios. In this work, we introduce CoDreamer, an
extension of the Dreamer algorithm for multi-agent environments. CoDreamer
leverages Graph Neural Networks for a two-level communication system to tackle
challenges such as partial observability and inter-agent cooperation.
Communication is separately utilised within the learned world models and within
the learned policies of each agent to enhance modelling and task-solving. We
show that CoDreamer offers greater expressive power than a naive application of
Dreamer, and we demonstrate its superiority over baseline methods across
various multi-agent environments.",2024-06-19,2024,2024-06,environment
"Tradeoffs When Considering Deep Reinforcement Learning for Contingency
  Management in Advanced Air Mobility","Air transportation is undergoing a rapid evolution globally with the
introduction of Advanced Air Mobility (AAM) and with it comes novel challenges
and opportunities for transforming aviation. As AAM operations introduce
increasing heterogeneity in vehicle capabilities and density, increased levels
of automation are likely necessary to achieve operational safety and efficiency
goals. This paper focuses on one example where increased automation has been
suggested. Autonomous operations will need contingency management systems that
can monitor evolving risk across a span of interrelated (or interdependent)
hazards and, if necessary, execute appropriate control interventions via
supervised or automated decision making. Accommodating this complex environment
may require automated functions (autonomy) that apply artificial intelligence
(AI) techniques that can adapt and respond to a quickly changing environment.
This paper explores the use of Deep Reinforcement Learning (DRL) which has
shown promising performance in complex and high-dimensional environments where
the objective can be constructed as a sequential decision-making problem. An
extension of a prior formulation of the contingency management problem as a
Markov Decision Process (MDP) is presented and uses a DRL framework to train
agents that mitigate hazards present in the simulation environment. A
comparison of these learning-based agents and classical techniques is presented
in terms of their performance, verification difficulties, and development
process.",2024-06-28,2024,2024-06,environment
"Craftium: An Extensible Framework for Creating Reinforcement Learning
  Environments","Most Reinforcement Learning (RL) environments are created by adapting
existing physics simulators or video games. However, they usually lack the
flexibility required for analyzing specific characteristics of RL methods often
relevant to research. This paper presents Craftium, a novel framework for
exploring and creating rich 3D visual RL environments that builds upon the
Minetest game engine and the popular Gymnasium API. Minetest is built to be
extended and can be used to easily create voxel-based 3D environments (often
similar to Minecraft), while Gymnasium offers a simple and common interface for
RL research. Craftium provides a platform that allows practitioners to create
fully customized environments to suit their specific research requirements,
ranging from simple visual tasks to infinite and procedurally generated worlds.
We also provide five ready-to-use environments for benchmarking and as examples
of how to develop new ones. The code and documentation are available at
https://github.com/mikelma/craftium/.",2024-07-04,2024,2024-07,environment
"Explorative Imitation Learning: A Path Signature Approach for Continuous
  Environments","Some imitation learning methods combine behavioural cloning with
self-supervision to infer actions from state pairs. However, most rely on a
large number of expert trajectories to increase generalisation and human
intervention to capture key aspects of the problem, such as domain constraints.
In this paper, we propose Continuous Imitation Learning from Observation
(CILO), a new method augmenting imitation learning with two important features:
(i) exploration, allowing for more diverse state transitions, requiring less
expert trajectories and resulting in fewer training iterations; and (ii) path
signatures, allowing for automatic encoding of constraints, through the
creation of non-parametric representations of agents and expert trajectories.
We compared CILO with a baseline and two leading imitation learning methods in
five environments. It had the best overall performance of all methods in all
environments, outperforming the expert in two of them.",2024-07-05,2024,2024-07,environment
"Efficiently Training Neural Networks for Imperfect Information Games by
  Sampling Information Sets","In imperfect information games, the evaluation of a game state not only
depends on the observable world but also relies on hidden parts of the
environment. As accessing the obstructed information trivialises state
evaluations, one approach to tackle such problems is to estimate the value of
the imperfect state as a combination of all states in the information set,
i.e., all possible states that are consistent with the current imperfect
information. In this work, the goal is to learn a function that maps from the
imperfect game information state to its expected value. However, constructing a
perfect training set, i.e. an enumeration of the whole information set for
numerous imperfect states, is often infeasible. To compute the expected values
for an imperfect information game like \textit{Reconnaissance Blind Chess}, one
would need to evaluate thousands of chess positions just to obtain the training
target for a single state. Still, the expected value of a state can already be
approximated with appropriate accuracy from a much smaller set of evaluations.
Thus, in this paper, we empirically investigate how a budget of perfect
information game evaluations should be distributed among training samples to
maximise the return. Our results show that sampling a small number of states,
in our experiments roughly 3, for a larger number of separate positions is
preferable over repeatedly sampling a smaller quantity of states. Thus, we find
that in our case, the quantity of different samples seems to be more important
than higher target quality.",2024-07-08,2024,2024-07,environment
"Industrial-Grade Time-Dependent Counterfactual Root Cause Analysis
  through the Unanticipated Point of Incipient Failure: a Proof of Concept","This paper describes the development of a counterfactual Root Cause Analysis
diagnosis approach for an industrial multivariate time series environment. It
drives the attention toward the Point of Incipient Failure, which is the moment
in time when the anomalous behavior is first observed, and where the root cause
is assumed to be found before the issue propagates. The paper presents the
elementary but essential concepts of the solution and illustrates them
experimentally on a simulated setting. Finally, it discusses avenues of
improvement for the maturity of the causal technology to meet the robustness
challenges of increasingly complex environments in the industry.",2024-07-10,2024,2024-07,environment
"Instruction Following with Goal-Conditioned Reinforcement Learning in
  Virtual Environments","In this study, we address the issue of enabling an artificial intelligence
agent to execute complex language instructions within virtual environments. In
our framework, we assume that these instructions involve intricate linguistic
structures and multiple interdependent tasks that must be navigated
successfully to achieve the desired outcomes. To effectively manage these
complexities, we propose a hierarchical framework that combines the deep
language comprehension of large language models with the adaptive
action-execution capabilities of reinforcement learning agents. The language
module (based on LLM) translates the language instruction into a high-level
action plan, which is then executed by a pre-trained reinforcement learning
agent. We have demonstrated the effectiveness of our approach in two different
environments: in IGLU, where agents are instructed to build structures, and in
Crafter, where agents perform tasks and interact with objects in the
surrounding environment according to language commands.",2024-07-12,2024,2024-07,environment
"Introducing VaDA: Novel Image Segmentation Model for Maritime Object
  Segmentation Using New Dataset","The maritime shipping industry is undergoing rapid evolution driven by
advancements in computer vision artificial intelligence (AI). Consequently,
research on AI-based object recognition models for maritime transportation is
steadily growing, leveraging advancements in sensor technology and computing
performance. However, object recognition in maritime environments faces
challenges such as light reflection, interference, intense lighting, and
various weather conditions. To address these challenges, high-performance deep
learning algorithms tailored to maritime imagery and high-quality datasets
specialized for maritime scenes are essential. Existing AI recognition models
and datasets have limited suitability for composing autonomous navigation
systems. Therefore, in this paper, we propose a Vertical and Detail Attention
(VaDA) model for maritime object segmentation and a new model evaluation
method, the Integrated Figure of Calculation Performance (IFCP), to verify its
suitability for the system in real-time. Additionally, we introduce a benchmark
maritime dataset, OASIs (Ocean AI Segmentation Initiatives) to standardize
model performance evaluation across diverse maritime environments. OASIs
dataset and details are available at our website:
https://www.navlue.com/dataset",2024-07-12,2024,2024-07,environment
"Intelligent Cross-Organizational Process Mining: A Survey and New
  Perspectives","Process mining, as a high-level field in data mining, plays a crucial role in
enhancing operational efficiency and decision-making across organizations. In
this survey paper, we delve into the growing significance and ongoing trends in
the field of process mining, advocating a specific viewpoint on its contents,
application, and development in modern businesses and process management,
particularly in cross-organizational settings. We first summarize the framework
of process mining, common industrial applications, and the latest advances
combined with artificial intelligence, such as workflow optimization,
compliance checking, and performance analysis. Then, we propose a holistic
framework for intelligent process analysis and outline initial methodologies in
cross-organizational settings, highlighting both challenges and opportunities.
This particular perspective aims to revolutionize process mining by leveraging
artificial intelligence to offer sophisticated solutions for complex,
multi-organizational data analysis. By integrating advanced machine learning
techniques, we can enhance predictive capabilities, streamline processes, and
facilitate real-time decision-making. Furthermore, we pinpoint avenues for
future investigations within the research community, encouraging the
exploration of innovative algorithms, data integration strategies, and
privacy-preserving methods to fully harness the potential of process mining in
diverse, interconnected business environments.",2024-07-15,2024,2024-07,environment
Affectively Framework: Towards Human-like Affect-Based Agents,"Game environments offer a unique opportunity for training virtual agents due
to their interactive nature, which provides diverse play traces and affect
labels. Despite their potential, no reinforcement learning framework
incorporates human affect models as part of their observation space or reward
mechanism. To address this, we present the \emph{Affectively Framework}, a set
of Open-AI Gym environments that integrate affect as part of the observation
space. This paper introduces the framework and its three game environments and
provides baseline experiments to validate its effectiveness and potential.",2024-07-25,2024,2024-07,environment
"ReALFRED: An Embodied Instruction Following Benchmark in Photo-Realistic
  Environments","Simulated virtual environments have been widely used to learn robotic agents
that perform daily household tasks. These environments encourage research
progress by far, but often provide limited object interactability, visual
appearance different from real-world environments, or relatively smaller
environment sizes. This prevents the learned models in the virtual scenes from
being readily deployable. To bridge the gap between these learning environments
and deploying (i.e., real) environments, we propose the ReALFRED benchmark that
employs real-world scenes, objects, and room layouts to learn agents to
complete household tasks by understanding free-form language instructions and
interacting with objects in large, multi-room and 3D-captured scenes.
Specifically, we extend the ALFRED benchmark with updates for larger
environmental spaces with smaller visual domain gaps. With ReALFRED, we analyze
previously crafted methods for the ALFRED benchmark and observe that they
consistently yield lower performance in all metrics, encouraging the community
to develop methods in more realistic environments. Our code and data are
publicly available.",2024-07-26,2024,2024-07,environment
"The Interpretability of Codebooks in Model-Based Reinforcement Learning
  is Limited","Interpretability of deep reinforcement learning systems could assist
operators with understanding how they interact with their environment. Vector
quantization methods -- also called codebook methods -- discretize a neural
network's latent space that is often suggested to yield emergent
interpretability. We investigate whether vector quantization in fact provides
interpretability in model-based reinforcement learning. Our experiments,
conducted in the reinforcement learning environment Crafter, show that the
codes of vector quantization models are inconsistent, have no guarantee of
uniqueness, and have a limited impact on concept disentanglement, all of which
are necessary traits for interpretability. We share insights on why vector
quantization may be fundamentally insufficient for model interpretability.",2024-07-28,2024,2024-07,environment
"Anomalous State Sequence Modeling to Enhance Safety in Reinforcement
  Learning","The deployment of artificial intelligence (AI) in decision-making
applications requires ensuring an appropriate level of safety and reliability,
particularly in changing environments that contain a large number of unknown
observations. To address this challenge, we propose a novel safe reinforcement
learning (RL) approach that utilizes an anomalous state sequence to enhance RL
safety. Our proposed solution Safe Reinforcement Learning with Anomalous State
Sequences (AnoSeqs) consists of two stages. First, we train an agent in a
non-safety-critical offline 'source' environment to collect safe state
sequences. Next, we use these safe sequences to build an anomaly detection
model that can detect potentially unsafe state sequences in a 'target'
safety-critical environment where failures can have high costs. The estimated
risk from the anomaly detection model is utilized to train a risk-averse RL
policy in the target environment; this involves adjusting the reward function
to penalize the agent for visiting anomalous states deemed unsafe by our
anomaly model. In experiments on multiple safety-critical benchmarking
environments including self-driving cars, our solution approach successfully
learns safer policies and proves that sequential anomaly detection can provide
an effective supervisory signal for training safety-aware RL agents",2024-07-29,2024,2024-07,environment
Human interaction classifier for LLM based chatbot,"This study investigates different approaches to classify human interactions
in an artificial intelligence-based environment, specifically for Applus+
IDIADA's intelligent agent AIDA. The main objective is to develop a classifier
that accurately identifies the type of interaction received (Conversation,
Services, or Document Translation) to direct requests to the appropriate
channel and provide a more specialized and efficient service. Various models
are compared, including LLM-based classifiers, KNN using Titan and Cohere
embeddings, SVM, and artificial neural networks. Results show that SVM and ANN
models with Cohere embeddings achieve the best overall performance, with
superior F1 scores and faster execution times compared to LLM-based approaches.
The study concludes that the SVM model with Cohere embeddings is the most
suitable option for classifying human interactions in the AIDA environment,
offering an optimal balance between accuracy and computational efficiency.",2024-07-31,2024,2024-07,environment
"Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain
  Agnostic Framework for Data-Driven Scientific Research","We introduce WarpSci, a domain agnostic framework designed to overcome
crucial system bottlenecks encountered in the application of reinforcement
learning to intricate environments with vast datasets featuring
high-dimensional observation or action spaces. Notably, our framework
eliminates the need for data transfer between the CPU and GPU, enabling the
concurrent execution of thousands of simulations on a single or multiple GPUs.
This high data throughput architecture proves particularly advantageous for
data-driven scientific research, where intricate environment models are
commonly essential.",2024-08-01,2024,2024-08,environment
"A Safe Exploration Strategy for Model-free Task Adaptation in
  Safety-constrained Grid Environments","Training a model-free reinforcement learning agent requires allowing the
agent to sufficiently explore the environment to search for an optimal policy.
In safety-constrained environments, utilizing unsupervised exploration or a
non-optimal policy may lead the agent to undesirable states, resulting in
outcomes that are potentially costly or hazardous for both the agent and the
environment. In this paper, we introduce a new exploration framework for
navigating the grid environments that enables model-free agents to interact
with the environment while adhering to safety constraints. Our framework
includes a pre-training phase, during which the agent learns to identify
potentially unsafe states based on both observable features and specified
safety constraints in the environment. Subsequently, a binary classification
model is trained to predict those unsafe states in new environments that
exhibit similar dynamics. This trained classifier empowers model-free agents to
determine situations in which employing random exploration or a suboptimal
policy may pose safety risks, in which case our framework prompts the agent to
follow a predefined safe policy to mitigate the potential for hazardous
consequences. We evaluated our framework on three randomly generated grid
environments and demonstrated how model-free agents can safely adapt to new
tasks and learn optimal policies for new environments. Our results indicate
that by defining an appropriate safe policy and utilizing a well-trained model
to detect unsafe states, our framework enables a model-free agent to adapt to
new tasks and environments with significantly fewer safety violations.",2024-08-02,2024,2024-08,environment
"Environment Complexity and Nash Equilibria in a Sequential Social
  Dilemma","Multi-agent reinforcement learning (MARL) methods, while effective in
zero-sum or positive-sum games, often yield suboptimal outcomes in general-sum
games where cooperation is essential for achieving globally optimal outcomes.
Matrix game social dilemmas, which abstract key aspects of general-sum
interactions, such as cooperation, risk, and trust, fail to model the temporal
and spatial dynamics characteristic of real-world scenarios. In response, our
study extends matrix game social dilemmas into more complex, higher-dimensional
MARL environments. We adapt a gridworld implementation of the Stag Hunt dilemma
to more closely match the decision-space of a one-shot matrix game while also
introducing variable environment complexity. Our findings indicate that as
complexity increases, MARL agents trained in these environments converge to
suboptimal strategies, consistent with the risk-dominant Nash equilibria
strategies found in matrix games. Our work highlights the impact of environment
complexity on achieving optimal outcomes in higher-dimensional game-theoretic
MARL environments.",2024-08-04,2024,2024-08,environment
"The Impact of Environment Configurations on the Stability of AI-Enabled
  Systems","Nowadays, software systems tend to include Artificial Intelligence (AI)
components. Changes in the operational environment have been known to
negatively impact the stability of AI-enabled software systems by causing
unintended changes in behavior. However, how an environment configuration
impacts the behavior of such systems has yet to be explored. Understanding and
quantifying the degree of instability caused by different environment settings
can help practitioners decide the best environment configuration for the most
stable AI systems. To achieve this goal, we performed experiments with eight
different combinations of three key environment variables (operating system,
Python version, and CPU architecture) on $30$ open-source AI-enabled systems
using the Travis CI platform. We determine the existence and the degree of
instability introduced by each configuration using three metrics: the output of
an AI component of the system (model performance), the time required to build
and run the system (processing time), and the cost associated with building and
running the system (expense). Our results indicate that changes in environment
configurations lead to instability across all three metrics; however, it is
observed more frequently with respect to processing time and expense rather
than model performance. For example, between Linux and MacOS, instability is
observed in 23\%, 96.67\%, and 100\% of the studied projects in model
performance, processing time, and expense, respectively. Our findings
underscore the importance of identifying the optimal combination of
configuration settings to mitigate drops in model performance and reduce the
processing time and expense before deploying an AI-enabled system.",2024-08-05,2024,2024-08,environment
Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications,"The ability of large language models (LLMs) to transform, interpret, and
comprehend vast quantities of heterogeneous data presents a significant
opportunity to enhance data-driven care delivery. However, the sensitive nature
of protected health information (PHI) raises valid concerns about data privacy
and trust in remote LLM platforms. In addition, the cost associated with
cloud-based artificial intelligence (AI) services continues to impede
widespread adoption. To address these challenges, we propose a shift in the LLM
execution environment from opaque, centralized cloud providers to a
decentralized and dynamic fog computing architecture. By executing open-weight
LLMs in more trusted environments, such as the user's edge device or a fog
layer within a local network, we aim to mitigate the privacy, trust, and
financial challenges associated with cloud-based LLMs. We further present
SpeziLLM, an open-source framework designed to facilitate rapid and seamless
leveraging of different LLM execution layers and lowering barriers to LLM
integration in digital health applications. We demonstrate SpeziLLM's broad
applicability across six digital health applications, showcasing its
versatility in various healthcare settings.",2024-08-08,2024,2024-08,environment
Detection and tracking of barchan dunes using Artificial Intelligence,"Barchans are crescent-shape dunes ubiquitous on Earth and other celestial
bodies, which are organized in barchan fields where they interact with each
other. Over the last decades, satellite images have been largely employed to
detect barchans on Earth and on the surface of Mars, with AI (Artificial
Intelligence) becoming an important tool for monitoring those bedforms.
However, automatic detection reported in previous works is limited to isolated
dunes and does not identify successfully groups of interacting barchans. In
this paper, we inquire into the automatic detection and tracking of barchans by
carrying out experiments and exploring the acquired images using AI. After
training a neural network with images from controlled experiments where complex
interactions took place between dunes, we did the same for satellite images
from Earth and Mars. We show, for the first time, that a neural network trained
properly can identify and track barchans interacting with each other in
different environments, using different image types (contrasts, colors, points
of view, resolutions, etc.), with confidence scores (accuracy) above 70%. Our
results represent a step further for automatically monitoring barchans, with
important applications for human activities on Earth, Mars and other celestial
bodies.",2024-08-14,2024,2024-08,environment
A Logic for Policy Based Resource Exchanges in Multiagent Systems,"In multiagent systems autonomous agents interact with each other to achieve
individual and collective goals. Typical interactions concern negotiation and
agreement on resource exchanges. Modeling and formalizing these agreements pose
significant challenges, particularly in capturing the dynamic behaviour of
agents, while ensuring that resources are correctly handled. Here, we propose
exchange environments as a formal setting where agents specify and obey
exchange policies, which are declarative statements about what resources they
offer and what they require in return. Furthermore, we introduce a decidable
extension of the computational fragment of linear logic as a fundamental tool
for representing exchange environments and studying their dynamics in terms of
provability.",2024-08-18,2024,2024-08,environment
"Multimodal Datasets and Benchmarks for Reasoning about Dynamic
  Spatio-Temporality in Everyday Environments","We used a 3D simulator to create artificial video data with standardized
annotations, aiming to aid in the development of Embodied AI. Our question
answering (QA) dataset measures the extent to which a robot can understand
human behavior and the environment in a home setting. Preliminary experiments
suggest our dataset is useful in measuring AI's comprehension of daily life.
\end{abstract}",2024-08-21,2024,2024-08,environment
Can Artificial Intelligence Embody Moral Values?,"The neutrality thesis holds that technology cannot be laden with values. This
long-standing view has faced critiques, but much of the argumentation against
neutrality has focused on traditional, non-smart technologies like bridges and
razors. In contrast, AI is a smart technology increasingly used in high-stakes
domains like healthcare, finance, and policing, where its decisions can cause
moral harm. In this paper, we argue that artificial intelligence, particularly
artificial agents that autonomously make decisions to pursue their goals,
challenge the neutrality thesis. Our central claim is that the computational
models underlying artificial agents can integrate representations of moral
values such as fairness, honesty and avoiding harm. We provide a conceptual
framework discussing the neutrality thesis, values, and AI. Moreover, we
examine two approaches to designing computational models of morality,
artificial conscience and ethical prompting, and present empirical evidence
from text-based game environments that artificial agents with such models
exhibit more ethical behavior compared to agents without these models. The
findings support that AI can embody moral values, which contradicts the claim
that all technologies are necessarily value-neutral.",2024-08-22,2024,2024-08,environment
Identifying the Best Arm in the Presence of Global Environment Shifts,"This paper formulates a new Best-Arm Identification problem in the
non-stationary stochastic bandits setting, where the means of all arms are
shifted in the same way due to a global influence of the environment. The aim
is to identify the unique best arm across environmental change given a fixed
total budget. While this setting can be regarded as a special case of
Adversarial Bandits or Corrupted Bandits, we demonstrate that existing
solutions tailored to those settings do not fully utilise the nature of this
global influence, and thus, do not work well in practice (despite their
theoretical guarantees). To overcome this issue, in this paper we develop a
novel selection policy that is consistent and robust in dealing with global
environmental shifts. We then propose an allocation policy, LinLUCB, which
exploits information about global shifts across all arms in each environment.
Empirical tests depict a significant improvement in our policies against other
existing methods.",2024-08-22,2024,2024-08,environment
"Localized Observation Abstraction Using Piecewise Linear Spatial Decay
  for Reinforcement Learning in Combat Simulations","In the domain of combat simulations, the training and deployment of deep
reinforcement learning (RL) agents still face substantial challenges due to the
dynamic and intricate nature of such environments. Unfortunately, as the
complexity of the scenarios and available information increases, the training
time required to achieve a certain threshold of performance does not just
increase, but often does so exponentially. This relationship underscores the
profound impact of complexity in training RL agents. This paper introduces a
novel approach that addresses this limitation in training artificial
intelligence (AI) agents using RL. Traditional RL methods have been shown to
struggle in these high-dimensional, dynamic environments due to real-world
computational constraints and the known sample inefficiency challenges of RL.
To overcome these limitations, we propose a method of localized observation
abstraction using piecewise linear spatial decay. This technique simplifies the
state space, reducing computational demands while still preserving essential
information, thereby enhancing AI training efficiency in dynamic environments
where spatial relationships are often critical. Our analysis reveals that this
localized observation approach consistently outperforms the more traditional
global observation approach across increasing scenario complexity levels. This
paper advances the research on observation abstractions for RL, illustrating
how localized observation with piecewise linear spatial decay can provide an
effective solution to large state representation challenges in dynamic
environments.",2024-08-23,2024,2024-08,environment
Environment-Centric Active Inference,"To handle unintended changes in the environment by agents, we propose an
environment-centric active inference EC-AIF in which the Markov Blanket of
active inference is defined starting from the environment. In normal active
inference, the Markov Blanket is defined starting from the agent. That is,
first the agent was defined as the entity that performs the ""action"" such as a
robot or a person, then the environment was defined as other people or objects
that are directly affected by the agent's ""action,"" and the boundary between
the agent and the environment was defined as the Markov Blanket. This
agent-centric definition does not allow the agent to respond to unintended
changes in the environment caused by factors outside of the defined
environment. In the proposed EC-AIF, there is no entity corresponding to an
agent. The environment includes all observable things, including people and
things conventionally considered to be the environment, as well as entities
that perform ""actions"" such as robots and people. Accordingly, all states,
including robots and people, are included in inference targets, eliminating
unintended changes in the environment. The EC-AIF was applied to a robot arm
and validated with an object transport task by the robot arm. The results
showed that the robot arm successfully transported objects while responding to
changes in the target position of the object and to changes in the orientation
of another robot arm.",2024-08-23,2024,2024-08,environment
"Artificial Intelligence in Education: Ethical Considerations and
  Insights from Ancient Greek Philosophy","This paper explores the ethical implications of integrating Artificial
Intelligence (AI) in educational settings, from primary schools to
universities, while drawing insights from ancient Greek philosophy to address
emerging concerns. As AI technologies increasingly influence learning
environments, they offer novel opportunities for personalized learning,
efficient assessment, and data-driven decision-making. However, these
advancements also raise critical ethical questions regarding data privacy,
algorithmic bias, student autonomy, and the changing roles of educators. This
research examines specific use cases of AI in education, analyzing both their
potential benefits and drawbacks. By revisiting the philosophical principles of
ancient Greek thinkers such as Socrates, Aristotle, and Plato, we discuss how
their writings can guide the ethical implementation of AI in modern education.
The paper argues that while AI presents significant challenges, a balanced
approach informed by classical philosophical thought can lead to an ethically
sound transformation of education. It emphasizes the evolving role of teachers
as facilitators and the importance of fostering student initiative in AI-rich
environments.",2024-09-04,2024,2024-09,environment
"Scalable Task Planning via Large Language Models and Structured World
  Representations","Planning methods struggle with computational intractability in solving
task-level problems in large-scale environments. This work explores leveraging
the commonsense knowledge encoded in LLMs to empower planning techniques to
deal with these complex scenarios. We achieve this by efficiently using LLMs to
prune irrelevant components from the planning problem's state space,
substantially simplifying its complexity. We demonstrate the efficacy of this
system through extensive experiments within a household simulation environment,
alongside real-world validation using a 7-DoF manipulator (video
https://youtu.be/6ro2UOtOQS4).",2024-09-07,2024,2024-09,environment
Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking,"Dialogue State Tracking (DST) is a key part of task-oriented dialogue
systems, identifying important information in conversations. However, its
accuracy drops significantly in spoken dialogue environments due to named
entity errors from Automatic Speech Recognition (ASR) systems. We introduce a
simple yet effective data augmentation method that targets those entities to
improve the robustness of DST model. Our novel method can control the placement
of errors using keyword-highlighted prompts while introducing phonetically
similar errors. As a result, our method generated sufficient error patterns on
keywords, leading to improved accuracy in noised and low-accuracy ASR
environments.",2024-09-10,2024,2024-09,environment
"Learning Generative Interactive Environments By Trained Agent
  Exploration","World models are increasingly pivotal in interpreting and simulating the
rules and actions of complex environments. Genie, a recent model, excels at
learning from visually diverse environments but relies on costly
human-collected data. We observe that their alternative method of using random
agents is too limited to explore the environment. We propose to improve the
model by employing reinforcement learning based agents for data generation.
This approach produces diverse datasets that enhance the model's ability to
adapt and perform well across various scenarios and realistic actions within
the environment. In this paper, we first release the model GenieRedux - an
implementation based on Genie. Additionally, we introduce GenieRedux-G, a
variant that uses the agent's readily available actions to factor out action
prediction uncertainty during validation. Our evaluation, including a
replication of the Coinrun case study, shows that GenieRedux-G achieves
superior visual fidelity and controllability using the trained agent
exploration. The proposed approach is reproducable, scalable and adaptable to
new types of environments. Our codebase is available at
https://github.com/insait-institute/GenieRedux .",2024-09-10,2024,2024-09,environment
"Online Decision MetaMorphFormer: A Casual Transformer-Based
  Reinforcement Learning Framework of Universal Embodied Intelligence","Interactive artificial intelligence in the motion control field is an
interesting topic, especially when universal knowledge is adaptive to multiple
tasks and universal environments. Despite there being increasing efforts in the
field of Reinforcement Learning (RL) with the aid of transformers, most of them
might be limited by the offline training pipeline, which prohibits exploration
and generalization abilities. To address this limitation, we propose the
framework of Online Decision MetaMorphFormer (ODM) which aims to achieve
self-awareness, environment recognition, and action planning through a unified
model architecture. Motivated by cognitive and behavioral psychology, an ODM
agent is able to learn from others, recognize the world, and practice itself
based on its own experience. ODM can also be applied to any arbitrary agent
with a multi-joint body, located in different environments, and trained with
different types of tasks using large-scale pre-trained datasets. Through the
use of pre-trained datasets, ODM can quickly warm up and learn the necessary
knowledge to perform the desired task, while the target environment continues
to reinforce the universal policy. Extensive online experiments as well as
few-shot and zero-shot environmental tests are used to verify ODM's performance
and generalization ability. The results of our study contribute to the study of
general artificial intelligence in embodied and cognitive fields. Code,
results, and video examples can be found on the website
\url{https://rlodm.github.io/odm/}.",2024-09-11,2024,2024-09,environment
Using The Concept Hierarchy for Household Action Recognition,"We propose a method to systematically represent both the static and the
dynamic components of environments, i.e. objects and agents, as well as the
changes that are happening in the environment, i.e. the actions and skills
performed by agents. Our approach, the Concept Hierarchy, provides the
necessary information for autonomous systems to represent environment states,
perform action modeling and recognition, and plan the execution of tasks.
Additionally, the hierarchical structure supports generalization and knowledge
transfer to environments. We rigorously define tasks, actions, skills, and
affordances that enable human-understandable action and skill recognition.",2024-09-13,2024,2024-09,environment
"Curricula for Learning Robust Policies with Factored State
  Representations in Changing Environments","Robust policies enable reinforcement learning agents to effectively adapt to
and operate in unpredictable, dynamic, and ever-changing real-world
environments. Factored representations, which break down complex state and
action spaces into distinct components, can improve generalization and sample
efficiency in policy learning. In this paper, we explore how the curriculum of
an agent using a factored state representation affects the robustness of the
learned policy. We experimentally demonstrate three simple curricula, such as
varying only the variable of highest regret between episodes, that can
significantly enhance policy robustness, offering practical insights for
reinforcement learning in complex environments.",2024-09-13,2024,2024-09,environment
Multi-agent Path Finding in Continuous Environment,"We address a variant of multi-agent path finding in continuous environment
(CE-MAPF), where agents move along sets of smooth curves. Collisions between
agents are resolved via avoidance in the space domain. A new Continuous
Environment Conflict-Based Search (CE-CBS) algorithm is proposed in this work.
CE-CBS combines conflict-based search (CBS) for the high-level search framework
with RRT* for low-level path planning. The CE-CBS algorithm is tested under
various settings on diverse CE-MAPF instances. Experimental results show that
CE-CBS is competitive w.r.t. to other algorithms that consider continuous
aspect in MAPF such as MAPF with continuous time.",2024-09-16,2024,2024-09,environment
"Fundamentals of legislation for autonomous artificial intelligence
  systems","The article proposes a method for forming a dedicated operational context in
course of development and implementation of autonomous corporate management
systems based on example of autonomous systems for a board of directors. The
significant part of the operational context for autonomous company management
systems is the regulatory and legal environment within which corporations
operate. In order to create a special operational context for autonomous
artificial intelligence systems, the wording of local regulatory documents can
be simultaneously presented in two versions: for use by people and for use by
autonomous systems. In this case, the artificial intelligence system will get a
well-defined operational context that allows such a system to perform functions
within the required standards. Local regulations that provide for the specifics
of the joint work of individuals and autonomous artificial intelligence systems
can create the basis of the relevant legislation governing the development and
implementation of autonomous systems.",2024-09-17,2024,2024-09,environment
Cooperative Resilience in Artificial Intelligence Multiagent Systems,"Resilience refers to the ability of systems to withstand, adapt to, and
recover from disruptive events. While studies on resilience have attracted
significant attention across various research domains, the precise definition
of this concept within the field of cooperative artificial intelligence remains
unclear. This paper addresses this gap by proposing a clear definition of
`cooperative resilience' and outlining a methodology for its quantitative
measurement. The methodology is validated in an environment with RL-based and
LLM-augmented autonomous agents, subjected to environmental changes and the
introduction of agents with unsustainable behaviors. These events are
parameterized to create various scenarios for measuring cooperative resilience.
The results highlight the crucial role of resilience metrics in analyzing how
the collective system prepares for, resists, recovers from, sustains
well-being, and transforms in the face of disruptions. These findings provide
foundational insights into the definition, measurement, and preliminary
analysis of cooperative resilience, offering significant implications for the
broader field of AI. Moreover, the methodology and metrics developed here can
be adapted to a wide range of AI applications, enhancing the reliability and
effectiveness of AI in dynamic and unpredictable environments.",2024-09-20,2024,2024-09,environment
"Optimized Monte Carlo Tree Search for Enhanced Decision Making in the
  FrozenLake Environment","Monte Carlo Tree Search (MCTS) is a powerful algorithm for solving complex
decision-making problems. This paper presents an optimized MCTS implementation
applied to the FrozenLake environment, a classic reinforcement learning task
characterized by stochastic transitions. The optimization leverages cumulative
reward and visit count tables along with the Upper Confidence Bound for Trees
(UCT) formula, resulting in efficient learning in a slippery grid world. We
benchmark our implementation against other decision-making algorithms,
including MCTS with Policy and Q-Learning, and perform a detailed comparison of
their performance. The results demonstrate that our optimized approach
effectively maximizes rewards and success rates while minimizing convergence
time, outperforming baseline methods, especially in environments with inherent
randomness.",2024-09-25,2024,2024-09,environment
"Social Conjuring: Multi-User Runtime Collaboration with AI in Building
  Virtual 3D Worlds","Generative artificial intelligence has shown promise in prompting virtual
worlds into existence, yet little attention has been given to understanding how
this process unfolds as social interaction. We present Social Conjurer, a
framework for AI-augmented dynamic 3D scene co-creation, where multiple users
collaboratively build and modify virtual worlds in real-time. Through an
expanded set of interactions, including social and tool-based engagements as
well as spatial reasoning, our framework facilitates the creation of rich,
diverse virtual environments. Findings from a preliminary user study (N=12)
provide insight into the user experience of this approach, how social contexts
shape the prompting of spatial environments, and perspective on social
applications of prompt-based 3D co-creation. In addition to highlighting the
potential of AI-supported multi-user world creation and offering new pathways
for AI-augmented creative processes in VR, this article presents a set of
implications for designing human-centered interfaces that incorporate AI models
into 3D content generation.",2024-09-30,2024,2024-09,environment
"Easydiagnos: a framework for accurate feature selection for automatic
  diagnosis in smart healthcare","The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.",2024-10-01,2024,2024-10,environment
"A transformer-based deep reinforcement learning approach to spatial
  navigation in a partially observable Morris Water Maze","Navigation is a fundamental cognitive skill extensively studied in
neuroscientific experiments and has lately gained substantial interest in
artificial intelligence research. Recreating the task solved by rodents in the
well-established Morris Water Maze (MWM) experiment, this work applies a
transformer-based architecture using deep reinforcement learning -- an approach
previously unexplored in this context -- to navigate a 2D version of the maze.
Specifically, the agent leverages a decoder-only transformer architecture
serving as a deep Q-network performing effective decision making in the
partially observable environment. We demonstrate that the proposed architecture
enables the agent to efficiently learn spatial navigation strategies,
overcoming challenges associated with a limited field of vision, corresponding
to the visual information available to a rodent in the MWM. Demonstrating the
potential of transformer-based models for enhancing navigation performance in
partially observable environments, this work suggests promising avenues for
future research in artificial agents whose behavior resembles that of
biological agents. Finally, the flexibility of the transformer architecture in
supporting varying input sequence lengths opens opportunities for gaining
increased understanding of the artificial agent's inner representation of the
environment.",2024-10-01,2024,2024-10,environment
"From Reward Shaping to Q-Shaping: Achieving Unbiased Learning with
  LLM-Guided Knowledge","Q-shaping is an extension of Q-value initialization and serves as an
alternative to reward shaping for incorporating domain knowledge to accelerate
agent training, thereby improving sample efficiency by directly shaping
Q-values. This approach is both general and robust across diverse tasks,
allowing for immediate impact assessment while guaranteeing optimality. We
evaluated Q-shaping across 20 different environments using a large language
model (LLM) as the heuristic provider. The results demonstrate that Q-shaping
significantly enhances sample efficiency, achieving a \textbf{16.87\%}
improvement over the best baseline in each environment and a \textbf{253.80\%}
improvement compared to LLM-based reward shaping methods. These findings
establish Q-shaping as a superior and unbiased alternative to conventional
reward shaping in reinforcement learning.",2024-10-02,2024,2024-10,environment
"AI Assistants for Incident Lifecycle in a Microservice Environment: A
  Systematic Literature Review","Incidents in microservice environments can be costly and challenging to
recover from due to their complexity and distributed nature. Recent
advancements in artificial intelligence (AI) offer promising solutions for
improving incident management. This paper systematically reviews primary
studies on AI assistants designed to support different phases of the incident
lifecycle. It highlights successful applications of AI, identifies gaps in
current research, and suggests future opportunities for enhancing incident
management through AI. By examining these studies, the paper aims to provide
insights into the effectiveness of AI tools and their potential to address
ongoing challenges in incident recovery.",2024-10-06,2024,2024-10,environment
"Transition of $α$-mixing in Random Iterations with Applications in
  Queuing Theory","Nonlinear time series models with exogenous regressors are essential in
econometrics, queuing theory, and machine learning, though their statistical
analysis remains incomplete. Key results, such as the law of large numbers and
the functional central limit theorem, are known for weakly dependent variables.
We demonstrate the transfer of mixing properties from the exogenous regressor
to the response via coupling arguments. Additionally, we study Markov chains in
random environments with drift and minorization conditions, even under
non-stationary environments with favorable mixing properties, and apply this
framework to single-server queuing models.",2024-10-07,2024,2024-10,environment
"Towards an Autonomous Surface Vehicle Prototype for Artificial
  Intelligence Applications of Water Quality Monitoring","The use of Autonomous Surface Vehicles, equipped with water quality sensors
and artificial vision systems, allows for a smart and adaptive deployment in
water resources environmental monitoring. This paper presents a real
implementation of a vehicle prototype that to address the use of Artificial
Intelligence algorithms and enhanced sensing techniques for water quality
monitoring. The vehicle is fully equipped with high-quality sensors to measure
water quality parameters and water depth. Furthermore, by means of a
stereo-camera, it also can detect and locate macro-plastics in real
environments by means of deep visual models, such as YOLOv5. In this paper,
experimental results, carried out in Lago Mayor (Sevilla), has been presented
as proof of the capabilities of the proposed architecture. The overall system,
and the early results obtained, are expected to provide a solid example of a
real platform useful for the water resource monitoring task, and to serve as a
real case scenario for deploying Artificial Intelligence algorithms, such as
path planning, artificial vision, etc.",2024-10-08,2024,2024-10,environment
"Impact of Artificial Intelligence on Environmental Quality through
  Technical Change: A Free Dynamic Equilibrium Approach","In the times we live in today, humanity faces unprecedented environmental
challenges. The emergence of artificial intelligence (AI) has opened new doors
in our collective efforts to address our planet's pressing problems; however,
many have doubts on the actual extent of impact that AI have on the
environment. In particular, AI also assisting dirty production is a drawback
that is largely absent from the literature. To investigate the impact of AI on
the environment, we establish mathematical models to model the economy and the
production process of goods based on outdated and advanced technologies. The
secondary results are stated in the form of lemmas, the main results are stated
in the form of theorems. From the theorems we conclude that AI may not on its
own prevent an environmental disaster, a reason of which is its concurrent
contribution to dirty production. With temporary government intervention,
however, AI is able to avert an environmental disaster.",2024-10-09,2024,2024-10,environment
"Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain
  Navigation","Model-free reinforcement learning has emerged as a powerful method for
developing robust robot control policies capable of navigating through complex
and unstructured terrains. The effectiveness of these methods hinges on two
essential elements: (1) the use of massively parallel physics simulations to
expedite policy training, and (2) an environment generator tasked with crafting
sufficiently challenging yet attainable terrains to facilitate continuous
policy improvement. Existing methods of environment generation often rely on
heuristics constrained by a set of parameters, limiting the diversity and
realism. In this work, we introduce the Adaptive Diffusion Terrain Generator
(ADTG), a novel method that leverages Denoising Diffusion Probabilistic Models
to dynamically expand existing training environments by adding more diverse and
complex terrains adaptive to the current policy. ADTG guides the diffusion
model's generation process through initial noise optimization, blending
noise-corrupted terrains from existing training environments weighted by the
policy's performance in each corresponding environment. By manipulating the
noise corruption level, ADTG seamlessly transitions between generating similar
terrains for policy fine-tuning and novel ones to expand training diversity.
Our experiments show that the policy trained by ADTG outperforms both
procedural generated and natural environments, along with popular navigation
methods.",2024-10-14,2024,2024-10,environment
"ASTM :Autonomous Smart Traffic Management System Using Artificial
  Intelligence CNN and LSTM","In the modern world, the development of Artificial Intelligence (AI) has
contributed to improvements in various areas, including automation, computer
vision, fraud detection, and more. AI can be leveraged to enhance the
efficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce
traffic congestion rates. This paper presents an Autonomous Smart Traffic
Management (STM) system that uses AI to improve traffic flow rates. The system
employs the YOLO V5 Convolutional Neural Network to detect vehicles in traffic
management images. Additionally, it predicts the number of vehicles for the
next 12 hours using a Recurrent Neural Network with Long Short-Term Memory
(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the
traffic cycle length based on these vehicle predictions, aided by AI. From the
results of the RNN-LSTM model for predicting vehicle numbers over the next 12
hours, we observe that the model predicts traffic with a Mean Squared Error
(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.
After simulating the STM system in the CARLA simulation environment, we found
that the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per
minute) is 50\% higher than the rate without STM (around 15 vehicles per
minute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5
seconds per vehicle) is 70\% lower than without STM (around 12 seconds per
vehicle). These results demonstrate that the STM system using AI can increase
traffic flow by 50\% and reduce vehicle pass delays by 70\%.",2024-10-14,2024,2024-10,environment
Privacy-Preserving Decentralized AI with Confidential Computing,"This paper addresses privacy protection in decentralized Artificial
Intelligence (AI) using Confidential Computing (CC) within the Atoma Network, a
decentralized AI platform designed for the Web3 domain. Decentralized AI
distributes AI services among multiple entities without centralized oversight,
fostering transparency and robustness. However, this structure introduces
significant privacy challenges, as sensitive assets such as proprietary models
and personal data may be exposed to untrusted participants. Cryptography-based
privacy protection techniques such as zero-knowledge machine learning (zkML)
suffers prohibitive computational overhead. To address the limitation, we
propose leveraging Confidential Computing (CC). Confidential Computing
leverages hardware-based Trusted Execution Environments (TEEs) to provide
isolation for processing sensitive data, ensuring that both model parameters
and user data remain secure, even in decentralized, potentially untrusted
environments. While TEEs face a few limitations, we believe they can bridge the
privacy gap in decentralized AI. We explore how we can integrate TEEs into
Atoma's decentralized framework.",2024-10-17,2024,2024-10,environment
Online Reinforcement Learning with Passive Memory,"This paper considers an online reinforcement learning algorithm that
leverages pre-collected data (passive memory) from the environment for online
interaction. We show that using passive memory improves performance and further
provide theoretical guarantees for regret that turns out to be near-minimax
optimal. Results show that the quality of passive memory determines
sub-optimality of the incurred regret. The proposed approach and results hold
in both continuous and discrete state-action spaces.",2024-10-18,2024,2024-10,environment
CybORG++: An Enhanced Gym for the Development of Autonomous Cyber Agents,"CybORG++ is an advanced toolkit for reinforcement learning research focused
on network defence. Building on the CAGE 2 CybORG environment, it introduces
key improvements, including enhanced debugging capabilities, refined agent
implementation support, and a streamlined environment that enables faster
training and easier customisation. Along with addressing several software bugs
from its predecessor, CybORG++ introduces MiniCAGE, a lightweight version of
CAGE 2, which improves performance dramatically, up to 1000x faster execution
in parallel iterations, without sacrificing accuracy or core functionality.
CybORG++ serves as a robust platform for developing and evaluating defensive
agents, making it a valuable resource for advancing enterprise network defence
research.",2024-10-18,2024,2024-10,environment
"Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor
  Environments","Deep Reinforcement learning (DRL) is used to enable autonomous navigation in
unknown environments. Most research assume perfect sensor data, but real-world
environments may contain natural and artificial sensor noise and denial. Here,
we present a benchmark of both well-used and emerging DRL algorithms in a
navigation task with configurable sensor denial effects. In particular, we are
interested in comparing how different DRL methods (e.g. model-free PPO vs.
model-based DreamerV3) are affected by sensor denial. We show that DreamerV3
outperforms other methods in the visual end-to-end navigation task with a
dynamic goal - and other methods are not able to learn this. Furthermore,
DreamerV3 generally outperforms other methods in sensor-denied environments. In
order to improve robustness, we use adversarial training and demonstrate an
improved performance in denied environments, although this generally comes with
a performance cost on the vanilla environments. We anticipate this benchmark of
different DRL methods and the usage of adversarial training to be a starting
point for the development of more elaborate navigation strategies that are
capable of dealing with uncertain and denied sensor readings.",2024-10-18,2024,2024-10,environment
MAC Revivo: Artificial Intelligence Paves the Way,"The vast adoption of Wi-Fi and/or Bluetooth capabilities in Internet of
Things (IoT) devices, along with the rapid growth of deployed smart devices,
has caused significant interference and congestion in the industrial,
scientific, and medical (ISM) bands. Traditional Wi-Fi Medium Access Control
(MAC) design faces significant challenges in managing increasingly complex
wireless environments while ensuring network Quality of Service (QoS)
performance. This paper explores the potential integration of advanced
Artificial Intelligence (AI) methods into the design of Wi-Fi MAC protocols. We
propose AI-MAC, an innovative approach that employs machine learning algorithms
to dynamically adapt to changing network conditions, optimize channel access,
mitigate interference, and ensure deterministic latency. By intelligently
predicting and managing interference, AI-MAC aims to provide a robust solution
for next generation of Wi-Fi networks, enabling seamless connectivity and
enhanced QoS. Our experimental results demonstrate that AI-MAC significantly
reduces both interference and latency, paving the way for more reliable and
efficient wireless communications in the increasingly crowded ISM band.",2024-10-21,2024,2024-10,environment
"DyPNIPP: Predicting Environment Dynamics for RL-based Robust Informative
  Path Planning","Informative path planning (IPP) is an important planning paradigm for various
real-world robotic applications such as environment monitoring. IPP involves
planning a path that can learn an accurate belief of the quantity of interest,
while adhering to planning constraints. Traditional IPP methods typically
require high computation time during execution, giving rise to reinforcement
learning (RL) based IPP methods. However, the existing RL-based methods do not
consider spatio-temporal environments which involve their own challenges due to
variations in environment characteristics. In this paper, we propose DyPNIPP, a
robust RL-based IPP framework, designed to operate effectively across
spatio-temporal environments with varying dynamics. To achieve this, DyPNIPP
incorporates domain randomization to train the agent across diverse
environments and introduces a dynamics prediction model to capture and adapt
the agent actions to specific environment dynamics. Our extensive experiments
in a wildfire environment demonstrate that DyPNIPP outperforms existing
RL-based IPP algorithms by significantly improving robustness and performing
across diverse environment conditions.",2024-10-22,2024,2024-10,environment
"Enhancing Two-Player Performance Through Single-Player Knowledge
  Transfer: An Empirical Study on Atari 2600 Games","Playing two-player games using reinforcement learning and self-play can be
challenging due to the complexity of two-player environments and the possible
instability in the training process. We propose that a reinforcement learning
algorithm can train more efficiently and achieve improved performance in a
two-player game if it leverages the knowledge from the single-player version of
the same game. This study examines the proposed idea in ten different Atari
2600 environments using the Atari 2600 RAM as the input state. We discuss the
advantages of using transfer learning from a single-player training process
over training in a two-player setting from scratch, and demonstrate our results
in a few measures such as training time and average total reward. We also
discuss a method of calculating RAM complexity and its relationship to
performance.",2024-10-22,2024,2024-10,environment
"PyTSC: A Unified Platform for Multi-Agent Reinforcement Learning in
  Traffic Signal Control","Multi-Agent Reinforcement Learning (MARL) presents a promising approach for
addressing the complexity of Traffic Signal Control (TSC) in urban
environments. However, existing platforms for MARL-based TSC research face
challenges such as slow simulation speeds and convoluted, difficult-to-maintain
codebases. To address these limitations, we introduce PyTSC, a robust and
flexible simulation environment that facilitates the training and evaluation of
MARL algorithms for TSC. PyTSC integrates multiple simulators, such as SUMO and
CityFlow, and offers a streamlined API, empowering researchers to explore a
broad spectrum of MARL approaches efficiently. PyTSC accelerates
experimentation and provides new opportunities for advancing intelligent
traffic management systems in real-world applications.",2024-10-23,2024,2024-10,environment
Adversarial Environment Design via Regret-Guided Diffusion Models,"Training agents that are robust to environmental changes remains a
significant challenge in deep reinforcement learning (RL). Unsupervised
environment design (UED) has recently emerged to address this issue by
generating a set of training environments tailored to the agent's capabilities.
While prior works demonstrate that UED has the potential to learn a robust
policy, their performance is constrained by the capabilities of the environment
generation. To this end, we propose a novel UED algorithm, adversarial
environment design via regret-guided diffusion models (ADD). The proposed
method guides the diffusion-based environment generator with the regret of the
agent to produce environments that the agent finds challenging but conducive to
further improvement. By exploiting the representation power of diffusion
models, ADD can directly generate adversarial environments while maintaining
the diversity of training environments, enabling the agent to effectively learn
a robust policy. Our experimental results demonstrate that the proposed method
successfully generates an instructive curriculum of environments, outperforming
UED baselines in zero-shot generalization across novel, out-of-distribution
environments. Project page: https://rllab-snu.github.io/projects/ADD",2024-10-25,2024,2024-10,environment
Generative AI for Accessible and Inclusive Extended Reality,"Artificial Intelligence-Generated Content (AIGC) has the potential to
transform how people build and interact with virtual environments. Within this
paper, we discuss potential benefits but also challenges that AIGC has for the
creation of inclusive and accessible virtual environments. Specifically, we
touch upon the decreased need for 3D modeling expertise, benefits of
symbolic-only as well as multimodal input, 3D content editing, and 3D model
accessibility as well as foundation model-specific challenges.",2024-10-31,2024,2024-10,environment
"COST CA20120 INTERACT Framework of Artificial Intelligence Based Channel
  Modeling","Accurate channel models are the prerequisite for communication-theoretic
investigations as well as system design. Channel modeling generally relies on
statistical and deterministic approaches. However, there are still significant
limits for the traditional modeling methods in terms of accuracy,
generalization ability, and computational complexity. The fundamental reason is
that establishing a quantified and accurate mapping between physical
environment and channel characteristics becomes increasing challenging for
modern communication systems. Here, in the context of COST CA20120 Action, we
evaluate and discuss the feasibility and implementation of using artificial
intelligence (AI) for channel modeling, and explore where the future of this
field lies. Firstly, we present a framework of AI-based channel modeling to
characterize complex wireless channels. Then, we highlight in detail some major
challenges and present the possible solutions: i) estimating the uncertainty of
AI-based channel predictions, ii) integrating prior knowledge of propagation to
improve generalization capabilities, and iii) interpretable AI for channel
modeling. We present and discuss illustrative numerical results to showcase the
capabilities of AI-based channel modeling.",2024-10-31,2024,2024-10,environment
"Simulation of Nanorobots with Artificial Intelligence and Reinforcement
  Learning for Advanced Cancer Cell Detection and Tracking","Nanorobots are a promising development in targeted drug delivery and the
treatment of neurological disorders, with potential for crossing the
blood-brain barrier (BBB). These small devices leverage advancements in
nanotechnology and bioengineering for precise navigation and targeted payload
delivery, particularly for conditions like brain tumors, Alzheimer's disease,
and Parkinson's disease. Recent progress in artificial intelligence (AI) and
machine learning (ML) has improved the navigation and effectiveness of
nanorobots, allowing them to detect and interact with cancer cells through
biomarker analysis. This study presents a new reinforcement learning (RL)
framework for optimizing nanorobot navigation in complex biological
environments, focusing on cancer cell detection by analyzing the concentration
gradients of surrounding biomarkers. We utilize a computer simulation model to
explore the behavior of nanorobots in a three-dimensional space with cancer
cells and biological barriers. The proposed method uses Q-learning to refine
movement strategies based on real-time biomarker concentration data, enabling
nanorobots to autonomously navigate to cancerous tissues for targeted drug
delivery. This research lays the groundwork for future laboratory experiments
and clinical applications, with implications for personalized medicine and less
invasive cancer treatments. The integration of intelligent nanorobots could
revolutionize therapeutic strategies, reducing side effects and enhancing
treatment effectiveness for cancer patients. Further research will investigate
the practical deployment of these technologies in medical settings, aiming to
unlock the full potential of nanorobotics in healthcare.",2024-11-04,2024,2024-11,environment
Eurekaverse: Environment Curriculum Generation via Large Language Models,"Recent work has demonstrated that a promising strategy for teaching robots a
wide range of complex skills is by training them on a curriculum of
progressively more challenging environments. However, developing an effective
curriculum of environment distributions currently requires significant
expertise, which must be repeated for every new domain. Our key insight is that
environments are often naturally represented as code. Thus, we probe whether
effective environment curriculum design can be achieved and automated via code
generation by large language models (LLM). In this paper, we introduce
Eurekaverse, an unsupervised environment design algorithm that uses LLMs to
sample progressively more challenging, diverse, and learnable environments for
skill training. We validate Eurekaverse's effectiveness in the domain of
quadrupedal parkour learning, in which a quadruped robot must traverse through
a variety of obstacle courses. The automatic curriculum designed by Eurekaverse
enables gradual learning of complex parkour skills in simulation and can
successfully transfer to the real-world, outperforming manual training courses
designed by humans.",2024-11-04,2024,2024-11,environment
"Evaluating Robustness of Reinforcement Learning Algorithms for
  Autonomous Shipping","Recently, there has been growing interest in autonomous shipping due to its
potential to improve maritime efficiency and safety. The use of advanced
technologies, such as artificial intelligence, can address the current
navigational and operational challenges in autonomous shipping. In particular,
inland waterway transport (IWT) presents a unique set of challenges, such as
crowded waterways and variable environmental conditions. In such dynamic
settings, the reliability and robustness of autonomous shipping solutions are
critical factors for ensuring safe operations. This paper examines the
robustness of benchmark deep reinforcement learning (RL) algorithms,
implemented for IWT within an autonomous shipping simulator, and their ability
to generate effective motion planning policies. We demonstrate that a
model-free approach can achieve an adequate policy in the simulator,
successfully navigating port environments never encountered during training. We
focus particularly on Soft-Actor Critic (SAC), which we show to be inherently
more robust to environmental disturbances compared to MuZero, a
state-of-the-art model-based RL algorithm. In this paper, we take a significant
step towards developing robust, applied RL frameworks that can be generalized
to various vessel types and navigate complex port- and inland environments and
scenarios.",2024-11-07,2024,2024-11,environment
"Development of a Human-Robot Interaction Platform for Dual-Arm Robots
  Based on ROS and Multimodal Artificial Intelligence","In this paper, we propose the development of an interactive platform between
humans and a dual-arm robotic system based on the Robot Operating System (ROS)
and a multimodal artificial intelligence model. Our proposed platform consists
of two main components: a dual-arm robotic hardware system and software that
includes image processing tasks and natural language processing using a 3D
camera and embedded computing. First, we designed and developed a dual-arm
robotic system with a positional accuracy of less than 2 cm, capable of
operating independently, performing industrial and service tasks while
simultaneously simulating and modeling the robot in the ROS environment.
Second, artificial intelligence models for image processing are integrated to
execute object picking and classification tasks with an accuracy of over 90%.
Finally, we developed remote control software using voice commands through a
natural language processing model. Experimental results demonstrate the
accuracy of the multimodal artificial intelligence model and the flexibility of
the dual-arm robotic system in interactive human environments.",2024-11-08,2024,2024-11,environment
Artificial Intelligence Ecosystem for Automating Self-Directed Teaching,"This research introduces an innovative artificial intelligence-driven
educational concept designed to optimize self-directed learning through
personalized course delivery and automated teaching assistance. The system
leverages fine-tuned AI models to create an adaptive learning environment that
encompasses customized roadmaps, automated presentation generation, and
three-dimensional modeling for complex concept visualization. By integrating
real-time virtual assistance for doubt resolution, the platform addresses the
immediate educational needs of learners while promoting autonomous learning
practices. This study explores the psychological advantages of self-directed
learning and demonstrates how AI automation can enhance educational outcomes
through personalized content delivery and interactive support mechanisms. The
research contributes to the growing field of educational technology by
presenting a comprehensive framework that combines automated content
generation, visual learning aids, and intelligent tutoring to create an
efficient, scalable solution for modern educational needs. Preliminary findings
suggest that this approach not only accommodates diverse learning styles but
also strengthens student engagement and knowledge retention through its
emphasis on self-paced, independent learning methodologies.",2024-11-11,2024,2024-11,environment
"Bio-inspired AI: Integrating Biological Complexity into Artificial
  Intelligence","The pursuit of creating artificial intelligence (AI) mirrors our longstanding
fascination with understanding our own intelligence. From the myths of Talos to
Aristotelian logic and Heron's inventions, we have sought to replicate the
marvels of the mind. While recent advances in AI hold promise, singular
approaches often fall short in capturing the essence of intelligence. This
paper explores how fundamental principles from biological
computation--particularly context-dependent, hierarchical information
processing, trial-and-error heuristics, and multi-scale organization--can guide
the design of truly intelligent systems. By examining the nuanced mechanisms of
biological intelligence, such as top-down causality and adaptive interaction
with the environment, we aim to illuminate potential limitations in artificial
constructs. Our goal is to provide a framework inspired by biological systems
for designing more adaptable and robust artificial intelligent systems.",2024-11-22,2024,2024-11,environment
Probing for Consciousness in Machines,"This study explores the potential for artificial agents to develop core
consciousness, as proposed by Antonio Damasio's theory of consciousness.
According to Damasio, the emergence of core consciousness relies on the
integration of a self model, informed by representations of emotions and
feelings, and a world model. We hypothesize that an artificial agent, trained
via reinforcement learning (RL) in a virtual environment, can develop
preliminary forms of these models as a byproduct of its primary task. The
agent's main objective is to learn to play a video game and explore the
environment. To evaluate the emergence of world and self models, we employ
probes-feedforward classifiers that use the activations of the trained agent's
neural networks to predict the spatial positions of the agent itself. Our
results demonstrate that the agent can form rudimentary world and self models,
suggesting a pathway toward developing machine consciousness. This research
provides foundational insights into the capabilities of artificial agents in
mirroring aspects of human consciousness, with implications for future
advancements in artificial intelligence.",2024-11-25,2024,2024-11,environment
"Characterized Diffusion Networks for Enhanced Autonomous Driving
  Trajectory Prediction","In this paper, we present a novel trajectory prediction model for autonomous
driving, combining a Characterized Diffusion Module and a Spatial-Temporal
Interaction Network to address the challenges posed by dynamic and
heterogeneous traffic environments. Our model enhances the accuracy and
reliability of trajectory predictions by incorporating uncertainty estimation
and complex agent interactions. Through extensive experimentation on public
datasets such as NGSIM, HighD, and MoCAD, our model significantly outperforms
existing state-of-the-art methods. We demonstrate its ability to capture the
underlying spatial-temporal dynamics of traffic scenarios and improve
prediction precision, especially in complex environments. The proposed model
showcases strong potential for application in real-world autonomous driving
systems.",2024-11-25,2024,2024-11,environment
"Publication Trends in Artificial Intelligence Conferences: The Rise of
  Super Prolific Authors","Papers published in top conferences contribute influential discoveries that
are reshaping the landscape of modern Artificial Intelligence (AI). We analyzed
87,137 papers from 11 AI conferences to examine publication trends over the
past decade. Our findings reveal a consistent increase in both the number of
papers and authors, reflecting the growing interest in AI research. We also
observed a rise in prolific researchers who publish dozens of papers at the
same conference each year. In light of this analysis, the AI research community
should consider revisiting authorship policies, addressing equity concerns, and
evaluating the workload of junior researchers to foster a more sustainable and
inclusive research environment.",2024-11-28,2024,2024-11,environment
"An Integrated Artificial Intelligence Operating System for Advanced
  Low-Altitude Aviation Applications","This paper introduces a high-performance artificial intelligence operating
system tailored for low-altitude aviation, designed to address key challenges
such as real-time task execution, computational efficiency, and seamless
modular collaboration. Built on a powerful hardware platform and leveraging the
UNIX architecture, the system implements a distributed data processing strategy
that ensures rapid and efficient synchronization across critical modules,
including vision, navigation, and perception. By adopting dynamic resource
management, it optimally allocates computational resources, such as CPU and
GPU, based on task priority and workload, ensuring high performance for
demanding tasks like real-time video processing and AI model inference.
Furthermore, the system features an advanced interrupt handling mechanism that
allows for quick responses to sudden environmental changes, such as obstacle
detection, by prioritizing critical tasks, thus improving safety and mission
success rates. Robust security measures, including data encryption, access
control, and fault tolerance, ensure the system's resilience against external
threats and its ability to recover from potential hardware or software
failures. Complementing these core features are modular components for image
analysis, multi-sensor fusion, dynamic path planning, multi-drone coordination,
and ground station monitoring. Additionally, a low-code development platform
simplifies user customization, making the system adaptable to various
mission-specific needs. This comprehensive approach ensures the system meets
the evolving demands of intelligent aviation, providing a stable, efficient,
and secure environment for complex drone operations.",2024-11-28,2024,2024-11,environment
"More complex environments may be required to discover benefits of
  lifetime learning in evolving robots","It is well known that intra-life learning, defined as an additional
controller optimization loop, is beneficial for evolving robot morphologies for
locomotion. In this work, we investigate this further by comparing it in two
different environments: an easy flat environment and a more challenging hills
environment. We show that learning is significantly more beneficial in a hilly
environment than in a flat environment and that it might be needed to evaluate
robots in a more challenging environment to see the benefits of learning.",2024-12-11,2024,2024-12,environment
Survey on safe robot control via learning,"Control systems are critical to modern technological infrastructure, spanning
industries from aerospace to healthcare. This survey explores the landscape of
safe robot learning, investigating methods that balance high-performance
control with rigorous safety constraints. By examining classical control
techniques, learning-based approaches, and embedded system design, the research
seeks to understand how robotic systems can be developed to prevent hazardous
states while maintaining optimal performance across complex operational
environments.",2024-12-16,2024,2024-12,environment
"Future Research Avenues for Artificial Intelligence in Digital Gaming:
  An Exploratory Report","Video games are a natural and synergistic application domain for artificial
intelligence (AI) systems, offering both the potential to enhance player
experience and immersion, as well as providing valuable benchmarks and virtual
environments to advance AI technologies in general. This report presents a
high-level overview of five promising research pathways for applying
state-of-the-art AI methods, particularly deep learning, to digital gaming
within the context of the current research landscape. The objective of this
work is to outline a curated, non-exhaustive list of encouraging research
directions at the intersection of AI and video games that may serve to inspire
more rigorous and comprehensive research efforts in the future. We discuss (i)
investigating large language models as core engines for game agent modelling,
(ii) using neural cellular automata for procedural game content generation,
(iii) accelerating computationally expensive in-game simulations via deep
surrogate modelling, (iv) leveraging self-supervised learning to obtain useful
video game state embeddings, and (v) training generative models of interactive
worlds using unlabelled video data. We also briefly address current technical
challenges associated with the integration of advanced deep learning systems
into video game development, and indicate key areas where further progress is
likely to be beneficial.",2024-12-18,2024,2024-12,environment
Investigating Relational State Abstraction in Collaborative MARL,"This paper explores the impact of relational state abstraction on sample
efficiency and performance in collaborative Multi-Agent Reinforcement Learning.
The proposed abstraction is based on spatial relationships in environments
where direct communication between agents is not allowed, leveraging the
ubiquity of spatial reasoning in real-world multi-agent scenarios. We introduce
MARC (Multi-Agent Relational Critic), a simple yet effective critic
architecture incorporating spatial relational inductive biases by transforming
the state into a spatial graph and processing it through a relational graph
neural network. The performance of MARC is evaluated across six collaborative
tasks, including a novel environment with heterogeneous agents. We conduct a
comprehensive empirical analysis, comparing MARC against state-of-the-art MARL
baselines, demonstrating improvements in both sample efficiency and asymptotic
performance, as well as its potential for generalization. Our findings suggest
that a minimal integration of spatial relational inductive biases as
abstraction can yield substantial benefits without requiring complex designs or
task-specific engineering. This work provides insights into the potential of
relational state abstraction to address sample efficiency, a key challenge in
MARL, offering a promising direction for developing more efficient algorithms
in spatially complex environments.",2024-12-19,2024,2024-12,environment
Towards an Environmental Ethics of Artificial Intelligence,"In recent years, much research has been dedicated to uncovering the
environmental impact of Artificial Intelligence (AI), showing that training and
deploying AI systems require large amounts of energy and resources, and the
outcomes of AI may lead to decisions and actions that may negatively impact the
environment. This new knowledge raises new ethical questions, such as: When is
it (un)justifiable to develop an AI system, and how to make design choices,
considering its environmental impact? However, so far, the environmental impact
of AI has largely escaped ethical scrutiny, as AI ethics tends to focus
strongly on themes such as transparency, privacy, safety, responsibility, and
bias. Considering the environmental impact of AI from an ethical perspective
expands the scope of AI ethics beyond an anthropocentric focus towards
including more-than-human actors such as animals and ecosystems. This paper
explores the ethical implications of the environmental impact of AI for
designing AI systems by drawing on environmental justice literature, in which
three categories of justice are distinguished, referring to three elements that
can be unjust: the distribution of benefits and burdens (distributive justice),
decision-making procedures (procedural justice), and institutionalized social
norms (justice as recognition). Based on these tenets of justice, we outline
criteria for developing environmentally just AI systems, given their ecological
impact.",2024-12-19,2024,2024-12,environment
"Generalized Back-Stepping Experience Replay in Sparse-Reward
  Environments","Back-stepping experience replay (BER) is a reinforcement learning technique
that can accelerate learning efficiency in reversible environments. BER trains
an agent with generated back-stepping transitions of collected experiences and
normal forward transitions. However, the original algorithm is designed for a
dense-reward environment that does not require complex exploration, limiting
the BER technique to demonstrate its full potential. Herein, we propose an
enhanced version of BER called Generalized BER (GBER), which extends the
original algorithm to sparse-reward environments, particularly those with
complex structures that require the agent to explore. GBER improves the
performance of BER by introducing relabeling mechanism and applying diverse
sampling strategies. We evaluate our modified version, which is based on a
goal-conditioned deep deterministic policy gradient offline learning algorithm,
across various maze navigation environments. The experimental results indicate
that the GBER algorithm can significantly boost the performance and stability
of the baseline algorithm in various sparse-reward environments, especially
those with highly structural symmetricity.",2024-12-20,2024,2024-12,environment
"A Method for the Runtime Validation of AI-based Environment Perception
  in Automated Driving System","Environment perception is a fundamental part of the dynamic driving task
executed by Autonomous Driving Systems (ADS). Artificial Intelligence
(AI)-based approaches have prevailed over classical techniques for realizing
the environment perception. Current safety-relevant standards for automotive
systems, International Organization for Standardization (ISO) 26262 and ISO
21448, assume the existence of comprehensive requirements specifications. These
specifications serve as the basis on which the functionality of an automotive
system can be rigorously tested and checked for compliance with safety
regulations. However, AI-based perception systems do not have complete
requirements specification. Instead, large datasets are used to train AI-based
perception systems. This paper presents a function monitor for the functional
runtime monitoring of a two-folded AI-based environment perception for ADS,
based respectively on camera and LiDAR sensors. To evaluate the applicability
of the function monitor, we conduct a qualitative scenario-based evaluation in
a controlled laboratory environment using a model car. The evaluation results
then are discussed to provide insights into the monitor's performance and its
suitability for real-world applications.",2024-12-21,2024,2024-12,environment
"Environment Descriptions for Usability and Generalisation in
  Reinforcement Learning","The majority of current reinforcement learning (RL) research involves
training and deploying agents in environments that are implemented by engineers
in general-purpose programming languages and more advanced frameworks such as
CUDA or JAX. This makes the application of RL to novel problems of interest
inaccessible to small organisations or private individuals with insufficient
engineering expertise. This position paper argues that, to enable more
widespread adoption of RL, it is important for the research community to shift
focus towards methodologies where environments are described in user-friendly
domain-specific or natural languages. Aside from improving the usability of RL,
such language-based environment descriptions may also provide valuable context
and boost the ability of trained agents to generalise to unseen environments
within the set of all environments that can be described in any language of
choice.",2024-12-22,2024,2024-12,environment
Exploring Flexible Scenario Generation in Godot Simulator,"Cyber-physical systems (CPS) combine cyber and physical components engineered
to make decisions and interact within dynamic environments. Ensuring the safety
of CPS is of great importance, requiring extensive testing across diverse and
complex scenarios. To generate as many testing scenarios as possible, previous
efforts have focused on describing scenarios using formal languages to generate
scenes. In this paper, we introduce an alternative approach: reconstructing
scenes inside the open-source game engine, Godot. We have developed a pipeline
that enables the reconstruction of testing scenes directly from provided images
of scenarios. These reconstructed scenes can then be deployed within simulated
environments to assess a CPS. This approach offers a scalable and flexible
solution for testing CPS in realistic environments.",2024-12-24,2024,2024-12,environment
"How Do Artificial Intelligences Think? The Three Mathematico-Cognitive
  Factors of Categorical Segmentation Operated by Synthetic Neurons","How do the synthetic neurons in language models create ""thought categories""
to segment and analyze their informational environment? What are the cognitive
characteristics, at the very level of formal neurons, of this artificial
categorical thought? Based on the mathematical nature of algebraic operations
inherent to neuronal aggregation functions, we attempt to identify
mathematico-cognitive factors that genetically shape the categorical
reconstruction of the informational world faced by artificial cognition. This
study explores these concepts through the notions of priming, attention, and
categorical phasing.",2024-12-26,2024,2024-12,environment
"Towards General Purpose Robots at Scale: Lifelong Learning and Learning
  to Use Memory","The widespread success of artificial intelligence in fields like natural
language processing and computer vision has not yet fully transferred to
robotics, where progress is hindered by the lack of large-scale training data
and the complexity of real-world tasks. To address this, many robot learning
researchers are pushing to get robots deployed at scale in everyday
unstructured environments like our homes to initiate a data flywheel. While
current robot learning systems are effective for certain short-horizon tasks,
they are not designed to autonomously operate over long time horizons in
unstructured environments. This thesis focuses on addressing two key challenges
for robots operating over long time horizons: memory and lifelong learning.
  We propose two novel methods to advance these capabilities. First, we
introduce t-DGR, a trajectory-based deep generative replay method that achieves
state-of-the-art performance on Continual World benchmarks, advancing lifelong
learning. Second, we develop a framework that leverages human demonstrations to
teach agents effective memory utilization, improving learning efficiency and
success rates on Memory Gym tasks. Finally, we discuss future directions for
achieving the lifelong learning and memory capabilities necessary for robots to
function at scale in real-world settings.",2024-12-28,2024,2024-12,environment
