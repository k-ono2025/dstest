title,summary,published,year,month,category
"Use of semantic technologies for the development of a dynamic
  trajectories generator in a Semantic Chemistry eLearning platform","ChemgaPedia is a multimedia, webbased eLearning service platform that
currently contains about 18.000 pages organized in 1.700 chapters covering the
complete bachelor studies in chemistry and related topics of chemistry,
pharmacy, and life sciences. The eLearning encyclopedia contains some 25.000
media objects and the eLearning platform provides services such as virtual and
remote labs for experiments. With up to 350.000 users per month the platform is
the most frequently used scientific educational service in the German spoken
Internet. In this demo we show the benefit of mapping the static eLearning
contents of ChemgaPedia to a Linked Data representation for Semantic Chemistry
which allows for generating dynamic eLearning paths tailored to the semantic
profiles of the users.",2010-12-07,2010,2010-12,chemistry
Local Optima Networks of the Quadratic Assignment Problem,"Using a recently proposed model for combinatorial landscapes, Local Optima
Networks (LON), we conduct a thorough analysis of two types of instances of the
Quadratic Assignment Problem (QAP). This network model is a reduction of the
landscape in which the nodes correspond to the local optima, and the edges
account for the notion of adjacency between their basins of attraction. The
model was inspired by the notion of 'inherent network' of potential energy
surfaces proposed in physical-chemistry. The local optima networks extracted
from the so called uniform and real-like QAP instances, show features clearly
distinguishing these two types of instances. Apart from a clear confirmation
that the search difficulty increases with the problem dimension, the analysis
provides new confirming evidence explaining why the real-like instances are
easier to solve exactly using heuristic search, while the uniform instances are
easier to solve approximately. Although the local optima network model is still
under development, we argue that it provides a novel view of combinatorial
landscapes, opening up the possibilities for new analytical tools and
understanding of problem difficulty in combinatorial optimization.",2011-07-21,2011,2011-07,chemistry
Ontologies for the Integration of Air Quality Models and 3D City Models,"The holistic approach to sustainable urban planning implies using different
models in an integrated way that is capable of simulating the urban system. As
the interconnection of such models is not a trivial task, one of the key
elements that may be applied is the description of the urban geometric
properties in an ""interoperable"" way. Focusing on air quality as one of the
most pronounced urban problems, the geometric aspects of a city may be
described by objects such as those defined in CityGML, so that an appropriate
air quality model can be applied for estimating the quality of the urban air on
the basis of atmospheric flow and chemistry equations.
  In this paper we first present theoretical background and motivations for the
interconnection of 3D city models and other models related to sustainable
development and urban planning. Then we present a practical experiment based on
the interconnection of CityGML with an air quality model. Our approach is based
on the creation of an ontology of air quality models and on the extension of an
ontology of urban planning process (OUPP) that acts as an ontology mediator.",2012-01-31,2012,2012-01,chemistry
"What's in an `is about' link? Chemical diagrams and the Information
  Artifact Ontology","The Information Artifact Ontology is an ontology in the domain of information
entities. Core to the definition of what it is to be an information entity is
the claim that an information entity must be `about' something, which is
encoded in an axiom expressing that all information entities are about some
entity. This axiom comes into conflict with ontological realism, since many
information entities seem to be about non-existing entities, such as
hypothetical molecules. We discuss this problem in the context of diagrams of
molecules, a kind of information entity pervasively used throughout
computational chemistry. We then propose a solution that recognizes that
information entities such as diagrams are expressions of diagrammatic
languages. In so doing, we not only address the problem of classifying diagrams
that seem to be about non-existing entities but also allow a more sophisticated
categorisation of information entities.",2012-04-21,2012,2012-04,chemistry
Design for a Darwinian Brain: Part 1. Philosophy and Neuroscience,"Physical symbol systems are needed for open-ended cognition. A good way to
understand physical symbol systems is by comparison of thought to chemistry.
Both have systematicity, productivity and compositionality. The state of the
art in cognitive architectures for open-ended cognition is critically assessed.
I conclude that a cognitive architecture that evolves symbol structures in the
brain is a promising candidate to explain open-ended cognition. Part 2 of the
paper presents such a cognitive architecture.",2013-03-28,2013,2013-03,chemistry
"Chemlambda, universality and self-multiplication","We present chemlambda (or the chemical concrete machine), an artificial
chemistry with the following properties: (a) is Turing complete, (b) has a
model of decentralized, distributed computing associated to it, (c) works at
the level of individual (artificial) molecules, subject of reversible, but
otherwise deterministic interactions with a small number of enzymes, (d)
encodes information in the geometrical structure of the molecules and not in
their numbers, (e) all interactions are purely local in space and time. This is
part of a larger project to create computing, artificial chemistry and
artificial life in a distributed context, using topological and graphical
languages.",2014-03-31,2014,2014-03,chemistry
Prediction of Radiation Fog by DNA Computing,"In this paper we propose a wet lab algorithm for prediction of radiation fog
by DNA computing. The concept of DNA computing is essentially exploited for
generating the classifier algorithm in the wet lab. The classifier is based on
a new concept of similarity based fuzzy reasoning suitable for wet lab
implementation. This new concept of similarity based fuzzy reasoning is
different from conventional approach to fuzzy reasoning based on similarity
measure and also replaces the logical aspect of classical fuzzy reasoning by
DNA chemistry. Thus, we add a new dimension to existing forms of fuzzy
reasoning by bringing it down to nanoscale. We exploit the concept of massive
parallelism of DNA computing by designing this new classifier in the wet lab.
This newly designed classifier is very much generalized in nature and apart
from prediction of radiation fog this methodology can be applied to other types
of data also. To achieve our goal we first fuzzify the given observed
parameters in a form of synthetic DNA sequence which is called fuzzy DNA and
which handles the vague concept of human reasoning.",2015-07-07,2015,2015-07,chemistry
"Enacting textual entailment and ontologies for automated essay grading
  in chemical domain","We propose a system for automated essay grading using ontologies and textual
entailment. The process of textual entailment is guided by hypotheses, which
are extracted from a domain ontology. Textual entailment checks if the truth of
the hypothesis follows from a given text. We enact textual entailment to
compare students answer to a model answer obtained from ontology. We validated
the solution against various essays written by students in the chemistry
domain.",2015-11-09,2015,2015-11,chemistry
Gated Graph Sequence Neural Networks,"Graph-structured data appears frequently in domains including chemistry,
natural language semantics, social networks, and knowledge bases. In this work,
we study feature learning techniques for graph-structured inputs. Our starting
point is previous work on Graph Neural Networks (Scarselli et al., 2009), which
we modify to use gated recurrent units and modern optimization techniques and
then extend to output sequences. The result is a flexible and broadly useful
class of neural network models that has favorable inductive biases relative to
purely sequence-based models (e.g., LSTMs) when the problem is
graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and
graph algorithm learning tasks. We then show it achieves state-of-the-art
performance on a problem from program verification, in which subgraphs need to
be matched to abstract data structures.",2015-11-17,2015,2015-11,chemistry
A Chain-Detection Algorithm for Two-Dimensional Grids,"We describe a general method of detecting valid chains or links of pieces on
a two-dimensional grid. Specifically, using the example of the chess variant
known as Switch-Side Chain-Chess (SSCC). Presently, no foolproof method of
detecting such chains in any given chess position is known and existing graph
theory, to our knowledge, is unable to fully address this problem either. We
therefore propose a solution implemented and tested using the C++ programming
language. We have been unable to find an incorrect result and therefore offer
it as the most viable solution thus far to the chain-detection problem in this
chess variant. The algorithm is also scalable, in principle, to areas beyond
two-dimensional grids such as 3D analysis and molecular chemistry.",2016-10-12,2016,2016-10,chemistry
"Theory-guided Data Science: A New Paradigm for Scientific Discovery from
  Data","Data science models, although successful in a number of commercial domains,
have had limited applicability in scientific problems involving complex
physical phenomena. Theory-guided data science (TGDS) is an emerging paradigm
that aims to leverage the wealth of scientific knowledge for improving the
effectiveness of data science models in enabling scientific discovery. The
overarching vision of TGDS is to introduce scientific consistency as an
essential component for learning generalizable models. Further, by producing
scientifically interpretable models, TGDS aims to advance our scientific
understanding by discovering novel domain insights. Indeed, the paradigm of
TGDS has started to gain prominence in a number of scientific disciplines such
as turbulence modeling, material discovery, quantum chemistry, bio-medical
science, bio-marker discovery, climate science, and hydrology. In this paper,
we formally conceptualize the paradigm of TGDS and present a taxonomy of
research themes in TGDS. We describe several approaches for integrating domain
knowledge in different research themes using illustrative examples from
different disciplines. We also highlight some of the promising avenues of novel
research for realizing the full potential of theory-guided data science.",2016-12-27,2016,2016-12,chemistry
Deep Learning for Computational Chemistry,"The rise and fall of artificial neural networks is well documented in the
scientific literature of both computer science and computational chemistry. Yet
almost two decades later, we are now seeing a resurgence of interest in deep
learning, a machine learning algorithm based on multilayer neural networks.
Within the last few years, we have seen the transformative impact of deep
learning in many domains, particularly in speech recognition and computer
vision, to the extent that the majority of expert practitioners in those field
are now regularly eschewing prior established models in favor of deep learning
models. In this review, we provide an introductory overview into the theory of
deep neural networks and their unique properties that distinguish them from
traditional machine learning algorithms used in cheminformatics. By providing
an overview of the variety of emerging applications of deep neural networks, we
highlight its ubiquity and broad applicability to a wide range of challenges in
the field, including QSAR, virtual screening, protein structure prediction,
quantum chemistry, materials design and property prediction. In reviewing the
performance of deep neural networks, we observed a consistent outperformance
against non-neural networks state-of-the-art models across disparate research
topics, and deep neural network based models often exceeded the ""glass ceiling""
expectations of their respective tasks. Coupled with the maturity of
GPU-accelerated computing for training deep neural networks and the exponential
growth of chemical data on which to train these networks on, we anticipate that
deep learning algorithms will be a valuable tool for computational chemistry.",2017-01-17,2017,2017-01,chemistry
"Towards ""AlphaChem"": Chemical Synthesis Planning with Tree Search and
  Deep Neural Network Policies","Retrosynthesis is a technique to plan the chemical synthesis of organic
molecules, for example drugs, agro- and fine chemicals. In retrosynthesis, a
search tree is built by analysing molecules recursively and dissecting them
into simpler molecular building blocks until one obtains a set of known
building blocks. The search space is intractably large, and it is difficult to
determine the value of retrosynthetic positions. Here, we propose to model
retrosynthesis as a Markov Decision Process. In combination with a Deep Neural
Network policy learned from essentially the complete published knowledge of
chemistry, Monte Carlo Tree Search (MCTS) can be used to evaluate positions. In
exploratory studies, we demonstrate that MCTS with neural network policies
outperforms the traditionally used best-first search with hand-coded
heuristics.",2017-01-31,2017,2017-01,chemistry
CLBlast: A Tuned OpenCL BLAS Library,"This work introduces CLBlast, an open-source BLAS library providing optimized
OpenCL routines to accelerate dense linear algebra for a wide variety of
devices. It is targeted at machine learning and HPC applications and thus
provides a fast matrix-multiplication routine (GEMM) to accelerate the core of
many applications (e.g. deep learning, iterative solvers, astrophysics,
computational fluid dynamics, quantum chemistry). CLBlast has five main
advantages over other OpenCL BLAS libraries: 1) it is optimized for and tested
on a large variety of OpenCL devices including less commonly used devices such
as embedded and low-power GPUs, 2) it can be explicitly tuned for specific
problem-sizes on specific hardware platforms, 3) it can perform operations in
half-precision floating-point FP16 saving bandwidth, time and energy, 4) it has
an optional CUDA back-end, 5) and it can combine multiple operations in a
single batched routine, accelerating smaller problems significantly. This paper
describes the library and demonstrates the advantages of CLBlast experimentally
for different use-cases on a wide variety of OpenCL hardware.",2017-05-12,2017,2017-05,chemistry
"Chemception: A Deep Neural Network with Minimal Chemistry Knowledge
  Matches the Performance of Expert-developed QSAR/QSPR Models","In the last few years, we have seen the transformative impact of deep
learning in many applications, particularly in speech recognition and computer
vision. Inspired by Google's Inception-ResNet deep convolutional neural network
(CNN) for image classification, we have developed ""Chemception"", a deep CNN for
the prediction of chemical properties, using just the images of 2D drawings of
molecules. We develop Chemception without providing any additional explicit
chemistry knowledge, such as basic concepts like periodicity, or advanced
features like molecular descriptors and fingerprints. We then show how
Chemception can serve as a general-purpose neural network architecture for
predicting toxicity, activity, and solvation properties when trained on a
modest database of 600 to 40,000 compounds. When compared to multi-layer
perceptron (MLP) deep neural networks trained with ECFP fingerprints,
Chemception slightly outperforms in activity and solvation prediction and
slightly underperforms in toxicity prediction. Having matched the performance
of expert-developed QSAR/QSPR deep learning models, our work demonstrates the
plausibility of using deep neural networks to assist in computational chemistry
research, where the feature engineering process is performed primarily by a
deep learning algorithm.",2017-06-20,2017,2017-06,chemistry
Learning to Plan Chemical Syntheses,"From medicines to materials, small organic molecules are indispensable for
human well-being. To plan their syntheses, chemists employ a problem solving
technique called retrosynthesis. In retrosynthesis, target molecules are
recursively transformed into increasingly simpler precursor compounds until a
set of readily available starting materials is obtained. Computer-aided
retrosynthesis would be a highly valuable tool, however, past approaches were
slow and provided results of unsatisfactory quality. Here, we employ Monte
Carlo Tree Search (MCTS) to efficiently discover retrosynthetic routes. MCTS
was combined with an expansion policy network that guides the search, and an
""in-scope"" filter network to pre-select the most promising retrosynthetic
steps. These deep neural networks were trained on 12 million reactions, which
represents essentially all reactions ever published in organic chemistry. Our
system solves almost twice as many molecules and is 30 times faster in
comparison to the traditional search method based on extracted rules and
hand-coded heuristics. Finally after a 60 year history of computer-aided
synthesis planning, chemists can no longer distinguish between routes generated
by a computer system and real routes taken from the scientific literature. We
anticipate that our method will accelerate drug and materials discovery by
assisting chemists to plan better syntheses faster, and by enabling fully
automated robot synthesis.",2017-08-14,2017,2017-08,chemistry
Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network,"The prediction of organic reaction outcomes is a fundamental problem in
computational chemistry. Since a reaction may involve hundreds of atoms, fully
exploring the space of possible transformations is intractable. The current
solution utilizes reaction templates to limit the space, but it suffers from
coverage and efficiency issues. In this paper, we propose a template-free
approach to efficiently explore the space of product molecules by first
pinpointing the reaction center -- the set of nodes and edges where graph edits
occur. Since only a small number of atoms contribute to reaction center, we can
directly enumerate candidate products. The generated candidates are scored by a
Weisfeiler-Lehman Difference Network that models high-order interactions
between changes occurring at nodes across the molecule. Our framework
outperforms the top-performing template-based approach with a 10\% margin,
while running orders of magnitude faster. Finally, we demonstrate that the
model accuracy rivals the performance of domain experts.",2017-09-13,2017,2017-09,chemistry
"How Much Chemistry Does a Deep Neural Network Need to Know to Make
  Accurate Predictions?","The meteoric rise of deep learning models in computer vision research, having
achieved human-level accuracy in image recognition tasks is firm evidence of
the impact of representation learning of deep neural networks. In the chemistry
domain, recent advances have also led to the development of similar CNN models,
such as Chemception, that is trained to predict chemical properties using
images of molecular drawings. In this work, we investigate the effects of
systematically removing and adding localized domain-specific information to the
image channels of the training data. By augmenting images with only 3
additional basic information, and without introducing any architectural
changes, we demonstrate that an augmented Chemception (AugChemception)
outperforms the original model in the prediction of toxicity, activity, and
solvation free energy. Then, by altering the information content in the images,
and examining the resulting model's performance, we also identify two distinct
learning patterns in predicting toxicity/activity as compared to solvation free
energy. These patterns suggest that Chemception is learning about its tasks in
the manner that is consistent with established knowledge. Thus, our work
demonstrates that advanced chemical knowledge is not a pre-requisite for deep
learning models to accurately predict complex chemical properties.",2017-10-05,2017,2017-10,chemistry
Distributed Kernel K-Means for Large Scale Clustering,"Clustering samples according to an effective metric and/or vector space
representation is a challenging unsupervised learning task with a wide spectrum
of applications. Among several clustering algorithms, k-means and its
kernelized version have still a wide audience because of their conceptual
simplicity and efficacy. However, the systematic application of the kernelized
version of k-means is hampered by its inherent square scaling in memory with
the number of samples. In this contribution, we devise an approximate strategy
to minimize the kernel k-means cost function in which the trade-off between
accuracy and velocity is automatically ruled by the available system memory.
Moreover, we define an ad-hoc parallelization scheme well suited for hybrid
cpu-gpu state-of-the-art parallel architectures. We proved the effectiveness
both of the approximation scheme and of the parallelization method on standard
UCI datasets and on molecular dynamics (MD) data in the realm of computational
chemistry. In this applicative domain, clustering can play a key role for both
quantitively estimating kinetics rates via Markov State Models or to give
qualitatively a human compatible summarization of the underlying chemical
phenomenon under study. For these reasons, we selected it as a valuable
real-world application scenario.",2017-10-09,2017,2017-10,chemistry
"Using Rule-Based Labels for Weak Supervised Learning: A ChemNet for
  Transferable Chemical Property Prediction","With access to large datasets, deep neural networks (DNN) have achieved
human-level accuracy in image and speech recognition tasks. However, in
chemistry, data is inherently small and fragmented. In this work, we develop an
approach of using rule-based knowledge for training ChemNet, a transferable and
generalizable deep neural network for chemical property prediction that learns
in a weak-supervised manner from large unlabeled chemical databases. When
coupled with transfer learning approaches to predict other smaller datasets for
chemical properties that it was not originally trained on, we show that
ChemNet's accuracy outperforms contemporary DNN models that were trained using
conventional supervised learning. Furthermore, we demonstrate that the ChemNet
pre-training approach is equally effective on both CNN (Chemception) and RNN
(SMILES2vec) models, indicating that this approach is network architecture
agnostic and is effective across multiple data modalities. Our results indicate
a pre-trained ChemNet that incorporates chemistry domain knowledge, enables the
development of generalizable neural networks for more accurate prediction of
novel chemical properties.",2017-12-07,2017,2017-12,chemistry
A bright future for financial agent-based models,"The history of research in finance and economics has been widely impacted by
the field of Agent-based Computational Economics (ACE). While at the same time
being popular among natural science researchers for its proximity to the
successful methods of physics and chemistry for example, the field of ACE has
also received critics by a part of the social science community for its lack of
empiricism. Yet recent trends have shifted the weights of these general
arguments and potentially given ACE a whole new range of realism. At the base
of these trends are found two present-day major scientific breakthroughs: the
steady shift of psychology towards a hard science due to the advances of
neuropsychology, and the progress of artificial intelligence and more
specifically machine learning due to increasing computational power and big
data. These two have also found common fields of study in the form of
computational neuroscience, and human-computer interaction, among others. We
outline here the main lines of a computational research study of collective
economic behavior via Agent-Based Models (ABM) or Multi-Agent System (MAS),
where each agent would be endowed with specific cognitive and behavioral biases
known to the field of neuroeconomics, and at the same time autonomously
implement rational quantitative financial strategies updated by machine
learning. We postulate that such ABMs would offer a whole new range of realism.",2018-01-24,2018,2018-01,chemistry
"Tensor field networks: Rotation- and translation-equivariant neural
  networks for 3D point clouds","We introduce tensor field neural networks, which are locally equivariant to
3D rotations, translations, and permutations of points at every layer. 3D
rotation equivariance removes the need for data augmentation to identify
features in arbitrary orientations. Our network uses filters built from
spherical harmonics; due to the mathematical consequences of this filter
choice, each layer accepts as input (and guarantees as output) scalars,
vectors, and higher-order tensors, in the geometric sense of these terms. We
demonstrate the capabilities of tensor field networks with tasks in geometry,
physics, and chemistry.",2018-02-22,2018,2018-02,chemistry
Fractal AI: A fragile theory of intelligence,"Fractal AI is a theory for general artificial intelligence. It allows
deriving new mathematical tools that constitute the foundations for a new kind
of stochastic calculus, by modelling information using cellular automaton-like
structures instead of smooth functions. In the repository included we are
presenting a new Agent, derived from the first principles of the theory, which
is capable of solving Atari games several orders of magnitude more efficiently
than other similar techniques, like Monte Carlo Tree Search. The code provided
shows how it is now possible to beat some of the current State of The Art
benchmarks on Atari games, without previous learning and using less than 1000
samples to calculate each one of the actions when standard MCTS uses 3 Million
samples. Among other things, Fractal AI makes it possible to generate a huge
database of top performing examples with a very little amount of computation
required, transforming Reinforcement Learning into a supervised problem. The
algorithm presented is capable of solving the exploration vs exploitation
dilemma on both the discrete and continuous cases, while maintaining control
over any aspect of the behaviour of the Agent. From a general approach, new
techniques presented here have direct applications to other areas such as
Non-equilibrium thermodynamics, chemistry, quantum physics, economics,
information theory, and non-linear control theory.",2018-03-13,2018,2018-03,chemistry
"Unraveling Go gaming nature by Ising Hamiltonian and common fate graphs:
  tactics and statistics","Go gaming is a struggle between adversaries, black and white simple stones,
and aim to control the most Go board territory for success. Rules are simple
but Go game fighting is highly intricate. Stones placement and interaction on
board is random-appearance, likewise interaction phenomena among basic elements
in physics thermodynamics, chemistry, biology, or social issues. We model the
Go game dynamic employing an Ising model energy function, whose interaction
coefficients reflect the application of rules and tactics to build long-term
strategies. At any step of the game, the energy function of the model assesses
the control and strength of a player over the board. A close fit between
predictions of the model with actual game's scores is obtained. AlphaGo
computer is the current top Go player, but its behavior does not wholly reveal
the Go gaming nature. The Ising function allows for precisely model the
stochastic evolutions of Go gaming patterns, so, to advance the understanding
on Go own-dynamic -beyond the player`s abilities. The analysis of the frequency
and combination of tactics shows the formation of patterns in the groups of
stones during a game, regarding the turn of each player, or if human or
computer adversaries are confronted.",2018-03-15,2018,2018-03,chemistry
"Graph Convolutional Policy Network for Goal-Directed Molecular Graph
  Generation","Generating novel graph structures that optimize given objectives while
obeying some given underlying rules is fundamental for chemistry, biology and
social science research. This is especially important in the task of molecular
graph generation, whose goal is to discover novel molecules with desired
properties such as drug-likeness and synthetic accessibility, while obeying
physical laws such as chemical valency. However, designing models to find
molecules that optimize desired properties while incorporating highly complex
and non-differentiable rules remains to be a challenging task. Here we propose
Graph Convolutional Policy Network (GCPN), a general graph convolutional
network based model for goal-directed graph generation through reinforcement
learning. The model is trained to optimize domain-specific rewards and
adversarial loss through policy gradient, and acts in an environment that
incorporates domain-specific rules. Experimental results show that GCPN can
achieve 61% improvement on chemical property optimization over state-of-the-art
baselines while resembling known molecules, and achieve 184% improvement on the
constrained property optimization task.",2018-06-07,2018,2018-06,chemistry
"Jointly learning relevant subgraph patterns and nonlinear models of
  their indicators","Classification and regression in which the inputs are graphs of arbitrary
size and shape have been paid attention in various fields such as computational
chemistry and bioinformatics. Subgraph indicators are often used as the most
fundamental features, but the number of possible subgraph patterns are
intractably large due to the combinatorial explosion. We propose a novel
efficient algorithm to jointly learn relevant subgraph patterns and nonlinear
models of their indicators. Previous methods for such joint learning of
subgraph features and models are based on search for single best subgraph
features with specific pruning and boosting procedures of adding their
indicators one by one, which result in linear models of subgraph indicators. In
contrast, the proposed approach is based on directly learning regression trees
for graph inputs using a newly derived bound of the total sum of squares for
data partitions by a given subgraph feature, and thus can learn nonlinear
models through standard gradient boosting. An illustrative example we call the
Graph-XOR problem to consider nonlinearity, numerical experiments with real
datasets, and scalability comparisons to naive approaches using explicit
pattern enumeration are also presented.",2018-07-09,2018,2018-07,chemistry
"Evaluation as a Service architecture and crowdsourced problems solving
  implemented in Optil.io platform","Reliable and trustworthy evaluation of algorithms is a challenging process.
Firstly, each algorithm has its strengths and weaknesses, and the selection of
test instances can significantly influence the assessment process. Secondly,
the measured performance of the algorithm highly depends on the test
environment architecture, i.e., CPU model, available memory, cache
configuration, operating system's kernel, and even compilation flags. Finally,
it is often difficult to compare algorithm with software prepared by other
researchers. Evaluation as a Service (EaaS) is a cloud computing architecture
that tries to make assessment process more reliable by providing online tools
and test instances dedicated to the evaluation of algorithms. One of such
platforms is Optil.io which gives the possibility to define problems, store
evaluation data and evaluate solutions submitted by researchers in almost real
time. In this paper, we briefly present this platform together with four
challenges that were organized with its support.",2018-07-14,2018,2018-07,chemistry
Optimization of Molecules via Deep Reinforcement Learning,"We present a framework, which we call Molecule Deep $Q$-Networks (MolDQN),
for molecule optimization by combining domain knowledge of chemistry and
state-of-the-art reinforcement learning techniques (double $Q$-learning and
randomized value functions). We directly define modifications on molecules,
thereby ensuring 100\% chemical validity. Further, we operate without
pre-training on any dataset to avoid possible bias from the choice of that set.
Inspired by problems faced during medicinal chemistry lead optimization, we
extend our model with multi-objective reinforcement learning, which maximizes
drug-likeness while maintaining similarity to the original molecule. We further
show the path through chemical space to achieve optimization for a molecule to
understand how the model works.",2018-10-19,2018,2018-10,chemistry
"Physics Guided RNNs for Modeling Dynamical Systems: A Case Study in
  Simulating Lake Temperature Profiles","This paper proposes a physics-guided recurrent neural network model (PGRNN)
that combines RNNs and physics-based models to leverage their complementary
strengths and improve the modeling of physical processes. Specifically, we show
that a PGRNN can improve prediction accuracy over that of physical models,
while generating outputs consistent with physical laws, and achieving good
generalizability. Standard RNNs, even when producing superior prediction
accuracy, often produce physically inconsistent results and lack
generalizability. We further enhance this approach by using a pre-training
method that leverages the simulated data from a physics-based model to address
the scarcity of observed data. The PGRNN has the flexibility to incorporate
additional physical constraints and we incorporate a density-depth
relationship. Both enhancements further improve PGRNN performance. Although we
present and evaluate this methodology in the context of modeling the dynamics
of temperature in lakes, it is applicable more widely to a range of scientific
and engineering disciplines where mechanistic (also known as process-based)
models are used, e.g., power engineering, climate science, materials science,
computational chemistry, and biomedicine.",2018-10-31,2018,2018-10,chemistry
"Multi-Label Robust Factorization Autoencoder and its Application in
  Predicting Drug-Drug Interactions","Drug-drug interactions (DDIs) are a major cause of preventable
hospitalizations and deaths. Predicting the occurrence of DDIs helps drug
safety professionals allocate investigative resources and take appropriate
regulatory action promptly. Traditional DDI prediction methods predict DDIs
based on the similarity between drugs. Recently, researchers revealed that
predictive performance can be improved by better modeling the interactions
between drug pairs with bilinear forms. However, the shallow models leveraging
bilinear forms suffer from limitations on capturing complicated nonlinear
interactions between drug pairs. To this end, we propose Multi-Label Robust
Factorization Autoencoder (abbreviated to MuLFA) for DDI prediction, which
learns a representation of interactions between drug pairs and has the
capability of characterizing complicated nonlinear interactions more precisely.
Moreover, a novel loss called CuXCov is designed to effectively learn the
parameters of MuLFA. Furthermore, the decoder is able to generate high-risk
chemical structures of drug pairs for specific DDIs, assisting pharmacists to
better understand the relationship between drug chemistry and DDI. Experimental
results on real-world datasets demonstrate that MuLFA consistently outperforms
state-of-the-art methods; particularly, it increases 21:3% predictive
performance compared to the best baseline for top 50 frequent DDIs.We also
illustrate various case studies to demonstrate the efficacy of the chemical
structures generated by MuLFA in DDI diagnosis.",2018-11-01,2018,2018-11,chemistry
"Linear and Nonlinear Identification of Dryer System Using Artificial
  Intelligence and Neural Networks","As you read these words you are using a complex biological neural network.
You have a highly interconnected set of some neurons to facilitate your
reading, breathing, motion and thinking. Each of your biological neurons, a
rich assembly of tissue and chemistry, has the complexity, if not the speed, of
a microprocessor. Some of your neural structure was with you at birth. Other
parts have been established by experience.",2018-11-16,2018,2018-11,chemistry
"ParsRec: A Novel Meta-Learning Approach to Recommending Bibliographic
  Reference Parsers","Bibliographic reference parsers extract machine-readable metadata such as
author names, title, journal, and year from bibliographic reference strings. To
extract the metadata, the parsers apply heuristics or machine learning.
However, no reference parser, and no algorithm, consistently gives the best
results in every scenario. For instance, one tool may be best in extracting
titles in ACM citation style, but only third best when APA is used. Another
tool may be best in extracting English author names, while another one is best
for noisy data (i.e. inconsistent citation styles). In this paper, which is an
extended version of our recent RecSys poster, we address the problem of
reference parsing from a recommender-systems and meta-learning perspective. We
propose ParsRec, a meta-learning based recommender-system that recommends the
potentially most effective parser for a given reference string. ParsRec
recommends one out of 10 open-source parsers: Anystyle-Parser, Biblio, CERMINE,
Citation, Citation-Parser, GROBID, ParsCit, PDFSSA4MET, Reference Tagger, and
Science Parse. We evaluate ParsRec on 105k references from chemistry. We
propose two approaches to meta-learning recommendations. The first approach
learns the best parser for an entire reference string. The second approach
learns the best parser for each metadata type in a reference string. The second
approach achieved a 2.6% increase in F1 (0.909 vs. 0.886) over the best single
parser (GROBID), reducing the false positive rate by 20.2% (0.075 vs. 0.094),
and the false negative rate by 18.9% (0.107 vs. 0.132).",2018-11-26,2018,2018-11,chemistry
"Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation
  Models","Generative models are becoming a tool of choice for exploring the molecular
space. These models learn on a large training dataset and produce novel
molecular structures with similar properties. Generated structures can be
utilized for virtual screening or training semi-supervised predictive models in
the downstream tasks. While there are plenty of generative models, it is
unclear how to compare and rank them. In this work, we introduce a benchmarking
platform called Molecular Sets (MOSES) to standardize training and comparison
of molecular generative models. MOSES provides a training and testing datasets,
and a set of metrics to evaluate the quality and diversity of generated
structures. We have implemented and compared several molecular generation
models and suggest to use our results as reference points for further
advancements in generative chemistry research. The platform and source code are
available at https://github.com/molecularsets/moses.",2018-11-29,2018,2018-11,chemistry
Tensor networks for complex quantum systems,"Tensor network states and methods have erupted in recent years. Originally
developed in the context of condensed matter physics and based on
renormalization group ideas, tensor networks lived a revival thanks to quantum
information theory and the understanding of entanglement in quantum many-body
systems. Moreover, it has been not-so-long realized that tensor network states
play a key role in other scientific disciplines, such as quantum gravity and
artificial intelligence. In this context, here we provide an overview of basic
concepts and key developments in the field. In particular, we briefly discuss
the most important tensor network structures and algorithms, together with a
sketch on advances related to global and gauge symmetries, fermions,
topological order, classification of phases, entanglement Hamiltonians,
AdS/CFT, artificial intelligence, the 2d Hubbard model, 2d quantum
antiferromagnets, conformal field theory, quantum chemistry, disordered
systems, and many-body localization.",2018-12-10,2018,2018-12,chemistry
"Design of materials properties and device performance in memristive
  systems","Future development of the modern nanoelectronics and its flagships internet
of things and artificial intelligence as well as many related applications is
largely associated with memristive elements. This technology offers a broad
spectrum of functionalities, however, it follows predominantly a
phenomenological approach and crucial challenge/limit for further development
remains variability and lack of fundamental materials' design strategy. Here we
demonstrate the vital importance of materials' purity for determining
memristors' functionalities, showing that part per million foreign elements
significantly change the performance. By appropriate choice of chemistry and
amount of doping material we can selectively enhance desired operation mode. We
highlight how dopant dependent structure and charge/potential distribution in
the space charge layers and the cell capacitance determine the device kinetics
and functions. We evidence for first time experimentally the relation between
materials properties and switching/neuromorphic performance, thus providing
rules and directions for a rational design of memristive devices.",2019-02-05,2019,2019-02,chemistry
Atomistic structure learning,"One endeavour of modern physical chemistry is to use bottom-up approaches to
design materials and drugs with desired properties. Here we introduce an
atomistic structure learning algorithm (ASLA) that utilizes a convolutional
neural network to build 2D compounds and layered structures atom by atom. The
algorithm takes no prior data or knowledge on atomic interactions but inquires
a first-principles quantum mechanical program for physical properties. Using
reinforcement learning, the algorithm accumulates knowledge of chemical
compound space for a given number and type of atoms and stores this in the
neural network, ultimately learning the blueprint for the optimal structural
arrangement of the atoms for a given target property. ASLA is demonstrated to
work on diverse problems, including grain boundaries in graphene sheets,
organic compound formation and a surface oxide structure. This approach to
structure prediction is a first step toward direct manipulation of atoms with
artificially intelligent first principles computer codes.",2019-02-27,2019,2019-02,chemistry
Accelerated Nuclear Magnetic Resonance Spectroscopy with Deep Learning,"Nuclear magnetic resonance (NMR) spectroscopy serves as an indispensable tool
in chemistry and biology but often suffers from long experimental time. We
present a proof-of-concept of application of deep learning and neural network
for high-quality, reliable, and very fast NMR spectra reconstruction from
limited experimental data. We show that the neural network training can be
achieved using solely synthetic NMR signal, which lifts the prohibiting demand
for a large volume of realistic training data usually required in the deep
learning approach.",2019-04-09,2019,2019-04,chemistry
"Exploration of Self-Propelling Droplets Using a Curiosity Driven Robotic
  Assistant","We describe a chemical robotic assistant equipped with a curiosity algorithm
(CA) that can efficiently explore the state a complex chemical system can
exhibit. The CA-robot is designed to explore formulations in an open-ended way
with no explicit optimization target. By applying the CA-robot to the study of
self-propelling multicomponent oil-in-water droplets, we are able to observe an
order of magnitude more variety of droplet behaviours than possible with a
random parameter search and given the same budget. We demonstrate that the
CA-robot enabled the discovery of a sudden and highly specific response of
droplets to slight temperature changes. Six modes of self-propelled droplets
motion were identified and classified using a time-temperature phase diagram
and probed using a variety of techniques including NMR. This work illustrates
how target free search can significantly increase the rate of unpredictable
observations leading to new discoveries with potential applications in
formulation chemistry.",2019-04-22,2019,2019-04,chemistry
From Ansätze to Z-gates: a NASA View of Quantum Computing,"For the last few years, the NASA Quantum Artificial Intelligence Laboratory
(QuAIL) has been performing research to assess the potential impact of quantum
computers on challenging computational problems relevant to future NASA
missions. A key aspect of this research is devising methods to most effectively
utilize emerging quantum computing hardware. Research questions include what
experiments on early quantum hardware would give the most insight into the
potential impact of quantum computing, the design of algorithms to explore on
such hardware, and the development of tools to minimize the quantum resource
requirements. We survey work relevant to these questions, with a particular
emphasis on our recent work in quantum algorithms and applications, in
elucidating mechanisms of quantum mechanics and their uses for quantum
computational purposes, and in simulation, compilation, and physics-inspired
classical algorithms. To our early application thrusts in planning and
scheduling, fault diagnosis, and machine learning, we add thrusts related to
robustness of communication networks and the simulation of many-body systems
for material science and chemistry. We provide a brief update on quantum
annealing work, but concentrate on gate-model quantum computing research
advances within the last couple of years.",2019-05-08,2019,2019-05,chemistry
Explainability Techniques for Graph Convolutional Networks,"Graph Networks are used to make decisions in potentially complex scenarios
but it is usually not obvious how or why they made them. In this work, we study
the explainability of Graph Network decisions using two main classes of
techniques, gradient-based and decomposition-based, on a toy dataset and a
chemistry task. Our study sets the ground for future development as well as
application to real-world problems.",2019-05-31,2019,2019-05,chemistry
"Molecular Property Prediction: A Multilevel Quantum Interactions
  Modeling Perspective","Predicting molecular properties (e.g., atomization energy) is an essential
issue in quantum chemistry, which could speed up much research progress, such
as drug designing and substance discovery. Traditional studies based on density
functional theory (DFT) in physics are proved to be time-consuming for
predicting large number of molecules. Recently, the machine learning methods,
which consider much rule-based information, have also shown potentials for this
issue. However, the complex inherent quantum interactions of molecules are
still largely underexplored by existing solutions. In this paper, we propose a
generalizable and transferable Multilevel Graph Convolutional neural Network
(MGCN) for molecular property prediction. Specifically, we represent each
molecule as a graph to preserve its internal structure. Moreover, the
well-designed hierarchical graph neural network directly extracts features from
the conformation and spatial information followed by the multilevel
interactions. As a consequence, the multilevel overall representations can be
utilized to make the prediction. Extensive experiments on both datasets of
equilibrium and off-equilibrium molecules demonstrate the effectiveness of our
model. Furthermore, the detailed results also prove that MGCN is generalizable
and transferable for the prediction.",2019-06-25,2019,2019-06,chemistry
"The Ramanujan Machine: Automatically Generated Conjectures on
  Fundamental Constants","Fundamental mathematical constants like $e$ and $\pi$ are ubiquitous in
diverse fields of science, from abstract mathematics to physics, biology and
chemistry. For centuries, new formulas relating fundamental constants have been
scarce and usually discovered sporadically. Here we propose a novel and
systematic approach that leverages algorithms for deriving mathematical
formulas for fundamental constants and help reveal their underlying structure.
Our algorithms find dozens of well-known as well as previously unknown
continued fraction representations of $\pi$, $e$, Catalan's constant, and
values of the Riemann zeta function. Two example conjectures found by our
algorithm and so far unproven are: \begin{equation*} \frac{24}{\pi^2} = 2 +
7\cdot 0\cdot 1+ \frac{8\cdot1^4}{2 + 7\cdot 1\cdot 2 + \frac{8\cdot2^4}{2 +
7\cdot 2\cdot 3 + \frac{8\cdot3^4}{2 + 7\cdot 3\cdot 4 +
\frac{8\cdot4^4}{..}}}} \quad\quad,\quad\quad \frac{8}{7 \zeta(3)} = 1\cdot 1 -
\frac{1^6}{3\cdot 7 - \frac{2^6}{5\cdot 19 - \frac{3^6}{7\cdot 37 -
\frac{4^6}{..}}}} \end{equation*} We present two algorithms that proved useful
in finding conjectures: a Meet-In-The-Middle (MITM) algorithm and a Gradient
Descent (GD) tailored to the recurrent structure of continued fractions. Both
algorithms are based on matching numerical values and thus they conjecture
formulas without providing proofs and without requiring prior knowledge on any
underlying mathematical structure. This approach is especially attractive for
constants for which no mathematical structure is known, as it reverses the
conventional approach of sequential logic in formal proofs. Instead, our work
supports a different approach for research: algorithms utilizing numerical data
to unveil mathematical structures, thus trying to play the role of intuition of
great mathematicians of the past, providing leads to new mathematical research.",2019-06-29,2019,2019-06,chemistry
"Multiple-objective Reinforcement Learning for Inverse Design and
  Identification","The aim of the inverse chemical design is to develop new molecules with given
optimized molecular properties or objectives. Recently, generative deep
learning (DL) networks are considered as the state-of-the-art in inverse
chemical design and have achieved early success in generating molecular
structures with desired properties in the pharmaceutical and material chemistry
fields. However, satisfying a large number (larger than 10 objectives) of
molecular objectives is a limitation of current generative models. To improve
the model's ability to handle a large number of molecule design objectives, we
developed a Reinforcement Learning (RL) based generative framework to optimize
chemical molecule generation. Our use of Curriculum Learning (CL) to fine-tune
the pre-trained generative network allowed the model to satisfy up to 21
objectives and increase the generative network's robustness. The experiments
show that the proposed multiple-objective RL-based generative model can
correctly identify unknown molecules with an 83 to 100 percent success rate,
compared to the baseline approach of 0 percent. Additionally, this proposed
generative model is not limited to just chemistry research challenges; we
anticipate that problems that utilize RL with multiple-objectives will benefit
from this framework.",2019-10-09,2019,2019-10,chemistry
"DEFT-FUNNEL: an open-source global optimization solver for constrained
  grey-box and black-box problems","The fast-growing need for grey-box and black-box optimization methods for
constrained global optimization problems in fields such as medicine, chemistry,
engineering and artificial intelligence, has contributed for the design of new
efficient algorithms for finding the best possible solution. In this work, we
present DEFT-FUNNEL, an open-source global optimization algorithm for general
constrained grey-box and black-box problems that belongs to the class of
trust-region sequential quadratic optimization algorithms. It extends the
previous works by Sampaio and Toint (2015, 2016) to a global optimization
solver that is able to exploit information from closed-form functions.
Polynomial interpolation models are used as surrogates for the black-box
functions and a clustering-based multistart strategy is applied for searching
for the global minima. Numerical experiments show that DEFT-FUNNEL compares
favorably with other state-of-the-art methods on two sets of benchmark
problems: one set containing problems where every function is a black box and
another set with problems where some of the functions and their derivatives are
known to the solver. The code as well as the test sets used for experiments are
available at the Github repository http://github.com/phrsampaio/deft-funnel.",2019-12-29,2019,2019-12,chemistry
"Emo-CNN for Perceiving Stress from Audio Signals: A Brain Chemistry
  Approach","Emotion plays a key role in many applications like healthcare, to gather
patients emotional behavior. There are certain emotions which are given more
importance due to their effectiveness in understanding human feelings. In this
paper, we propose an approach that models human stress from audio signals. The
research challenge in speech emotion detection is defining the very meaning of
stress and being able to categorize it in a precise manner. Supervised Machine
Learning models, including state of the art Deep Learning classification
methods, rely on the availability of clean and labelled data. One of the
problems in affective computation and emotion detection is the limited amount
of annotated data of stress. The existing labelled stress emotion datasets are
highly subjective to the perception of the annotator.
  We address the first issue of feature selection by exploiting the use of
traditional MFCC features in Convolutional Neural Network. Our experiments show
that Emo-CNN consistently and significantly outperforms the popular existing
methods over multiple datasets. It achieves 90.2% categorical accuracy on the
Emo-DB dataset. To tackle the second and the more significant problem of
subjectivity in stress labels, we use Lovheim's cube, which is a 3-dimensional
projection of emotions. The cube aims at explaining the relationship between
these neurotransmitters and the positions of emotions in 3D space. The learnt
emotion representations from the Emo-CNN are mapped to the cube using three
component PCA (Principal Component Analysis) which is then used to model human
stress. This proposed approach not only circumvents the need for labelled
stress data but also complies with the psychological theory of emotions given
by Lovheim's cube. We believe that this work is the first step towards creating
a connection between Artificial Intelligence and the chemistry of human
emotions.",2020-01-08,2020,2020-01,chemistry
"Scientific AI in materials science: a path to a sustainable and scalable
  paradigm","Recently there has been an ever-increasing trend in the use of machine
learning (ML) and artificial intelligence (AI) methods by the materials
science, condensed matter physics, and chemistry communities. This perspective
article identifies key scientific, technical, and social opportunities that the
materials community must prioritize to consistently develop and leverage
Scientific AI to provide a credible path towards the advancement of current
materials-limited technologies. Here we highlight the intersections of these
opportunities with a series of proposed paths forward. The opportunities are
roughly sorted from scientific/technical (e.g., development of robust,
physically meaningful multiscale material representations) to social (e.g.,
promoting an AI-ready workforce). The proposed paths forward range from
developing new infrastructure and capabilities to deploying them in industry
and academia. We provide a brief introduction to AI in materials science and
engineering, followed by detailed discussions of each of the opportunities and
paths forward.",2020-03-18,2020,2020-03,chemistry
Autonomous discovery in the chemical sciences part I: Progress,"This two-part review examines how automation has contributed to different
aspects of discovery in the chemical sciences. In this first part, we describe
a classification for discoveries of physical matter (molecules, materials,
devices), processes, and models and how they are unified as search problems. We
then introduce a set of questions and considerations relevant to assessing the
extent of autonomy. Finally, we describe many case studies of discoveries
accelerated by or resulting from computer assistance and automation from the
domains of synthetic chemistry, drug discovery, inorganic chemistry, and
materials science. These illustrate how rapid advancements in hardware
automation and machine learning continue to transform the nature of
experimentation and modelling.
  Part two reflects on these case studies and identifies a set of open
challenges for the field.",2020-03-30,2020,2020-03,chemistry
"Artificial chemistry experiments with chemlambda, lambda calculus,
  interaction combinators","Given a graph rewrite system, a graph G is a quine graph if it has a non-void
maximal collection of non-conflicting matches of left patterns of graphs
rewrites, such that after the parallel application of the rewrites we obtain a
graph isomorphic with G. Such graphs exhibit a metabolism, they can multiply or
they can die, when reduced by a random rewriting algorithm.
  These are introductory notes to the pages of artificial chemistry experiments
with chemlambda, lambda calculus or interaction combinators, available from the
entry page https://chemlambda.github.io/index.html . The experiments are
bundled into pages, all of them based on a library of programs, on a database
which contains hundreds of graphs and on a database of about 150 pages of text
comments and a collection of more than 200 animations, most of them which can
be re-done live, via the programs. There are links to public repositories of
other contributors to these experiments, with versions of these programs in
python, haskell, awk or javascript.",2020-03-31,2020,2020-03,chemistry
"Artificial life properties of directed interaction combinators vs.
  chemlambda","We provide a framework for experimentation at
https://mbuliga.github.io/quinegraphs/ic-vs-chem.html#icvschem with two
artificial chemistries: directed interaction combinators (dirIC, defined in
section 2) and chemlambda. We are interested if these chemistries allow for
artificial life behaviour: replication, metabolism and death.
  The main conclusion of these experiments is that graph rewrites systems which
allow conflicting rewrites are better than those which don't, as concerns their
artificial life properties. This is in contradiction with the search for good
graph rewrite systems for decentralized computing, where non-conflicting graph
rewrite systems are historically preferred.
  This continues the artificial chemistry experiments with chemlambda, lambda
calculus or interaction combinators, available from the entry page at
https://chemlambda.github.io/index.html and described in arXiv:2003.14332.",2020-05-12,2020,2020-05,chemistry
Higher-Order Explanations of Graph Neural Networks via Relevant Walks,"Graph Neural Networks (GNNs) are a popular approach for predicting graph
structured data. As GNNs tightly entangle the input graph into the neural
network structure, common explainable AI approaches are not applicable. To a
large extent, GNNs have remained black-boxes for the user so far. In this
paper, we show that GNNs can in fact be naturally explained using higher-order
expansions, i.e. by identifying groups of edges that jointly contribute to the
prediction. Practically, we find that such explanations can be extracted using
a nested attribution scheme, where existing techniques such as layer-wise
relevance propagation (LRP) can be applied at each step. The output is a
collection of walks into the input graph that are relevant for the prediction.
Our novel explanation method, which we denote by GNN-LRP, is applicable to a
broad range of graph neural networks and lets us extract practically relevant
insights on sentiment analysis of text data, structure-property relationships
in quantum chemistry, and image classification.",2020-06-05,2020,2020-06,chemistry
Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search,"Retrosynthetic planning is a critical task in organic chemistry which
identifies a series of reactions that can lead to the synthesis of a target
product. The vast number of possible chemical transformations makes the size of
the search space very big, and retrosynthetic planning is challenging even for
experienced chemists. However, existing methods either require expensive return
estimation by rollout with high variance, or optimize for search speed rather
than the quality. In this paper, we propose Retro*, a neural-based A*-like
algorithm that finds high-quality synthetic routes efficiently. It maintains
the search as an AND-OR tree, and learns a neural search bias with off-policy
data. Then guided by this neural network, it performs best-first search
efficiently during new planning episodes. Experiments on benchmark USPTO
datasets show that, our proposed method outperforms existing state-of-the-art
with respect to both the success rate and solution quality, while being more
efficient at the same time.",2020-06-29,2020,2020-06,chemistry
Machine learning for electronically excited states of molecules,"Electronically excited states of molecules are at the heart of
photochemistry, photophysics, as well as photobiology and also play a role in
material science. Their theoretical description requires highly accurate
quantum chemical calculations, which are computationally expensive. In this
review, we focus on how machine learning is employed not only to speed up such
excited-state simulations but also how this branch of artificial intelligence
can be used to advance this exciting research field in all its aspects.
Discussed applications of machine learning for excited states include
excited-state dynamics simulations, static calculations of absorption spectra,
as well as many others. In order to put these studies into context, we discuss
the promises and pitfalls of the involved machine learning techniques. Since
the latter are mostly based on quantum chemistry calculations, we also provide
a short introduction into excited-state electronic structure methods,
approaches for nonadiabatic dynamics simulations and describe tricks and
problems when using them in machine learning for excited states of molecules.",2020-07-10,2020,2020-07,chemistry
Toward the quantification of cognition,"The machinery of the human brain -- analog, probabilistic, embodied -- can be
characterized computationally, but what machinery confers what computational
powers? Any such system can be abstractly cast in terms of two computational
components: a finite state machine carrying out computational steps, whether
via currents, chemistry, or mechanics; plus a set of allowable memory
operations, typically formulated in terms of an information store that can be
read from and written to, whether via synaptic change, state transition, or
recurrent activity. Probing these mechanisms for their information content, we
can capture the difference in computational power that various systems are
capable of. Most human cognitive abilities, from perception to action to
memory, are shared with other species; we seek to characterize those (few)
capabilities that are ubiquitously present among humans and absent from other
species. Three realms of formidable constraints -- a) measurable human
cognitive abilities, b) measurable allometric anatomic brain characteristics,
and c) measurable features of specific automata and formal grammars --
illustrate remarkably sharp restrictions on human abilities, unexpectedly
confining human cognition to a specific class of automata (""nested stack""),
which are markedly below Turing machines.",2020-08-12,2020,2020-08,chemistry
"Generative chemistry: drug discovery with deep learning generative
  models","The de novo design of molecular structures using deep learning generative
models introduces an encouraging solution to drug discovery in the face of the
continuously increased cost of new drug development. From the generation of
original texts, images, and videos, to the scratching of novel molecular
structures, the incredible creativity of deep learning generative models
surprised us about the height machine intelligence can achieve. The purpose of
this paper is to review the latest advances in generative chemistry which
relies on generative modeling to expedite the drug discovery process. This
review starts with a brief history of artificial intelligence in drug discovery
to outline this emerging paradigm. Commonly used chemical databases, molecular
representations, and tools in cheminformatics and machine learning are covered
as the infrastructure for the generative chemistry. The detailed discussions on
utilizing cutting-edge generative architectures, including recurrent neural
network, variational autoencoder, adversarial autoencoder, and generative
adversarial network for compound generation are focused. Challenges and future
perspectives follow.",2020-08-20,2020,2020-08,chemistry
Shannon Entropy Rate of Hidden Markov Processes,"Hidden Markov chains are widely applied statistical models of stochastic
processes, from fundamental physics and chemistry to finance, health, and
artificial intelligence. The hidden Markov processes they generate are
notoriously complicated, however, even if the chain is finite state: no finite
expression for their Shannon entropy rate exists, as the set of their
predictive features is generically infinite. As such, to date one cannot make
general statements about how random they are nor how structured. Here, we
address the first part of this challenge by showing how to efficiently and
accurately calculate their entropy rates. We also show how this method gives
the minimal set of infinite predictive features. A sequel addresses the
challenge's second part on structure.",2020-08-29,2020,2020-08,chemistry
"On Open and Strong-Scaling Tools for Atom Probe Crystallography:
  High-Throughput Methods for Indexing Crystal Structure and Orientation","Volumetric crystal structure indexing and orientation mapping are key data
processing steps for virtually any quantitative study of spatial correlations
between the local chemistry and the microstructure of a material. For electron
and X-ray diffraction methods it is possible to develop indexing tools which
compare measured and analytically computed patterns to decode the structure and
relative orientation within local regions of interest. Consequently, a number
of numerically efficient and automated software tools exist to solve the above
characterisation tasks.
  For atom probe tomography (APT) experiments, however, the strategy of making
comparisons between measured and analytically computed patterns is less robust
because many APT datasets may contain substantial noise. Given that general
enough predictive models for such noise remain elusive, crystallography tools
for APT face several limitations: Their robustness to noise, and therefore,
their capability to identify and distinguish different crystal structures and
orientation is limited. In addition, the tools are sequential and demand
substantial manual interaction. In combination, this makes robust uncertainty
quantifying with automated high-throughput studies of the latent
crystallographic information a difficult task with APT data.
  To improve the situation, we review the existent methods and discuss how they
link to those in the diffraction communities. With this we modify some of the
APT methods to yield more robust descriptors of the atomic arrangement. We
report how this enables the development of an open-source software tool for
strong-scaling and automated identifying of crystal structure and mapping
crystal orientation in nanocrystalline APT datasets with multiple phases.",2020-09-01,2020,2020-09,chemistry
"Testing the Quantitative Spacetime Hypothesis using Artificial Narrative
  Comprehension (II) : Establishing the Geometry of Invariant Concepts, Themes,
  and Namespaces","Given a pool of observations selected from a sensor stream, input data can be
robustly represented, via a multiscale process, in terms of invariant concepts,
and themes. Applying this to episodic natural language data, one may obtain a
graph geometry associated with the decomposition, which is a direct encoding of
spacetime relationships for the events. This study contributes to an ongoing
application of the Semantic Spacetime Hypothesis, and demonstrates the
unsupervised analysis of narrative texts using inexpensive computational
methods without knowledge of linguistics. Data streams are parsed and
fractionated into small constituents, by multiscale interferometry, in the
manner of bioinformatic analysis. Fragments may then be recombined to construct
original sensory episodes---or form new narratives by a chemistry of
association and pattern reconstruction, based only on the four fundamental
spacetime relationships. There is a straightforward correspondence between
bioinformatic processes and this cognitive representation of natural language.
Features identifiable as `concepts' and `narrative themes' span three main
scales (micro, meso, and macro). Fragments of the input act as symbols in a
hierarchy of alphabets that define new effective languages at each scale.",2020-09-23,2020,2020-09,chemistry
Information Obfuscation of Graph Neural Networks,"While the advent of Graph Neural Networks (GNNs) has greatly improved node
and graph representation learning in many applications, the neighborhood
aggregation scheme exposes additional vulnerabilities to adversaries seeking to
extract node-level information about sensitive attributes. In this paper, we
study the problem of protecting sensitive attributes by information obfuscation
when learning with graph structured data. We propose a framework to locally
filter out pre-determined sensitive attributes via adversarial training with
the total variation and the Wasserstein distance. Our method creates a strong
defense against inference attacks, while only suffering small loss in task
performance. Theoretically, we analyze the effectiveness of our framework
against a worst-case adversary, and characterize an inherent trade-off between
maximizing predictive accuracy and minimizing information leakage. Experiments
across multiple datasets from recommender systems, knowledge graphs and quantum
chemistry demonstrate that the proposed approach provides a robust defense
across various graph structures and tasks, while producing competitive GNN
encoders for downstream tasks.",2020-09-28,2020,2020-09,chemistry
End-to-End Differentiable Molecular Mechanics Force Field Construction,"Molecular mechanics (MM) potentials have long been a workhorse of
computational chemistry. Leveraging accuracy and speed, these functional forms
find use in a wide variety of applications in biomolecular modeling and drug
discovery, from rapid virtual screening to detailed free energy calculations.
Traditionally, MM potentials have relied on human-curated, inflexible, and
poorly extensible discrete chemical perception rules or applying parameters to
small molecules or biopolymers, making it difficult to optimize both types and
parameters to fit quantum chemical or physical property data. Here, we propose
an alternative approach that uses graph neural networks to perceive chemical
environments, producing continuous atom embeddings from which valence and
nonbonded parameters can be predicted using invariance-preserving layers. Since
all stages are built from smooth neural functions, the entire process is
modular and end-to-end differentiable with respect to model parameters,
allowing new force fields to be easily constructed, extended, and applied to
arbitrary molecules. We show that this approach is not only sufficiently
expressive to reproduce legacy atom types, but that it can learn to accurately
reproduce and extend existing molecular mechanics force fields. Trained with
arbitrary loss functions, it can construct entirely new force fields
self-consistently applicable to both biopolymers and small molecules directly
from quantum chemical calculations, with superior fidelity than traditional
atom or parameter typing schemes. When trained on the same quantum chemical
small molecule dataset used to parameterize the openff-1.2.0 small molecule
force field augmented with a peptide dataset, the resulting espaloma model
shows superior accuracy vis-\`a-vis experiments in computing relative
alchemical free energy calculations for a popular benchmark set.",2020-10-02,2020,2020-10,chemistry
Scientific intuition inspired by machine learning generated hypotheses,"Machine learning with application to questions in the physical sciences has
become a widely used tool, successfully applied to classification, regression
and optimization tasks in many areas. Research focus mostly lies in improving
the accuracy of the machine learning models in numerical predictions, while
scientific understanding is still almost exclusively generated by human
researchers analysing numerical results and drawing conclusions. In this work,
we shift the focus on the insights and the knowledge obtained by the machine
learning models themselves. In particular, we study how it can be extracted and
used to inspire human scientists to increase their intuitions and understanding
of natural systems. We apply gradient boosting in decision trees to extract
human interpretable insights from big data sets from chemistry and physics. In
chemistry, we not only rediscover widely know rules of thumb but also find new
interesting motifs that tell us how to control solubility and energy levels of
organic molecules. At the same time, in quantum physics, we gain new
understanding on experiments for quantum entanglement. The ability to go beyond
numerics and to enter the realm of scientific insight and hypothesis generation
opens the door to use machine learning to accelerate the discovery of
conceptual understanding in some of the most challenging domains of science.",2020-10-27,2020,2020-10,chemistry
Social Chemistry 101: Learning to Reason about Social and Moral Norms,"Social norms -- the unspoken commonsense rules about acceptable social
behavior -- are crucial in understanding the underlying causes and intents of
people's actions in narratives. For example, underlying an action such as
""wanting to call cops on my neighbors"" are social norms that inform our
conduct, such as ""It is expected that you report crimes.""
  We present Social Chemistry, a new conceptual formalism to study people's
everyday social norms and moral judgments over a rich spectrum of real life
situations described in natural language. We introduce Social-Chem-101, a
large-scale corpus that catalogs 292k rules-of-thumb such as ""it is rude to run
a blender at 5am"" as the basic conceptual units. Each rule-of-thumb is further
broken down with 12 different dimensions of people's judgments, including
social judgments of good and bad, moral foundations, expected cultural
pressure, and assumed legality, which together amount to over 4.5 million
annotations of categorical labels and free-text descriptions.
  Comprehensive empirical results based on state-of-the-art neural models
demonstrate that computational modeling of social norms is a promising research
direction. Our model framework, Neural Norm Transformer, learns and generalizes
Social-Chem-101 to successfully reason about previously unseen situations,
generating relevant (and potentially novel) attribute-aware social
rules-of-thumb.",2020-11-01,2020,2020-11,chemistry
"Molecular representation learning with language models and
  domain-relevant auxiliary tasks","We apply a Transformer architecture, specifically BERT, to learn flexible and
high quality molecular representations for drug discovery problems. We study
the impact of using different combinations of self-supervised tasks for
pre-training, and present our results for the established Virtual Screening and
QSAR benchmarks. We show that: i) The selection of appropriate self-supervised
task(s) for pre-training has a significant impact on performance in subsequent
downstream tasks such as Virtual Screening. ii) Using auxiliary tasks with more
domain relevance for Chemistry, such as learning to predict calculated
molecular properties, increases the fidelity of our learnt representations.
iii) Finally, we show that molecular representations learnt by our model
`MolBert' improve upon the current state of the art on the benchmark datasets.",2020-11-26,2020,2020-11,chemistry
"Data-driven equation for drug-membrane permeability across drugs and
  membranes","Drug efficacy depends on its capacity to permeate across the cell membrane.
We consider the prediction of passive drug-membrane permeability coefficients.
Beyond the widely recognized correlation with hydrophobicity, we additionally
consider the functional relationship between passive permeation and acidity. To
discover easily interpretable equations that explain the data well, we use the
recently proposed sure-independence screening and sparsifying operator (SISSO),
an artificial-intelligence technique that combines symbolic regression with
compressed sensing. Our study is based on a large in silico dataset of 0.4
million small molecules extracted from coarse-grained simulations. We
rationalize the equation suggested by SISSO via an analysis of the
inhomogeneous solubility-diffusion model in several asymptotic acidity regimes.
We further extend our analysis to the dependence on lipid-membrane composition.
Lipid-tail unsaturation plays a key role, but surprisingly contributes stepwise
rather than proportionally. Our results are in line with previously observed
changes in permeability, suggesting the distinction between liquid-disordered
(Ld) and liquid-ordered (Lo) permeation. Together, compressed sensing with
analytically derived asymptotes establish and validate an accurate, broadly
applicable, and interpretable equation for passive permeability across both
drug and lipid-tail chemistry.",2020-12-03,2020,2020-12,chemistry
"Domain Adaptation of NMT models for English-Hindi Machine Translation
  Task at AdapMT ICON 2020","Recent advancements in Neural Machine Translation (NMT) models have proved to
produce a state of the art results on machine translation for low resource
Indian languages. This paper describes the neural machine translation systems
for the English-Hindi language presented in AdapMT Shared Task ICON 2020. The
shared task aims to build a translation system for Indian languages in specific
domains like Artificial Intelligence (AI) and Chemistry using a small in-domain
parallel corpus. We evaluated the effectiveness of two popular NMT models i.e,
LSTM, and Transformer architectures for the English-Hindi machine translation
task based on BLEU scores. We train these models primarily using the out of
domain data and employ simple domain adaptation techniques based on the
characteristics of the in-domain dataset. The fine-tuning and mixed-domain data
approaches are used for domain adaptation. Our team was ranked first in the
chemistry and general domain En-Hi translation task and second in the AI domain
En-Hi translation task.",2020-12-22,2020,2020-12,chemistry
Constraining chemical networks inAstrochemistry,"Databases of gas and surface chemical reactions are a key tool for scientists
working in a wide range of physical sciences. In Astrochemistry, databases of
chemical reactions are used as inputs to chemical models to determine the
abundances of the interstellar medium. Gas chemistry and, in particular, grain
surface chemistry and its treatment in gas-grain chemical models are however
areas of large uncertainty. Many reactions - especially on the dust grains -
have not been systematically experimentally studied. Moreover, experimental
measurements are often not easily translated to the rate equation approach most
commonly used in astrochemical modelling. Reducing the degree of uncertainty
intrinsic in these databases is therefore a prime problem, but has so far been
approached mainly by ad hoc procedures of essentially trial and error. In this
chapter we review the problem of the determination of accurate and complete
chemical networks in the wider context of Astrochemistry and explore the
possibility of using statistical methods and machine learning (ML) techniques
to reduce the uncertainty in chemical networks.",2021-01-13,2021,2021-01,chemistry
Noisy intermediate-scale quantum (NISQ) algorithms,"A universal fault-tolerant quantum computer that can solve efficiently
problems such as integer factorization and unstructured database search
requires millions of qubits with low error rates and long coherence times.
While the experimental advancement towards realizing such devices will
potentially take decades of research, noisy intermediate-scale quantum (NISQ)
computers already exist. These computers are composed of hundreds of noisy
qubits, i.e. qubits that are not error-corrected, and therefore perform
imperfect operations in a limited coherence time. In the search for quantum
advantage with these devices, algorithms have been proposed for applications in
various disciplines spanning physics, machine learning, quantum chemistry and
combinatorial optimization. The goal of such algorithms is to leverage the
limited available resources to perform classically challenging tasks. In this
review, we provide a thorough summary of NISQ computational paradigms and
algorithms. We discuss the key structure of these algorithms, their
limitations, and advantages. We additionally provide a comprehensive overview
of various benchmarking and software tools useful for programming and testing
NISQ devices.",2021-01-21,2021,2021-01,chemistry
Chemistry42: An AI-based platform for de novo molecular design,"Chemistry42 is a software platform for de novo small molecule design that
integrates Artificial Intelligence (AI) techniques with computational and
medicinal chemistry methods. Chemistry42 is unique in its ability to generate
novel molecular structures with predefined properties validated through in
vitro and in vivo studies. Chemistry42 is a core component of Insilico Medicine
Pharma.ai drug discovery suite that also includes target discovery and
multi-omics data analysis (PandaOmics) and clinical trial outcomes predictions
(InClinico).",2021-01-22,2021,2021-01,chemistry
"The 4th International Workshop on Smart Simulation and Modelling for
  Complex Systems","Computer-based modelling and simulation have become useful tools to
facilitate humans to understand systems in different domains, such as physics,
astrophysics, chemistry, biology, economics, engineering and social science. A
complex system is featured with a large number of interacting components
(agents, processes, etc.), whose aggregate activities are nonlinear and
self-organized. Complex systems are hard to be simulated or modelled by using
traditional computational approaches due to complex relationships among system
components, distributed features of resources, and dynamics of environments.
Meanwhile, smart systems such as multi-agent systems have demonstrated
advantages and great potentials in modelling and simulating complex systems.",2021-02-01,2021,2021-02,chemistry
Unassisted Noise Reduction of Chemical Reaction Data Sets,"Existing deep learning models applied to reaction prediction in organic
chemistry can reach high levels of accuracy (> 90% for Natural Language
Processing-based ones). With no chemical knowledge embedded than the
information learnt from reaction data, the quality of the data sets plays a
crucial role in the performance of the prediction models. While human curation
is prohibitively expensive, the need for unaided approaches to remove
chemically incorrect entries from existing data sets is essential to improve
artificial intelligence models' performance in synthetic chemistry tasks. Here
we propose a machine learning-based, unassisted approach to remove chemically
wrong entries from chemical reaction collections. We applied this method to the
collection of chemical reactions Pistachio and to an open data set, both
extracted from USPTO (United States Patent Office) patents. Our results show an
improved prediction quality for models trained on the cleaned and balanced data
sets. For the retrosynthetic models, the round-trip accuracy metric grows by 13
percentage points and the value of the cumulative Jensen Shannon divergence
decreases by 30% compared to its original record. The coverage remains high
with 97%, and the value of the class-diversity is not affected by the cleaning.
The proposed strategy is the first unassisted rule-free technique to address
automatic noise reduction in chemical data sets.",2021-02-02,2021,2021-02,chemistry
"A Possible Artificial Intelligence Ecosystem Avatar: the Moorea case
  (IDEA)","High-throughput data collection techniques and largescale (cloud) computing
are transforming our understanding of ecosystems at all scales by allowing the
integration of multimodal data such as physics, chemistry, biology, ecology,
fishing, economics and other social sciences in a common computational
framework. We focus in this paper on a large scale data assimilation and
prediction backbone based on Deep Stacking Networks (DSN) in the frame of the
IDEA (Island Digital Ecosystem Avatars) project (Moorea Island), based on the
subdivision of the island in watersheds and lagoon units. We also describe
several kinds of raw data that can train and constrain such an ecosystem avatar
model, as well as second level data such as ecological or physical indexes /
indicators.",2021-02-04,2021,2021-02,chemistry
Few-shot Conformal Prediction with Auxiliary Tasks,"We develop a novel approach to conformal prediction when the target task has
limited data available for training. Conformal prediction identifies a small
set of promising output candidates in place of a single prediction, with
guarantees that the set contains the correct answer with high probability. When
training data is limited, however, the predicted set can easily become unusably
large. In this work, we obtain substantially tighter prediction sets while
maintaining desirable marginal guarantees by casting conformal prediction as a
meta-learning paradigm over exchangeable collections of auxiliary tasks. Our
conformalization algorithm is simple, fast, and agnostic to the choice of
underlying model, learning algorithm, or dataset. We demonstrate the
effectiveness of this approach across a number of few-shot classification and
regression tasks in natural language processing, computer vision, and
computational chemistry for drug discovery.",2021-02-17,2021,2021-02,chemistry
Full Page Handwriting Recognition via Image to Sequence Extraction,"We present a Neural Network based Handwritten Text Recognition (HTR) model
architecture that can be trained to recognize full pages of handwritten or
printed text without image segmentation. Being based on Image to Sequence
architecture, it can extract text present in an image and then sequence it
correctly without imposing any constraints regarding orientation, layout and
size of text and non-text. Further, it can also be trained to generate
auxiliary markup related to formatting, layout and content. We use character
level vocabulary, thereby enabling language and terminology of any subject. The
model achieves a new state-of-art in paragraph level recognition on the IAM
dataset. When evaluated on scans of real world handwritten free form test
answers - beset with curved and slanted lines, drawings, tables, math,
chemistry and other symbols - it performs better than all commercially
available HTR cloud APIs. It is deployed in production as part of a commercial
web application.",2021-03-11,2021,2021-03,chemistry
"Graph Entropy Guided Node Embedding Dimension Selection for Graph Neural
  Networks","Graph representation learning has achieved great success in many areas,
including e-commerce, chemistry, biology, etc. However, the fundamental problem
of choosing the appropriate dimension of node embedding for a given graph still
remains unsolved. The commonly used strategies for Node Embedding Dimension
Selection (NEDS) based on grid search or empirical knowledge suffer from heavy
computation and poor model performance. In this paper, we revisit NEDS from the
perspective of minimum entropy principle. Subsequently, we propose a novel
Minimum Graph Entropy (MinGE) algorithm for NEDS with graph data. To be
specific, MinGE considers both feature entropy and structure entropy on graphs,
which are carefully designed according to the characteristics of the rich
information in them. The feature entropy, which assumes the embeddings of
adjacent nodes to be more similar, connects node features and link topology on
graphs. The structure entropy takes the normalized degree as basic unit to
further measure the higher-order structure of graphs. Based on them, we design
MinGE to directly calculate the ideal node embedding dimension for any graph.
Finally, comprehensive experiments with popular Graph Neural Networks (GNNs) on
benchmark datasets demonstrate the effectiveness and generalizability of our
proposed MinGE.",2021-05-07,2021,2021-05,chemistry
Neural Error Mitigation of Near-Term Quantum Simulations,"Near-term quantum computers provide a promising platform for finding ground
states of quantum systems, which is an essential task in physics, chemistry,
and materials science. Near-term approaches, however, are constrained by the
effects of noise as well as the limited resources of near-term quantum
hardware. We introduce ""neural error mitigation,"" which uses neural networks to
improve estimates of ground states and ground-state observables obtained using
near-term quantum simulations. To demonstrate our method's broad applicability,
we employ neural error mitigation to find the ground states of the H$_2$ and
LiH molecular Hamiltonians, as well as the lattice Schwinger model, prepared
via the variational quantum eigensolver (VQE). Our results show that neural
error mitigation improves numerical and experimental VQE computations to yield
low energy errors, high fidelities, and accurate estimations of more-complex
observables like order parameters and entanglement entropy, without requiring
additional quantum resources. Furthermore, neural error mitigation is agnostic
with respect to the quantum state preparation algorithm used, the quantum
hardware it is implemented on, and the particular noise channel affecting the
experiment, contributing to its versatility as a tool for quantum simulation.",2021-05-17,2021,2021-05,chemistry
"Communication is the universal solvent: atreya bot -- an interactive bot
  for chemical scientists","Conversational agents are a recent trend in human-computer interaction,
deployed in multidisciplinary applications to assist the users. In this paper,
we introduce ""Atreya"", an interactive bot for chemistry enthusiasts,
researchers, and students to study the ChEMBL database. Atreya is hosted by
Telegram, a popular cloud-based instant messaging application. This
user-friendly bot queries the ChEMBL database, retrieves the drug details for a
particular disease, targets associated with that drug, etc. This paper explores
the potential of using a conversational agent to assist chemistry students and
chemical scientist in complex information seeking process.",2021-06-14,2021,2021-06,chemistry
"NG+ : A Multi-Step Matrix-Product Natural Gradient Method for Deep
  Learning","In this paper, a novel second-order method called NG+ is proposed. By
following the rule ``the shape of the gradient equals the shape of the
parameter"", we define a generalized fisher information matrix (GFIM) using the
products of gradients in the matrix form rather than the traditional
vectorization. Then, our generalized natural gradient direction is simply the
inverse of the GFIM multiplies the gradient in the matrix form. Moreover, the
GFIM and its inverse keeps the same for multiple steps so that the
computational cost can be controlled and is comparable with the first-order
methods. A global convergence is established under some mild conditions and a
regret bound is also given for the online learning setting. Numerical results
on image classification with ResNet50, quantum chemistry modeling with Schnet,
neural machine translation with Transformer and recommendation system with DLRM
illustrate that GN+ is competitive with the state-of-the-art methods.",2021-06-14,2021,2021-06,chemistry
"Total Nitrogen Estimation in Agricultural Soils via Aerial Multispectral
  Imaging and LIBS","Measuring soil health indicators is an important and challenging task that
affects farmers' decisions on timing, placement, and quantity of fertilizers
applied in the farms. Most existing methods to measure soil health indicators
(SHIs) are in-lab wet chemistry or spectroscopy-based methods, which require
significant human input and effort, time-consuming, costly, and are
low-throughput in nature. To address this challenge, we develop an artificial
intelligence (AI)-driven near real-time unmanned aerial vehicle (UAV)-based
multispectral sensing (UMS) solution to estimate total nitrogen (TN) of the
soil, an important macro-nutrient or SHI that directly affects the crop health.
Accurate prediction of soil TN can significantly increase crop yield through
informed decision making on the timing of seed planting, and fertilizer
quantity and timing. We train two machine learning models including multi-layer
perceptron and support vector machine to predict the soil nitrogen using a
suite of data classes including multispectral characteristics of the soil and
crops in red, near-infrared, and green spectral bands, computed vegetation
indices, and environmental variables including air temperature and relative
humidity. To generate the ground-truth data or the training data for the
machine learning models, we measure the total nitrogen of the soil samples
(collected from a farm) using laser-induced breakdown spectroscopy (LIBS).",2021-07-06,2021,2021-07,chemistry
"A Point Cloud-Based Deep Learning Strategy for Protein-Ligand Binding
  Affinity Prediction","There is great interest to develop artificial intelligence-based
protein-ligand affinity models due to their immense applications in drug
discovery. In this paper, PointNet and PointTransformer, two pointwise
multi-layer perceptrons have been applied for protein-ligand affinity
prediction for the first time. Three-dimensional point clouds could be rapidly
generated from the data sets in PDBbind-2016, which contain 3 772 and 11 327
individual point clouds derived from the refined or/and general sets,
respectively. These point clouds were used to train PointNet or
PointTransformer, resulting in protein-ligand affinity prediction models with
Pearson correlation coefficients R = 0.831 or 0.859 from the larger point
clouds respectively, based on the CASF-2016 benchmark test. The analysis of the
parameters suggests that the two deep learning models were capable to learn
many interactions between proteins and their ligands, and these key atoms for
the interaction could be visualized in point clouds. The protein-ligand
interaction features learned by PointTransformer could be further adapted for
the XGBoost-based machine learning algorithm, resulting in prediction models
with an average Rp of 0.831, which is on par with the state-of-the-art machine
learning models based on PDBbind database. These results suggest that point
clouds derived from the PDBbind datasets are useful to evaluate the performance
of 3D point clouds-centered deep learning algorithms, which could learn
critical protein-ligand interactions from natural evolution or medicinal
chemistry and have wide applications in studying protein-ligand interactions.",2021-07-09,2021,2021-07,chemistry
"From data to noise to data: mixing physics across temperatures with
  generative artificial intelligence","Using simulations or experiments performed at some set of temperatures to
learn about the physics or chemistry at some other arbitrary temperature is a
problem of immense practical and theoretical relevance. Here we develop a
framework based on statistical mechanics and generative Artificial Intelligence
that allows solving this problem. Specifically, we work with denoising
diffusion probabilistic models, and show how these models in combination with
replica exchange molecular dynamics achieve superior sampling of the
biomolecular energy landscape at temperatures that were never even simulated
without assuming any particular slow degrees of freedom. The key idea is to
treat the temperature as a fluctuating random variable and not a control
parameter as is usually done. This allows us to directly sample from the joint
probability distribution in configuration and temperature space. The results
here are demonstrated for a chirally symmetric peptide and single-strand
ribonucleic acid undergoing conformational transitions in all-atom water. We
demonstrate how we can discover transition states and metastable states that
were previously unseen at the temperature of interest, and even bypass the need
to perform further simulations for wide range of temperatures. At the same
time, any unphysical states are easily identifiable through very low Boltzmann
weights. The procedure while shown here for a class of molecular simulations
should be more generally applicable to mixing information across simulations
and experiments with varying control parameters.",2021-07-15,2021,2021-07,chemistry
"Learning Attributed Graph Representations with Communicative Message
  Passing Transformer","Constructing appropriate representations of molecules lies at the core of
numerous tasks such as material science, chemistry and drug designs. Recent
researches abstract molecules as attributed graphs and employ graph neural
networks (GNN) for molecular representation learning, which have made
remarkable achievements in molecular graph modeling. Albeit powerful, current
models either are based on local aggregation operations and thus miss
higher-order graph properties or focus on only node information without fully
using the edge information. For this sake, we propose a Communicative Message
Passing Transformer (CoMPT) neural network to improve the molecular graph
representation by reinforcing message interactions between nodes and edges
based on the Transformer architecture. Unlike the previous transformer-style
GNNs that treat molecules as fully connected graphs, we introduce a message
diffusion mechanism to leverage the graph connectivity inductive bias and
reduce the message enrichment explosion. Extensive experiments demonstrated
that the proposed model obtained superior performances (around 4$\%$ on
average) against state-of-the-art baselines on seven chemical property datasets
(graph-level tasks) and two chemical shift datasets (node-level tasks). Further
visualization studies also indicated a better representation capacity achieved
by our model.",2021-07-19,2021,2021-07,chemistry
"Multiple Query Optimization using a Hybrid Approach of Classical and
  Quantum Computing","Quantum computing promises to solve difficult optimization problems in
chemistry, physics and mathematics more efficiently than classical computers,
but requires fault-tolerant quantum computers with millions of qubits. To
overcome errors introduced by today's quantum computers, hybrid algorithms
combining classical and quantum computers are used. In this paper we tackle the
multiple query optimization problem (MQO) which is an important NP-hard problem
in the area of data-intensive problems. We propose a novel hybrid
classical-quantum algorithm to solve the MQO on a gate-based quantum computer.
We perform a detailed experimental evaluation of our algorithm and compare its
performance against a competing approach that employs a quantum annealer --
another type of quantum computer. Our experimental results demonstrate that our
algorithm currently can only handle small problem sizes due to the limited
number of qubits available on a gate-based quantum computer compared to a
quantum computer based on quantum annealing. However, our algorithm shows a
qubit efficiency of close to 99% which is almost a factor of 2 higher compared
to the state of the art implementation. Finally, we analyze how our algorithm
scales with larger problem sizes and conclude that our approach shows promising
results for near-term quantum computers.",2021-07-22,2021,2021-07,chemistry
Geometric Deep Learning on Molecular Representations,"Geometric deep learning (GDL), which is based on neural network architectures
that incorporate and process symmetry information, has emerged as a recent
paradigm in artificial intelligence. GDL bears particular promise in molecular
modeling applications, in which various molecular representations with
different symmetry properties and levels of abstraction exist. This review
provides a structured and harmonized overview of molecular GDL, highlighting
its applications in drug discovery, chemical synthesis prediction, and quantum
chemistry. Emphasis is placed on the relevance of the learned molecular
features and their complementarity to well-established molecular descriptors.
This review provides an overview of current challenges and opportunities, and
presents a forecast of the future of GDL for molecular sciences.",2021-07-26,2021,2021-07,chemistry
"Natural Language Processing Models That Automate Programming Will
  Transform Chemistry Research and Teaching","Natural language processing models have emerged that can generate usable
software and automate a number of programming tasks with high fidelity. These
tools have yet to have an impact on the chemistry community. Yet, our initial
testing demonstrates that this form of Artificial Intelligence is poised to
transform chemistry and chemical engineering research. Here, we review
developments that brought us to this point, examine applications in chemistry,
and give our perspective on how this may fundamentally alter research and
teaching.",2021-08-30,2021,2021-08,chemistry
"IGNNITION: Bridging the Gap Between Graph Neural Networks and Networking
  Systems","Recent years have seen the vast potential of Graph Neural Networks (GNN) in
many fields where data is structured as graphs (e.g., chemistry, recommender
systems). In particular, GNNs are becoming increasingly popular in the field of
networking, as graphs are intrinsically present at many levels (e.g., topology,
routing). The main novelty of GNNs is their ability to generalize to other
networks unseen during training, which is an essential feature for developing
practical Machine Learning (ML) solutions for networking. However, implementing
a functional GNN prototype is currently a cumbersome task that requires strong
skills in neural network programming. This poses an important barrier to
network engineers that often do not have the necessary ML expertise. In this
article, we present IGNNITION, a novel open-source framework that enables fast
prototyping of GNNs for networking systems. IGNNITION is based on an intuitive
high-level abstraction that hides the complexity behind GNNs, while still
offering great flexibility to build custom GNN architectures. To showcase the
versatility and performance of this framework, we implement two
state-of-the-art GNN models applied to different networking use cases. Our
results show that the GNN models produced by IGNNITION are equivalent in terms
of accuracy and performance to their native implementations in TensorFlow.",2021-09-14,2021,2021-09,chemistry
"Automated and Explainable Ontology Extension Based on Deep Learning: A
  Case Study in the Chemical Domain","Reference ontologies provide a shared vocabulary and knowledge resource for
their domain. Manual construction enables them to maintain a high quality,
allowing them to be widely accepted across their community. However, the manual
development process does not scale for large domains. We present a new
methodology for automatic ontology extension and apply it to the ChEBI
ontology, a prominent reference ontology for life sciences chemistry. We
trained a Transformer-based deep learning model on the leaf node structures
from the ChEBI ontology and the classes to which they belong. The model is then
capable of automatically classifying previously unseen chemical structures. The
proposed model achieved an overall F1 score of 0.80, an improvement of 6
percentage points over our previous results on the same dataset. Additionally,
we demonstrate how visualizing the model's attention weights can help to
explain the results by providing insight into how the model made its decisions.",2021-09-19,2021,2021-09,chemistry
Loop-Free Tensor Networks for High-Energy Physics,"This brief review introduces the reader to tensor network methods, a powerful
theoretical and numerical paradigm spawning from condensed matter physics and
quantum information science and increasingly exploited in different fields of
research, from artificial intelligence to quantum chemistry. Here, we
specialise our presentation on the application of loop-free tensor network
methods to the study of High-Energy Physics (HEP) problems and, in particular,
to the study of lattice gauge theories where tensor networks can be applied in
regimes where Monte Carlo methods are hindered by the sign problem.",2021-09-24,2021,2021-09,chemistry
Natural Computational Architectures for Cognitive Info-Communication,"Recent comprehensive overview of 40 years of research in cognitive
architectures, (Kotseruba and Tsotsos 2020), evaluates modelling of the core
cognitive abilities in humans, but only marginally addresses biologically
plausible approaches based on natural computation. This mini review presents a
set of perspectives and approaches which have shaped the development of
biologically inspired computational models in the recent past that can lead to
the development of biologically more realistic cognitive architectures. For
describing continuum of natural cognitive architectures, from basal cellular to
human-level cognition, we use evolutionary info-computational framework, where
natural/ physical/ morphological computation leads to evolution of increasingly
complex cognitive systems. Forty years ago, when the first cognitive
architectures have been proposed, understanding of cognition, embodiment and
evolution was different. So was the state of the art of information physics,
bioinformatics, information chemistry, computational neuroscience, complexity
theory, self-organization, theory of evolution, information and computation.
Novel developments support a constructive interdisciplinary framework for
cognitive architectures in the context of computing nature, where interactions
between constituents at different levels of organization lead to
complexification of agency and increased cognitive capacities. We identify
several important research questions for further investigation that can
increase understanding of cognition in nature and inspire new developments of
cognitive technologies. Recently, basal cell cognition attracted a lot of
interest for its possible applications in medicine, new computing technologies,
as well as micro- and nanorobotics.",2021-10-01,2021,2021-10,chemistry
"A Deep Dive into Machine Learning Density Functional Theory for
  Materials Science and Chemistry","With the growth of computational resources, the scope of electronic structure
simulations has increased greatly. Artificial intelligence and robust data
analysis hold the promise to accelerate large-scale simulations and their
analysis to hitherto unattainable scales. Machine learning is a rapidly growing
field for the processing of such complex datasets. It has recently gained
traction in the domain of electronic structure simulations, where density
functional theory takes the prominent role of the most widely used electronic
structure method. Thus, DFT calculations represent one of the largest loads on
academic high-performance computing systems across the world. Accelerating
these with machine learning can reduce the resources required and enables
simulations of larger systems. Hence, the combination of density functional
theory and machine learning has the potential to rapidly advance electronic
structure applications such as in-silico materials discovery and the search for
new chemical reaction pathways. We provide the theoretical background of both
density functional theory and machine learning on a generally accessible level.
This serves as the basis of our comprehensive review including research
articles up to December 2020 in chemistry and materials science that employ
machine-learning techniques. In our analysis, we categorize the body of
research into main threads and extract impactful results. We conclude our
review with an outlook on exciting research directions in terms of a citation
analysis.",2021-10-03,2021,2021-10,chemistry
"Geometric and Physical Quantities Improve E(3) Equivariant Message
  Passing","Including covariant information, such as position, force, velocity or spin is
important in many tasks in computational physics and chemistry. We introduce
Steerable E(3) Equivariant Graph Neural Networks (SEGNNs) that generalise
equivariant graph networks, such that node and edge attributes are not
restricted to invariant scalars, but can contain covariant information, such as
vectors or tensors. This model, composed of steerable MLPs, is able to
incorporate geometric and physical information in both the message and update
functions. Through the definition of steerable node attributes, the MLPs
provide a new class of activation functions for general use with steerable
feature fields. We discuss ours and related work through the lens of
equivariant non-linear convolutions, which further allows us to pin-point the
successful components of SEGNNs: non-linear message aggregation improves upon
classic linear (steerable) point convolutions; steerable messages improve upon
recent equivariant graph networks that send invariant messages. We demonstrate
the effectiveness of our method on several tasks in computational physics and
chemistry and provide extensive ablation studies.",2021-10-06,2021,2021-10,chemistry
"The AI Triplet: Computational, Conceptual, and Mathematical Knowledge in
  AI Education","Efforts to enhance education and broaden participation in AI will benefit
from a systematic understanding of the competencies underlying AI expertise. In
this paper, we observe that AI expertise requires integrating computational,
conceptual, and mathematical knowledge and representations. We call this the
``AI triplet,'' similar in spirit to the ``chemistry triplet'' that has heavily
influenced the past four decades of chemistry education research. We describe a
theoretical foundation for this triplet and show how it maps onto two sample AI
topics: tree search and gradient descent. Finally, just as the chemistry
triplet has impacted chemistry education in concrete ways, we suggest two
initial hypotheses for how the AI triplet might impact AI education: 1) how we
can help AI students gain proficiency in moving between the corners of the
triplet; and 2) how all corners of the AI triplet highlight the need for
supporting students' spatial cognitive skills.",2021-10-14,2021,2021-10,chemistry
Geometric Transformer for End-to-End Molecule Properties Prediction,"Transformers have become methods of choice in many applications thanks to
their ability to represent complex interactions between elements. However,
extending the Transformer architecture to non-sequential data such as molecules
and enabling its training on small datasets remains a challenge. In this work,
we introduce a Transformer-based architecture for molecule property prediction,
which is able to capture the geometry of the molecule. We modify the classical
positional encoder by an initial encoding of the molecule geometry, as well as
a learned gated self-attention mechanism. We further suggest an augmentation
scheme for molecular data capable of avoiding the overfitting induced by the
overparameterized architecture. The proposed framework outperforms the
state-of-the-art methods while being based on pure machine learning solely,
i.e. the method does not incorporate domain knowledge from quantum chemistry
and does not use extended geometric inputs besides the pairwise atomic
distances.",2021-10-26,2021,2021-10,chemistry
"Scientific Discovery and the Cost of Measurement -- Balancing
  Information and Cost in Reinforcement Learning","The use of reinforcement learning (RL) in scientific applications, such as
materials design and automated chemistry, is increasing. A major challenge,
however, lies in fact that measuring the state of the system is often costly
and time consuming in scientific applications, whereas policy learning with RL
requires a measurement after each time step. In this work, we make the
measurement costs explicit in the form of a costed reward and propose a
framework that enables off-the-shelf deep RL algorithms to learn a policy for
both selecting actions and determining whether or not to measure the current
state of the system at each time step. In this way, the agents learn to balance
the need for information with the cost of information. Our results show that
when trained under this regime, the Dueling DQN and PPO agents can learn
optimal action policies whilst making up to 50\% fewer state measurements, and
recurrent neural networks can produce a greater than 50\% reduction in
measurements. We postulate the these reduction can help to lower the barrier to
applying RL to real-world scientific applications.",2021-12-14,2021,2021-12,chemistry
"Beyond Low Earth Orbit: Biomonitoring, Artificial Intelligence, and
  Precision Space Health","Human space exploration beyond low Earth orbit will involve missions of
significant distance and duration. To effectively mitigate myriad space health
hazards, paradigm shifts in data and space health systems are necessary to
enable Earth-independence, rather than Earth-reliance. Promising developments
in the fields of artificial intelligence and machine learning for biology and
health can address these needs. We propose an appropriately autonomous and
intelligent Precision Space Health system that will monitor, aggregate, and
assess biomedical statuses; analyze and predict personalized adverse health
outcomes; adapt and respond to newly accumulated data; and provide preventive,
actionable, and timely insights to individual deep space crew members and
iterative decision support to their crew medical officer. Here we present a
summary of recommendations from a workshop organized by the National
Aeronautics and Space Administration, on future applications of artificial
intelligence in space biology and health. In the next decade, biomonitoring
technology, biomarker science, spacecraft hardware, intelligent software, and
streamlined data management must mature and be woven together into a Precision
Space Health system to enable humanity to thrive in deep space.",2021-12-22,2021,2021-12,chemistry
"Beyond Low Earth Orbit: Biological Research, Artificial Intelligence,
  and Self-Driving Labs","Space biology research aims to understand fundamental effects of spaceflight
on organisms, develop foundational knowledge to support deep space exploration,
and ultimately bioengineer spacecraft and habitats to stabilize the ecosystem
of plants, crops, microbes, animals, and humans for sustained multi-planetary
life. To advance these aims, the field leverages experiments, platforms, data,
and model organisms from both spaceborne and ground-analog studies. As research
is extended beyond low Earth orbit, experiments and platforms must be maximally
autonomous, light, agile, and intelligent to expedite knowledge discovery. Here
we present a summary of recommendations from a workshop organized by the
National Aeronautics and Space Administration on artificial intelligence,
machine learning, and modeling applications which offer key solutions toward
these space biology challenges. In the next decade, the synthesis of artificial
intelligence into the field of space biology will deepen the biological
understanding of spaceflight effects, facilitate predictive modeling and
analytics, support maximally autonomous and reproducible experiments, and
efficiently manage spaceborne data and metadata, all with the goal to enable
life to thrive in deep space.",2021-12-22,2021,2021-12,chemistry
"AlphaFold Accelerates Artificial Intelligence Powered Drug Discovery:
  Efficient Discovery of a Novel Cyclin-dependent Kinase 20 (CDK20) Small
  Molecule Inhibitor","The AlphaFold computer program predicted protein structures for the whole
human genome, which has been considered as a remarkable breakthrough both in
artificial intelligence (AI) application and structural biology. Despite the
varying confidence level, these predicted structures still could significantly
contribute to structure-based drug design of novel targets, especially the ones
with no or limited structural information. In this work, we successfully
applied AlphaFold in our end-to-end AI-powered drug discovery engines
constituted of a biocomputational platform PandaOmics and a generative
chemistry platform Chemistry42, to identify a first-in-class hit molecule of a
novel target without an experimental structure starting from target selection
towards hit identification in a cost- and time-efficient manner. PandaOmics
provided the targets of interest and Chemistry42 generated the molecules based
on the AlphaFold predicted structure, and the selected molecules were
synthesized and tested in biological assays. Through this approach, we
identified a small molecule hit compound for CDK20 with a Kd value of 8.9 +/-
1.6 uM (n = 4) within 30 days from target selection and after only synthesizing
7 compounds. Based on the available data, the second round of AI-powered
compound generation was conducted and through which, a more potent hit
molecule, ISM042-2 048, was discovered with a Kd value of 210.0 +/- 42.4 nM (n
= 2), within 30 days and after synthesizing 6 compounds from the discovery of
the first hit ISM042-2-001. To the best of our knowledge, this is the first
reported small molecule targeting CDK20 and more importantly, this work is the
first demonstration of AlphaFold application in the hit identification process
in early drug discovery.",2022-01-21,2022,2022-01,chemistry
"DrugOOD: Out-of-Distribution (OOD) Dataset Curator and Benchmark for
  AI-aided Drug Discovery -- A Focus on Affinity Prediction Problems with Noise
  Annotations","AI-aided drug discovery (AIDD) is gaining increasing popularity due to its
promise of making the search for new pharmaceuticals quicker, cheaper and more
efficient. In spite of its extensive use in many fields, such as ADMET
prediction, virtual screening, protein folding and generative chemistry, little
has been explored in terms of the out-of-distribution (OOD) learning problem
with \emph{noise}, which is inevitable in real world AIDD applications.
  In this work, we present DrugOOD, a systematic OOD dataset curator and
benchmark for AI-aided drug discovery, which comes with an open-source Python
package that fully automates the data curation and OOD benchmarking processes.
We focus on one of the most crucial problems in AIDD: drug target binding
affinity prediction, which involves both macromolecule (protein target) and
small-molecule (drug compound). In contrast to only providing fixed datasets,
DrugOOD offers automated dataset curator with user-friendly customization
scripts, rich domain annotations aligned with biochemistry knowledge, realistic
noise annotations and rigorous benchmarking of state-of-the-art OOD algorithms.
Since the molecular data is often modeled as irregular graphs using graph
neural network (GNN) backbones, DrugOOD also serves as a valuable testbed for
\emph{graph OOD learning} problems. Extensive empirical studies have shown a
significant performance gap between in-distribution and out-of-distribution
experiments, which highlights the need to develop better schemes that can allow
for OOD generalization under noise for AIDD.",2022-01-24,2022,2022-01,chemistry
"Semi-Supervised GCN for learning Molecular Structure-Activity
  Relationships","Since the introduction of artificial intelligence in medicinal chemistry, the
necessity has emerged to analyse how molecular property variation is modulated
by either single atoms or chemical groups. In this paper, we propose to train
graph-to-graph neural network using semi-supervised learning for attributing
structure-property relationships. As initial case studies we apply the method
to solubility and molecular acidity while checking its consistency in
comparison with known experimental chemical data. As final goal, our approach
could represent a valuable tool to deal with problems such as activity cliffs,
lead optimization and de-novo drug design.",2022-01-25,2022,2022-01,chemistry
"MolNet: A Chemically Intuitive Graph Neural Network for Prediction of
  Molecular Properties","The graph neural network (GNN) has been a powerful deep-learning tool in
chemistry domain, due to its close connection with molecular graphs. Most GNN
models collect and update atom and molecule features from the fed atom (and, in
some cases, bond) features, which are basically based on the two-dimensional
(2D) graph representation of 3D molecules. Correspondingly, the adjacency
matrix, containing the information on covalent bonds, or equivalent data
structures (e.g., lists) have been the main core in the feature-updating
processes, such as graph convolution. However, the 2D-based models do not
faithfully represent 3D molecules and their physicochemical properties,
exemplified by the overlooked field effect that is a ""through-space"" effect,
not a ""through-bond"" effect. The GNN model proposed herein, denoted as MolNet,
is chemically intuitive, accommodating the 3D non-bond information in a
molecule, with a noncovalent adjacency matrix $\bf{\bar A}$, and also
bond-strength information from a weighted bond matrix $\bf{B}$. The noncovalent
atoms, not directly bonded to a given atom in a molecule, are identified within
5 $\unicode{x212B}$ of cut-off range for the construction of $\bf{\bar A}$, and
$\bf{B}$ has edge weights of 1, 1.5, 2, and 3 for single, aromatic, double, and
triple bonds, respectively. Comparative studies show that MolNet outperforms
various baseline GNN models and gives a state-of-the-art performance in the
classification task of BACE dataset and regression task of ESOL dataset. This
work suggests a future direction of deep-learning chemistry in the construction
of deep-learning models that are chemically intuitive and comparable with the
existing chemistry concepts and tools.",2022-02-01,2022,2022-02,chemistry
Target-aware Molecular Graph Generation,"Generating molecules with desired biological activities has attracted growing
attention in drug discovery. Previous molecular generation models are designed
as chemocentric methods that hardly consider the drug-target interaction,
limiting their practical applications. In this paper, we aim to generate
molecular drugs in a target-aware manner that bridges biological activity and
molecular design. To solve this problem, we compile a benchmark dataset from
several publicly available datasets and build baselines in a unified framework.
Building on the recent advantages of flow-based molecular generation models, we
propose SiamFlow, which forces the flow to fit the distribution of target
sequence embeddings in latent space. Specifically, we employ an alignment loss
and a uniform loss to bring target sequence embeddings and drug graph
embeddings into agreements while avoiding collapse. Furthermore, we formulate
the alignment into a one-to-many problem by learning spaces of target sequence
embeddings. Experiments quantitatively show that our proposed method learns
meaningful representations in the latent space toward the target-aware
molecular graph generation and provides an alternative approach to bridge
biology and chemistry in drug discovery.",2022-02-10,2022,2022-02,chemistry
ChemicalX: A Deep Learning Library for Drug Pair Scoring,"In this paper, we introduce ChemicalX, a PyTorch-based deep learning library
designed for providing a range of state of the art models to solve the drug
pair scoring task. The primary objective of the library is to make deep drug
pair scoring models accessible to machine learning researchers and
practitioners in a streamlined framework.The design of ChemicalX reuses
existing high level model training utilities, geometric deep learning, and deep
chemistry layers from the PyTorch ecosystem. Our system provides neural network
layers, custom pair scoring architectures, data loaders, and batch iterators
for end users. We showcase these features with example code snippets and case
studies to highlight the characteristics of ChemicalX. A range of experiments
on real world drug-drug interaction, polypharmacy side effect, and combination
synergy prediction tasks demonstrate that the models available in ChemicalX are
effective at solving the pair scoring task. Finally, we show that ChemicalX
could be used to train and score machine learning models on large drug pair
datasets with hundreds of thousands of compounds on commodity hardware.",2022-02-10,2022,2022-02,chemistry
"Improving Molecular Representation Learning with Metric
  Learning-enhanced Optimal Transport","Training data are usually limited or heterogeneous in many chemical and
biological applications. Existing machine learning models for chemistry and
materials science fail to consider generalizing beyond training domains. In
this article, we develop a novel optimal transport-based algorithm termed MROT
to enhance their generalization capability for molecular regression problems.
MROT learns a continuous label of the data by measuring a new metric of domain
distances and a posterior variance regularization over the transport plan to
bridge the chemical domain gap. Among downstream tasks, we consider basic
chemical regression tasks in unsupervised and semi-supervised settings,
including chemical property prediction and materials adsorption selection.
Extensive experiments show that MROT significantly outperforms state-of-the-art
models, showing promising potential in accelerating the discovery of new
substances with desired properties.",2022-02-13,2022,2022-02,chemistry
"Fast and Accurate Linear Fitting for Incompletely Sampled Gaussian
  Function With a Long Tail","Fitting experiment data onto a curve is a common signal processing technique
to extract data features and establish the relationship between variables.
Often, we expect the curve to comply with some analytical function and then
turn data fitting into estimating the unknown parameters of a function. Among
analytical functions for data fitting, Gaussian function is the most widely
used one due to its extensive applications in numerous science and engineering
fields. To name just a few, Gaussian function is highly popular in statistical
signal processing and analysis, thanks to the central limit theorem [1];
Gaussian function frequently appears in the quantum harmonic oscillator,
quantum field theory, optics, lasers, and many other theories and models in
Physics [2]; moreover, Gaussian function is widely applied in chemistry for
depicting molecular orbitals, in computer science for imaging processing and in
artificial intelligence for defining neural networks.",2022-03-15,2022,2022-03,chemistry
SELFIES and the future of molecular string representations,"Artificial intelligence (AI) and machine learning (ML) are expanding in
popularity for broad applications to challenging tasks in chemistry and
materials science. Examples include the prediction of properties, the discovery
of new reaction pathways, or the design of new molecules. The machine needs to
read and write fluently in a chemical language for each of these tasks. Strings
are a common tool to represent molecular graphs, and the most popular molecular
string representation, SMILES, has powered cheminformatics since the late
1980s. However, in the context of AI and ML in chemistry, SMILES has several
shortcomings -- most pertinently, most combinations of symbols lead to invalid
results with no valid chemical interpretation. To overcome this issue, a new
language for molecules was introduced in 2020 that guarantees 100\% robustness:
SELFIES (SELF-referencIng Embedded Strings). SELFIES has since simplified and
enabled numerous new applications in chemistry. In this manuscript, we look to
the future and discuss molecular string representations, along with their
respective opportunities and challenges. We propose 16 concrete Future Projects
for robust molecular representations. These involve the extension toward new
chemical domains, exciting questions at the interface of AI and robust
languages and interpretability for both humans and machines. We hope that these
proposals will inspire several follow-up works exploiting the full potential of
molecular string representations for the future of AI in chemistry and
materials science.",2022-03-31,2022,2022-03,chemistry
Translation between Molecules and Natural Language,"We present $\textbf{MolT5}$ $-$ a self-supervised learning framework for
pretraining models on a vast amount of unlabeled natural language text and
molecule strings. $\textbf{MolT5}$ allows for new, useful, and challenging
analogs of traditional vision-language tasks, such as molecule captioning and
text-based de novo molecule generation (altogether: translation between
molecules and language), which we explore for the first time. Since
$\textbf{MolT5}$ pretrains models on single-modal data, it helps overcome the
chemistry domain shortcoming of data scarcity. Furthermore, we consider several
metrics, including a new cross-modal embedding-based metric, to evaluate the
tasks of molecule captioning and text-based molecule generation. Our results
show that $\textbf{MolT5}$-based models are able to generate outputs, both
molecules and captions, which in many cases are high quality.",2022-04-25,2022,2022-04,chemistry
"Crystal Transformer: Self-learning neural language model for Generative
  and Tinkering Design of Materials","Self-supervised neural language models have recently achieved unprecedented
success, from natural language processing to learning the languages of
biological sequences and organic molecules. These models have demonstrated
superior performance in the generation, structure classification, and
functional predictions for proteins and molecules with learned representations.
However, most of the masking-based pre-trained language models are not designed
for generative design, and their black-box nature makes it difficult to
interpret their design logic. Here we propose BLMM Crystal Transformer, a
neural network based probabilistic generative model for generative and
tinkering design of inorganic materials. Our model is built on the blank
filling language model for text generation and has demonstrated unique
advantages in learning the ""materials grammars"" together with high-quality
generation, interpretability, and data efficiency. It can generate chemically
valid materials compositions with as high as 89.7\% charge neutrality and
84.8\% balanced electronegativity, which are more than 4 and 8 times higher
compared to a pseudo random sampling baseline. The probabilistic generation
process of BLMM allows it to recommend tinkering operations based on learned
materials chemistry and makes it useful for materials doping. Combined with the
TCSP crysal structure prediction algorithm, We have applied our model to
discover a set of new materials as validated using DFT calculations. Our work
thus brings the unsupervised transformer language models based generative
artificial intelligence to inorganic materials. A user-friendly web app has
been developed for computational materials doping and can be accessed freely at
\url{www.materialsatlas.org/blmtinker}.",2022-04-25,2022,2022-04,chemistry
"Multimodal Transformer-based Model for Buchwald-Hartwig and
  Suzuki-Miyaura Reaction Yield Prediction","Predicting the yield percentage of a chemical reaction is useful in many
aspects such as reducing wet-lab experimentation by giving the priority to the
reactions with a high predicted yield. In this work we investigated the use of
multiple type inputs to predict chemical reaction yield. We used simplified
molecular-input line-entry system (SMILES) as well as calculated chemical
descriptors as model inputs. The model consists of a pre-trained bidirectional
transformer-based encoder (BERT) and a multi-layer perceptron (MLP) with a
regression head to predict the yield. We experimented on two high throughput
experimentation (HTE) datasets for Buchwald-Hartwig and Suzuki-Miyaura
reactions. The experiments show improvements in the prediction on both datasets
compared to systems using only SMILES or chemical descriptors as input. We also
tested the model's performance on out-of-sample dataset splits of
Buchwald-Hartwig and achieved comparable results with the state-of-the-art. In
addition to predicting the yield, we demonstrated the model's ability to
suggest the optimum (highest yield) reaction conditions. The model was able to
suggest conditions that achieves 94% of the optimum reported yields. This
proves the model to be useful in achieving the best results in the wet lab
without expensive experimentation.",2022-04-27,2022,2022-04,chemistry
FAIR data enabling new horizons for materials research,"The prosperity and lifestyle of our society are very much governed by
achievements in condensed matter physics, chemistry and materials science,
because new products for sectors such as energy, the environment, health,
mobility and information technology (IT) rely largely on improved or even new
materials. Examples include solid-state lighting, touchscreens, batteries,
implants, drug delivery and many more. The enormous amount of research data
produced every day in these fields represents a gold mine of the twenty-first
century. This gold mine is, however, of little value if these data are not
comprehensively characterized and made available. How can we refine this
feedstock; that is, turn data into knowledge and value? For this, a FAIR
(findable, accessible, interoperable and reusable) data infrastructure is a
must. Only then can data be readily shared and explored using data analytics
and artificial intelligence (AI) methods. Making data 'findable and AI ready'
(a forward-looking interpretation of the acronym) will change the way in which
science is carried out today. In this Perspective, we discuss how we can
prepare to make this happen for the field of materials science.",2022-04-28,2022,2022-04,chemistry
Power and limitations of single-qubit native quantum neural networks,"Quantum neural networks (QNNs) have emerged as a leading strategy to
establish applications in machine learning, chemistry, and optimization. While
the applications of QNN have been widely investigated, its theoretical
foundation remains less understood. In this paper, we formulate a theoretical
framework for the expressive ability of data re-uploading quantum neural
networks that consist of interleaved encoding circuit blocks and trainable
circuit blocks. First, we prove that single-qubit quantum neural networks can
approximate any univariate function by mapping the model to a partial Fourier
series. We in particular establish the exact correlations between the
parameters of the trainable gates and the Fourier coefficients, resolving an
open problem on the universal approximation property of QNN. Second, we discuss
the limitations of single-qubit native QNNs on approximating multivariate
functions by analyzing the frequency spectrum and the flexibility of Fourier
coefficients. We further demonstrate the expressivity and limitations of
single-qubit native QNNs via numerical experiments. We believe these results
would improve our understanding of QNNs and provide a helpful guideline for
designing powerful QNNs for machine learning tasks.",2022-05-16,2022,2022-05,chemistry
"Overview of STEM Science as Process, Method, Material, and Data Named
  Entities","We are faced with an unprecedented production in scholarly publications
worldwide. Stakeholders in the digital libraries posit that the document-based
publishing paradigm has reached the limits of adequacy. Instead, structured,
machine-interpretable, fine-grained scholarly knowledge publishing as Knowledge
Graphs (KG) is strongly advocated. In this work, we develop and analyze a
large-scale structured dataset of STEM articles across 10 different
disciplines, viz. Agriculture, Astronomy, Biology, Chemistry, Computer Science,
Earth Science, Engineering, Material Science, Mathematics, and Medicine. Our
analysis is defined over a large-scale corpus comprising 60K abstracts
structured as four scientific entities process, method, material, and data.
Thus our study presents, for the first-time, an analysis of a large-scale
multidisciplinary corpus under the construct of four named entity labels that
are specifically defined and selected to be domain-independent as opposed to
domain-specific. The work is then inadvertently a feasibility test of
characterizing multidisciplinary science with domain-independent concepts.
Further, to summarize the distinct facets of scientific knowledge per concept
per discipline, a set of word cloud visualizations are offered. The
STEM-NER-60k corpus, created in this work, comprises over 1M extracted entities
from 60k STEM articles obtained from a major publishing platform and is
publicly released https://github.com/jd-coderepos/stem-ner-60k.",2022-05-24,2022,2022-05,chemistry
"MolScribe: Robust Molecular Structure Recognition with Image-To-Graph
  Generation","Molecular structure recognition is the task of translating a molecular image
into its graph structure. Significant variation in drawing styles and
conventions exhibited in chemical literature poses a significant challenge for
automating this task. In this paper, we propose MolScribe, a novel
image-to-graph generation model that explicitly predicts atoms and bonds, along
with their geometric layouts, to construct the molecular structure. Our model
flexibly incorporates symbolic chemistry constraints to recognize chirality and
expand abbreviated structures. We further develop data augmentation strategies
to enhance the model robustness against domain shifts. In experiments on both
synthetic and realistic molecular images, MolScribe significantly outperforms
previous models, achieving 76-93% accuracy on public benchmarks. Chemists can
also easily verify MolScribe's prediction, informed by its confidence
estimation and atom-level alignment with the input image. MolScribe is publicly
available through Python and web interfaces:
https://github.com/thomas0809/MolScribe.",2022-05-28,2022,2022-05,chemistry
"Machine vision for vial positioning detection toward the safe automation
  of material synthesis","Although robot-based automation in chemistry laboratories can accelerate the
material development process, surveillance-free environments may lead to
dangerous accidents primarily due to machine control errors. Object detection
techniques can play vital roles in addressing these safety issues; however,
state-of-the-art detectors, including single-shot detector (SSD) models, suffer
from insufficient accuracy in environments involving complex and noisy scenes.
With the aim of improving safety in a surveillance-free laboratory, we report a
novel deep learning (DL)-based object detector, namely, DenseSSD. For the
foremost and frequent problem of detecting vial positions, DenseSSD achieved a
mean average precision (mAP) over 95% based on a complex dataset involving both
empty and solution-filled vials, greatly exceeding those of conventional
detectors; such high precision is critical to minimizing failure-induced
accidents. Additionally, DenseSSD was observed to be highly insensitive to the
environmental changes, maintaining its high precision under the variations of
solution colors or testing view angles. The robustness of DenseSSD would allow
the utilized equipment settings to be more flexible. This work demonstrates
that DenseSSD is useful for enhancing safety in an automated material synthesis
environment, and it can be extended to various applications where high
detection accuracy and speed are both needed.",2022-06-15,2022,2022-06,chemistry
Approximate Equivariance SO(3) Needlet Convolution,"This paper develops a rotation-invariant needlet convolution for rotation
group SO(3) to distill multiscale information of spherical signals. The
spherical needlet transform is generalized from $\mathbb{S}^2$ onto the SO(3)
group, which decomposes a spherical signal to approximate and detailed spectral
coefficients by a set of tight framelet operators. The spherical signal during
the decomposition and reconstruction achieves rotation invariance. Based on
needlet transforms, we form a Needlet approximate Equivariance Spherical CNN
(NES) with multiple SO(3) needlet convolutional layers. The network establishes
a powerful tool to extract geometric-invariant features of spherical signals.
The model allows sufficient network scalability with multi-resolution
representation. A robust signal embedding is learned with wavelet shrinkage
activation function, which filters out redundant high-pass representation while
maintaining approximate rotation invariance. The NES achieves state-of-the-art
performance for quantum chemistry regression and Cosmic Microwave Background
(CMB) delensing reconstruction, which shows great potential for solving
scientific challenges with high-resolution and multi-scale spherical signal
representation.",2022-06-17,2022,2022-06,chemistry
RetroGraph: Retrosynthetic Planning with Graph Search,"Retrosynthetic planning, which aims to find a reaction pathway to synthesize
a target molecule, plays an important role in chemistry and drug discovery.
This task is usually modeled as a search problem. Recently, data-driven methods
have attracted many research interests and shown promising results for
retrosynthetic planning. We observe that the same intermediate molecules are
visited many times in the searching process, and they are usually independently
treated in previous tree-based methods (e.g., AND-OR tree search, Monte Carlo
tree search). Such redundancies make the search process inefficient. We propose
a graph-based search policy that eliminates the redundant explorations of any
intermediate molecules. As searching over a graph is more complicated than over
a tree, we further adopt a graph neural network to guide the search over
graphs. Meanwhile, our method can search a batch of targets together in the
graph and remove the inter-target duplication in the tree-based search methods.
Experimental results on two datasets demonstrate the effectiveness of our
method. Especially on the widely used USPTO benchmark, we improve the search
success rate to 99.47%, advancing previous state-of-the-art performance for 2.6
points.",2022-06-23,2022,2022-06,chemistry
Solving Quantitative Reasoning Problems with Language Models,"Language models have achieved remarkable performance on a wide range of tasks
that require natural language understanding. Nevertheless, state-of-the-art
models have generally struggled with tasks that require quantitative reasoning,
such as solving mathematics, science, and engineering problems at the college
level. To help close this gap, we introduce Minerva, a large language model
pretrained on general natural language data and further trained on technical
content. The model achieves state-of-the-art performance on technical
benchmarks without the use of external tools. We also evaluate our model on
over two hundred undergraduate-level problems in physics, biology, chemistry,
economics, and other sciences that require quantitative reasoning, and find
that the model can correctly answer nearly a third of them.",2022-06-29,2022,2022-06,chemistry
"Multiscale Neural Operator: Learning Fast and Grid-independent PDE
  Solvers","Numerical simulations in climate, chemistry, or astrophysics are
computationally too expensive for uncertainty quantification or
parameter-exploration at high-resolution. Reduced-order or surrogate models are
multiple orders of magnitude faster, but traditional surrogates are inflexible
or inaccurate and pure machine learning (ML)-based surrogates too data-hungry.
We propose a hybrid, flexible surrogate model that exploits known physics for
simulating large-scale dynamics and limits learning to the hard-to-model term,
which is called parametrization or closure and captures the effect of fine-
onto large-scale dynamics. Leveraging neural operators, we are the first to
learn grid-independent, non-local, and flexible parametrizations. Our
\textit{multiscale neural operator} is motivated by a rich literature in
multiscale modeling, has quasilinear runtime complexity, is more accurate or
flexible than state-of-the-art parametrizations and demonstrated on the chaotic
equation multiscale Lorenz96.",2022-07-23,2022,2022-07,chemistry
"AI-driven Hypergraph Network of Organic Chemistry: Network Statistics
  and Applications in Reaction Classification","Rapid discovery of new reactions and molecules in recent years has been
facilitated by the advancements in high throughput screening, accessibility to
a much more complex chemical design space, and the development of accurate
molecular modeling frameworks. A holistic study of the growing chemistry
literature is, therefore, required that focuses on understanding the recent
trends and extrapolating them into possible future trajectories. To this end,
several network theory-based studies have been reported that use a directed
graph representation of chemical reactions. Here, we perform a study based on
representing chemical reactions as hypergraphs where the hyperedges represent
chemical reactions and nodes represent the participating molecules. We use a
standard reactions dataset to construct a hypernetwork and report its
statistics such as degree distributions, average path length, assortativity or
degree correlations, PageRank centrality, and graph-based clusters (or
communities). We also compute each statistic for an equivalent directed graph
representation of reactions to draw parallels and highlight differences between
the two. To demonstrate the AI applicability of hypergraph reaction
representation, we generate dense hypergraph embeddings and use them in the
reaction classification problem. We conclude that the hypernetwork
representation is flexible, preserves reaction context, and uncovers hidden
insights that are otherwise not apparent in a traditional directed graph
representation of chemical reactions.",2022-08-02,2022,2022-08,chemistry
"MetaRF: Differentiable Random Forest for Reaction Yield Prediction with
  a Few Trails","Artificial intelligence has deeply revolutionized the field of medicinal
chemistry with many impressive applications, but the success of these
applications requires a massive amount of training samples with high-quality
annotations, which seriously limits the wide usage of data-driven methods. In
this paper, we focus on the reaction yield prediction problem, which assists
chemists in selecting high-yield reactions in a new chemical space only with a
few experimental trials. To attack this challenge, we first put forth MetaRF,
an attention-based differentiable random forest model specially designed for
the few-shot yield prediction, where the attention weight of a random forest is
automatically optimized by the meta-learning framework and can be quickly
adapted to predict the performance of new reagents while given a few additional
samples. To improve the few-shot learning performance, we further introduce a
dimension-reduction based sampling method to determine valuable samples to be
experimentally tested and then learned. Our methodology is evaluated on three
different datasets and acquires satisfactory performance on few-shot
prediction. In high-throughput experimentation (HTE) datasets, the average
yield of our methodology's top 10 high-yield reactions is relatively close to
the results of ideal yield selection.",2022-08-22,2022,2022-08,chemistry
"A Molecular Multimodal Foundation Model Associating Molecule Graphs with
  Natural Language","Although artificial intelligence (AI) has made significant progress in
understanding molecules in a wide range of fields, existing models generally
acquire the single cognitive ability from the single molecular modality. Since
the hierarchy of molecular knowledge is profound, even humans learn from
different modalities including both intuitive diagrams and professional texts
to assist their understanding. Inspired by this, we propose a molecular
multimodal foundation model which is pretrained from molecular graphs and their
semantically related textual data (crawled from published Scientific Citation
Index papers) via contrastive learning. This AI model represents a critical
attempt that directly bridges molecular graphs and natural language.
Importantly, through capturing the specific and complementary information of
the two modalities, our proposed model can better grasp molecular expertise.
Experimental results show that our model not only exhibits promising
performance in cross-modal tasks such as cross-modal retrieval and molecule
caption, but also enhances molecular property prediction and possesses
capability to generate meaningful molecular graphs from natural language
descriptions. We believe that our model would have a broad impact on
AI-empowered fields across disciplines such as biology, chemistry, materials,
environment, and medicine, among others.",2022-09-12,2022,2022-09,chemistry
"Tartarus: A Benchmarking Platform for Realistic And Practical Inverse
  Molecular Design","The efficient exploration of chemical space to design molecules with intended
properties enables the accelerated discovery of drugs, materials, and
catalysts, and is one of the most important outstanding challenges in
chemistry. Encouraged by the recent surge in computer power and artificial
intelligence development, many algorithms have been developed to tackle this
problem. However, despite the emergence of many new approaches in recent years,
comparatively little progress has been made in developing realistic benchmarks
that reflect the complexity of molecular design for real-world applications. In
this work, we develop a set of practical benchmark tasks relying on physical
simulation of molecular systems mimicking real-life molecular design problems
for materials, drugs, and chemical reactions. Additionally, we demonstrate the
utility and ease of use of our new benchmark set by demonstrating how to
compare the performance of several well-established families of algorithms.
Surprisingly, we find that model performance can strongly depend on the
benchmark domain. We believe that our benchmark suite will help move the field
towards more realistic molecular design benchmarks, and move the development of
inverse molecular design algorithms closer to designing molecules that solve
existing problems in both academia and industry alike.",2022-09-26,2022,2022-09,chemistry
"Provenance of Lyfe: Chemical Autonomous Agents Surviving through
  Associative Learning","We present a benchmark study of autonomous, chemical agents exhibiting
associative learning of an environmental feature. Associative learning has been
widely studied in cognitive science and artificial intelligence, but are most
commonly implemented in highly complex or carefully engineered systems such as
animal brains, artificial neural networks, DNA computing systems and gene
regulatory networks. The ability to encode environmental correlations and use
them to make predictions is a benchmark of biological resilience, and underpins
a plethora of adaptive responses in the living hierarchy, spanning prey animal
species anticipating the arrival of predators, to epigenetic systems in
microorganisms learning environmental correlations. Given the ubiquitous and
essential presence of learning behaviours in the biosphere, we aimed to explore
whether simple, non-living dissipative structures could also exhibit
associative learning. Inspired by previous modeling of associative learning in
chemical networks, we simulated simple systems composed of long and short term
memory chemical species that could encode the presence or absence of temporal
correlations between two external species. The ability to learn this
association was implemented in Gray-Scott reaction-diffusion spots, emergent
chemical patterns that exhibit self-replication and homeostasis. With the novel
ability of associative learning, we demonstrate that simple chemical patterns
can exhibit a broad repertoire of life-like behaviour, paving the way for in
vitro studies of autonomous chemical learning systems, with potential relevance
to artificial life, origins of life, and systems chemistry. The experimental
realisation of these learning behaviours in protocell systems could advance a
novel research direction in astrobiology, since our system significantly
reduces the lower bound on the required complexity for emergent learning.",2022-10-11,2022,2022-10,chemistry
Perspectives for self-driving labs in synthetic biology,"Self-driving labs (SDLs) combine fully automated experiments with artificial
intelligence (AI) that decides the next set of experiments. Taken to their
ultimate expression, SDLs could usher a new paradigm of scientific research,
where the world is probed, interpreted, and explained by machines for human
benefit. While there are functioning SDLs in the fields of chemistry and
materials science, we contend that synthetic biology provides a unique
opportunity since the genome provides a single target for affecting the
incredibly wide repertoire of biological cell behavior. However, the level of
investment required for the creation of biological SDLs is only warranted if
directed towards solving difficult and enabling biological questions. Here, we
discuss challenges and opportunities in creating SDLs for synthetic biology.",2022-10-14,2022,2022-10,chemistry
"PEMP: Leveraging Physics Properties to Enhance Molecular Property
  Prediction","Molecular property prediction is essential for drug discovery. In recent
years, deep learning methods have been introduced to this area and achieved
state-of-the-art performances. However, most of existing methods ignore the
intrinsic relations between molecular properties which can be utilized to
improve the performances of corresponding prediction tasks. In this paper, we
propose a new approach, namely Physics properties Enhanced Molecular Property
prediction (PEMP), to utilize relations between molecular properties revealed
by previous physics theory and physical chemistry studies. Specifically, we
enhance the training of the chemical and physiological property predictors with
related physics property prediction tasks. We design two different methods for
PEMP, respectively based on multi-task learning and transfer learning. Both
methods include a model-agnostic molecule representation module and a property
prediction module. In our implementation, we adopt both the state-of-the-art
molecule embedding models under the supervised learning paradigm and the
pretraining paradigm as the molecule representation module of PEMP,
respectively. Experimental results on public benchmark MoleculeNet show that
the proposed methods have the ability to outperform corresponding
state-of-the-art models.",2022-10-18,2022,2022-10,chemistry
"Solving the Schrodinger equation with genetic algorithms: a practical
  approach","The Schrodinger equation is one of the most important equations in physics
and chemistry and can be solved in the simplest cases by computer numerical
methods. Since the beginning of the 70s of the last century the computer began
to be used to solve this equation in elementary quantum systems, e.g. and in
the most complex case a hydrogen-like system. Obtaining the solution means
finding the wave function, which allows predicting the physical and chemical
properties of the quantum system. However, when a quantum system is more
complex than a hydrogen-like system then we must be satisfied with an
approximate solution of the equation. During the last decade the application of
algorithms and principles of quantum computation in disciplines other than
physics and chemistry, such as biology and artificial intelligence, has led to
the search for alternative techniques with which to obtain approximate
solutions of the Schrodinger equation. In this paper, we review and illustrate
the application of genetic algorithms, i.e. stochastic optimization procedures
inspired by Darwinian evolution, in elementary quantum systems and in quantum
models of artificial intelligence. In this last field, we illustrate with two
toy models how to solve the Schrodinger equation in an elementary model of a
quantum neuron and in the synthesis of quantum circuits controlling the
behavior of a Braitenberg vehicle.",2022-10-27,2022,2022-10,chemistry
"Exploring the Advantages of Quantum Generative Adversarial Networks in
  Generative Chemistry","De novo drug design with desired biological activities is crucial for
developing novel therapeutics for patients. The drug development process is
time and resource-consuming, and it has a low probability of success. Recent
advances in machine learning and deep learning technology have reduced the time
and cost of the discovery process and therefore, improved pharmaceutical
research and development. In this paper, we explore the combination of two
rapidly-developing fields with lead candidate discovery in the drug development
process. First, Artificial intelligence has already been demonstrated to
successfully accelerate conventional drug design approaches. Second, quantum
computing has demonstrated promising potential in different applications, such
as quantum chemistry, combinatorial optimizations, and machine learning. This
manuscript explores hybrid quantum-classical generative adversarial networks
(GAN) for small molecule discovery. We substituted each element of GAN with a
variational quantum circuit (VQC) and demonstrated the quantum advantages in
the small drug discovery. Utilizing a VQC in the noise generator of a GAN to
generate small molecules achieves better physicochemical properties and
performance in the goal-directed benchmark than the classical counterpart.
Moreover, we demonstrate the potential of a VQC with only tens of learnable
parameters in the generator of GAN to generate small molecules. We also
demonstrate the quantum advantage of a VQC in the discriminator of GAN. In this
hybrid model, the number of learnable parameters is significantly less than the
classical ones, and it can still generate valid molecules. The hybrid model
with only tens of training parameters in the quantum discriminator outperforms
the MLP-based one in terms of both generated molecule properties and the
achieved KL divergence.",2022-10-30,2022,2022-10,chemistry
"QuACK: Accelerating Gradient-Based Quantum Optimization with Koopman
  Operator Learning","Quantum optimization, a key application of quantum computing, has
traditionally been stymied by the linearly increasing complexity of gradient
calculations with an increasing number of parameters. This work bridges the gap
between Koopman operator theory, which has found utility in applications
because it allows for a linear representation of nonlinear dynamical systems,
and natural gradient methods in quantum optimization, leading to a significant
acceleration of gradient-based quantum optimization. We present Quantum-circuit
Alternating Controlled Koopman learning (QuACK), a novel framework that
leverages an alternating algorithm for efficient prediction of gradient
dynamics on quantum computers. We demonstrate QuACK's remarkable ability to
accelerate gradient-based optimization across a range of applications in
quantum optimization and machine learning. In fact, our empirical studies,
spanning quantum chemistry, quantum condensed matter, quantum machine learning,
and noisy environments, have shown accelerations of more than 200x speedup in
the overparameterized regime, 10x speedup in the smooth regime, and 3x speedup
in the non-smooth regime. With QuACK, we offer a robust advancement that
harnesses the advantage of gradient-based quantum optimization for practical
benefits.",2022-11-02,2022,2022-11,chemistry
Quantum Deep Dreaming: A Novel Approach for Quantum Circuit Design,"One of the challenges currently facing the quantum computing community is the
design of quantum circuits which can efficiently run on near-term quantum
computers, known as the quantum compiling problem. Algorithms such as the
Variational Quantum Eigensolver (VQE), Quantum Approximate Optimization
Algorithm (QAOA), and Quantum Architecture Search (QAS) have been shown to
generate or find optimal near-term quantum circuits. However, these methods are
computationally expensive and yield little insight into the circuit design
process. In this paper, we propose Quantum Deep Dreaming (QDD), an algorithm
that generates optimal quantum circuit architectures for specified objectives,
such as ground state preparation, while providing insight into the circuit
design process. In QDD, we first train a neural network to predict some
property of a quantum circuit (such as VQE energy). Then, we employ the Deep
Dreaming technique on the trained network to iteratively update an initial
circuit to achieve a target property value (such as ground state VQE energy).
Importantly, this iterative updating allows us to analyze the intermediate
circuits of the dreaming process and gain insights into the circuit features
that the network is modifying during dreaming. We demonstrate that QDD
successfully generates, or 'dreams', circuits of six qubits close to ground
state energy (Transverse Field Ising Model VQE energy) and that dreaming
analysis yields circuit design insights. QDD is designed to optimize circuits
with any target property and can be applied to circuit design problems both
within and outside of quantum chemistry. Hence, QDD lays the foundation for the
future discovery of optimized quantum circuits and for increased
interpretability of automated quantum algorithm design.",2022-11-05,2022,2022-11,chemistry
Toward Human-AI Co-creation to Accelerate Material Discovery,"There is an increasing need in our society to achieve faster advances in
Science to tackle urgent problems, such as climate changes, environmental
hazards, sustainable energy systems, pandemics, among others. In certain
domains like chemistry, scientific discovery carries the extra burden of
assessing risks of the proposed novel solutions before moving to the
experimental stage. Despite several recent advances in Machine Learning and AI
to address some of these challenges, there is still a gap in technologies to
support end-to-end discovery applications, integrating the myriad of available
technologies into a coherent, orchestrated, yet flexible discovery process.
Such applications need to handle complex knowledge management at scale,
enabling knowledge consumption and production in a timely and efficient way for
subject matter experts (SMEs). Furthermore, the discovery of novel functional
materials strongly relies on the development of exploration strategies in the
chemical space. For instance, generative models have gained attention within
the scientific community due to their ability to generate enormous volumes of
novel molecules across material domains. These models exhibit extreme
creativity that often translates in low viability of the generated candidates.
In this work, we propose a workbench framework that aims at enabling the
human-AI co-creation to reduce the time until the first discovery and the
opportunity costs involved. This framework relies on a knowledge base with
domain and process knowledge, and user-interaction components to acquire
knowledge and advise the SMEs. Currently,the framework supports four main
activities: generative modeling, dataset triage, molecule adjudication, and
risk assessment.",2022-11-05,2022,2022-11,chemistry
Model free variable importance for high dimensional data,"A model-agnostic variable importance method can be used with arbitrary
prediction functions. Here we present some model-free methods that do not
require access to the prediction function. This is useful when that function is
proprietary and not available, or just extremely expensive. It is also useful
when studying residuals from a model. The cohort Shapley (CS) method is
model-free but has exponential cost in the dimension of the input space. A
supervised on-manifold Shapley method from Frye et al. (2020) is also model
free but requires as input a second black box model that has to be trained for
the Shapley value problem. We introduce an integrated gradient (IG) version of
cohort Shapley, called IGCS, with cost $\mathcal{O}(nd)$. We show that over the
vast majority of the relevant unit cube that the IGCS value function is close
to a multilinear function for which IGCS matches CS. Another benefit of IGCS is
that is allows IG methods to be used with binary predictors. We use some area
between curves (ABC) measures to quantify the performance of IGCS. On a problem
from high energy physics we verify that IGCS has nearly the same ABCs as CS
does. We also use it on a problem from computational chemistry in 1024
variables. We see there that IGCS attains much higher ABCs than we get from
Monte Carlo sampling. The code is publicly available at
https://github.com/cohortshapley/cohortintgrad",2022-11-15,2022,2022-11,chemistry
"Near-Term Quantum Computing Techniques: Variational Quantum Algorithms,
  Error Mitigation, Circuit Compilation, Benchmarking and Classical Simulation","Quantum computing is a game-changing technology for global academia, research
centers and industries including computational science, mathematics, finance,
pharmaceutical, materials science, chemistry and cryptography. Although it has
seen a major boost in the last decade, we are still a long way from reaching
the maturity of a full-fledged quantum computer. That said, we will be in the
Noisy-Intermediate Scale Quantum (NISQ) era for a long time, working on dozens
or even thousands of qubits quantum computing systems. An outstanding
challenge, then, is to come up with an application that can reliably carry out
a nontrivial task of interest on the near-term quantum devices with
non-negligible quantum noise. To address this challenge, several near-term
quantum computing techniques, including variational quantum algorithms, error
mitigation, quantum circuit compilation and benchmarking protocols, have been
proposed to characterize and mitigate errors, and to implement algorithms with
a certain resistance to noise, so as to enhance the capabilities of near-term
quantum devices and explore the boundaries of their ability to realize useful
applications. Besides, the development of near-term quantum devices is
inseparable from the efficient classical simulation, which plays a vital role
in quantum algorithm design and verification, error-tolerant verification and
other applications. This review will provide a thorough introduction of these
near-term quantum computing techniques, report on their progress, and finally
discuss the future prospect of these techniques, which we hope will motivate
researchers to undertake additional studies in this field.",2022-11-16,2022,2022-11,chemistry
"SnCQA: A hardware-efficient equivariant quantum convolutional circuit
  architecture","We propose SnCQA, a set of hardware-efficient variational circuits of
equivariant quantum convolutional circuits respective to permutation symmetries
and spatial lattice symmetries with the number of qubits $n$. By exploiting
permutation symmetries of the system, such as lattice Hamiltonians common to
many quantum many-body and quantum chemistry problems, Our quantum neural
networks are suitable for solving machine learning problems where permutation
symmetries are present, which could lead to significant savings of
computational costs. Aside from its theoretical novelty, we find our
simulations perform well in practical instances of learning ground states in
quantum computational chemistry, where we could achieve comparable performances
to traditional methods with few tens of parameters. Compared to other
traditional variational quantum circuits, such as the pure hardware-efficient
ansatz (pHEA), we show that SnCQA is more scalable, accurate, and noise
resilient (with $20\times$ better performance on $3 \times 4$ square lattice
and $200\% - 1000\%$ resource savings in various lattice sizes and key
criterions such as the number of layers, parameters, and times to converge in
our cases), suggesting a potentially favorable experiment on near-time quantum
devices.",2022-11-23,2022,2022-11,chemistry
"Accelerating Inverse Learning via Intelligent Localization with
  Exploratory Sampling","In the scope of ""AI for Science"", solving inverse problems is a longstanding
challenge in materials and drug discovery, where the goal is to determine the
hidden structures given a set of desirable properties. Deep generative models
are recently proposed to solve inverse problems, but these currently use
expensive forward operators and struggle in precisely localizing the exact
solutions and fully exploring the parameter spaces without missing solutions.
In this work, we propose a novel approach (called iPage) to accelerate the
inverse learning process by leveraging probabilistic inference from deep
invertible models and deterministic optimization via fast gradient descent.
Given a target property, the learned invertible model provides a posterior over
the parameter space; we identify these posterior samples as an intelligent
prior initialization which enables us to narrow down the search space. We then
perform gradient descent to calibrate the inverse solutions within a local
region. Meanwhile, a space-filling sampling is imposed on the latent space to
better explore and capture all possible solutions. We evaluate our approach on
three benchmark tasks and two created datasets with real-world applications
from quantum chemistry and additive manufacturing, and find our method achieves
superior performance compared to several state-of-the-art baseline methods. The
iPage code is available at https://github.com/jxzhangjhu/MatDesINNe.",2022-12-02,2022,2022-12,chemistry
"Multi-modal Molecule Structure-text Model for Text-based Retrieval and
  Editing","There is increasing adoption of artificial intelligence in drug discovery.
However, existing studies use machine learning to mainly utilize the chemical
structures of molecules but ignore the vast textual knowledge available in
chemistry. Incorporating textual knowledge enables us to realize new drug
design objectives, adapt to text-based instructions and predict complex
biological activities. Here we present a multi-modal molecule structure-text
model, MoleculeSTM, by jointly learning molecules' chemical structures and
textual descriptions via a contrastive learning strategy. To train MoleculeSTM,
we construct a large multi-modal dataset, namely, PubChemSTM, with over 280,000
chemical structure-text pairs. To demonstrate the effectiveness and utility of
MoleculeSTM, we design two challenging zero-shot tasks based on text
instructions, including structure-text retrieval and molecule editing.
MoleculeSTM has two main properties: open vocabulary and compositionality via
natural language. In experiments, MoleculeSTM obtains the state-of-the-art
generalization ability to novel biochemical concepts across various benchmarks.",2022-12-21,2022,2022-12,chemistry
"ACE, a generic constraint solver","Constraint Programming (CP) is a useful technology for modeling and solving
combinatorial constrained problems. On the one hand, on can use a library like
PyCSP3 for easily modeling problems arising in various application fields
(e.g., scheduling, planning, data-mining, cryptography, bio-informatics,
organic chemistry, etc.). Problem instances can then be directly generated from
specific models and data. On the other hand, for solving instances (notably,
represented in XCSP3 format), one can use a constraint solver like ACE, which
is presented in this paper. ACE is an open-source constraint solver, developed
in Java, which focuses on integer variables (including 0/1-Boolean variables),
state-of-the-art table constraints, popular global constraints, search
heuristics and (mono-criterion) optimization.",2023-01-06,2023,2023-01,chemistry
Recent advances in artificial intelligence for retrosynthesis,"Retrosynthesis is the cornerstone of organic chemistry, providing chemists in
material and drug manufacturing access to poorly available and brand-new
molecules. Conventional rule-based or expert-based computer-aided synthesis has
obvious limitations, such as high labor costs and limited search space. In
recent years, dramatic breakthroughs driven by artificial intelligence have
revolutionized retrosynthesis. Here we aim to present a comprehensive review of
recent advances in AI-based retrosynthesis. For single-step and multi-step
retrosynthesis both, we first list their goal and provide a thorough taxonomy
of existing methods. Afterwards, we analyze these methods in terms of their
mechanism and performance, and introduce popular evaluation metrics for them,
in which we also provide a detailed comparison among representative methods on
several public datasets. In the next part we introduce popular databases and
established platforms for retrosynthesis. Finally, this review concludes with a
discussion about promising research directions in this field.",2023-01-14,2023,2023-01,chemistry
Ontology Pre-training for Poison Prediction,"Integrating human knowledge into neural networks has the potential to improve
their robustness and interpretability. We have developed a novel approach to
integrate knowledge from ontologies into the structure of a Transformer network
which we call ontology pre-training: we train the network to predict membership
in ontology classes as a way to embed the structure of the ontology into the
network, and subsequently fine-tune the network for the particular prediction
task. We apply this approach to a case study in predicting the potential
toxicity of a small molecule based on its molecular structure, a challenging
task for machine learning in life sciences chemistry. Our approach improves on
the state of the art, and moreover has several additional benefits. First, we
are able to show that the model learns to focus attention on more meaningful
chemical groups when making predictions with ontology pre-training than
without, paving a path towards greater robustness and interpretability. Second,
the training time is reduced after ontology pre-training, indicating that the
model is better placed to learn what matters for toxicity prediction with the
ontology pre-training than without. This strategy has general applicability as
a neuro-symbolic approach to embed meaningful semantics into neural networks.",2023-01-20,2023,2023-01,chemistry
"Can an AI Win Ghana's National Science and Maths Quiz? An AI Grand
  Challenge for Education","There is a lack of enough qualified teachers across Africa which hampers
efforts to provide adequate learning support such as educational question
answering (EQA) to students. An AI system that can enable students to ask
questions via text or voice and get instant answers will make high-quality
education accessible. Despite advances in the field of AI, there exists no
robust benchmark or challenge to enable building such an (EQA) AI within the
African context. Ghana's National Science and Maths Quiz competition (NSMQ) is
the perfect competition to evaluate the potential of such an AI due to its wide
coverage of scientific fields, variety of question types, highly competitive
nature, and live, real-world format. The NSMQ is a Jeopardy-style annual live
quiz competition in which 3 teams of 2 students compete by answering questions
across biology, chemistry, physics, and math in 5 rounds over 5 progressive
stages until a winning team is crowned for that year. In this position paper,
we propose the NSMQ AI Grand Challenge, an AI Grand Challenge for Education
using Ghana's National Science and Maths Quiz competition (NSMQ) as a case
study. Our proposed grand challenge is to ""Build an AI to compete live in
Ghana's National Science and Maths Quiz (NSMQ) competition and win - performing
better than the best contestants in all rounds and stages of the competition.""
We describe the competition, and key technical challenges to address along with
ideas from recent advances in machine learning that could be leveraged to solve
this challenge. This position paper is a first step towards conquering such a
challenge and importantly, making advances in AI for education in the African
context towards democratizing high-quality education across Africa.",2023-01-30,2023,2023-01,chemistry
"HOAX: A Hyperparameter Optimization Algorithm Explorer for Neural
  Networks","Computational chemistry has become an important tool to predict and
understand molecular properties and reactions. Even though recent years have
seen a significant growth in new algorithms and computational methods that
speed up quantum chemical calculations, the bottleneck for trajectory-based
methods to study photoinduced processes is still the huge number of electronic
structure calculations. In this work, we present an innovative solution, in
which the amount of electronic structure calculations is drastically reduced,
by employing machine learning algorithms and methods borrowed from the realm of
artificial intelligence. However, applying these algorithms effectively
requires finding optimal hyperparameters, which remains a challenge itself.
Here we present an automated user-friendly framework, HOAX, to perform the
hyperparameter optimization for neural networks, which bypasses the need for a
lengthy manual process. The neural network generated potential energy surfaces
(PESs) reduces the computational costs compared to the ab initio-based PESs. We
perform a comparative investigation on the performance of different
hyperparameter optimiziation algorithms, namely grid search, simulated
annealing, genetic algorithm, and bayesian optimizer in finding the optimal
hyperparameters necessary for constructing the well-performing neural network
in order to fit the PESs of small organic molecules. Our results show that this
automated toolkit not only facilitate a straightforward way to perform the
hyperparameter optimization but also the resulting neural networks-based
generated PESs are in reasonable agreement with the ab initio-based PESs.",2023-02-01,2023,2023-02,chemistry
"Molecular Geometry-aware Transformer for accurate 3D Atomic System
  modeling","Molecular dynamic simulations are important in computational physics,
chemistry, material, and biology. Machine learning-based methods have shown
strong abilities in predicting molecular energy and properties and are much
faster than DFT calculations. Molecular energy is at least related to atoms,
bonds, bond angles, torsion angles, and nonbonding atom pairs. Previous
Transformer models only use atoms as inputs which lack explicit modeling of the
aforementioned factors. To alleviate this limitation, we propose Moleformer, a
novel Transformer architecture that takes nodes (atoms) and edges (bonds and
nonbonding atom pairs) as inputs and models the interactions among them using
rotational and translational invariant geometry-aware spatial encoding.
Proposed spatial encoding calculates relative position information including
distances and angles among nodes and edges. We benchmark Moleformer on OC20 and
QM9 datasets, and our model achieves state-of-the-art on the initial state to
relaxed energy prediction of OC20 and is very competitive in QM9 on predicting
quantum chemical properties compared to other Transformer and Graph Neural
Network (GNN) methods which proves the effectiveness of the proposed
geometry-aware spatial encoding in Moleformer.",2023-02-02,2023,2023-02,chemistry
"Diversity Through Exclusion (DTE): Niche Identification for
  Reinforcement Learning through Value-Decomposition","Many environments contain numerous available niches of variable value, each
associated with a different local optimum in the space of behaviors (policy
space). In such situations it is often difficult to design a learning process
capable of evading distraction by poor local optima long enough to stumble upon
the best available niche. In this work we propose a generic reinforcement
learning (RL) algorithm that performs better than baseline deep Q-learning
algorithms in such environments with multiple variably-valued niches. The
algorithm we propose consists of two parts: an agent architecture and a
learning rule. The agent architecture contains multiple sub-policies. The
learning rule is inspired by fitness sharing in evolutionary computation and
applied in reinforcement learning using Value-Decomposition-Networks in a novel
manner for a single-agent's internal population. It can concretely be
understood as adding an extra loss term where one policy's experience is also
used to update all the other policies in a manner that decreases their value
estimates for the visited states. In particular, when one sub-policy visits a
particular state frequently this decreases the value predicted for other
sub-policies for going to that state. Further, we introduce an artificial
chemistry inspired platform where it is easy to create tasks with multiple
rewarding strategies utilizing different resources (i.e. multiple niches). We
show that agents trained this way can escape poor-but-attractive local optima
to instead converge to harder-to-discover higher value strategies in both the
artificial chemistry environments and in simpler illustrative environments.",2023-02-02,2023,2023-02,chemistry
"Dynamical Equations With Bottom-up Self-Organizing Properties Learn
  Accurate Dynamical Hierarchies Without Any Loss Function","Self-organization is ubiquitous in nature and mind. However, machine learning
and theories of cognition still barely touch the subject. The hurdle is that
general patterns are difficult to define in terms of dynamical equations and
designing a system that could learn by reordering itself is still to be seen.
Here, we propose a learning system, where patterns are defined within the realm
of nonlinear dynamics with positive and negative feedback loops, allowing
attractor-repeller pairs to emerge for each pattern observed. Experiments
reveal that such a system can map temporal to spatial correlation, enabling
hierarchical structures to be learned from sequential data. The results are
accurate enough to surpass state-of-the-art unsupervised learning algorithms in
seven out of eight experiments as well as two real-world problems.
Interestingly, the dynamic nature of the system makes it inherently adaptive,
giving rise to phenomena similar to phase transitions in
chemistry/thermodynamics when the input structure changes. Thus, the work here
sheds light on how self-organization can allow for pattern recognition and
hints at how intelligent behavior might emerge from simple dynamic equations
without any objective/loss function.",2023-02-04,2023,2023-02,chemistry
"Orders-of-coupling representation with a single neural network with
  optimal neuron activation functions and without nonlinear parameter
  optimization","Representations of multivariate functions with low-dimensional functions that
depend on subsets of original coordinates (corresponding of different orders of
coupling) are useful in quantum dynamics and other applications, especially
where integration is needed. Such representations can be conveniently built
with machine learning methods, and previously, methods building the
lower-dimensional terms of such representations with neural networks [e.g.
Comput. Phys. Comm. 180 (2009) 2002] and Gaussian process regressions [e.g.
Mach. Learn. Sci. Technol. 3 (2022) 01LT02] were proposed. Here, we show that
neural network models of orders-of-coupling representations can be easily built
by using a recently proposed neural network with optimal neuron activation
functions computed with a first-order additive Gaussian process regression
[arXiv:2301.05567] and avoiding non-linear parameter optimization. Examples are
given of representations of molecular potential energy surfaces.",2023-02-11,2023,2023-02,chemistry
"PrefixMol: Target- and Chemistry-aware Molecule Design via Prefix
  Embedding","Is there a unified model for generating molecules considering different
conditions, such as binding pockets and chemical properties? Although
target-aware generative models have made significant advances in drug design,
they do not consider chemistry conditions and cannot guarantee the desired
chemical properties. Unfortunately, merging the target-aware and chemical-aware
models into a unified model to meet customized requirements may lead to the
problem of negative transfer. Inspired by the success of multi-task learning in
the NLP area, we use prefix embeddings to provide a novel generative model that
considers both the targeted pocket's circumstances and a variety of chemical
properties. All conditional information is represented as learnable features,
which the generative model subsequently employs as a contextual prompt.
Experiments show that our model exhibits good controllability in both single
and multi-conditional molecular generation. The controllability enables us to
outperform previous structure-based drug design methods. More interestingly, we
open up the attention mechanism and reveal coupling relationships between
conditions, providing guidance for multi-conditional molecule generation.",2023-02-14,2023,2023-02,chemistry
"CHA2: CHemistry Aware Convex Hull Autoencoder Towards Inverse Molecular
  Design","Optimizing molecular design and discovering novel chemical structures to meet
certain objectives, such as quantitative estimates of the drug-likeness score
(QEDs), is NP-hard due to the vast combinatorial design space of discrete
molecular structures, which makes it near impossible to explore the entire
search space comprehensively to exploit de novo structures with properties of
interest. To address this challenge, reducing the intractable search space into
a lower-dimensional latent volume helps examine molecular candidates more
feasibly via inverse design. Autoencoders are suitable deep learning
techniques, equipped with an encoder that reduces the discrete molecular
structure into a latent space and a decoder that inverts the search space back
to the molecular design. The continuous property of the latent space, which
characterizes the discrete chemical structures, provides a flexible
representation for inverse design in order to discover novel molecules.
However, exploring this latent space requires certain insights to generate new
structures. We propose using a convex hall surrounding the top molecules in
terms of high QEDs to ensnare a tight subspace in the latent representation as
an efficient way to reveal novel molecules with high QEDs. We demonstrate the
effectiveness of our suggested method by using the QM9 as a training dataset
along with the Self- Referencing Embedded Strings (SELFIES) representation to
calibrate the autoencoder in order to carry out the Inverse molecular design
that leads to unfold novel chemical structure.",2023-02-21,2023,2023-02,chemistry
Neuro-symbolic Commonsense Social Reasoning,"Social norms underlie all human social interactions, yet formalizing and
reasoning with them remains a major challenge for AI systems. We present a
novel system for taking social rules of thumb (ROTs) in natural language from
the Social Chemistry 101 dataset and converting them to first-order logic where
reasoning is performed using a neuro-symbolic theorem prover. We accomplish
this in several steps. First, ROTs are converted into Abstract Meaning
Representation (AMR), which is a graphical representation of the concepts in a
sentence, and align the AMR with RoBERTa embeddings. We then generate alternate
simplified versions of the AMR via a novel algorithm, recombining and merging
embeddings for added robustness against different wordings of text, and
incorrect AMR parses. The AMR is then converted into first-order logic, and is
queried with a neuro-symbolic theorem prover. The goal of this paper is to
develop and evaluate a neuro-symbolic method which performs explicit reasoning
about social situations in a logical form.",2023-03-14,2023,2023-03,chemistry
"HomPINNs: homotopy physics-informed neural networks for solving the
  inverse problems of nonlinear differential equations with multiple solutions","Due to the complex behavior arising from non-uniqueness, symmetry, and
bifurcations in the solution space, solving inverse problems of nonlinear
differential equations (DEs) with multiple solutions is a challenging task. To
address this, we propose homotopy physics-informed neural networks (HomPINNs),
a novel framework that leverages homotopy continuation and neural networks
(NNs) to solve inverse problems. The proposed framework begins with the use of
NNs to simultaneously approximate unlabeled observations across diverse
solutions while adhering to DE constraints. Through homotopy continuation, the
proposed method solves the inverse problem by tracing the observations and
identifying multiple solutions. The experiments involve testing the performance
of the proposed method on one-dimensional DEs and applying it to solve a
two-dimensional Gray-Scott simulation. Our findings demonstrate that the
proposed method is scalable and adaptable, providing an effective solution for
solving DEs with multiple solutions and unknown parameters. Moreover, it has
significant potential for various applications in scientific computing, such as
modeling complex systems and solving inverse problems in physics, chemistry,
biology, etc.",2023-04-06,2023,2023-04,chemistry
"Deep learning of experimental electrochemistry for battery cathodes
  across diverse compositions","Artificial intelligence (AI) has emerged as a tool for discovering and
optimizing novel battery materials. However, the adoption of AI in battery
cathode representation and discovery is still limited due to the complexity of
optimizing multiple performance properties and the scarcity of high-fidelity
data. In this study, we present a machine-learning model (DRXNet) for battery
informatics and demonstrate the application in the discovery and optimization
of disordered rocksalt (DRX) cathode materials. We have compiled the
electrochemistry data of DRX cathodes over the past five years, resulting in a
dataset of more than 19,000 discharge voltage profiles on diverse chemistries
spanning 14 different metal species. Learning from this extensive dataset, our
DRXNet model can automatically capture critical features in the cycling curves
of DRX cathodes under various conditions. Illustratively, the model gives
rational predictions of the discharge capacity for diverse compositions in the
Li--Mn--O--F chemical space as well as for high-entropy systems. As a universal
model trained on diverse chemistries, our approach offers a data-driven
solution to facilitate the rapid identification of novel cathode materials,
accelerating the development of next-generation batteries for carbon
neutralization.",2023-04-11,2023,2023-04,chemistry
"Cluster Flow: how a hierarchical clustering layer make allows deep-NNs
  more resilient to hacking, more human-like and easily implements relational
  reasoning","Despite the huge recent breakthroughs in neural networks (NNs) for artificial
intelligence (specifically deep convolutional networks) such NNs do not achieve
human-level performance: they can be hacked by images that would fool no human
and lack `common sense'. It has been argued that a basis of human-level
intelligence is mankind's ability to perform relational reasoning: the
comparison of different objects, measuring similarity, grasping of relations
between objects and the converse, figuring out the odd one out in a set of
objects. Mankind can even do this with objects they have never seen before.
Here we show how ClusterFlow, a semi-supervised hierarchical clustering
framework can operate on trained NNs utilising the rich multi-dimensional class
and feature data found at the pre-SoftMax layer to build a hyperspacial map of
classes/features and this adds more human-like functionality to modern deep
convolutional neural networks. We demonstrate this with 3 tasks. 1. the
statistical learning based `mistakes' made by infants when attending to images
of cats and dogs. 2. improving both the resilience to hacking images and the
accurate measure of certainty in deep-NNs. 3. Relational reasoning over sets of
images, including those not known to the NN nor seen before. We also
demonstrate that ClusterFlow can work on non-NN data and deal with missing data
by testing it on a Chemistry dataset. This work suggests that modern deep NNs
can be made more human-like without re-training of the NNs. As it is known that
some methods used in deep and convolutional NNs are not biologically plausible
or perhaps even the best approach: the ClusterFlow framework can sit on top of
any NN and will be a useful tool to add as NNs are improved in this regard.",2023-04-27,2023,2023-04,chemistry
An Exploration of Conditioning Methods in Graph Neural Networks,"The flexibility and effectiveness of message passing based graph neural
networks (GNNs) induced considerable advances in deep learning on
graph-structured data. In such approaches, GNNs recursively update node
representations based on their neighbors and they gain expressivity through the
use of node and edge attribute vectors. E.g., in computational tasks such as
physics and chemistry usage of edge attributes such as relative position or
distance proved to be essential. In this work, we address not what kind of
attributes to use, but how to condition on this information to improve model
performance. We consider three types of conditioning; weak, strong, and pure,
which respectively relate to concatenation-based conditioning, gating, and
transformations that are causally dependent on the attributes. This
categorization provides a unifying viewpoint on different classes of GNNs, from
separable convolutions to various forms of message passing networks. We provide
an empirical study on the effect of conditioning methods in several tasks in
computational chemistry.",2023-05-03,2023,2023-05,chemistry
"G-MATT: Single-step Retrosynthesis Prediction using Molecular Grammar
  Tree Transformer","Various template-based and template-free approaches have been proposed for
single-step retrosynthesis prediction in recent years. While these approaches
demonstrate strong performance from a data-driven metrics standpoint, many
model architectures do not incorporate underlying chemistry principles. Here,
we propose a novel chemistry-aware retrosynthesis prediction framework that
combines powerful data-driven models with prior domain knowledge. We present a
tree-to-sequence transformer architecture that utilizes hierarchical SMILES
grammar-based trees, incorporating crucial chemistry information that is often
overlooked by SMILES text-based representations, such as local structures and
functional groups. The proposed framework, grammar-based molecular attention
tree transformer (G-MATT), achieves significant performance improvements
compared to baseline retrosynthesis models. G-MATT achieves a promising top-1
accuracy of 51% (top-10 accuracy of 79.1%), invalid rate of 1.5%, and bioactive
similarity rate of 74.8% on the USPTO- 50K dataset. Additional analyses of
G-MATT attention maps demonstrate the ability to retain chemistry knowledge
without relying on excessively complex model architectures.",2023-05-04,2023,2023-05,chemistry
RxnScribe: A Sequence Generation Model for Reaction Diagram Parsing,"Reaction diagram parsing is the task of extracting reaction schemes from a
diagram in the chemistry literature. The reaction diagrams can be arbitrarily
complex, thus robustly parsing them into structured data is an open challenge.
In this paper, we present RxnScribe, a machine learning model for parsing
reaction diagrams of varying styles. We formulate this structured prediction
task with a sequence generation approach, which condenses the traditional
pipeline into an end-to-end model. We train RxnScribe on a dataset of 1,378
diagrams and evaluate it with cross validation, achieving an 80.0% soft match
F1 score, with significant improvements over previous models. Our code and data
are publicly available at https://github.com/thomas0809/RxnScribe.",2023-05-19,2023,2023-05,chemistry
"Automated Feedback Generation for a Chemistry Database and Abstracting
  Exercise","Timely feedback is an important part of teaching and learning. Here we
describe how a readily available neural network transformer (machine-learning)
model (BERT) can be used to give feedback on the structure of the response to
an abstracting exercise where students are asked to summarise the contents of a
published article after finding it from a publication database. The dataset
contained 207 submissions from two consecutive years of the course, summarising
a total of 21 different papers from the primary literature. The model was
pre-trained using an available dataset (approx. 15,000 samples) and then
fine-tuned on 80% of the submitted dataset. This fine tuning was seen to be
important. The sentences in the student submissions are characterised into
three classes - background, technique and observation - which allows a
comparison of how each submission is structured. Comparing the structure of the
students' abstract a large collection of those from the PubMed database shows
that students in this exercise concentrate more on the background to the paper
and less on the techniques and results than the abstracts to papers themselves.
The results allowed feedback for each submitted assignment to be automatically
generated.",2023-05-22,2023,2023-05,chemistry
"Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For
  Large Language Models","The performance of large language models (LLMs) on existing reasoning
benchmarks has significantly improved over the past years. In response, we
present JEEBench, a considerably more challenging benchmark dataset for
evaluating the problem solving abilities of LLMs. We curate 515 challenging
pre-engineering mathematics, physics and chemistry problems from the highly
competitive IIT JEE-Advanced exam. Long-horizon reasoning on top of deep
in-domain knowledge is essential for solving problems in this benchmark. Our
evaluation on various open-source and proprietary models reveals that the
highest performance, even after using techniques like self-consistency,
self-refinement and chain-of-thought prompting, is less than 40%. The typical
failure modes of GPT-4, the best model, are errors in algebraic manipulation,
difficulty in grounding abstract concepts into mathematical equations
accurately and failure in retrieving relevant domain-specific concepts. We also
observe that by mere prompting, GPT-4 is unable to assess risk introduced by
negative marking for incorrect answers. For this, we develop a post-hoc
confidence-thresholding method over self-consistency, which enables effective
response selection. We hope that our challenging benchmark will guide future
re-search in problem-solving using LLMs.",2023-05-24,2023,2023-05,chemistry
"Metrics for quantifying isotropy in high dimensional unsupervised
  clustering tasks in a materials context","Clustering is a common task in machine learning, but clusters of unlabelled
data can be hard to quantify. The application of clustering algorithms in
chemistry is often dependant on material representation. Ascertaining the
effects of different representations, clustering algorithms, or data
transformations on the resulting clusters is difficult due to the
dimensionality of these data. We present a thorough analysis of measures for
isotropy of a cluster, including a novel implantation based on an existing
derivation. Using fractional anisotropy, a common method used in medical
imaging for comparison, we then expand these measures to examine the average
isotropy of a set of clusters. A use case for such measures is demonstrated by
quantifying the effects of kernel approximation functions on different
representations of the Inorganic Crystal Structure Database. Broader
applicability of these methods is demonstrated in analysing learnt embedding of
the MNIST dataset. Random clusters are explored to examine the differences
between isotropy measures presented, and to see how each method scales with the
dimensionality. Python implementations of these measures are provided for use
by the community.",2023-05-25,2023,2023-05,chemistry
"What can Large Language Models do in chemistry? A comprehensive
  benchmark on eight tasks","Large Language Models (LLMs) with strong abilities in natural language
processing tasks have emerged and have been applied in various kinds of areas
such as science, finance and software engineering. However, the capability of
LLMs to advance the field of chemistry remains unclear. In this paper, rather
than pursuing state-of-the-art performance, we aim to evaluate capabilities of
LLMs in a wide range of tasks across the chemistry domain. We identify three
key chemistry-related capabilities including understanding, reasoning and
explaining to explore in LLMs and establish a benchmark containing eight
chemistry tasks. Our analysis draws on widely recognized datasets facilitating
a broad exploration of the capacities of LLMs within the context of practical
chemistry. Five LLMs (GPT-4, GPT-3.5, Davinci-003, Llama and Galactica) are
evaluated for each chemistry task in zero-shot and few-shot in-context learning
settings with carefully selected demonstration examples and specially crafted
prompts. Our investigation found that GPT-4 outperformed other models and LLMs
exhibit different competitive levels in eight chemistry tasks. In addition to
the key findings from the comprehensive benchmark analysis, our work provides
insights into the limitation of current LLMs and the impact of in-context
learning settings on LLMs' performance across various chemistry tasks. The code
and datasets used in this study are available at
https://github.com/ChemFoundationModels/ChemLLMBench.",2023-05-27,2023,2023-05,chemistry
"Catalysis distillation neural network for the few shot open catalyst
  challenge","The integration of artificial intelligence and science has resulted in
substantial progress in computational chemistry methods for the design and
discovery of novel catalysts. Nonetheless, the challenges of electrocatalytic
reactions and developing a large-scale language model in catalysis persist, and
the recent success of ChatGPT's (Chat Generative Pre-trained Transformer)
few-shot methods surpassing BERT (Bidirectional Encoder Representation from
Transformers) underscores the importance of addressing limited data, expensive
computations, time constraints and structure-activity relationship in research.
Hence, the development of few-shot techniques for catalysis is critical and
essential, regardless of present and future requirements. This paper introduces
the Few-Shot Open Catalyst Challenge 2023, a competition aimed at advancing the
application of machine learning technology for predicting catalytic reactions
on catalytic surfaces, with a specific focus on dual-atom catalysts in hydrogen
peroxide electrocatalysis. To address the challenge of limited data in
catalysis, we propose a machine learning approach based on MLP-Like and a
framework called Catalysis Distillation Graph Neural Network (CDGNN). Our
results demonstrate that CDGNN effectively learns embeddings from catalytic
structures, enabling the capture of structure-adsorption relationships. This
accomplishment has resulted in the utmost advanced and efficient determination
of the reaction pathway for hydrogen peroxide, surpassing the current graph
neural network approach by 16.1%.. Consequently, CDGNN presents a promising
approach for few-shot learning in catalysis.",2023-05-31,2023,2023-05,chemistry
chemSKI with tokens: world building and economy in the SKI universe,"chemSKI with tokens is a confluent graph rewrite system where all rewrites
are local, which moreover can be used to do SKI calculus reductions. The graph
rewrites of chemSKI are made conservative by the use of tokens. We thus achieve
several goals: conservative rewrites in a chemical style, a solution to the
problem of new edge names in a distributed, decentralized graphical reduction
and a new estimation of the cost of a combinatory calculus computation. This
formalism can be used either as an artificial chemistry or as a model of a
virtual decentralized machine which performs only local reductions. A programs
repository and the same article with simulations are available at github at
https://mbuliga.github.io/chemski/chemski-with-tokens.html",2023-06-01,2023,2023-06,chemistry
CIN++: Enhancing Topological Message Passing,"Graph Neural Networks (GNNs) have demonstrated remarkable success in learning
from graph-structured data. However, they face significant limitations in
expressive power, struggling with long-range interactions and lacking a
principled approach to modeling higher-order structures and group interactions.
Cellular Isomorphism Networks (CINs) recently addressed most of these
challenges with a message passing scheme based on cell complexes. Despite their
advantages, CINs make use only of boundary and upper messages which do not
consider a direct interaction between the rings present in the underlying
complex. Accounting for these interactions might be crucial for learning
representations of many real-world complex phenomena such as the dynamics of
supramolecular assemblies, neural activity within the brain, and gene
regulation processes. In this work, we propose CIN++, an enhancement of the
topological message passing scheme introduced in CINs. Our message passing
scheme accounts for the aforementioned limitations by letting the cells to
receive also lower messages within each layer. By providing a more
comprehensive representation of higher-order and long-range interactions, our
enhanced topological message passing scheme achieves state-of-the-art results
on large-scale and long-range chemistry benchmarks.",2023-06-06,2023,2023-06,chemistry
"A generative artificial intelligence framework based on a molecular
  diffusion model for the design of metal-organic frameworks for carbon capture","Metal-organic frameworks (MOFs) exhibit great promise for CO2 capture.
However, finding the best performing materials poses computational and
experimental grand challenges in view of the vast chemical space of potential
building blocks. Here, we introduce GHP-MOFassemble, a generative artificial
intelligence (AI), high performance framework for the rational and accelerated
design of MOFs with high CO2 adsorption capacity and synthesizable linkers.
GHP-MOFassemble generates novel linkers, assembled with one of three
pre-selected metal nodes (Cu paddlewheel, Zn paddlewheel, Zn tetramer) into
MOFs in a primitive cubic topology. GHP-MOFassemble screens and validates
AI-generated MOFs for uniqueness, synthesizability, structural validity, uses
molecular dynamics simulations to study their stability and chemical
consistency, and crystal graph neural networks and Grand Canonical Monte Carlo
simulations to quantify their CO2 adsorption capacities. We present the top six
AI-generated MOFs with CO2 capacities greater than 2 $m mol/g$, i.e., higher
than 96.9% of structures in the hypothetical MOF dataset.",2023-06-14,2023,2023-06,chemistry
"Symmetry-Informed Geometric Representation for Molecules, Proteins, and
  Crystalline Materials","Artificial intelligence for scientific discovery has recently generated
significant interest within the machine learning and scientific communities,
particularly in the domains of chemistry, biology, and material discovery. For
these scientific problems, molecules serve as the fundamental building blocks,
and machine learning has emerged as a highly effective and powerful tool for
modeling their geometric structures. Nevertheless, due to the rapidly evolving
process of the field and the knowledge gap between science (e.g., physics,
chemistry, & biology) and machine learning communities, a benchmarking study on
geometrical representation for such data has not been conducted. To address
such an issue, in this paper, we first provide a unified view of the current
symmetry-informed geometric methods, classifying them into three main
categories: invariance, equivariance with spherical frame basis, and
equivariance with vector frame basis. Then we propose a platform, coined
Geom3D, which enables benchmarking the effectiveness of geometric strategies.
Geom3D contains 16 advanced symmetry-informed geometric representation models
and 14 geometric pretraining methods over 46 diverse datasets, including small
molecules, proteins, and crystalline materials. We hope that Geom3D can, on the
one hand, eliminate barriers for machine learning researchers interested in
exploring scientific problems; and, on the other hand, provide valuable
guidance for researchers in computational chemistry, structural biology, and
materials science, aiding in the informed selection of representation
techniques for specific applications.",2023-06-15,2023,2023-06,chemistry
QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules,"Supervised machine learning approaches have been increasingly used in
accelerating electronic structure prediction as surrogates of first-principle
computational methods, such as density functional theory (DFT). While numerous
quantum chemistry datasets focus on chemical properties and atomic forces, the
ability to achieve accurate and efficient prediction of the Hamiltonian matrix
is highly desired, as it is the most important and fundamental physical
quantity that determines the quantum states of physical systems and chemical
properties. In this work, we generate a new Quantum Hamiltonian dataset, named
as QH9, to provide precise Hamiltonian matrices for 999 or 2998 molecular
dynamics trajectories and 130,831 stable molecular geometries, based on the QM9
dataset. By designing benchmark tasks with various molecules, we show that
current machine learning models have the capacity to predict Hamiltonian
matrices for arbitrary molecules. Both the QH9 dataset and the baseline models
are provided to the community through an open-source benchmark, which can be
highly valuable for developing machine learning methods and accelerating
molecular and materials design for scientific and technological applications.
Our benchmark is publicly available at
https://github.com/divelab/AIRS/tree/main/OpenDFT/QHBench.",2023-06-15,2023,2023-06,chemistry
On the Interplay of Subset Selection and Informed Graph Neural Networks,"Machine learning techniques paired with the availability of massive datasets
dramatically enhance our ability to explore the chemical compound space by
providing fast and accurate predictions of molecular properties. However,
learning on large datasets is strongly limited by the availability of
computational resources and can be infeasible in some scenarios. Moreover, the
instances in the datasets may not yet be labelled and generating the labels can
be costly, as in the case of quantum chemistry computations. Thus, there is a
need to select small training subsets from large pools of unlabelled data
points and to develop reliable ML methods that can effectively learn from small
training sets. This work focuses on predicting the molecules atomization energy
in the QM9 dataset. We investigate the advantages of employing domain
knowledge-based data sampling methods for an efficient training set selection
combined with informed ML techniques. In particular, we show how maximizing
molecular diversity in the training set selection process increases the
robustness of linear and nonlinear regression techniques such as kernel methods
and graph neural networks. We also check the reliability of the predictions
made by the graph neural network with a model-agnostic explainer based on the
rate distortion explanation framework.",2023-06-15,2023,2023-06,chemistry
"Matrix Diagonalization as a Board Game: Teaching an Eigensolver the
  Fastest Path to Solution","Matrix diagonalization is at the cornerstone of numerous fields of scientific
computing. Diagonalizing a matrix to solve an eigenvalue problem requires a
sequential path of iterations that eventually reaches a sufficiently converged
and accurate solution for all the eigenvalues and eigenvectors. This typically
translates into a high computational cost. Here we demonstrate how
reinforcement learning, using the AlphaZero framework, can accelerate Jacobi
matrix diagonalizations by viewing the selection of the fastest path to
solution as a board game. To demonstrate the viability of our approach we apply
the Jacobi diagonalization algorithm to symmetric Hamiltonian matrices that
appear in quantum chemistry calculations. We find that a significant
acceleration can often be achieved. Our findings highlight the opportunity to
use machine learning as a promising tool to improve the performance of
numerical linear algebra.",2023-06-16,2023,2023-06,chemistry
A GPT-4 Reticular Chemist for Guiding MOF Discovery,"We present a new framework integrating the AI model GPT-4 into the iterative
process of reticular chemistry experimentation, leveraging a cooperative
workflow of interaction between AI and a human researcher. This GPT-4 Reticular
Chemist is an integrated system composed of three phases. Each of these
utilizes GPT-4 in various capacities, wherein GPT-4 provides detailed
instructions for chemical experimentation and the human provides feedback on
the experimental outcomes, including both success and failures, for the
in-context learning of AI in the next iteration. This iterative human-AI
interaction enabled GPT-4 to learn from the outcomes, much like an experienced
chemist, by a prompt-learning strategy. Importantly, the system is based on
natural language for both development and operation, eliminating the need for
coding skills, and thus, make it accessible to all chemists. Our collaboration
with GPT-4 Reticular Chemist guided the discovery of an isoreticular series of
MOFs, with each synthesis fine-tuned through iterative feedback and expert
suggestions. This workflow presents a potential for broader applications in
scientific research by harnessing the capability of large language models like
GPT-4 to enhance the feasibility and efficiency of research activities.",2023-06-20,2023,2023-06,chemistry
"NNQS-Transformer: an Efficient and Scalable Neural Network Quantum
  States Approach for Ab initio Quantum Chemistry","Neural network quantum state (NNQS) has emerged as a promising candidate for
quantum many-body problems, but its practical applications are often hindered
by the high cost of sampling and local energy calculation. We develop a
high-performance NNQS method for \textit{ab initio} electronic structure
calculations. The major innovations include: (1) A transformer based
architecture as the quantum wave function ansatz; (2) A data-centric
parallelization scheme for the variational Monte Carlo (VMC) algorithm which
preserves data locality and well adapts for different computing architectures;
(3) A parallel batch sampling strategy which reduces the sampling cost and
achieves good load balance; (4) A parallel local energy evaluation scheme which
is both memory and computationally efficient; (5) Study of real chemical
systems demonstrates both the superior accuracy of our method compared to
state-of-the-art and the strong and weak scalability for large molecular
systems with up to $120$ spin orbitals.",2023-06-29,2023,2023-06,chemistry
Artificial Intelligence for Drug Discovery: Are We There Yet?,"Drug discovery is adapting to novel technologies such as data science,
informatics, and artificial intelligence (AI) to accelerate effective treatment
development while reducing costs and animal experiments. AI is transforming
drug discovery, as indicated by increasing interest from investors, industrial
and academic scientists, and legislators. Successful drug discovery requires
optimizing properties related to pharmacodynamics, pharmacokinetics, and
clinical outcomes. This review discusses the use of AI in the three pillars of
drug discovery: diseases, targets, and therapeutic modalities, with a focus on
small molecule drugs. AI technologies, such as generative chemistry, machine
learning, and multi-property optimization, have enabled several compounds to
enter clinical trials. The scientific community must carefully vet known
information to address the reproducibility crisis. The full potential of AI in
drug discovery can only be realized with sufficient ground truth and
appropriate human intervention at later pipeline stages.",2023-07-13,2023,2023-07,chemistry
"SciBench: Evaluating College-Level Scientific Problem-Solving Abilities
  of Large Language Models","Most of the existing Large Language Model (LLM) benchmarks on scientific
problem reasoning focus on problems grounded in high-school subjects and are
confined to elementary algebraic operations. To systematically examine the
reasoning capabilities required for solving complex scientific problems, we
introduce an expansive benchmark suite SciBench for LLMs. SciBench contains a
carefully curated dataset featuring a range of collegiate-level scientific
problems from mathematics, chemistry, and physics domains. Based on the
dataset, we conduct an in-depth benchmarking study of representative
open-source and proprietary LLMs with various prompting strategies. The results
reveal that the current LLMs fall short of delivering satisfactory performance,
with the best overall score of merely 43.22%. Furthermore, through a detailed
user study, we categorize the errors made by LLMs into ten problem-solving
abilities. Our analysis indicates that no single prompting strategy
significantly outperforms the others and some strategies that demonstrate
improvements in certain problem-solving skills could result in declines in
other skills. We envision that SciBench will catalyze further developments in
the reasoning abilities of LLMs, thereby ultimately contributing to scientific
research and discovery.",2023-07-20,2023,2023-07,chemistry
"Rotation-Invariant Random Features Provide a Strong Baseline for Machine
  Learning on 3D Point Clouds","Rotational invariance is a popular inductive bias used by many fields in
machine learning, such as computer vision and machine learning for quantum
chemistry. Rotation-invariant machine learning methods set the state of the art
for many tasks, including molecular property prediction and 3D shape
classification. These methods generally either rely on task-specific
rotation-invariant features, or they use general-purpose deep neural networks
which are complicated to design and train. However, it is unclear whether the
success of these methods is primarily due to the rotation invariance or the
deep neural networks. To address this question, we suggest a simple and
general-purpose method for learning rotation-invariant functions of
three-dimensional point cloud data using a random features approach.
Specifically, we extend the random features method of Rahimi & Recht 2007 by
deriving a version that is invariant to three-dimensional rotations and showing
that it is fast to evaluate on point cloud data. We show through experiments
that our method matches or outperforms the performance of general-purpose
rotation-invariant neural networks on standard molecular property prediction
benchmark datasets QM7 and QM9. We also show that our method is general-purpose
and provides a rotation-invariant baseline on the ModelNet40 shape
classification task. Finally, we show that our method has an order of magnitude
smaller prediction latency than competing kernel methods.",2023-07-27,2023,2023-07,chemistry
"Ultrafast Radiographic Imaging and Tracking: An overview of instruments,
  methods, data, and applications","Ultrafast radiographic imaging and tracking (U-RadIT) use state-of-the-art
ionizing particle and light sources to experimentally study sub-nanosecond
dynamic processes in physics, chemistry, biology, geology, materials science
and other fields. These processes, fundamental to nuclear fusion energy,
advanced manufacturing, green transportation and others, often involve one mole
or more atoms, and thus are challenging to compute by using the first
principles of quantum physics or other forward models. One of the central
problems in U-RadIT is to optimize information yield through, e.g.
high-luminosity X-ray and particle sources, efficient imaging and tracking
detectors, novel methods to collect data, and large-bandwidth online and
offline data processing, regulated by the underlying physics, statistics, and
computing power. We review and highlight recent progress in: a.) Detectors; b.)
U-RadIT modalities; c.) Data and algorithms; and d.) Applications.
Hardware-centric approaches to U-RadIT optimization are constrained by detector
material properties, low signal-to-noise ratio, high cost and long development
cycles of critical hardware components such as ASICs. Interpretation of
experimental data, including comparisons with forward models, is frequently
hindered by sparse measurements, model and measurement uncertainties, and
noise. Alternatively, U-RadIT make increasing use of data science and machine
learning algorithms, including experimental implementations of compressed
sensing. Machine learning and artificial intelligence approaches, refined by
physics and materials information, may also contribute significantly to data
interpretation, uncertainty quantification, and U-RadIT optimization.",2023-08-21,2023,2023-08,chemistry
Beyond MD17: the reactive xxMD dataset,"System specific neural force fields (NFFs) have gained popularity in
computational chemistry. One of the most popular datasets as a bencharmk to
develop NFFs models is the MD17 dataset and its subsequent extension. These
datasets comprise geometries from the equilibrium region of the ground
electronic state potential energy surface, sampled from direct adiabatic
dynamics. However, many chemical reactions involve significant molecular
geometrical deformations, for example, bond breaking. Therefore, MD17 is
inadequate to represent a chemical reaction. To address this limitation in
MD17, we introduce a new dataset, called Extended Excited-state Molecular
Dynamics (xxMD) dataset. The xxMD dataset involves geometries sampled from
direct non-adiabatic dynamics, and the energies are computed at both
multireference wavefunction theory and density functional theory. We show that
the xxMD dataset involves diverse geometries which represent chemical
reactions. Assessment of NFF models on xxMD dataset reveals significantly
higher predictive errors than those reported for MD17 and its variants. This
work underscores the challenges faced in crafting a generalizable NFF model
with extrapolation capability.",2023-08-22,2023,2023-08,chemistry
DARWIN Series: Domain Specific Large Language Models for Natural Science,"Emerging tools bring forth fresh approaches to work, and the field of natural
science is no different. In natural science, traditional manual, serial, and
labour-intensive work is being augmented by automated, parallel, and iterative
processes driven by artificial intelligence-based experimental automation and
more. To add new capabilities in natural science, enabling the acceleration and
enrichment of automation of the discovery process, we present DARWIN, a series
of tailored LLMs for natural science, mainly in physics, chemistry, and
material science. This series relies on open-source LLM, incorporating
structured and unstructured scientific knowledge from public datasets and
literature. We fine-tuned the models using over 60,000 instruction data points,
emphasizing factual correctness. During the fine-tuning, we introduce the
Scientific Instruction Generation (SIG) model, automating instruction
generation from scientific texts. This eliminates the need for manual
extraction or domain-specific knowledge graphs and efficiently injects
scientific knowledge into the model. We also explore multi-task training
strategies, revealing interconnections between scientific tasks. DARWIN series
not only achieves state-of-the-art results on various scientific tasks but also
diminishes reliance on closed-source AI models. Our research showcases the
ability of LLM in the scientific domain, with the overarching goal of fostering
prosperity within the broader AI for science community.",2023-08-25,2023,2023-08,chemistry
"Enabling Inverse Design in Chemical Compound Space: Mapping Quantum
  Properties to Structures for Small Organic Molecules","Computer-driven molecular design combines the principles of chemistry,
physics, and artificial intelligence to identify novel chemical compounds and
materials with desired properties for a specific application. In particular,
quantum-mechanical (QM) methods combined with machine learning (ML) techniques
have accelerated the estimation of accurate molecular properties, providing a
direct mapping from 3D molecular structures to their properties. However, the
development of reliable and efficient methodologies to enable \emph{inverse
mapping} in chemical space is a long-standing challenge that has not been
accomplished yet. Here, we address this challenge by demonstrating the
possibility of parametrizing a given chemical space with a finite set of
extensive and intensive QM properties. In doing so, we develop a
proof-of-concept implementation that combines a Variational Auto-Encoder (VAE)
trained on molecular structures with a property encoder designed to learn the
latent representation from a set of QM properties. The result of this joint
architecture is a common latent space representation for both structures and
properties, which enables property-to-structure mapping for small drug-like
molecules contained in the QM7-X dataset. We illustrate the capabilities of our
approach by conditional generation of \emph{de novo} molecular structures with
targeted properties, transition path interpolation for chemical reactions as
well as insights into property-structure relationships. Our findings thus
provide a proof-of-principle demonstration aiming to enable the inverse
property-to-structure design in diverse chemical spaces.",2023-09-01,2023,2023-09,chemistry
"Gramian Angular Fields for leveraging pretrained computer vision models
  with anomalous diffusion trajectories","Anomalous diffusion is present at all scales, from atomic to large scales.
Some exemplary systems are; ultra-cold atoms, telomeres in the nucleus of
cells, moisture transport in cement-based materials, the free movement of
arthropods, and the migration patterns of birds. The characterization of the
diffusion gives critical information about the dynamics of these systems and
provides an interdisciplinary framework with which to study diffusive
transport. Thus, the problem of identifying underlying diffusive regimes and
inferring the anomalous diffusion exponent {$\alpha$} with high confidence is
critical to physics, chemistry, biology, and ecology. Classification and
analysis of raw trajectories combining machine learning techniques with
statistics extracted from them have widely been studied in the Anomalous
Diffusion Challenge ge (Munoz-Gil et al., 2021). Here we present a new
data-driven method for working with diffusive trajectories. This method
utilizes Gramian Angular Fields (GAF) to encode one-dimensional trajectories as
images (Gramian Matrices), while preserving their spatiotemporal structure for
input to computer-vision models. This allows us to leverage two
well-established pre-trained computer-vision models, ResNet and MobileNet, to
characterize the underlying diffusive regime, and infer the anomalous diffusion
exponent {$\alpha$}. Short raw trajectories, of lengths between 10 and 50, are
commonly encountered in single-particle tracking experiments and are the most
difficult to characterize. We show that by using GAF images, we can outperform
the current state-of-the-art while increasing accessibility to machine learning
methods in an applied setting.",2023-09-02,2023,2023-09,chemistry
"Insights Into the Inner Workings of Transformer Models for Protein
  Function Prediction","Motivation: We explored how explainable artificial intelligence (XAI) can
help to shed light into the inner workings of neural networks for protein
function prediction, by extending the widely used XAI method of integrated
gradients such that latent representations inside of transformer models, which
were finetuned to Gene Ontology term and Enzyme Commission number prediction,
can be inspected too. Results: The approach enabled us to identify amino acids
in the sequences that the transformers pay particular attention to, and to show
that these relevant sequence parts reflect expectations from biology and
chemistry, both in the embedding layer and inside of the model, where we
identified transformer heads with a statistically significant correspondence of
attribution maps with ground truth sequence annotations (e.g. transmembrane
regions, active sites) across many proteins. Availability and Implementation:
Source code can be accessed at https://github.com/markuswenzel/xai-proteins .",2023-09-07,2023,2023-09,chemistry
"CloudBrain-NMR: An Intelligent Cloud Computing Platform for NMR
  Spectroscopy Processing, Reconstruction and Analysis","Nuclear Magnetic Resonance (NMR) spectroscopy has served as a powerful
analytical tool for studying molecular structure and dynamics in chemistry and
biology. However, the processing of raw data acquired from NMR spectrometers
and subsequent quantitative analysis involves various specialized tools, which
necessitates comprehensive knowledge in programming and NMR. Particularly, the
emerging deep learning tools is hard to be widely used in NMR due to the
sophisticated setup of computation. Thus, NMR processing is not an easy task
for chemist and biologists. In this work, we present CloudBrain-NMR, an
intelligent online cloud computing platform designed for NMR data reading,
processing, reconstruction, and quantitative analysis. The platform is
conveniently accessed through a web browser, eliminating the need for any
program installation on the user side. CloudBrain-NMR uses parallel computing
with graphics processing units and central processing units, resulting in
significantly shortened computation time. Furthermore, it incorporates
state-of-the-art deep learning-based algorithms offering comprehensive
functionalities that allow users to complete the entire processing procedure
without relying on additional software. This platform has empowered NMR
applications with advanced artificial intelligence processing. CloudBrain-NMR
is openly accessible for free usage at https://csrc.xmu.edu.cn/CloudBrain.html",2023-09-12,2023,2023-09,chemistry
Molecular Conformation Generation via Shifting Scores,"Molecular conformation generation, a critical aspect of computational
chemistry, involves producing the three-dimensional conformer geometry for a
given molecule. Generating molecular conformation via diffusion requires
learning to reverse a noising process. Diffusion on inter-atomic distances
instead of conformation preserves SE(3)-equivalence and shows superior
performance compared to alternative techniques, whereas related generative
modelings are predominantly based upon heuristical assumptions. In response to
this, we propose a novel molecular conformation generation approach driven by
the observation that the disintegration of a molecule can be viewed as casting
increasing force fields to its composing atoms, such that the distribution of
the change of inter-atomic distance shifts from Gaussian to Maxwell-Boltzmann
distribution. The corresponding generative modeling ensures a feasible
inter-atomic distance geometry and exhibits time reversibility. Experimental
results on molecular datasets demonstrate the advantages of the proposed
shifting distribution compared to the state-of-the-art.",2023-09-12,2023,2023-09,chemistry
"GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven
  Robotic Lab","The integration of robots in chemical experiments has enhanced experimental
efficiency, but lacking the human intelligence to comprehend literature, they
seldom provide assistance in experimental design. Therefore, achieving
full-process autonomy from experiment design to validation in self-driven
laboratories (SDL) remains a challenge. The introduction of Generative
Pre-trained Transformers (GPT), particularly GPT-4, into robotic
experimentation offers a solution. We introduce GPT-Lab, a paradigm that
employs GPT models to give robots human-like intelligence. With our robotic
experimentation platform, GPT-Lab mines literature for materials and methods
and validates findings through high-throughput synthesis. As a demonstration,
GPT-Lab analyzed 500 articles, identified 18 potential reagents, and
successfully produced an accurate humidity colorimetric sensor with a root mean
square error (RMSE) of 2.68%. This showcases the rapid materials discovery and
validation potential of our system.",2023-09-15,2023,2023-09,chemistry
"Machine Learning Data Suitability and Performance Testing Using Fault
  Injection Testing Framework","Creating resilient machine learning (ML) systems has become necessary to
ensure production-ready ML systems that acquire user confidence seamlessly. The
quality of the input data and the model highly influence the successful
end-to-end testing in data-sensitive systems. However, the testing approaches
of input data are not as systematic and are few compared to model testing. To
address this gap, this paper presents the Fault Injection for Undesirable
Learning in input Data (FIUL-Data) testing framework that tests the resilience
of ML models to multiple intentionally-triggered data faults. Data mutators
explore vulnerabilities of ML systems against the effects of different fault
injections. The proposed framework is designed based on three main ideas: The
mutators are not random; one data mutator is applied at an instance of time,
and the selected ML models are optimized beforehand. This paper evaluates the
FIUL-Data framework using data from analytical chemistry, comprising retention
time measurements of anti-sense oligonucleotide. Empirical evaluation is
carried out in a two-step process in which the responses of selected ML models
to data mutation are analyzed individually and then compared with each other.
The results show that the FIUL-Data framework allows the evaluation of the
resilience of ML models. In most experiments cases, ML models show higher
resilience at larger training datasets, where gradient boost performed better
than support vector regression in smaller training sets. Overall, the mean
squared error metric is useful in evaluating the resilience of models due to
its higher sensitivity to data mutation.",2023-09-20,2023,2023-09,chemistry
"Morphological Computing as Logic Underlying Cognition in Human, Animal,
  and Intelligent Machine","This work examines the interconnections between logic, epistemology, and
sciences within the Naturalist tradition. It presents a scheme that connects
logic, mathematics, physics, chemistry, biology, and cognition, emphasizing
scale-invariant, self-organizing dynamics across organizational tiers of
nature. The inherent logic of agency exists in natural processes at various
levels, under information exchanges. It applies to humans, animals, and
artifactual agents. The common human-centric, natural language-based logic is
an example of complex logic evolved by living organisms that already appears in
the simplest form at the level of basal cognition of unicellular organisms.
Thus, cognitive logic stems from the evolution of physical, chemical, and
biological logic. In a computing nature framework with a self-organizing
agency, innovative computational frameworks grounded in
morphological/physical/natural computation can be used to explain the genesis
of human-centered logic through the steps of naturalized logical processes at
lower levels of organization. The Extended Evolutionary Synthesis of living
agents is essential for understanding the emergence of human-level logic and
the relationship between logic and information processing/computational
epistemology. We conclude that more research is needed to elucidate the details
of the mechanisms linking natural phenomena with the logic of agency in nature.",2023-09-25,2023,2023-09,chemistry
"C3Net: interatomic potential neural network for prediction of
  physicochemical properties in heterogenous systems","Understanding the interactions of a solute with its environment is of
fundamental importance in chemistry and biology. In this work, we propose a
deep neural network architecture for atom type embeddings in its molecular
context and interatomic potential that follows fundamental physical laws. The
architecture is applied to predict physicochemical properties in heterogeneous
systems including solvation in diverse solvents, 1-octanol-water partitioning,
and PAMPA with a single set of network weights. We show that our architecture
is generalized well to the physicochemical properties and outperforms
state-of-the-art approaches based on quantum mechanics and neural networks in
the task of solvation free energy prediction. The interatomic potentials at
each atom in a solute obtained from the model allow quantitative analysis of
the physicochemical properties at atomic resolution consistent with chemical
and physical reasoning. The software is available at
https://github.com/SehanLee/C3Net.",2023-09-27,2023,2023-09,chemistry
Language models in molecular discovery,"The success of language models, especially transformer-based architectures,
has trickled into other domains giving rise to ""scientific language models""
that operate on small molecules, proteins or polymers. In chemistry, language
models contribute to accelerating the molecule discovery cycle as evidenced by
promising recent findings in early-stage drug discovery. Here, we review the
role of language models in molecular discovery, underlining their strength in
de novo drug design, property prediction and reaction chemistry. We highlight
valuable open-source software assets thus lowering the entry barrier to the
field of scientific language modeling. Last, we sketch a vision for future
molecular design that combines a chatbot interface with access to computational
chemistry tools. Our contribution serves as a valuable resource for
researchers, chemists, and AI enthusiasts interested in understanding how
language models can and will be used to accelerate chemical discovery.",2023-09-28,2023,2023-09,chemistry
Neural scaling laws for phenotypic drug discovery,"Recent breakthroughs by deep neural networks (DNNs) in natural language
processing (NLP) and computer vision have been driven by a scale-up of models
and data rather than the discovery of novel computing paradigms. Here, we
investigate if scale can have a similar impact for models designed to aid small
molecule drug discovery. We address this question through a large-scale and
systematic analysis of how DNN size, data diet, and learning routines interact
to impact accuracy on our Phenotypic Chemistry Arena (Pheno-CA) benchmark: a
diverse set of drug development tasks posed on image-based high content
screening data. Surprisingly, we find that DNNs explicitly supervised to solve
tasks in the Pheno-CA do not continuously improve as their data and model size
is scaled-up. To address this issue, we introduce a novel precursor task, the
Inverse Biological Process (IBP), which is designed to resemble the causal
objective functions that have proven successful for NLP. We indeed find that
DNNs first trained with IBP then probed for performance on the Pheno-CA
significantly outperform task-supervised DNNs. More importantly, the
performance of these IBP-trained DNNs monotonically improves with data and
model scale. Our findings reveal that the DNN ingredients needed to accurately
solve small molecule drug development tasks are already in our hands, and
project how much more experimental data is needed to achieve any desired level
of improvement. We release our Pheno-CA benchmark and code to encourage further
study of neural scaling laws for small molecule drug discovery.",2023-09-28,2023,2023-09,chemistry
"Knowledge Graphs for the Life Sciences: Recent Developments, Challenges
  and Opportunities","The term life sciences refers to the disciplines that study living organisms
and life processes, and include chemistry, biology, medicine, and a range of
other related disciplines. Research efforts in life sciences are heavily
data-driven, as they produce and consume vast amounts of scientific data, much
of which is intrinsically relational and graph-structured.
  The volume of data and the complexity of scientific concepts and relations
referred to therein promote the application of advanced knowledge-driven
technologies for managing and interpreting data, with the ultimate aim to
advance scientific discovery.
  In this survey and position paper, we discuss recent developments and
advances in the use of graph-based technologies in life sciences and set out a
vision for how these technologies will impact these fields into the future. We
focus on three broad topics: the construction and management of Knowledge
Graphs (KGs), the use of KGs and associated technologies in the discovery of
new knowledge, and the use of KGs in artificial intelligence applications to
support explanations (explainable AI). We select a few exemplary use cases for
each topic, discuss the challenges and open research questions within these
topics, and conclude with a perspective and outlook that summarizes the
overarching challenges and their potential solutions as a guide for future
research.",2023-09-29,2023,2023-09,chemistry
"UPAR: A Kantian-Inspired Prompting Framework for Enhancing Large
  Language Model Capabilities","Large Language Models (LLMs) have demonstrated impressive inferential
capabilities, with numerous research endeavors devoted to enhancing this
capacity through prompting. Despite these efforts, a unified epistemological
foundation is still conspicuously absent. Drawing inspiration from Kant's a
priori philosophy, we propose the UPAR prompting framework, designed to emulate
the structure of human cognition within LLMs. The UPAR framework is delineated
into four phases: ""Understand"", ""Plan"", ""Act"", and ""Reflect"", enabling the
extraction of structured information from complex contexts, prior planning of
solutions, execution according to plan, and self-reflection. This structure
significantly augments the explainability and accuracy of LLM inference,
producing a human-understandable and inspectable inferential trajectory.
Furthermore, our work offers an epistemological foundation for existing
prompting techniques, allowing for a possible systematic integration of these
methods. With GPT-4, our approach elevates the accuracy from COT baseline of
22.92% to 58.33% in a challenging subset of GSM8K, and from 67.91% to 75.40% in
the causal judgment task. Without using few-shot examples or external tools,
UPAR significantly outperforms existing prompting methods on SCIBENCH, a
challenging dataset containing collegiate-level mathematics, chemistry, and
physics scientific problems.",2023-09-30,2023,2023-09,chemistry
On Training Derivative-Constrained Neural Networks,"We refer to the setting where the (partial) derivatives of a neural network's
(NN's) predictions with respect to its inputs are used as additional training
signal as a derivative-constrained (DC) NN. This situation is common in
physics-informed settings in the natural sciences. We propose an integrated
RELU (IReLU) activation function to improve training of DC NNs. We also
investigate denormalization and label rescaling to help stabilize DC training.
We evaluate our methods on physics-informed settings including quantum
chemistry and Scientific Machine Learning (SciML) tasks. We demonstrate that
existing architectures with IReLU activations combined with denormalization and
label rescaling better incorporate training signal provided by derivative
constraints.",2023-10-02,2023,2023-10,chemistry
MapperGPT: Large Language Models for Linking and Mapping Entities,"Aligning terminological resources, including ontologies, controlled
vocabularies, taxonomies, and value sets is a critical part of data integration
in many domains such as healthcare, chemistry, and biomedical research. Entity
mapping is the process of determining correspondences between entities across
these resources, such as gene identifiers, disease concepts, or chemical entity
identifiers. Many tools have been developed to compute such mappings based on
common structural features and lexical information such as labels and synonyms.
Lexical approaches in particular often provide very high recall, but low
precision, due to lexical ambiguity. As a consequence of this, mapping efforts
often resort to a labor intensive manual mapping refinement through a human
curator.
  Large Language Models (LLMs), such as the ones employed by ChatGPT, have
generalizable abilities to perform a wide range of tasks, including
question-answering and information extraction. Here we present MapperGPT, an
approach that uses LLMs to review and refine mapping relationships as a
post-processing step, in concert with existing high-recall methods that are
based on lexical and structural heuristics.
  We evaluated MapperGPT on a series of alignment tasks from different domains,
including anatomy, developmental biology, and renal diseases. We devised a
collection of tasks that are designed to be particularly challenging for
lexical methods. We show that when used in combination with high-recall
methods, MapperGPT can provide a substantial improvement in accuracy, beating
state-of-the-art (SOTA) methods such as LogMap.",2023-10-05,2023,2023-10,chemistry
Evolutionary Retrosynthetic Route Planning,"Molecular retrosynthesis is a significant and complex problem in the field of
chemistry, however, traditional manual synthesis methods not only need
well-trained experts but also are time-consuming. With the development of big
data and machine learning, artificial intelligence (AI) based retrosynthesis is
attracting more attention and has become a valuable tool for molecular
retrosynthesis. At present, Monte Carlo tree search is a mainstream search
framework employed to address this problem. Nevertheless, its search efficiency
is compromised by its large search space. Therefore, this paper proposes a
novel approach for retrosynthetic route planning based on evolutionary
optimization, marking the first use of Evolutionary Algorithm (EA) in the field
of multi-step retrosynthesis. The proposed method involves modeling the
retrosynthetic problem into an optimization problem, defining the search space
and operators. Additionally, to improve the search efficiency, a parallel
strategy is implemented. The new approach is applied to four case products and
compared with Monte Carlo tree search. The experimental results show that, in
comparison to the Monte Carlo tree search algorithm, EA significantly reduces
the number of calling single-step model by an average of 53.9%. The time
required to search three solutions decreases by an average of 83.9%, and the
number of feasible search routes increases by 1.38 times. The source code is
available at https://github.com/ilog-ecnu/EvoRRP.",2023-10-08,2023,2023-10,chemistry
"Take a Step Back: Evoking Reasoning via Abstraction in Large Language
  Models","We present Step-Back Prompting, a simple prompting technique that enables
LLMs to do abstractions to derive high-level concepts and first principles from
instances containing specific details. Using the concepts and principles to
guide reasoning, LLMs significantly improve their abilities in following a
correct reasoning path towards the solution. We conduct experiments of
Step-Back Prompting with PaLM-2L, GPT-4 and Llama2-70B models, and observe
substantial performance gains on various challenging reasoning-intensive tasks
including STEM, Knowledge QA, and Multi-Hop Reasoning. For instance, Step-Back
Prompting improves PaLM-2L performance on MMLU (Physics and Chemistry) by 7%
and 11% respectively, TimeQA by 27%, and MuSiQue by 7%.",2023-10-09,2023,2023-10,chemistry
"Cousins Of The Vendi Score: A Family Of Similarity-Based Diversity
  Metrics For Science And Machine Learning","Measuring diversity accurately is important for many scientific fields,
including machine learning (ML), ecology, and chemistry. The Vendi Score was
introduced as a generic similarity-based diversity metric that extends the Hill
number of order q=1 by leveraging ideas from quantum statistical mechanics.
Contrary to many diversity metrics in ecology, the Vendi Score accounts for
similarity and does not require knowledge of the prevalence of the categories
in the collection to be evaluated for diversity. However, the Vendi Score
treats each item in a given collection with a level of sensitivity proportional
to the item's prevalence. This is undesirable in settings where there is a
significant imbalance in item prevalence. In this paper, we extend the other
Hill numbers using similarity to provide flexibility in allocating sensitivity
to rare or common items. This leads to a family of diversity metrics -- Vendi
scores with different levels of sensitivity -- that can be used in a variety of
applications. We study the properties of the scores in a synthetic controlled
setting where the ground truth diversity is known. We then test their utility
in improving molecular simulations via Vendi Sampling. Finally, we use the
Vendi scores to better understand the behavior of image generative models in
terms of memorization, duplication, diversity, and sample quality.",2023-10-19,2023,2023-10,chemistry
"ReLM: Leveraging Language Models for Enhanced Chemical Reaction
  Prediction","Predicting chemical reactions, a fundamental challenge in chemistry, involves
forecasting the resulting products from a given reaction process. Conventional
techniques, notably those employing Graph Neural Networks (GNNs), are often
limited by insufficient training data and their inability to utilize textual
information, undermining their applicability in real-world applications. In
this work, we propose ReLM, a novel framework that leverages the chemical
knowledge encoded in language models (LMs) to assist GNNs, thereby enhancing
the accuracy of real-world chemical reaction predictions. To further enhance
the model's robustness and interpretability, we incorporate the confidence
score strategy, enabling the LMs to self-assess the reliability of their
predictions. Our experimental results demonstrate that ReLM improves the
performance of state-of-the-art GNN-based methods across various chemical
reaction datasets, especially in out-of-distribution settings. Codes are
available at https://github.com/syr-cn/ReLM.",2023-10-20,2023,2023-10,chemistry
"Monte Carlo Thought Search: Large Language Model Querying for Complex
  Scientific Reasoning in Catalyst Design","Discovering novel catalysts requires complex reasoning involving multiple
chemical properties and resultant trade-offs, leading to a combinatorial growth
in the search space. While large language models (LLM) have demonstrated novel
capabilities for chemistry through complex instruction following capabilities
and high quality reasoning, a goal-driven combinatorial search using LLMs has
not been explored in detail. In this work, we present a Monte Carlo Tree
Search-based approach that improves beyond state-of-the-art chain-of-thought
prompting variants to augment scientific reasoning. We introduce two new
reasoning datasets: 1) a curation of computational chemistry simulations, and
2) diverse questions written by catalysis researchers for reasoning about novel
chemical conversion processes. We improve over the best baseline by 25.8\% and
find that our approach can augment scientist's reasoning and discovery process
with novel insights.",2023-10-22,2023,2023-10,chemistry
Using Slisemap to interpret physical data,"Manifold visualisation techniques are commonly used to visualise
high-dimensional datasets in physical sciences. In this paper we apply a
recently introduced manifold visualisation method, called Slise, on datasets
from physics and chemistry. Slisemap combines manifold visualisation with
explainable artificial intelligence. Explainable artificial intelligence is
used to investigate the decision processes of black box machine learning models
and complex simulators. With Slisemap we find an embedding such that data items
with similar local explanations are grouped together. Hence, Slisemap gives us
an overview of the different behaviours of a black box model. This makes
Slisemap into a supervised manifold visualisation method, where the patterns in
the embedding reflect a target property. In this paper we show how Slisemap can
be used and evaluated on physical data and that Slisemap is helpful in finding
meaningful information on classification and regression models trained on these
datasets.",2023-10-24,2023,2023-10,chemistry
Re-evaluating Retrosynthesis Algorithms with Syntheseus,"Automated Synthesis Planning has recently re-emerged as a research area at
the intersection of chemistry and machine learning. Despite the appearance of
steady progress, we argue that imperfect benchmarks and inconsistent
comparisons mask systematic shortcomings of existing techniques, and
unnecessarily hamper progress. To remedy this, we present a synthesis planning
library with an extensive benchmarking framework, called syntheseus, which
promotes best practice by default, enabling consistent meaningful evaluation of
single-step models and multi-step planning algorithms. We demonstrate the
capabilities of syntheseus by re-evaluating several previous retrosynthesis
algorithms, and find that the ranking of state-of-the-art models changes in
controlled evaluation experiments. We end with guidance for future works in
this area, and call the community to engage in the discussion on how to improve
benchmarks for synthesis planning.",2023-10-30,2023,2023-10,chemistry
"MLatom 3: Platform for machine learning-enhanced computational chemistry
  simulations and workflows","Machine learning (ML) is increasingly becoming a common tool in computational
chemistry. At the same time, the rapid development of ML methods requires a
flexible software framework for designing custom workflows. MLatom 3 is a
program package designed to leverage the power of ML to enhance typical
computational chemistry simulations and to create complex workflows. This
open-source package provides plenty of choice to the users who can run
simulations with the command line options, input files, or with scripts using
MLatom as a Python package, both on their computers and on the online XACS
cloud computing at XACScloud.com. Computational chemists can calculate energies
and thermochemical properties, optimize geometries, run molecular and quantum
dynamics, and simulate (ro)vibrational, one-photon UV/vis absorption, and
two-photon absorption spectra with ML, quantum mechanical, and combined models.
The users can choose from an extensive library of methods containing
pre-trained ML models and quantum mechanical approximations such as AIQM1
approaching coupled-cluster accuracy. The developers can build their own models
using various ML algorithms. The great flexibility of MLatom is largely due to
the extensive use of the interfaces to many state-of-the-art software packages
and libraries.",2023-10-31,2023,2023-10,chemistry
"Extracting human interpretable structure-property relationships in
  chemistry using XAI and large language models","Explainable Artificial Intelligence (XAI) is an emerging field in AI that
aims to address the opaque nature of machine learning models. Furthermore, it
has been shown that XAI can be used to extract input-output relationships,
making them a useful tool in chemistry to understand structure-property
relationships. However, one of the main limitations of XAI methods is that they
are developed for technically oriented users. We propose the XpertAI framework
that integrates XAI methods with large language models (LLMs) accessing
scientific literature to generate accessible natural language explanations of
raw chemical data automatically. We conducted 5 case studies to evaluate the
performance of XpertAI. Our results show that XpertAI combines the strengths of
LLMs and XAI tools in generating specific, scientific, and interpretable
explanations.",2023-11-07,2023,2023-11,chemistry
"The Impact of Large Language Models on Scientific Discovery: a
  Preliminary Study using GPT-4","In recent years, groundbreaking advancements in natural language processing
have culminated in the emergence of powerful large language models (LLMs),
which have showcased remarkable capabilities across a vast array of domains,
including the understanding, generation, and translation of natural language,
and even tasks that extend beyond language processing. In this report, we delve
into the performance of LLMs within the context of scientific discovery,
focusing on GPT-4, the state-of-the-art language model. Our investigation spans
a diverse range of scientific areas encompassing drug discovery, biology,
computational chemistry (density functional theory (DFT) and molecular dynamics
(MD)), materials design, and partial differential equations (PDE). Evaluating
GPT-4 on scientific tasks is crucial for uncovering its potential across
various research domains, validating its domain-specific expertise,
accelerating scientific progress, optimizing resource allocation, guiding
future model development, and fostering interdisciplinary research. Our
exploration methodology primarily consists of expert-driven case assessments,
which offer qualitative insights into the model's comprehension of intricate
scientific concepts and relationships, and occasionally benchmark testing,
which quantitatively evaluates the model's capacity to solve well-defined
domain-specific problems. Our preliminary exploration indicates that GPT-4
exhibits promising potential for a variety of scientific applications,
demonstrating its aptitude for handling complex problem-solving and knowledge
integration tasks. Broadly speaking, we evaluate GPT-4's knowledge base,
scientific understanding, scientific numerical calculation abilities, and
various scientific prediction capabilities.",2023-11-13,2023,2023-11,chemistry
"A Proposed Artificial Neural Network based Approach for Molecules Bitter
  Prediction","In recent years, the development of Artificial Intelligence (AI) has offered
the possibility to tackle many interdisciplinary problems, and the field of
chemistry is not an exception. Drug analysis is crucial in drug discovery,
playing an important role in human life. However, this task encounters many
difficulties due to the wide range of computational chemistry methods. Drug
analysis also involves a massive amount of work, including determining taste.
Thus, applying deep learning to predict a molecule's bitterness is inevitable
to accelerate innovation in drug analysis by reducing the time spent. This
paper proposes an artificial neural network (ANN) based approach (EC-ANN) for
the molecule's bitter prediction. Our approach took the SMILE (Simplified
molecular-input line-entry system) string of a molecule as the input data for
the prediction, and the 256-bit ECFP descriptor is the input vector for our
network. It showed impressive results compared to state-of-the-art, with a
higher performance on two out of three test sets according to the experiences
on three popular test sets: Phyto-Dictionary, Unimi, and Bitter-new set [1].
For the Phyto-Dictionary test set, our model recorded 0.95 and 0.983 in
F1-score and AUPR, respectively, depicted as the highest score in F1-score. For
the Unimi test set, our model achieved 0.88 in F1-score and 0.88 in AUPR, which
is roughly 12.3% higher than the peak of previous models [1, 2, 3, 4, 5].",2023-11-15,2023,2023-11,chemistry
Structured Chemistry Reasoning with Large Language Models,"Large Language Models (LLMs) excel in diverse areas, yet struggle with
complex scientific reasoning, especially in the field of chemistry. Different
from the simple chemistry tasks (e.g., molecule classification) addressed in
previous studies, complex chemistry problems require not only vast knowledge
and precise calculation, but also compositional reasoning about rich dynamic
interactions of different concepts (e.g., temperature changes). Our study shows
that even advanced LLMs, like GPT-4, can fail easily in different ways.
Interestingly, the errors often stem not from a lack of domain knowledge within
the LLMs, but rather from the absence of an effective reasoning structure that
guides the LLMs to elicit the right knowledge, incorporate the knowledge in
step-by-step reasoning, and iteratively refine results for further improved
quality. On this basis, we introduce StructChem, a simple yet effective
prompting strategy that offers the desired guidance and substantially boosts
the LLMs' chemical reasoning capability. Testing across four chemistry areas --
quantum chemistry, mechanics, physical chemistry, and kinetics -- StructChem
substantially enhances GPT-4's performance, with up to 30\% peak improvement.
Our analysis also underscores the unique difficulties of precise grounded
reasoning in science with LLMs, highlighting a need for more research in this
area. Code is available at \url{https://github.com/ozyyshr/StructChem}.",2023-11-16,2023,2023-11,chemistry
"Chemist-X: Large Language Model-empowered Agent for Reaction Condition
  Recommendation in Chemical Synthesis","Recent AI research plots a promising future of automatic chemical reactions
within the chemistry society. This study proposes Chemist-X, a comprehensive AI
agent that automates the reaction condition optimization (RCO) task in chemical
synthesis with retrieval-augmented generation (RAG) technology and
AI-controlled wet-lab experiment executions. To begin with, as an emulation on
how chemical experts solve the RCO task, Chemist-X utilizes a novel RAG scheme
to interrogate available molecular and literature databases to narrow the
searching space for later processing. The agent then leverages a computer-aided
design (CAD) tool we have developed through a large language model (LLM)
supervised programming interface. With updated chemical knowledge obtained via
RAG, as well as the ability in using CAD tools, our agent significantly
outperforms conventional RCO AIs confined to the fixed knowledge within its
training data. Finally, Chemist-X interacts with the physical world through an
automated robotic system, which can validate the suggested chemical reaction
condition without human interventions. The control of the robotic system was
achieved with a novel algorithm we have developed for the equipment, which
relies on LLMs for reliable script generation. Results of our automatic wet-lab
experiments, achieved by fully LLM-supervised end-to-end operation with no
human in the lope, prove Chemist-X's ability in self-driving laboratories.",2023-11-16,2023,2023-11,chemistry
Decoding the Molecular Universe -- Workshop Report,"On August 9-10, 2023, a workshop was convened at the Pacific Northwest
National Laboratory (PNNL) in Richland, WA that brought together a group of
internationally recognized experts in metabolomics, natural products discovery,
chemical ecology, chemical and biological threat assessment, cheminformatics,
computational chemistry, cloud computing, artificial intelligence, and novel
technology development. These experts were invited to assess the value and
feasibility of a grand-scale project to create new technologies that would
allow the identification and quantification of all small molecules, or to
decode the molecular universe. The Decoding the Molecular Universe project
would extend and complement the success of the Human Genome Project by
developing new capabilities and technologies to measure small molecules
(defined as non-protein, non-polymer molecules less than 1500 Daltons) of any
origin and generated in biological systems or produced abiotically. Workshop
attendees 1) explored what new understanding of biological and environmental
systems could be revealed through the lens of small molecules; 2) characterized
the similarities in current needs and technical challenges between each science
or mission area for unambiguous and comprehensive determination of the
composition and quantities of small molecules of any sample; 3) determined the
extent to which technologies or methods currently exist for unambiguously and
comprehensively determining the small molecule composition of any sample and in
a reasonable time; and 4) identified the attributes of the ideal technology or
approach for universal small molecule measurement and identification. The
workshop concluded with a discussion of how a project of this scale could be
undertaken, possible thrusts for the project, early proof-of-principle
applications, and similar efforts upon which the project could be modeled.",2023-11-19,2023,2023-11,chemistry
"Coarse-Grained Configurational Polymer Fingerprints for Property
  Prediction using Machine Learning","In this work, we present a method to generate a configurational level
fingerprint for polymers using the Bead-Spring-Model. Unlike some of the
previous fingerprinting approaches that employ monomer-level information where
atomistic descriptors are computed using quantum chemistry calculations, this
approach incorporates configurational information from a coarse-grained model
of a long polymer chain. The proposed approach may be advantageous for the
study of behavior resulting from large molecular weights. To create this
fingerprint, we make use of two kinds of descriptors. First, we calculate
certain geometric descriptors like Re2, Rg2 etc. and label them as Calculated
Descriptors. Second, we generate a set of data-driven descriptors using an
unsupervised autoencoder model and call them Learnt Descriptors. Using a
combination of both of them, we are able to learn mappings from the structure
to various properties of the polymer chain by training ML models. We test our
fingerprint to predict the probability of occurrence of a configuration at
equilibrium, which is approximated by a simple linear relationship between the
instantaneous internal energy and equilibrium average internal energy.",2023-11-20,2023,2023-11,chemistry
GPQA: A Graduate-Level Google-Proof Q&A Benchmark,"We present GPQA, a challenging dataset of 448 multiple-choice questions
written by domain experts in biology, physics, and chemistry. We ensure that
the questions are high-quality and extremely difficult: experts who have or are
pursuing PhDs in the corresponding domains reach 65% accuracy (74% when
discounting clear mistakes the experts identified in retrospect), while highly
skilled non-expert validators only reach 34% accuracy, despite spending on
average over 30 minutes with unrestricted access to the web (i.e., the
questions are ""Google-proof""). The questions are also difficult for
state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving
39% accuracy. If we are to use future AI systems to help us answer very hard
questions, for example, when developing new scientific knowledge, we need to
develop scalable oversight methods that enable humans to supervise their
outputs, which may be difficult even if the supervisors are themselves skilled
and knowledgeable. The difficulty of GPQA both for skilled non-experts and
frontier AI systems should enable realistic scalable oversight experiments,
which we hope can help devise ways for human experts to reliably get truthful
information from AI systems that surpass human capabilities.",2023-11-20,2023,2023-11,chemistry
GAIA: a benchmark for General AI Assistants,"We introduce GAIA, a benchmark for General AI Assistants that, if solved,
would represent a milestone in AI research. GAIA proposes real-world questions
that require a set of fundamental abilities such as reasoning, multi-modality
handling, web browsing, and generally tool-use proficiency. GAIA questions are
conceptually simple for humans yet challenging for most advanced AIs: we show
that human respondents obtain 92\% vs. 15\% for GPT-4 equipped with plugins.
This notable performance disparity contrasts with the recent trend of LLMs
outperforming humans on tasks requiring professional skills in e.g. law or
chemistry. GAIA's philosophy departs from the current trend in AI benchmarks
suggesting to target tasks that are ever more difficult for humans. We posit
that the advent of Artificial General Intelligence (AGI) hinges on a system's
capability to exhibit similar robustness as the average human does on such
questions. Using GAIA's methodology, we devise 466 questions and their answer.
We release our questions while retaining answers to 300 of them to power a
leader-board available at https://huggingface.co/gaia-benchmark.",2023-11-21,2023,2023-11,chemistry
"ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for
  Interdisciplinary Science","Large language models record impressive performance on many natural language
processing tasks. However, their knowledge capacity is limited to the
pretraining corpus. Retrieval augmentation offers an effective solution by
retrieving context from external knowledge sources to complement the language
model. However, existing retrieval augmentation techniques ignore the
structural relationships between these documents. Furthermore, retrieval models
are not explored much in scientific tasks, especially in regard to the
faithfulness of retrieved documents. In this paper, we propose a novel
structure-aware retrieval augmented language model that accommodates document
structure during retrieval augmentation. We create a heterogeneous document
graph capturing multiple types of relationships (e.g., citation, co-authorship,
etc.) that connect documents from more than 15 scientific disciplines (e.g.,
Physics, Medicine, Chemistry, etc.). We train a graph neural network on the
curated document graph to act as a structural encoder for the corresponding
passages retrieved during the model pretraining. Particularly, along with text
embeddings of the retrieved passages, we obtain structural embeddings of the
documents (passages) and fuse them together before feeding them to the language
model. We evaluate our model extensively on various scientific benchmarks that
include science question-answering and scientific document classification
tasks. Experimental results demonstrate that structure-aware retrieval improves
retrieving more coherent, faithful and contextually relevant passages, while
showing a comparable performance in the overall accuracy.",2023-11-21,2023,2023-11,chemistry
"Everybody Needs a Little HELP: Explaining Graphs via Hierarchical
  Concepts","Graph neural networks (GNNs) have led to major breakthroughs in a variety of
domains such as drug discovery, social network analysis, and travel time
estimation. However, they lack interpretability which hinders human trust and
thereby deployment to settings with high-stakes decisions. A line of
interpretable methods approach this by discovering a small set of relevant
concepts as subgraphs in the last GNN layer that together explain the
prediction. This can yield oversimplified explanations, failing to explain the
interaction between GNN layers. To address this oversight, we provide HELP
(Hierarchical Explainable Latent Pooling), a novel, inherently interpretable
graph pooling approach that reveals how concepts from different GNN layers
compose to new ones in later steps. HELP is more than 1-WL expressive and is
the first non-spectral, end-to-end-learnable, hierarchical graph pooling method
that can learn to pool a variable number of arbitrary connected components. We
empirically demonstrate that it performs on-par with standard GCNs and popular
pooling methods in terms of accuracy while yielding explanations that are
aligned with expert knowledge in the domains of chemistry and social networks.
In addition to a qualitative analysis, we employ concept completeness scores as
well as concept conformity, a novel metric to measure the noise in discovered
concepts, quantitatively verifying that the discovered concepts are
significantly easier to fully understand than those from previous work. Our
work represents a first step towards an understanding of graph neural networks
that goes beyond a set of concepts from the final layer and instead explains
the complex interplay of concepts on different levels.",2023-11-25,2023,2023-11,chemistry
"Transforming organic chemistry research paradigms: moving from manual
  efforts to the intersection of automation and artificial intelligence","Organic chemistry is undergoing a major paradigm shift, moving from a
labor-intensive approach to a new era dominated by automation and artificial
intelligence (AI). This transformative shift is being driven by technological
advances, the ever-increasing demand for greater research efficiency and
accuracy, and the burgeoning growth of interdisciplinary research. AI models,
supported by computational power and algorithms, are drastically reshaping
synthetic planning and introducing groundbreaking ways to tackle complex
molecular synthesis. In addition, autonomous robotic systems are rapidly
accelerating the pace of discovery by performing tedious tasks with
unprecedented speed and precision. This article examines the multiple
opportunities and challenges presented by this paradigm shift and explores its
far-reaching implications. It provides valuable insights into the future
trajectory of organic chemistry research, which is increasingly defined by the
synergistic interaction of automation and AI.",2023-11-26,2023,2023-11,chemistry
"Meta-Diversity Search in Complex Systems, A Recipe for Artificial
  Open-Endedness ?","Can we build an artificial system that would be able to generate endless
surprises if ran ""forever"" in Minecraft? While there is not a single path
toward solving that grand challenge, this article presents what we believe to
be some working ingredients for the endless generation of novel increasingly
complex artifacts in Minecraft. Our framework for an open-ended system includes
two components: a complex system used to recursively grow and complexify
artifacts over time, and a discovery algorithm that leverages the concept of
meta-diversity search. Since complex systems have shown to enable the emergence
of considerable complexity from set of simple rules, we believe them to be
great candidates to generate all sort of artifacts in Minecraft. Yet, the space
of possible artifacts that can be generated by these systems is often unknown,
challenging to characterize and explore. Therefore automating the long-term
discovery of novel and increasingly complex artifacts in these systems is an
exciting research field. To approach these challenges, we formulate the problem
of meta-diversity search where an artificial ""discovery assistant""
incrementally learns a diverse set of representations to characterize behaviors
and searches to discover diverse patterns within each of them. A successful
discovery assistant should continuously seek for novel sources of diversities
while being able to quickly specialize the search toward a new unknown type of
diversity. To implement those ideas in the Minecraft environment, we simulate
an artificial ""chemistry"" system based on Lenia continuous cellular automaton
for generating artifacts, as well as an artificial ""discovery assistant""
(called Holmes) for the artifact-discovery process. Holmes incrementally learns
a hierarchy of modular representations to characterize divergent sources of
diversity and uses a goal-based intrinsically-motivated exploration as the
diversity search strategy.",2023-12-01,2023,2023-12,chemistry
"AdsorbRL: Deep Multi-Objective Reinforcement Learning for Inverse
  Catalysts Design","A central challenge of the clean energy transition is the development of
catalysts for low-emissions technologies. Recent advances in Machine Learning
for quantum chemistry drastically accelerate the computation of catalytic
activity descriptors such as adsorption energies. Here we introduce AdsorbRL, a
Deep Reinforcement Learning agent aiming to identify potential catalysts given
a multi-objective binding energy target, trained using offline learning on the
Open Catalyst 2020 and Materials Project data sets. We experiment with Deep
Q-Network agents to traverse the space of all ~160,000 possible unary, binary
and ternary compounds of 55 chemical elements, with very sparse rewards based
on adsorption energy known for only between 2,000 and 3,000 catalysts per
adsorbate. To constrain the actions space, we introduce Random Edge Traversal
and train a single-objective DQN agent on the known states subgraph, which we
find strengthens target binding energy by an average of 4.1 eV. We extend this
approach to multi-objective, goal-conditioned learning, and train a DQN agent
to identify materials with the highest (respectively lowest) adsorption
energies for multiple simultaneous target adsorbates. We experiment with
Objective Sub-Sampling, a novel training scheme aimed at encouraging
exploration in the multi-objective setup, and demonstrate simultaneous
adsorption energy improvement across all target adsorbates, by an average of
0.8 eV. Overall, our results suggest strong potential for Deep Reinforcement
Learning applied to the inverse catalysts design problem.",2023-12-04,2023,2023-12,chemistry
"AI-driven emergence of frequency information non-uniform distribution
  via THz metasurface spectrum prediction","Recently, artificial intelligence has been extensively deployed across
various scientific disciplines, optimizing and guiding the progression of
experiments through the integration of abundant datasets, whilst continuously
probing the vast theoretical space encapsulated within the data. Particularly,
deep learning models, due to their end-to-end adaptive learning capabilities,
are capable of autonomously learning intrinsic data features, thereby
transcending the limitations of traditional experience to a certain extent.
Here, we unveil previously unreported information characteristics pertaining to
different frequencies emerged during our work on predicting the terahertz
spectral modulation effects of metasurfaces based on AI-prediction. Moreover,
we have substantiated that our proposed methodology of simply adding
supplementary multi-frequency inputs to the existing dataset during the target
spectral prediction process can significantly enhance the predictive accuracy
of the network. This approach effectively optimizes the utilization of existing
datasets and paves the way for interdisciplinary research and applications in
artificial intelligence, chemistry, composite material design, biomedicine, and
other fields.",2023-12-05,2023,2023-12,chemistry
"Molecule Joint Auto-Encoding: Trajectory Pretraining with 2D and 3D
  Diffusion","Recently, artificial intelligence for drug discovery has raised increasing
interest in both machine learning and chemistry domains. The fundamental
building block for drug discovery is molecule geometry and thus, the molecule's
geometrical representation is the main bottleneck to better utilize machine
learning techniques for drug discovery. In this work, we propose a pretraining
method for molecule joint auto-encoding (MoleculeJAE). MoleculeJAE can learn
both the 2D bond (topology) and 3D conformation (geometry) information, and a
diffusion process model is applied to mimic the augmented trajectories of such
two modalities, based on which, MoleculeJAE will learn the inherent chemical
structure in a self-supervised manner. Thus, the pretrained geometrical
representation in MoleculeJAE is expected to benefit downstream
geometry-related tasks. Empirically, MoleculeJAE proves its effectiveness by
reaching state-of-the-art performance on 15 out of 20 tasks by comparing it
with 12 competitive baselines.",2023-12-06,2023,2023-12,chemistry
MatterGen: a generative model for inorganic materials design,"The design of functional materials with desired properties is essential in
driving technological advances in areas like energy storage, catalysis, and
carbon capture. Generative models provide a new paradigm for materials design
by directly generating entirely novel materials given desired property
constraints. Despite recent progress, current generative models have low
success rate in proposing stable crystals, or can only satisfy a very limited
set of property constraints. Here, we present MatterGen, a model that generates
stable, diverse inorganic materials across the periodic table and can further
be fine-tuned to steer the generation towards a broad range of property
constraints. To enable this, we introduce a new diffusion-based generative
process that produces crystalline structures by gradually refining atom types,
coordinates, and the periodic lattice. We further introduce adapter modules to
enable fine-tuning towards any given property constraints with a labeled
dataset. Compared to prior generative models, structures produced by MatterGen
are more than twice as likely to be novel and stable, and more than 15 times
closer to the local energy minimum. After fine-tuning, MatterGen successfully
generates stable, novel materials with desired chemistry, symmetry, as well as
mechanical, electronic and magnetic properties. Finally, we demonstrate
multi-property materials design capabilities by proposing structures that have
both high magnetic density and a chemical composition with low supply-chain
risk. We believe that the quality of generated materials and the breadth of
MatterGen's capabilities represent a major advancement towards creating a
universal generative model for materials design.",2023-12-06,2023,2023-12,chemistry
Predictive Chemistry Augmented with Text Retrieval,"This paper focuses on using natural language descriptions to enhance
predictive models in the chemistry field. Conventionally, chemoinformatics
models are trained with extensive structured data manually extracted from the
literature. In this paper, we introduce TextReact, a novel method that directly
augments predictive chemistry with texts retrieved from the literature.
TextReact retrieves text descriptions relevant for a given chemical reaction,
and then aligns them with the molecular representation of the reaction. This
alignment is enhanced via an auxiliary masked LM objective incorporated in the
predictor training. We empirically validate the framework on two chemistry
tasks: reaction condition recommendation and one-step retrosynthesis. By
leveraging text retrieval, TextReact significantly outperforms state-of-the-art
chemoinformatics models trained solely on molecular data.",2023-12-08,2023,2023-12,chemistry
Image and Data Mining in Reticular Chemistry Using GPT-4V,"The integration of artificial intelligence into scientific research has
reached a new pinnacle with GPT-4V, a large language model featuring enhanced
vision capabilities, accessible through ChatGPT or an API. This study
demonstrates the remarkable ability of GPT-4V to navigate and obtain complex
data for metal-organic frameworks, especially from graphical sources. Our
approach involved an automated process of converting 346 scholarly articles
into 6240 images, which represents a benchmark dataset in this task, followed
by deploying GPT-4V to categorize and analyze these images using natural
language prompts. This methodology enabled GPT-4V to accurately identify and
interpret key plots integral to MOF characterization, such as nitrogen
isotherms, PXRD patterns, and TGA curves, among others, with accuracy and
recall above 93%. The model's proficiency in extracting critical information
from these plots not only underscores its capability in data mining but also
highlights its potential in aiding the creation of comprehensive digital
databases for reticular chemistry. In addition, the extracted nitrogen isotherm
data from the selected literature allowed for a comparison between theoretical
and experimental porosity values for over 200 compounds, highlighting certain
discrepancies and underscoring the importance of integrating computational and
experimental data. This work highlights the potential of AI in accelerating
scientific discovery and innovation, bridging the gap between computational
tools and experimental research, and paving the way for more efficient,
inclusive, and comprehensive scientific inquiry.",2023-12-09,2023,2023-12,chemistry
"Using Think-Aloud Data to Understand Relations between Self-Regulation
  Cycle Characteristics and Student Performance in Intelligent Tutoring Systems","Numerous studies demonstrate the importance of self-regulation during
learning by problem-solving. Recent work in learning analytics has largely
examined students' use of SRL concerning overall learning gains. Limited
research has related SRL to in-the-moment performance differences among
learners. The present study investigates SRL behaviors in relationship to
learners' moment-by-moment performance while working with intelligent tutoring
systems for stoichiometry chemistry. We demonstrate the feasibility of labeling
SRL behaviors based on AI-generated think-aloud transcripts, identifying the
presence or absence of four SRL categories (processing information, planning,
enacting, and realizing errors) in each utterance. Using the SRL codes, we
conducted regression analyses to examine how the use of SRL in terms of
presence, frequency, cyclical characteristics, and recency relate to student
performance on subsequent steps in multi-step problems. A model considering
students' SRL cycle characteristics outperformed a model only using
in-the-moment SRL assessment. In line with theoretical predictions, students'
actions during earlier, process-heavy stages of SRL cycles exhibited lower
moment-by-moment correctness during problem-solving than later SRL cycle
stages. We discuss system re-design opportunities to add SRL support during
stages of processing and paths forward for using machine learning to speed
research depending on the assessment of SRL based on transcription of
think-aloud data.",2023-12-09,2023,2023-12,chemistry
Drivers and Barriers of AI Adoption and Use in Scientific Research,"New technologies have the power to revolutionize science. It has happened in
the past and is happening again with the emergence of new computational tools,
such as artificial intelligence and machine learning. Despite the documented
impact of these technologies, there remains a significant gap in understanding
the process of their adoption within the scientific community. In this paper,
we draw on theories of scientific and technical human capital to study the
integration of AI in scientific research, focusing on the human capital of
scientists and the external resources available within their network of
collaborators and institutions. We validate our hypotheses on a large sample of
publications from OpenAlex, covering all sciences from 1980 to 2020, and
identify a set key drivers and inhibitors of AI adoption and use in science.
Our results suggest that AI is pioneered by domain scientists with a `taste for
exploration' and who are embedded in a network rich of computer scientists,
experienced AI scientists and early-career researchers; they come from
institutions with high citation impact and a relatively strong publication
history on AI. The access to computing resources only matters for a few
scientific disciplines, such as chemistry and medical sciences. Once AI is
integrated into research, most adoption factors continue to influence its
subsequent reuse. Implications for the organization and management of science
in the evolving era of AI-driven discovery are discussed.",2023-12-15,2023,2023-12,chemistry
Enabling Accelerators for Graph Computing,"The advent of Graph Neural Networks (GNNs) has revolutionized the field of
machine learning, offering a novel paradigm for learning on graph-structured
data. Unlike traditional neural networks, GNNs are capable of capturing complex
relationships and dependencies inherent in graph data, making them particularly
suited for a wide range of applications including social network analysis,
molecular chemistry, and network security. GNNs, with their unique structure
and operation, present new computational challenges compared to conventional
neural networks. This requires comprehensive benchmarking and a thorough
characterization of GNNs to obtain insight into their computational
requirements and to identify potential performance bottlenecks. In this thesis,
we aim to develop a better understanding of how GNNs interact with the
underlying hardware and will leverage this knowledge as we design specialized
accelerators and develop new optimizations, leading to more efficient and
faster GNN computations. A pivotal component within GNNs is the Sparse General
Matrix-Matrix Multiplication (SpGEMM) kernel, known for its computational
intensity and irregular memory access patterns. In this thesis, we address the
challenges posed by SpGEMM by implementing a highly optimized hashing-based
SpGEMM kernel tailored for a custom accelerator. Synthesizing these insights
and optimizations, we design state-of-the-art hardware accelerators capable of
efficiently handling various GNN workloads. Our accelerator architectures are
built on our characterization of GNN computational demands, providing clear
motivation for our approaches. This exploration into novel models underlines
our comprehensive approach, as we strive to enable accelerators that are not
just performant, but also versatile, able to adapt to the evolving landscape of
graph computing.",2023-12-16,2023,2023-12,chemistry
Continuous-time Graph Representation with Sequential Survival Process,"Over the past two decades, there has been a tremendous increase in the growth
of representation learning methods for graphs, with numerous applications
across various fields, including bioinformatics, chemistry, and the social
sciences. However, current dynamic network approaches focus on discrete-time
networks or treat links in continuous-time networks as instantaneous events.
Therefore, these approaches have limitations in capturing the persistence or
absence of links that continuously emerge and disappear over time for
particular durations. To address this, we propose a novel stochastic process
relying on survival functions to model the durations of links and their
absences over time. This forms a generic new likelihood specification
explicitly accounting for intermittent edge-persistent networks, namely GraSSP:
Graph Representation with Sequential Survival Process. We apply the developed
framework to a recent continuous time dynamic latent distance model
characterizing network dynamics in terms of a sequence of piecewise linear
movements of nodes in latent space. We quantitatively assess the developed
framework in various downstream tasks, such as link prediction and network
completion, demonstrating that the developed modeling framework accounting for
link persistence and absence well tracks the intrinsic trajectories of nodes in
a latent space and captures the underlying characteristics of evolving network
structure.",2023-12-20,2023,2023-12,chemistry
"An integrated framework for accelerating reactive flow simulation using
  GPU and machine learning models","Recent progress in artificial intelligence (AI) and high-performance
computing (HPC) have brought potentially game-changing opportunities in
accelerating reactive flow simulations. In this study, we introduce an
open-source computational fluid dynamics (CFD) framework that integrates the
strengths of machine learning (ML) and graphics processing unit (GPU) to
demonstrate their combined capability. Within this framework, all computational
operations are solely executed on GPU, including ML-accelerated chemistry
integration, fully-implicit solving of PDEs, and computation of thermal and
transport properties, thereby eliminating the CPU-GPU memory copy overhead.
Optimisations both within the kernel functions and during the kernel launch
process are conducted to enhance computational performance. Strategies such as
static data reorganisation and dynamic data allocation are adopted to reduce
the GPU memory footprint. The computational performance is evaluated in two
turbulent flame benchmarks using quasi-DNS and LES modelling, respectively.
Remarkably, while maintaining a similar level of accuracy to the conventional
CPU/CVODE-based solver, the GPU/ML-accelerated approach shows an overall
speedup of over two orders of magnitude for both cases. This result highlights
that high-fidelity turbulent combustion simulation with finite-rate chemistry
that requires normally hundreds of CPUs can now be performed on portable
devices such as laptops with a medium-end GPU.",2023-12-21,2023,2023-12,chemistry
"Diffusion-Driven Generative Framework for Molecular Conformation
  Prediction","The task of deducing three-dimensional molecular configurations from their
two-dimensional graph representations holds paramount importance in the fields
of computational chemistry and pharmaceutical development. The rapid
advancement of machine learning, particularly within the domain of deep
generative networks, has revolutionized the precision of predictive modeling in
this context. Traditional approaches often adopt a two-step strategy: initially
estimating interatomic distances and subsequently refining the spatial
molecular structure by solving a distance geometry problem. However, this
sequential approach occasionally falls short in accurately capturing the
intricacies of local atomic arrangements, thereby compromising the fidelity of
the resulting structural models. Addressing these limitations, this research
introduces a cutting-edge generative framework named DDGF. This framework is
grounded in the principles of diffusion observed in classical non-equilibrium
thermodynamics. DDGF views atoms as discrete entities and excels in guiding the
reversal of diffusion, transforming a distribution of stochastic noise back
into coherent molecular structures through a process akin to a Markov chain.
This transformation commences with the initial representation of a molecular
graph in an abstract latent space, culminating in the realization of
three-dimensional structures via a sophisticated bilevel optimization scheme
meticulously tailored to meet the specific requirements of the task. One of the
formidable challenges in this modeling endeavor involves preserving
roto-translational invariance to ensure that the generated molecular
conformations adhere to the laws of physics. Extensive experimental evaluations
confirm the efficacy of the proposed DDGF in comparison to state-of-the-art
methods.",2023-12-22,2023,2023-12,chemistry
"Towards End-to-End Structure Solutions from Information-Compromised
  Diffraction Data via Generative Deep Learning","The revolution in materials in the past century was built on a knowledge of
the atomic arrangements and the structure-property relationship. The sine qua
non for obtaining quantitative structural information is single crystal
crystallography. However, increasingly we need to solve structures in cases
where the information content in our input signal is significantly degraded,
for example, due to orientational averaging of grains, finite size effects due
to nanostructure, and mixed signals due to sample heterogeneity. Understanding
the structure property relationships in such situations is, if anything, more
important and insightful, yet we do not have robust approaches for
accomplishing it. In principle, machine learning (ML) and deep learning (DL)
are promising approaches since they augment information in the degraded input
signal with prior knowledge learned from large databases of already known
structures. Here we present a novel ML approach, a variational query-based
multi-branch deep neural network that has the promise to be a robust but
general tool to address this problem end-to-end. We demonstrate the approach on
computed powder x-ray diffraction (PXRD), along with partial chemical
composition information, as input. We choose as a structural representation a
modified electron density we call the Cartesian mapped electron density (CMED),
that straightforwardly allows our ML model to learn material structures across
different chemistries, symmetries and crystal systems. When evaluated on
theoretically simulated data for the cubic and trigonal crystal systems, the
system achieves up to $93.4\%$ average similarity with the ground truth on
unseen materials, both with known and partially-known chemical composition
information, showing great promise for successful structure solution even from
degraded and incomplete input data.",2023-12-23,2023,2023-12,chemistry
"Generating High-Precision Force Fields for Molecular Dynamics
  Simulations to Study Chemical Reaction Mechanisms using Molecular
  Configuration Transformer","Theoretical studies on chemical reaction mechanisms have been crucial in
organic chemistry. Traditionally, calculating the manually constructed
molecular conformations of transition states for chemical reactions using
quantum chemical calculations is the most commonly used method. However, this
way is heavily dependent on individual experience and chemical intuition. In
our previous study, we proposed a research paradigm that uses enhanced sampling
in molecular dynamics simulations to study chemical reactions. This approach
can directly simulate the entire process of a chemical reaction. However, the
computational speed limits the use of high-precision potential energy functions
for simulations. To address this issue, we present a scheme for training
high-precision force fields for molecular modeling using a previously developed
graph-neural-network-based molecular model, molecular configuration
transformer. This potential energy function allows for highly accurate
simulations at a low computational cost, leading to more precise calculations
of the mechanism of chemical reactions. We applied this approach to study a
Claisen rearrangement reaction and a Carbonyl insertion reaction catalyzed by
Manganese.",2023-12-31,2023,2023-12,chemistry
GraphGPT: Generative Pre-trained Graph Eulerian Transformer,"We introduceGraphGPT, a novel self-supervised generative pre-trained model
for graph learning based on the Graph Eulerian Transformer (GET). First, we
propose GET, which combines a standard transformer encoder or decoder
architecture with an innovative graph-to-sequence transformation method. This
method converts graphs or sampled subgraphs into sequences of tokens
representing nodes, edges, and attributes in a reversible manner using Eulerian
paths. We pre-train GET using either of the two self-supervised tasks:
next-token prediction (NTP) and scheduled masked-token prediction (SMTP). The
pre-trained model is then fine-tuned for downstream tasks such as graph-,
edge-, and node-level prediction. Despite its simplicity, GraphGPT achieves
performance comparable to or surpassing state-of-the-art methods on multiple
large-scale Open Graph Benchmark (OGB) datasets. It demonstrates exceptional
results on the molecular property prediction dataset PCQM4Mv2 and the
protein-protein interaction dataset ogbl-ppa. Notably, generative pre-training
enables scaling GraphGPT to 2 billion parameters while maintaining performance
gains - a breakthrough that overcomes the scalability limitations of
traditional Graph Neural Networks (GNNs) and prior graph transformers (GTs). To
advance research in graph foundation models and facilitate scientific discovery
in chemistry, materials science, and related fields, we will release the source
code (https://github.com/alibaba/graph-gpt) and pre-trained checkpoints.",2023-12-31,2023,2023-12,chemistry
On the Expressive Power of Graph Neural Networks,"The study of Graph Neural Networks has received considerable interest in the
past few years. By extending deep learning to graph-structured data, GNNs can
solve a diverse set of tasks in fields including social science, chemistry, and
medicine. The development of GNN architectures has largely been focused on
improving empirical performance on tasks like node or graph classification.
However, a line of recent work has instead sought to find GNN architectures
that have desirable theoretical properties - by studying their expressive power
and designing architectures that maximize this expressiveness.
  While there is no consensus on the best way to define the expressiveness of a
GNN, it can be viewed from several well-motivated perspectives. Perhaps the
most natural approach is to study the universal approximation properties of
GNNs, much in the way that this has been studied extensively for MLPs. Another
direction focuses on the extent to which GNNs can distinguish between different
graph structures, relating this to the graph isomorphism test. Besides, a GNN's
ability to compute graph properties such as graph moments has been suggested as
another form of expressiveness. All of these different definitions are
complementary and have yielded different recommendations for GNN architecture
choices. In this paper, we would like to give an overview of the notion of
""expressive power"" of GNNs and provide some valuable insights regarding the
design choices of GNNs.",2024-01-03,2024,2024-01,chemistry
"ORGANA: A Robotic Assistant for Automated Chemistry Experimentation and
  Characterization","Chemistry experiments can be resource- and labor-intensive, often requiring
manual tasks like polishing electrodes in electrochemistry. Traditional lab
automation infrastructure faces challenges adapting to new experiments. To
address this, we introduce ORGANA, an assistive robotic system that automates
diverse chemistry experiments using decision-making and perception tools. It
makes decisions with chemists in the loop to control robots and lab devices.
ORGANA interacts with chemists using Large Language Models (LLMs) to derive
experiment goals, handle disambiguation, and provide experiment logs. ORGANA
plans and executes complex tasks with visual feedback, while supporting
scheduling and parallel task execution. We demonstrate ORGANA's capabilities in
solubility, pH measurement, recrystallization, and electrochemistry
experiments. In electrochemistry, it executes a 19-step plan in parallel to
characterize quinone derivatives for flow batteries. Our user study shows
ORGANA reduces frustration and physical demand by over 50%, with users saving
an average of 80.3% of their time when using it.",2024-01-13,2024,2024-01,chemistry
ChemDFM: A Large Language Foundation Model for Chemistry,"Artificial intelligence (AI) has played an increasingly important role in
chemical research. However, most models currently used in chemistry are
specialist models that require training and tuning for specific tasks. A more
generic and efficient solution would be an AI model that could address many
tasks and support free-form dialogue in the broad field of chemistry. In its
utmost form, such a generalist AI chemist could be referred to as Chemical
General Intelligence. Large language models (LLMs) have recently logged
tremendous success in the general domain of natural language processing,
showing emerging task generalization and free-form dialogue capabilities.
However, domain knowledge of chemistry is largely missing when training
general-domain LLMs. The lack of such knowledge greatly hinders the performance
of generalist LLMs in the field of chemistry. To this end, we develop ChemDFM,
a pioneering LLM for chemistry trained on 34B tokens from chemical literature
and textbooks, and fine-tuned using 2.7M instructions. As a result, it can
understand and reason with chemical knowledge in free-form dialogue.
Quantitative evaluations show that ChemDFM significantly surpasses most
representative open-source LLMs. It outperforms GPT-4 on a great portion of
chemical tasks, despite the substantial size difference. We have open-sourced
the inference codes, evaluation datasets, and model weights of ChemDFM on
Huggingface (https://huggingface.co/OpenDFM/ChemDFM-v1.0-13B).",2024-01-26,2024,2024-01,chemistry
"LLaMP: Large Language Model Made Powerful for High-fidelity Materials
  Knowledge Retrieval and Distillation","Reducing hallucination of Large Language Models (LLMs) is imperative for use
in the sciences, where reliability and reproducibility are crucial. However,
LLMs inherently lack long-term memory, making it a nontrivial, ad hoc, and
inevitably biased task to fine-tune them on domain-specific literature and
data. Here we introduce LLaMP, a multimodal retrieval-augmented generation
(RAG) framework of hierarchical reasoning-and-acting (ReAct) agents that can
dynamically and recursively interact with computational and experimental data
on Materials Project (MP) and run atomistic simulations via high-throughput
workflow interface. Without fine-tuning, LLaMP demonstrates strong tool usage
ability to comprehend and integrate various modalities of materials science
concepts, fetch relevant data stores on the fly, process higher-order data
(such as crystal structure and elastic tensor), and streamline complex tasks in
computational materials and chemistry. We propose a simple metric combining
uncertainty and confidence estimates to evaluate the self-consistency of
responses by LLaMP and vanilla LLMs. Our benchmark shows that LLaMP effectively
mitigates the intrinsic bias in LLMs, counteracting the errors on bulk moduli,
electronic bandgaps, and formation energies that seem to derive from mixed data
sources. We also demonstrate LLaMP's capability to edit crystal structures and
run annealing molecular dynamics simulations using pre-trained machine-learning
force fields. The framework offers an intuitive and nearly hallucination-free
approach to exploring and scaling materials informatics, and establishes a
pathway for knowledge distillation and fine-tuning other language models. Code
and live demo are available at https://github.com/chiang-yuan/llamp",2024-01-30,2024,2024-01,chemistry
From Words to Molecules: A Survey of Large Language Models in Chemistry,"In recent years, Large Language Models (LLMs) have achieved significant
success in natural language processing (NLP) and various interdisciplinary
areas. However, applying LLMs to chemistry is a complex task that requires
specialized domain knowledge. This paper provides a thorough exploration of the
nuanced methodologies employed in integrating LLMs into the field of chemistry,
delving into the complexities and innovations at this interdisciplinary
juncture. Specifically, our analysis begins with examining how molecular
information is fed into LLMs through various representation and tokenization
methods. We then categorize chemical LLMs into three distinct groups based on
the domain and modality of their input data, and discuss approaches for
integrating these inputs for LLMs. Furthermore, this paper delves into the
pretraining objectives with adaptations to chemical LLMs. After that, we
explore the diverse applications of LLMs in chemistry, including novel
paradigms for their application in chemistry tasks. Finally, we identify
promising research directions, including further integration with chemical
knowledge, advancements in continual learning, and improvements in model
interpretability, paving the way for groundbreaking developments in the field.",2024-02-02,2024,2024-02,chemistry
"Curriculum reinforcement learning for quantum architecture search under
  hardware errors","The key challenge in the noisy intermediate-scale quantum era is finding
useful circuits compatible with current device limitations. Variational quantum
algorithms (VQAs) offer a potential solution by fixing the circuit architecture
and optimizing individual gate parameters in an external loop. However,
parameter optimization can become intractable, and the overall performance of
the algorithm depends heavily on the initially chosen circuit architecture.
Several quantum architecture search (QAS) algorithms have been developed to
design useful circuit architectures automatically. In the case of parameter
optimization alone, noise effects have been observed to dramatically influence
the performance of the optimizer and final outcomes, which is a key line of
study. However, the effects of noise on the architecture search, which could be
just as critical, are poorly understood. This work addresses this gap by
introducing a curriculum-based reinforcement learning QAS (CRLQAS) algorithm
designed to tackle challenges in realistic VQA deployment. The algorithm
incorporates (i) a 3D architecture encoding and restrictions on environment
dynamics to explore the search space of possible circuits efficiently, (ii) an
episode halting scheme to steer the agent to find shorter circuits, and (iii) a
novel variant of simultaneous perturbation stochastic approximation as an
optimizer for faster convergence. To facilitate studies, we developed an
optimized simulator for our algorithm, significantly improving computational
efficiency in simulating noisy quantum circuits by employing the Pauli-transfer
matrix formalism in the Pauli-Liouville basis. Numerical experiments focusing
on quantum chemistry tasks demonstrate that CRLQAS outperforms existing QAS
algorithms across several metrics in both noiseless and noisy environments.",2024-02-05,2024,2024-02,chemistry
"SceMQA: A Scientific College Entrance Level Multimodal Question
  Answering Benchmark","The paper introduces SceMQA, a novel benchmark for scientific multimodal
question answering at the college entrance level. It addresses a critical
educational phase often overlooked in existing benchmarks, spanning high school
to pre-college levels. SceMQA focuses on core science subjects including
Mathematics, Physics, Chemistry, and Biology. It features a blend of
multiple-choice and free-response formats, ensuring a comprehensive evaluation
of AI models' abilities. Additionally, our benchmark provides specific
knowledge points for each problem and detailed explanations for each answer.
SceMQA also uniquely presents problems with identical contexts but varied
questions to facilitate a more thorough and accurate assessment of reasoning
capabilities. In the experiment, we evaluate both open-source and close-source
state-of-the-art Multimodal Large Language Models (MLLMs), across various
experimental settings. The results show that further research and development
are needed in developing more capable MLLM, as highlighted by only 50% to 60%
accuracy achieved by the strongest models. Our benchmark and analysis will be
available at https://scemqa.github.io/",2024-02-06,2024,2024-02,chemistry
"cecilia: A Machine Learning-Based Pipeline for Measuring Metal
  Abundances of Helium-rich Polluted White Dwarfs","Over the past several decades, conventional spectral analysis techniques of
polluted white dwarfs have become powerful tools to learn about the geology and
chemistry of extrasolar bodies. Despite their proven capabilities and extensive
legacy of scientific discoveries, these techniques are however still limited by
their manual, time-intensive, and iterative nature. As a result, they are
susceptible to human errors and are difficult to scale up to population-wide
studies of metal pollution. This paper seeks to address this problem by
presenting cecilia, the first Machine Learning (ML)-powered spectral modeling
code designed to measure the metal abundances of intermediate-temperature
(10,000$\leq T_{\rm eff} \leq$20,000 K), Helium-rich polluted white dwarfs.
Trained with more than 22,000 randomly drawn atmosphere models and stellar
parameters, our pipeline aims to overcome the limitations of classical methods
by replacing the generation of synthetic spectra from computationally expensive
codes and uniformly spaced model grids, with a fast, automated, and efficient
neural-network-based interpolator. More specifically, cecilia combines
state-of-the-art atmosphere models, powerful artificial intelligence tools, and
robust statistical techniques to rapidly generate synthetic spectra of polluted
white dwarfs in high-dimensional space, and enable accurate ($\lesssim$0.1 dex)
and simultaneous measurements of 14 stellar parameters -- including 11
elemental abundances -- from real spectroscopic observations. As massively
multiplexed astronomical surveys begin scientific operations, cecilia's
performance has the potential to unlock large-scale studies of extrasolar
geochemistry and propel the field of white dwarf science into the era of Big
Data. In doing so, we aspire to uncover new statistical insights that were
previously impractical with traditional white dwarf characterisation
techniques.",2024-02-07,2024,2024-02,chemistry
ChemLLM: A Chemical Large Language Model,"Large language models (LLMs) have made impressive progress in chemistry
applications. However, the community lacks an LLM specifically designed for
chemistry. The main challenges are two-fold: firstly, most chemical data and
scientific knowledge are stored in structured databases, which limits the
model's ability to sustain coherent dialogue when used directly. Secondly,
there is an absence of objective and fair benchmark that encompass most
chemistry tasks. Here, we introduce ChemLLM, a comprehensive framework that
features the first LLM dedicated to chemistry. It also includes ChemData, a
dataset specifically designed for instruction tuning, and ChemBench, a robust
benchmark covering nine essential chemistry tasks. ChemLLM is adept at
performing various tasks across chemical disciplines with fluid dialogue
interaction. Notably, ChemLLM achieves results comparable to GPT-4 on the core
chemical tasks and demonstrates competitive performance with LLMs of similar
size in general scenarios. ChemLLM paves a new path for exploration in chemical
studies, and our method of incorporating structured chemical knowledge into
dialogue systems sets a new standard for developing LLMs in various scientific
fields. Codes, Datasets, and Model weights are publicly accessible at
https://hf.co/AI4Chem",2024-02-10,2024,2024-02,chemistry
"X-LoRA: Mixture of Low-Rank Adapter Experts, a Flexible Framework for
  Large Language Models with Applications in Protein Mechanics and Molecular
  Design","We report a mixture of expert strategy to create fine-tuned large language
models using a deep layer-wise token-level approach based on low-rank
adaptation (LoRA). Starting with a set of pre-trained LoRA adapters, our gating
strategy uses the hidden states to dynamically mix adapted layers, allowing the
resulting X-LoRA model to draw upon different capabilities and create
never-before-used deep layer-wise combinations to solve tasks. The design is
inspired by the biological principles of universality and diversity, where
neural network building blocks are reused in different hierarchical
manifestations. Hence, the X-LoRA model can be easily implemented for any
existing large language model (LLM) without a need for modifications of the
underlying structure. We develop a tailored X-LoRA model that offers scientific
capabilities including forward/inverse analysis tasks and enhanced reasoning
capability, focused on biomaterial analysis, protein mechanics and design. The
impact of this work include access to readily expandable and adaptable models
with strong domain knowledge and the capability to integrate across areas of
knowledge. Featuring experts in biology, mathematics, reasoning, bio-inspired
materials, mechanics and materials, chemistry, protein biophysics, mechanics
and quantum-mechanics based molecular properties, we conduct a series of
physics-focused case studies. We examine knowledge recall, protein mechanics
forward/inverse tasks, protein design, adversarial agentic modeling including
ontological knowledge graph construction, as well as molecular design. The
model is capable not only of making quantitative predictions of nanomechanical
properties of proteins or quantum mechanical molecular properties, but also
reasons over the results and correctly predicts likely mechanisms that explain
distinct molecular behaviors.",2024-02-11,2024,2024-02,chemistry
ChatCell: Facilitating Single-Cell Analysis with Natural Language,"As Large Language Models (LLMs) rapidly evolve, their influence in science is
becoming increasingly prominent. The emerging capabilities of LLMs in task
generalization and free-form dialogue can significantly advance fields like
chemistry and biology. However, the field of single-cell biology, which forms
the foundational building blocks of living organisms, still faces several
challenges. High knowledge barriers and limited scalability in current methods
restrict the full exploitation of LLMs in mastering single-cell data, impeding
direct accessibility and rapid iteration. To this end, we introduce ChatCell,
which signifies a paradigm shift by facilitating single-cell analysis with
natural language. Leveraging vocabulary adaptation and unified sequence
generation, ChatCell has acquired profound expertise in single-cell biology and
the capability to accommodate a diverse range of analysis tasks. Extensive
experiments further demonstrate ChatCell's robust performance and potential to
deepen single-cell insights, paving the way for more accessible and intuitive
exploration in this pivotal field. Our project homepage is available at
https://zjunlp.github.io/project/ChatCell.",2024-02-13,2024,2024-02,chemistry
"LlaSMol: Advancing Large Language Models for Chemistry with a
  Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset","Chemistry plays a crucial role in many domains, such as drug discovery and
material science. While large language models (LLMs) such as GPT-4 exhibit
remarkable capabilities on natural language processing tasks, existing research
indicates that their performance on chemistry tasks is discouragingly low. In
this paper, however, we demonstrate that our developed LLMs can achieve very
strong results on a comprehensive set of chemistry tasks, outperforming the
most advanced GPT-4 and Claude 3 Opus by a substantial margin. To accomplish
this, we propose SMolInstruct, a large-scale, comprehensive, and high-quality
dataset for instruction tuning. It contains 14 selected chemistry tasks and
over three million samples, laying a solid foundation for training and
evaluating LLMs for chemistry. Using SMolInstruct, we fine-tune a set of
open-source LLMs, among which, we find that Mistral serves as the best base
model for chemistry tasks. Our analysis further demonstrates the critical role
of the proposed dataset in driving the performance improvements.",2024-02-14,2024,2024-02,chemistry
"ChemReasoner: Heuristic Search over a Large Language Model's Knowledge
  Space using Quantum-Chemical Feedback","The discovery of new catalysts is essential for the design of new and more
efficient chemical processes in order to transition to a sustainable future. We
introduce an AI-guided computational screening framework unifying linguistic
reasoning with quantum-chemistry based feedback from 3D atomistic
representations. Our approach formulates catalyst discovery as an uncertain
environment where an agent actively searches for highly effective catalysts via
the iterative combination of large language model (LLM)-derived hypotheses and
atomistic graph neural network (GNN)-derived feedback. Identified catalysts in
intermediate search steps undergo structural evaluation based on spatial
orientation, reaction pathways, and stability. Scoring functions based on
adsorption energies and reaction energy barriers steer the exploration in the
LLM's knowledge space toward energetically favorable, high-efficiency
catalysts. We introduce planning methods that automatically guide the
exploration without human input, providing competitive performance against
expert-enumerated chemical descriptor-based implementations. By integrating
language-guided reasoning with computational chemistry feedback, our work
pioneers AI-accelerated, trustworthy catalyst discovery.",2024-02-15,2024,2024-02,chemistry
"Revealing the Relationship Between Publication Bias and Chemical
  Reactivity with Contrastive Learning","A synthetic method's substrate tolerance and generality are often showcased
in a ""substrate scope"" table. However, substrate selection exhibits a
frequently discussed publication bias: unsuccessful experiments or low-yielding
results are rarely reported. In this work, we explore more deeply the
relationship between such publication bias and chemical reactivity beyond the
simple analysis of yield distributions using a novel neural network training
strategy, substrate scope contrastive learning. By treating reported substrates
as positive samples and non-reported substrates as negative samples, our
contrastive learning strategy teaches a model to group molecules within a
numerical embedding space, based on historical trends in published substrate
scope tables. Training on 20,798 aryl halides in the CAS Content
Collection$^{\text{TM}}$, spanning thousands of publications from 2010-2015, we
demonstrate that the learned embeddings exhibit a correlation with physical
organic reactivity descriptors through both intuitive visualizations and
quantitative regression analyses. Additionally, these embeddings are applicable
to various reaction modeling tasks like yield prediction and regioselectivity
prediction, underscoring the potential to use historical reaction data as a
pre-training task. This work not only presents a chemistry-specific machine
learning training strategy to learn from literature data in a new way, but also
represents a unique approach to uncover trends in chemical reactivity reflected
by trends in substrate selection in publications.",2024-02-19,2024,2024-02,chemistry
"An Autonomous Large Language Model Agent for Chemical Literature Data
  Mining","Chemical synthesis, which is crucial for advancing material synthesis and
drug discovery, impacts various sectors including environmental science and
healthcare. The rise of technology in chemistry has generated extensive
chemical data, challenging researchers to discern patterns and refine synthesis
processes. Artificial intelligence (AI) helps by analyzing data to optimize
synthesis and increase yields. However, AI faces challenges in processing
literature data due to the unstructured format and diverse writing style of
chemical literature. To overcome these difficulties, we introduce an end-to-end
AI agent framework capable of high-fidelity extraction from extensive chemical
literature. This AI agent employs large language models (LLMs) for prompt
generation and iterative optimization. It functions as a chemistry assistant,
automating data collection and analysis, thereby saving manpower and enhancing
performance. Our framework's efficacy is evaluated using accuracy, recall, and
F1 score of reaction condition data, and we compared our method with human
experts in terms of content correctness and time efficiency. The proposed
approach marks a significant advancement in automating chemical literature
extraction and demonstrates the potential for AI to revolutionize data
management and utilization in chemistry.",2024-02-20,2024,2024-02,chemistry
"Contextual Molecule Representation Learning from Chemical Reaction
  Knowledge","In recent years, self-supervised learning has emerged as a powerful tool to
harness abundant unlabelled data for representation learning and has been
broadly adopted in diverse areas. However, when applied to molecular
representation learning (MRL), prevailing techniques such as masked sub-unit
reconstruction often fall short, due to the high degree of freedom in the
possible combinations of atoms within molecules, which brings insurmountable
complexity to the masking-reconstruction paradigm. To tackle this challenge, we
introduce REMO, a self-supervised learning framework that takes advantage of
well-defined atom-combination rules in common chemistry. Specifically, REMO
pre-trains graph/Transformer encoders on 1.7 million known chemical reactions
in the literature. We propose two pre-training objectives: Masked Reaction
Centre Reconstruction (MRCR) and Reaction Centre Identification (RCI). REMO
offers a novel solution to MRL by exploiting the underlying shared patterns in
chemical reactions as \textit{context} for pre-training, which effectively
infers meaningful representations of common chemistry knowledge. Such
contextual representations can then be utilized to support diverse downstream
molecular tasks with minimum finetuning, such as affinity prediction and
drug-drug interaction prediction. Extensive experimental results on
MoleculeACE, ACNet, drug-drug interaction (DDI), and reaction type
classification show that across all tested downstream tasks, REMO outperforms
the standard baseline of single-molecule masked modeling used in current MRL.
Remarkably, REMO is the pioneering deep learning model surpassing
fingerprint-based methods in activity cliff benchmarks.",2024-02-21,2024,2024-02,chemistry
"TaxDiff: Taxonomic-Guided Diffusion Model for Protein Sequence
  Generation","Designing protein sequences with specific biological functions and structural
stability is crucial in biology and chemistry. Generative models already
demonstrated their capabilities for reliable protein design. However, previous
models are limited to the unconditional generation of protein sequences and
lack the controllable generation ability that is vital to biological tasks. In
this work, we propose TaxDiff, a taxonomic-guided diffusion model for
controllable protein sequence generation that combines biological species
information with the generative capabilities of diffusion models to generate
structurally stable proteins within the sequence space. Specifically, taxonomic
control information is inserted into each layer of the transformer block to
achieve fine-grained control. The combination of global and local attention
ensures the sequence consistency and structural foldability of
taxonomic-specific proteins. Extensive experiments demonstrate that TaxDiff can
consistently achieve better performance on multiple protein sequence generation
benchmarks in both taxonomic-guided controllable generation and unconditional
generation. Remarkably, the sequences generated by TaxDiff even surpass those
produced by direct-structure-generation models in terms of confidence based on
predicted structures and require only a quarter of the time of models based on
the diffusion model. The code for generating proteins and training new versions
of TaxDiff is available at:https://github.com/Linzy19/TaxDiff.",2024-02-27,2024,2024-02,chemistry
"Leveraging Biomolecule and Natural Language through Multi-Modal
  Learning: A Survey","The integration of biomolecular modeling with natural language (BL) has
emerged as a promising interdisciplinary area at the intersection of artificial
intelligence, chemistry and biology. This approach leverages the rich,
multifaceted descriptions of biomolecules contained within textual data sources
to enhance our fundamental understanding and enable downstream computational
tasks such as biomolecule property prediction. The fusion of the nuanced
narratives expressed through natural language with the structural and
functional specifics of biomolecules described via various molecular modeling
techniques opens new avenues for comprehensively representing and analyzing
biomolecules. By incorporating the contextual language data that surrounds
biomolecules into their modeling, BL aims to capture a holistic view
encompassing both the symbolic qualities conveyed through language as well as
quantitative structural characteristics. In this review, we provide an
extensive analysis of recent advancements achieved through cross modeling of
biomolecules and natural language. (1) We begin by outlining the technical
representations of biomolecules employed, including sequences, 2D graphs, and
3D structures. (2) We then examine in depth the rationale and key objectives
underlying effective multi-modal integration of language and molecular data
sources. (3) We subsequently survey the practical applications enabled to date
in this developing research area. (4) We also compile and summarize the
available resources and datasets to facilitate future work. (5) Looking ahead,
we identify several promising research directions worthy of further exploration
and investment to continue advancing the field. The related resources and
contents are updating in
\url{https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling}.",2024-03-03,2024,2024-03,chemistry
Brilla AI: AI Contestant for the National Science and Maths Quiz,"The African continent lacks enough qualified teachers which hampers the
provision of adequate learning support. An AI could potentially augment the
efforts of the limited number of teachers, leading to better learning outcomes.
Towards that end, this work describes and evaluates the first key output for
the NSMQ AI Grand Challenge, which proposes a robust, real-world benchmark for
such an AI: ""Build an AI to compete live in Ghana's National Science and Maths
Quiz (NSMQ) competition and win - performing better than the best contestants
in all rounds and stages of the competition"". The NSMQ is an annual live
science and mathematics competition for senior secondary school students in
Ghana in which 3 teams of 2 students compete by answering questions across
biology, chemistry, physics, and math in 5 rounds over 5 progressive stages
until a winning team is crowned for that year. In this work, we built Brilla
AI, an AI contestant that we deployed to unofficially compete remotely and live
in the Riddles round of the 2023 NSMQ Grand Finale, the first of its kind in
the 30-year history of the competition. Brilla AI is currently available as a
web app that livestreams the Riddles round of the contest, and runs 4 machine
learning systems: (1) speech to text (2) question extraction (3) question
answering and (4) text to speech that work together in real-time to quickly and
accurately provide an answer, and then say it with a Ghanaian accent. In its
debut, our AI answered one of the 4 riddles ahead of the 3 human contesting
teams, unofficially placing second (tied). Improvements and extensions of this
AI could potentially be deployed to offer science tutoring to students and
eventually enable millions across Africa to have one-on-one learning
interactions, democratizing science education.",2024-03-04,2024,2024-03,chemistry
"MolNexTR: A Generalized Deep Learning Model for Molecular Image
  Recognition","In the field of chemical structure recognition, the task of converting
molecular images into machine-readable data formats such as SMILES string
stands as a significant challenge, primarily due to the varied drawing styles
and conventions prevalent in chemical literature. To bridge this gap, we
proposed MolNexTR, a novel image-to-graph deep learning model that collaborates
to fuse the strengths of ConvNext, a powerful Convolutional Neural Network
variant, and Vision-TRansformer. This integration facilitates a more detailed
extraction of both local and global features from molecular images. MolNexTR
can predict atoms and bonds simultaneously and understand their layout rules.
It also excels at flexibly integrating symbolic chemistry principles to discern
chirality and decipher abbreviated structures. We further incorporate a series
of advanced algorithms, including an improved data augmentation module, an
image contamination module, and a post-processing module for getting the final
SMILES output. These modules cooperate to enhance the model's robustness to
diverse styles of molecular images found in real literature. In our test sets,
MolNexTR has demonstrated superior performance, achieving an accuracy rate of
81-97%, marking a significant advancement in the domain of molecular structure
recognition.",2024-03-06,2024,2024-03,chemistry
"KIF: A Wikidata-Based Framework for Integrating Heterogeneous Knowledge
  Sources","We present a Wikidata-based framework, called KIF, for virtually integrating
heterogeneous knowledge sources. KIF is written in Python and is released as
open-source. It leverages Wikidata's data model and vocabulary plus
user-defined mappings to construct a unified view of the underlying sources
while keeping track of the context and provenance of their statements. The
underlying sources can be triplestores, relational databases, CSV files, etc.,
which may or may not use the vocabulary and RDF encoding of Wikidata. The end
result is a virtual knowledge base which behaves like an ""extended Wikidata""
and which can be queried using a simple but expressive pattern language,
defined in terms of Wikidata's data model. In this paper, we present the design
and implementation of KIF, discuss how we have used it to solve a real
integration problem in the domain of chemistry (involving Wikidata, PubChem,
and IBM CIRCA), and present experimental results on the performance and
overhead of KIF",2024-03-15,2024,2024-03,chemistry
"TransPeakNet: Solvent-Aware 2D NMR Prediction via Multi-Task
  Pre-Training and Unsupervised Learning","Nuclear Magnetic Resonance (NMR) spectroscopy is essential for revealing
molecular structure, electronic environment, and dynamics. Accurate NMR shift
prediction allows researchers to validate structures by comparing predicted and
observed shifts. While Machine Learning (ML) has improved one-dimensional (1D)
NMR shift prediction, predicting 2D NMR remains challenging due to limited
annotated data. To address this, we introduce an unsupervised training
framework for predicting cross-peaks in 2D NMR, specifically Heteronuclear
Single Quantum Coherence (HSQC).Our approach pretrains an ML model on an
annotated 1D dataset of 1H and 13C shifts, then finetunes it in an unsupervised
manner using unlabeled HSQC data, which simultaneously generates cross-peak
annotations. Our model also adjusts for solvent effects. Evaluation on 479
expert-annotated HSQC spectra demonstrates our model's superiority over
traditional methods (ChemDraw and Mestrenova), achieving Mean Absolute Errors
(MAEs) of 2.05 ppm and 0.165 ppm for 13C shifts and 1H shifts respectively. Our
algorithmic annotations show a 95.21% concordance with experts' assignments,
underscoring the approach's potential for structural elucidation in fields like
organic chemistry, pharmaceuticals, and natural products.",2024-03-17,2024,2024-03,chemistry
"PEaCE: A Chemistry-Oriented Dataset for Optical Character Recognition on
  Scientific Documents","Optical Character Recognition (OCR) is an established task with the objective
of identifying the text present in an image. While many off-the-shelf OCR
models exist, they are often trained for either scientific (e.g., formulae) or
generic printed English text. Extracting text from chemistry publications
requires an OCR model that is capable in both realms. Nougat, a recent tool,
exhibits strong ability to parse academic documents, but is unable to parse
tables in PubMed articles, which comprises a significant part of the academic
community and is the focus of this work. To mitigate this gap, we present the
Printed English and Chemical Equations (PEaCE) dataset, containing both
synthetic and real-world records, and evaluate the efficacy of
transformer-based OCR models when trained on this resource. Given that
real-world records contain artifacts not present in synthetic records, we
propose transformations that mimic such qualities. We perform a suite of
experiments to explore the impact of patch size, multi-domain training, and our
proposed transformations, ultimately finding that models with a small patch
size trained on multiple domains using the proposed transformations yield the
best performance. Our dataset and code is available at
https://github.com/ZN1010/PEaCE.",2024-03-23,2024,2024-03,chemistry
"On machine learning analysis of atomic force microscopy images for image
  classification, sample surface recognition","Atomic force microscopy (AFM or SPM) imaging is one of the best matches with
machine learning (ML) analysis among microscopy techniques. The digital format
of AFM images allows for direct utilization in ML algorithms without the need
for additional processing. Additionally, AFM enables the simultaneous imaging
of distributions of over a dozen different physicochemical properties of sample
surfaces, a process known as multidimensional imaging. While this wealth of
information can be challenging to analyze using traditional methods, ML
provides a seamless approach to this task. However, the relatively slow speed
of AFM imaging poses a challenge in applying deep learning methods broadly used
in image recognition. This Prospective is focused on ML
recognition/classification when using a relatively small number of AFM images,
small database. We discuss ML methods other than popular deep-learning neural
networks. The described approach has already been successfully used to analyze
and classify the surfaces of biological cells. It can be applied to recognize
medical images, specific material processing, in forensic studies, even to
identify the authenticity of arts. A general template for ML analysis specific
to AFM is suggested, with a specific example of the identification of cell
phenotype. Special attention is given to the analysis of the statistical
significance of the obtained results, an important feature that is often
overlooked in papers dealing with machine learning. A simple method for finding
statistical significance is also described.",2024-03-24,2024,2024-03,chemistry
Are large language models superhuman chemists?,"Large language models (LLMs) have gained widespread interest due to their
ability to process human language and perform tasks on which they have not been
explicitly trained.
  However, we possess only a limited systematic understanding of the chemical
capabilities of LLMs, which would be required to improve models and mitigate
potential harm. Here, we introduce ""ChemBench,"" an automated framework for
evaluating the chemical knowledge and reasoning abilities of state-of-the-art
LLMs against the expertise of chemists.
  We curated more than 2,700 question-answer pairs, evaluated leading open- and
closed-source LLMs, and found that the best models outperformed the best human
chemists in our study on average. However, the models struggle with some basic
tasks and provide overconfident predictions.
  These findings reveal LLMs' impressive chemical capabilities while
emphasizing the need for further research to improve their safety and
usefulness. They also suggest adapting chemistry education and show the value
of benchmarking frameworks for evaluating LLMs in specific domains.",2024-04-01,2024,2024-04,chemistry
"Graph Reinforcement Learning for Combinatorial Optimization: A Survey
  and Unifying Perspective","Graphs are a natural representation for systems based on relations between
connected entities. Combinatorial optimization problems, which arise when
considering an objective function related to a process of interest on discrete
structures, are often challenging due to the rapid growth of the solution
space. The trial-and-error paradigm of Reinforcement Learning has recently
emerged as a promising alternative to traditional methods, such as exact
algorithms and (meta)heuristics, for discovering better decision-making
strategies in a variety of disciplines including chemistry, computer science,
and statistics. Despite the fact that they arose in markedly different fields,
these techniques share significant commonalities. Therefore, we set out to
synthesize this work in a unifying perspective that we term Graph Reinforcement
Learning, interpreting it as a constructive decision-making method for graph
problems. After covering the relevant technical background, we review works
along the dividing line of whether the goal is to optimize graph structure
given a process of interest, or to optimize the outcome of the process itself
under fixed graph structure. Finally, we discuss the common challenges facing
the field and open research questions. In contrast with other surveys, the
present work focuses on non-canonical graph problems for which performant
algorithms are typically not known and Reinforcement Learning is able to
provide efficient and effective solutions.",2024-04-09,2024,2024-04,chemistry
"Shape Arithmetic Expressions: Advancing Scientific Discovery Beyond
  Closed-Form Equations","Symbolic regression has excelled in uncovering equations from physics,
chemistry, biology, and related disciplines. However, its effectiveness becomes
less certain when applied to experimental data lacking inherent closed-form
expressions. Empirically derived relationships, such as entire stress-strain
curves, may defy concise closed-form representation, compelling us to explore
more adaptive modeling approaches that balance flexibility with
interpretability. In our pursuit, we turn to Generalized Additive Models
(GAMs), a widely used class of models known for their versatility across
various domains. Although GAMs can capture non-linear relationships between
variables and targets, they cannot capture intricate feature interactions. In
this work, we investigate both of these challenges and propose a novel class of
models, Shape Arithmetic Expressions (SHAREs), that fuses GAM's flexible shape
functions with the complex feature interactions found in mathematical
expressions. SHAREs also provide a unifying framework for both of these
approaches. We also design a set of rules for constructing SHAREs that
guarantee transparency of the found expressions beyond the standard constraints
based on the model's size.",2024-04-15,2024,2024-04,chemistry
"Integrating Chemistry Knowledge in Large Language Models via Prompt
  Engineering","This paper presents a study on the integration of domain-specific knowledge
in prompt engineering to enhance the performance of large language models
(LLMs) in scientific domains. A benchmark dataset is curated to encapsulate the
intricate physical-chemical properties of small molecules, their drugability
for pharmacology, alongside the functional attributes of enzymes and crystal
materials, underscoring the relevance and applicability across biological and
chemical domains.The proposed domain-knowledge embedded prompt engineering
method outperforms traditional prompt engineering strategies on various
metrics, including capability, accuracy, F1 score, and hallucination drop. The
effectiveness of the method is demonstrated through case studies on complex
materials including the MacMillan catalyst, paclitaxel, and lithium cobalt
oxide. The results suggest that domain-knowledge prompts can guide LLMs to
generate more accurate and relevant responses, highlighting the potential of
LLMs as powerful tools for scientific discovery and innovation when equipped
with domain-specific prompts. The study also discusses limitations and future
directions for domain-specific prompt engineering development.",2024-04-22,2024,2024-04,chemistry
"Delayed Bottlenecking: Alleviating Forgetting in Pre-trained Graph
  Neural Networks","Pre-training GNNs to extract transferable knowledge and apply it to
downstream tasks has become the de facto standard of graph representation
learning. Recent works focused on designing self-supervised pre-training tasks
to extract useful and universal transferable knowledge from large-scale
unlabeled data. However, they have to face an inevitable question: traditional
pre-training strategies that aim at extracting useful information about
pre-training tasks, may not extract all useful information about the downstream
task. In this paper, we reexamine the pre-training process within traditional
pre-training and fine-tuning frameworks from the perspective of Information
Bottleneck (IB) and confirm that the forgetting phenomenon in pre-training
phase may cause detrimental effects on downstream tasks. Therefore, we propose
a novel \underline{D}elayed \underline{B}ottlenecking \underline{P}re-training
(DBP) framework which maintains as much as possible mutual information between
latent representations and training data during pre-training phase by
suppressing the compression operation and delays the compression operation to
fine-tuning phase to make sure the compression can be guided with labeled
fine-tuning data and downstream tasks. To achieve this, we design two
information control objectives that can be directly optimized and further
integrate them into the actual model design. Extensive experiments on both
chemistry and biology domains demonstrate the effectiveness of DBP.",2024-04-23,2024,2024-04,chemistry
Global Concept Explanations for Graphs by Contrastive Learning,"Beyond improving trust and validating model fairness, xAI practices also have
the potential to recover valuable scientific insights in application domains
where little to no prior human intuition exists. To that end, we propose a
method to extract global concept explanations from the predictions of graph
neural networks to develop a deeper understanding of the tasks underlying
structure-property relationships. We identify concept explanations as dense
clusters in the self-explaining Megan models subgraph latent space. For each
concept, we optimize a representative prototype graph and optionally use GPT-4
to provide hypotheses about why each structure has a certain effect on the
prediction. We conduct computational experiments on synthetic and real-world
graph property prediction tasks. For the synthetic tasks we find that our
method correctly reproduces the structural rules by which they were created.
For real-world molecular property regression and classification tasks, we find
that our method rediscovers established rules of thumb. More specifically, our
results for molecular mutagenicity prediction indicate more fine-grained
resolution of structural details than existing explainability methods,
consistent with previous results from chemistry literature. Overall, our
results show promising capability to extract the underlying structure-property
relationships for complex graph property prediction tasks.",2024-04-25,2024,2024-04,chemistry
"Non-Spatial Hash Chemistry as a Minimalistic Open-Ended Evolutionary
  System","There is an increasing level of interest in open-endedness in the recent
literature of Artificial Life and Artificial Intelligence. We previously
proposed the cardinality leap of possibility spaces as a promising mechanism to
facilitate open-endedness in artificial evolutionary systems, and demonstrated
its effectiveness using Hash Chemistry, an artificial chemistry model that used
a hash function as a universal fitness evaluator. However, the spatial nature
of Hash Chemistry came with extensive computational costs involved in its
simulation, and the particle density limit imposed to prevent explosion of
computational costs prevented unbounded growth in complexity of higher-order
entities. To address these limitations, here we propose a simpler non-spatial
variant of Hash Chemistry in which spatial proximity of particles are
represented explicitly in the form of multisets. This model modification
achieved a significant reduction of computational costs in simulating the
model. Results of numerical simulations showed much more significant unbounded
growth in both maximal and average sizes of replicating higher-order entities
than the original model, demonstrating the effectiveness of this non-spatial
model as a minimalistic example of open-ended evolutionary systems.",2024-04-27,2024,2024-04,chemistry
"AI for Manufacturing and Healthcare: a chemistry and engineering
  perspective","Artificial Intelligence (AI) approaches are increasingly being applied to
more and more domains of Science, Engineering, Chemistry, and Industries to not
only improve efficiencies and enhance productivity, but also enable new
capabilities. The new opportunities range from automated molecule design and
screening, properties prediction, gaining insights of chemical reactions, to
computer-aided design, predictive maintenance of systems, robotics, and
autonomous vehicles. This review focuses on the new applications of AI in
manufacturing and healthcare. For the Manufacturing Industries, we focus on AI
and algorithms for (1) Battery, (2) Flow Chemistry, (3) Additive Manufacturing,
(4) Sensors, and (5) Machine Vision. For Healthcare applications, we focus on:
(1) Medical Vision (2) Diagnosis, (3) Protein Design, and (4) Drug Discovery.
In the end, related topics are discussed, including physics integrated machine
learning, model explainability, security, and governance during model
deployment.",2024-05-02,2024,2024-05,chemistry
CACTUS: Chemistry Agent Connecting Tool-Usage to Science,"Large language models (LLMs) have shown remarkable potential in various
domains, but they often lack the ability to access and reason over
domain-specific knowledge and tools. In this paper, we introduced CACTUS
(Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that
integrates cheminformatics tools to enable advanced reasoning and
problem-solving in chemistry and molecular discovery. We evaluate the
performance of CACTUS using a diverse set of open-source LLMs, including
Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of
thousands of chemistry questions. Our results demonstrate that CACTUS
significantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b
models achieving the highest accuracy regardless of the prompting strategy
used. Moreover, we explore the impact of domain-specific prompting and hardware
configurations on model performance, highlighting the importance of prompt
engineering and the potential for deploying smaller models on consumer-grade
hardware without significant loss in accuracy. By combining the cognitive
capabilities of open-source LLMs with domain-specific tools, CACTUS can assist
researchers in tasks such as molecular property prediction, similarity
searching, and drug-likeness assessment. Furthermore, CACTUS represents a
significant milestone in the field of cheminformatics, offering an adaptable
tool for researchers engaged in chemistry and molecular discovery. By
integrating the strengths of open-source LLMs with domain-specific tools,
CACTUS has the potential to accelerate scientific advancement and unlock new
frontiers in the exploration of novel, effective, and safe therapeutic
candidates, catalysts, and materials. Moreover, CACTUS's ability to integrate
with automated experimentation platforms and make data-driven decisions in real
time opens up new possibilities for autonomous discovery.",2024-05-02,2024,2024-05,chemistry
"Single and Multi-Hop Question-Answering Datasets for Reticular Chemistry
  with GPT-4-Turbo","The rapid advancement in artificial intelligence and natural language
processing has led to the development of large-scale datasets aimed at
benchmarking the performance of machine learning models. Herein, we introduce
'RetChemQA,' a comprehensive benchmark dataset designed to evaluate the
capabilities of such models in the domain of reticular chemistry. This dataset
includes both single-hop and multi-hop question-answer pairs, encompassing
approximately 45,000 Q&As for each type. The questions have been extracted from
an extensive corpus of literature containing about 2,530 research papers from
publishers including NAS, ACS, RSC, Elsevier, and Nature Publishing Group,
among others. The dataset has been generated using OpenAI's GPT-4 Turbo, a
cutting-edge model known for its exceptional language understanding and
generation capabilities. In addition to the Q&A dataset, we also release a
dataset of synthesis conditions extracted from the corpus of literature used in
this study. The aim of RetChemQA is to provide a robust platform for the
development and evaluation of advanced machine learning algorithms,
particularly for the reticular chemistry community. The dataset is structured
to reflect the complexities and nuances of real-world scientific discourse,
thereby enabling nuanced performance assessments across a variety of tasks. The
dataset is available at the following link:
https://github.com/nakulrampal/RetChemQA",2024-05-03,2024,2024-05,chemistry
"CVTGAD: Simplified Transformer with Cross-View Attention for
  Unsupervised Graph-level Anomaly Detection","Unsupervised graph-level anomaly detection (UGAD) has received remarkable
performance in various critical disciplines, such as chemistry analysis and
bioinformatics. Existing UGAD paradigms often adopt data augmentation
techniques to construct multiple views, and then employ different strategies to
obtain representations from different views for jointly conducting UGAD.
However, most previous works only considered the relationship between
nodes/graphs from a limited receptive field, resulting in some key structure
patterns and feature information being neglected. In addition, most existing
methods consider different views separately in a parallel manner, which is not
able to explore the inter-relationship across different views directly. Thus, a
method with a larger receptive field that can explore the inter-relationship
across different views directly is in need. In this paper, we propose a novel
Simplified Transformer with Cross-View Attention for Unsupervised Graph-level
Anomaly Detection, namely, CVTGAD. To increase the receptive field, we
construct a simplified transformer-based module, exploiting the relationship
between nodes/graphs from both intra-graph and inter-graph perspectives.
Furthermore, we design a cross-view attention mechanism to directly exploit the
view co-occurrence between different views, bridging the inter-view gap at node
level and graph level. To the best of our knowledge, this is the first work to
apply transformer and cross attention to UGAD, which realizes graph neural
network and transformer working collaboratively. Extensive experiments on 15
real-world datasets of 3 fields demonstrate the superiority of CVTGAD on the
UGAD task. The code is available at
\url{https://github.com/jindongli-Ai/CVTGAD}.",2024-05-03,2024,2024-05,chemistry
"Multi-task learning for molecular electronic structure approaching
  coupled-cluster accuracy","Machine learning (ML) plays an important role in quantum chemistry, providing
fast-to-evaluate predictive models for various properties of molecules.
However, most existing ML models for molecular electronic properties use
density functional theory (DFT) databases as ground truth in training, and
their prediction accuracy cannot surpass that of DFT. In this work, we
developed a unified ML method for electronic structures of organic molecules
using the gold-standard CCSD(T) calculations as training data. Tested on
hydrocarbon molecules, our model outperforms DFT with the widely-used hybrid
and double hybrid functionals in computational costs and prediction accuracy of
various quantum chemical properties. As case studies, we apply the model to
aromatic compounds and semiconducting polymers on both ground state and excited
state properties, demonstrating its accuracy and generalization capability to
complex systems that are hard to calculate using CCSD(T)-level methods.",2024-05-09,2024,2024-05,chemistry
"Beyond traditional Magnetic Resonance processing with Artificial
  Intelligence","Smart signal processing approaches using Artificial Intelligence are gaining
momentum in NMR applications. In this study, we demonstrate that AI offers new
opportunities beyond tasks addressed by traditional techniques. We developed
and trained several artificial neural networks in our new toolbox Magnetic
Resonance with Artificial intelligence (MR-Ai) to solve three ""impossible""
problems: quadrature detection using only Echo (or Anti-Echo) modulation from
the traditional Echo/Anti-Echo scheme; accessing uncertainty of signal
intensity at each point in a spectrum processed by any given method; and
defining a reference-free score for quantitative access of NMR spectrum
quality. Our findings highlight the potential of AI techniques to revolutionize
NMR processing and analysis.",2024-05-13,2024,2024-05,chemistry
"ALMol: Aligned Language-Molecule Translation LLMs through Offline
  Preference Contrastive Optimisation","The field of chemistry and Artificial Intelligence (AI) intersection is an
area of active research that aims to accelerate scientific discovery. The
integration of large language models (LLMs) with scientific modalities has
shown significant promise in this endeavour. However, challenges persist in
effectively addressing training efficacy and the out-of-distribution problem,
particularly as existing approaches rely on larger models and datasets. In this
context, we focus on machine language-molecule translation and deploy a novel
training approach called contrastive preference optimisation, which avoids
generating translations that are merely adequate but not perfect. To ensure
generalisability and mitigate memorisation effects, we conduct experiments
using only 10% of the data. Our results demonstrate that our models achieve up
to a 32% improvement compared to counterpart models. Finally, we introduce a
fine-grained, domain-agnostic evaluation method to assess hallucination in LLMs
and promote responsible use.",2024-05-14,2024,2024-05,chemistry
"Specialising and Analysing Instruction-Tuned and Byte-Level Language
  Models for Organic Reaction Prediction","Transformer-based encoder-decoder models have demonstrated impressive results
in chemical reaction prediction tasks. However, these models typically rely on
pretraining using tens of millions of unlabelled molecules, which can be
time-consuming and GPU-intensive. One of the central questions we aim to answer
in this work is: Can FlanT5 and ByT5, the encode-decoder models pretrained
solely on language data, be effectively specialised for organic reaction
prediction through task-specific fine-tuning? We conduct a systematic empirical
study on several key issues of the process, including tokenisation, the impact
of (SMILES-oriented) pretraining, fine-tuning sample efficiency, and decoding
algorithms at inference. Our key findings indicate that although being
pretrained only on language tasks, FlanT5 and ByT5 provide a solid foundation
to fine-tune for reaction prediction, and thus become `chemistry domain
compatible' in the process. This suggests that GPU-intensive and expensive
pretraining on a large dataset of unlabelled molecules may be useful yet not
essential to leverage the power of language models for chemistry. All our
models achieve comparable Top-1 and Top-5 accuracy although some variation
across different models does exist. Notably, tokenisation and vocabulary
trimming slightly affect final performance but can speed up training and
inference; The most efficient greedy decoding strategy is very competitive
while only marginal gains can be achieved from more sophisticated decoding
algorithms. In summary, we evaluate FlanT5 and ByT5 across several dimensions
and benchmark their impact on organic reaction prediction, which may guide more
effective use of these state-of-the-art language models for chemistry-related
tasks in the future.",2024-05-17,2024,2024-05,chemistry
Retro-prob: Retrosynthetic Planning Based on a Probabilistic Model,"Retrosynthesis is a fundamental but challenging task in organic chemistry,
with broad applications in fields such as drug design and synthesis. Given a
target molecule, the goal of retrosynthesis is to find out a series of
reactions which could be assembled into a synthetic route which starts from
purchasable molecules and ends at the target molecule. The uncertainty of
reactions used in retrosynthetic planning, which is caused by hallucinations of
backward models, has recently been noticed. In this paper we propose a succinct
probabilistic model to describe such uncertainty. Based on the model, we
propose a new retrosynthesis planning algorithm called retro-prob to maximize
the successful synthesis probability of target molecules, which acquires high
efficiency by utilizing the chain rule of derivatives. Experiments on the
Paroutes benchmark show that retro-prob outperforms previous algorithms, retro*
and retro-fallback, both in speed and in the quality of synthesis plans.",2024-05-25,2024,2024-05,chemistry
"SE3Set: Harnessing equivariant hypergraph neural networks for molecular
  representation learning","In this paper, we develop SE3Set, an SE(3) equivariant hypergraph neural
network architecture tailored for advanced molecular representation learning.
Hypergraphs are not merely an extension of traditional graphs; they are pivotal
for modeling high-order relationships, a capability that conventional
equivariant graph-based methods lack due to their inherent limitations in
representing intricate many-body interactions. To achieve this, we first
construct hypergraphs via proposing a new fragmentation method that considers
both chemical and three-dimensional spatial information of molecular system. We
then design SE3Set, which incorporates equivariance into the hypergragh neural
network. This ensures that the learned molecular representations are invariant
to spatial transformations, thereby providing robustness essential for accurate
prediction of molecular properties. SE3Set has shown performance on par with
state-of-the-art (SOTA) models for small molecule datasets like QM9 and MD17.
It excels on the MD22 dataset, achieving a notable improvement of approximately
20% in accuracy across all molecules, which highlights the prevalence of
complex many-body interactions in larger molecules. This exceptional
performance of SE3Set across diverse molecular structures underscores its
transformative potential in computational chemistry, offering a route to more
accurate and physically nuanced modeling.",2024-05-26,2024,2024-05,chemistry
RLSF: Reinforcement Learning via Symbolic Feedback,"Reinforcement Learning with Human Feedback (RLHF) is considered a standard
approach to fine-tuning Large Language Models (LLMs). However, such methods
often face limitations such as unsound black-box reward models, difficulties in
collecting human preference data, and the reliance on sparse scalar rewards.
These methods often fall short when applied to tasks that require complex
domain-specific understanding.
  To address these challenges, we propose a new fine-tuning paradigm we refer
to as Reinforcement Learning via Symbolic Feedback (RLSF), which aims to
improve domain-specific understanding of LLMs more effectively than traditional
reward signals. In the RLSF setting, the LLM being fine-tuned is considered an
RL agent, while the environment is allowed access to reasoning or domain
knowledge tools (e.g., solvers, provers, algebra systems, or knowledge bases).
Crucially, in RLSF, these reasoning tools can provide feedback to the LLMs via
poly-sized certificates (e.g., proofs), that characterize errors in the
LLM-generated object with respect to some correctness specification. As a
bonus, our RLSF approach does not require the reasoning systems we use to be
differentiable. The ability of RLSF-based fine-tuning to leverage
certificate-generating symbolic tools enables sound fine-grained (token-level)
reward signals to LLMs, and thus addresses the limitations of traditional
reward models mentioned above.
  Via extensive evaluations, we show that our RLSF-based fine-tuning of LLMs
outperforms traditional approaches on five different applications, namely,
program synthesis from natural language pseudo-code to programming language,
three chemistry tasks, and solving the Game of 24. A takeaway is that
fine-tuning via RLSF enables relatively smaller LLMs to significantly
outperform closed-source models that are orders of magnitude larger (e.g.,
GPT-4).",2024-05-26,2024,2024-05,chemistry
UniIF: Unified Molecule Inverse Folding,"Molecule inverse folding has been a long-standing challenge in chemistry and
biology, with the potential to revolutionize drug discovery and material
science. Despite specified models have been proposed for different small- or
macro-molecules, few have attempted to unify the learning process, resulting in
redundant efforts. Complementary to recent advancements in molecular structure
prediction, such as RoseTTAFold All-Atom and AlphaFold3, we propose the unified
model UniIF for the inverse folding of all molecules. We do such unification in
two levels: 1) Data-Level: We propose a unified block graph data form for all
molecules, including the local frame building and geometric feature
initialization. 2) Model-Level: We introduce a geometric block attention
network, comprising a geometric interaction, interactive attention and virtual
long-term dependency modules, to capture the 3D interactions of all molecules.
Through comprehensive evaluations across various tasks such as protein design,
RNA design, and material design, we demonstrate that our proposed method
surpasses state-of-the-art methods on all tasks. UniIF offers a versatile and
effective solution for general molecule inverse folding.",2024-05-29,2024,2024-05,chemistry
Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models,"The startling success of ChatGPT and other large language models (LLMs) using
transformer-based generative neural network architecture in applications such
as natural language processing and image synthesis has many researchers excited
about potential opportunities in process systems engineering (PSE). The almost
human-like performance of LLMs in these areas is indeed very impressive,
surprising, and a major breakthrough. Their capabilities are very useful in
certain tasks, such as writing first drafts of documents, code writing
assistance, text summarization, etc. However, their success is limited in
highly scientific domains as they cannot yet reason, plan, or explain due to
their lack of in-depth domain knowledge. This is a problem in domains such as
chemical engineering as they are governed by fundamental laws of physics and
chemistry (and biology), constitutive relations, and highly technical knowledge
about materials, processes, and systems. Although purely data-driven machine
learning has its immediate uses, the long-term success of AI in scientific and
engineering domains would depend on developing hybrid AI systems that use first
principles and technical knowledge effectively. We call these hybrid AI systems
Large Knowledge Models (LKMs), as they will not be limited to only NLP-based
techniques or NLP-like applications. In this paper, we discuss the challenges
and opportunities in developing such systems in chemical engineering.",2024-05-29,2024,2024-05,chemistry
An Automatic Question Usability Evaluation Toolkit,"Evaluating multiple-choice questions (MCQs) involves either labor intensive
human assessments or automated methods that prioritize readability, often
overlooking deeper question design flaws. To address this issue, we introduce
the Scalable Automatic Question Usability Evaluation Toolkit (SAQUET), an
open-source tool that leverages the Item-Writing Flaws (IWF) rubric for a
comprehensive and automated quality evaluation of MCQs. By harnessing the
latest in large language models such as GPT-4, advanced word embeddings, and
Transformers designed to analyze textual complexity, SAQUET effectively
pinpoints and assesses a wide array of flaws in MCQs. We first demonstrate the
discrepancy between commonly used automated evaluation metrics and the human
assessment of MCQ quality. Then we evaluate SAQUET on a diverse dataset of MCQs
across the five domains of Chemistry, Statistics, Computer Science, Humanities,
and Healthcare, showing how it effectively distinguishes between flawed and
flawless questions, providing a level of analysis beyond what is achievable
with traditional metrics. With an accuracy rate of over 94% in detecting the
presence of flaws identified by human evaluators, our findings emphasize the
limitations of existing evaluation methods and showcase potential in improving
the quality of educational assessments.",2024-05-30,2024,2024-05,chemistry
"Automated Generation and Tagging of Knowledge Components from
  Multiple-Choice Questions","Knowledge Components (KCs) linked to assessments enhance the measurement of
student learning, enrich analytics, and facilitate adaptivity. However,
generating and linking KCs to assessment items requires significant effort and
domain-specific knowledge. To streamline this process for higher-education
courses, we employed GPT-4 to generate KCs for multiple-choice questions (MCQs)
in Chemistry and E-Learning. We analyzed discrepancies between the KCs
generated by the Large Language Model (LLM) and those made by humans through
evaluation from three domain experts in each subject area. This evaluation
aimed to determine whether, in instances of non-matching KCs, evaluators showed
a preference for the LLM-generated KCs over their human-created counterparts.
We also developed an ontology induction algorithm to cluster questions that
assess similar KCs based on their content. Our most effective LLM strategy
accurately matched KCs for 56% of Chemistry and 35% of E-Learning MCQs, with
even higher success when considering the top five KC suggestions. Human
evaluators favored LLM-generated KCs, choosing them over human-assigned ones
approximately two-thirds of the time, a preference that was statistically
significant across both domains. Our clustering algorithm successfully grouped
questions by their underlying KCs without needing explicit labels or contextual
information. This research advances the automation of KC generation and
classification for assessment items, alleviating the need for student data or
predefined KC labels.",2024-05-30,2024,2024-05,chemistry
Molecular Modelling of Aqueous Batteries,"Aqueous batteries play an increasingly important role for the development of
sustainable and safety-prioritised energy storage solutions. Compared to
conventional lithium-ion batteries, the cell chemistry in aqueous batteries
share many common features with those of electrolyzer and pseudo-capacitor
systems because of the involvement of aqueous electrolyte and proton activity.
This imposes the needs for a better understanding of the corresponding ion
solvation, intercalation and electron transfer processes at atomistic scale.
Therefore, this chapter provides an up-to-date overview of molecular modelling
techniques and their applications in aqueous batteries. In particular, we
emphasize on the dynamical and reactive description of aqueous battery systems
brought in by density functional theory-based molecular dynamics simulation
(DFTMD) and its machine-learning (ML) accelerated counterpart. Moreover, we
also cover the recent advancement of generative artificial intelligence (AI) in
molecular and materials design of aqueous batteries. Case studies presented
here include popular aqueous battery systems, such as water-in-salt
electrolytes, proton-coupled cathode materials, Zn-ion batteries as well as
organic redox flow batteries.",2024-06-01,2024,2024-06,chemistry
Evaluating the World Model Implicit in a Generative Model,"Recent work suggests that large language models may implicitly learn world
models. How should we assess this possibility? We formalize this question for
the case where the underlying reality is governed by a deterministic finite
automaton. This includes problems as diverse as simple logical reasoning,
geographic navigation, game-playing, and chemistry. We propose new evaluation
metrics for world model recovery inspired by the classic Myhill-Nerode theorem
from language theory. We illustrate their utility in three domains: game
playing, logic puzzles, and navigation. In all domains, the generative models
we consider do well on existing diagnostics for assessing world models, but our
evaluation metrics reveal their world models to be far less coherent than they
appear. Such incoherence creates fragility: using a generative model to solve
related but subtly different tasks can lead to failures. Building generative
models that meaningfully capture the underlying logic of the domains they model
would be immensely valuable; our results suggest new ways to assess how close a
given model is to that goal.",2024-06-06,2024,2024-06,chemistry
FlowMM: Generating Materials with Riemannian Flow Matching,"Crystalline materials are a fundamental component in next-generation
technologies, yet modeling their distribution presents unique computational
challenges. Of the plausible arrangements of atoms in a periodic lattice only a
vanishingly small percentage are thermodynamically stable, which is a key
indicator of the materials that can be experimentally realized. Two fundamental
tasks in this area are to (a) predict the stable crystal structure of a known
composition of elements and (b) propose novel compositions along with their
stable structures. We present FlowMM, a pair of generative models that achieve
state-of-the-art performance on both tasks while being more efficient and more
flexible than competing methods. We generalize Riemannian Flow Matching to suit
the symmetries inherent to crystals: translation, rotation, permutation, and
periodic boundary conditions. Our framework enables the freedom to choose the
flow base distributions, drastically simplifying the problem of learning
crystal structures compared with diffusion models. In addition to standard
benchmarks, we validate FlowMM's generated structures with quantum chemistry
calculations, demonstrating that it is about 3x more efficient, in terms of
integration steps, at finding stable materials compared to previous open
methods.",2024-06-07,2024,2024-06,chemistry
"MolX: Enhancing Large Language Models for Molecular Learning with A
  Multi-Modal Extension","Large Language Models (LLMs) with their strong task-handling capabilities
have shown remarkable advancements across a spectrum of fields, moving beyond
natural language understanding. However, their proficiency within the chemistry
domain remains restricted, especially in solving professional molecule-related
tasks. This challenge is attributed to their inherent limitations in
comprehending molecules using only common textual representations, i.e., SMILES
strings. In this study, we seek to enhance the ability of LLMs to comprehend
molecules by equipping them with a multi-modal external module, namely MolX. In
particular, instead of directly using a SMILES string to represent a molecule,
we utilize specific encoders to extract fine-grained features from both SMILES
string and 2D molecular graph representations for feeding into an LLM.
Moreover, a handcrafted molecular fingerprint is incorporated to leverage its
embedded domain knowledge. Then, to establish an alignment between MolX and the
LLM's textual input space, the whole model in which the LLM is frozen, is
pre-trained with a versatile strategy including a diverse set of tasks.
Experimental evaluations show that our proposed method outperforms baselines
across 4 downstream molecule-related tasks ranging from molecule-to-text
translation to retrosynthesis, with and without fine-tuning the LLM, while only
introducing a small number of trainable parameters 0.53% and 0.82%,
respectively.",2024-06-10,2024,2024-06,chemistry
"SciRIFF: A Resource to Enhance Language Model Instruction-Following over
  Scientific Literature","We present SciRIFF (Scientific Resource for Instruction-Following and
Finetuning), a dataset of 137K instruction-following demonstrations for 54
tasks covering five essential scientific literature understanding capabilities:
information extraction, summarization, question answering, claim verification,
and classification. SciRIFF demonstrations are notable for their long input
contexts, detailed task specifications, and complex structured outputs. While
instruction-following resources are available in specific domains such as
clinical medicine and chemistry, SciRIFF is the first dataset focused on
extracting and synthesizing information from research literature across a wide
range of scientific fields. To demonstrate the utility of SciRIFF, we develop a
sample-efficient strategy to adapt a general instruction-following model for
science by performing additional finetuning on a mix of general-domain and
SciRIFF demonstrations. In evaluations on nine held-out scientific tasks, our
model -- called SciTulu -- improves over a strong LLM baseline by 28.1% and
6.5% at the 7B and 70B scales respectively, while maintaining general
instruction-following performance within 2% of the baseline. We are optimistic
that SciRIFF will facilitate the development and evaluation of LLMs to help
researchers navigate the ever-growing body of scientific literature. We release
our dataset, model checkpoints, and data processing and evaluation code to
enable further research.",2024-06-10,2024,2024-06,chemistry
Are Large Language Models Good Statisticians?,"Large Language Models (LLMs) have demonstrated impressive capabilities across
a range of scientific tasks including mathematics, physics, and chemistry.
Despite their successes, the effectiveness of LLMs in handling complex
statistical tasks remains systematically under-explored. To bridge this gap, we
introduce StatQA, a new benchmark designed for statistical analysis tasks.
StatQA comprises 11,623 examples tailored to evaluate LLMs' proficiency in
specialized statistical tasks and their applicability assessment capabilities,
particularly for hypothesis testing methods. We systematically experiment with
representative LLMs using various prompting strategies and show that even
state-of-the-art models such as GPT-4o achieve a best performance of only
64.83%, indicating significant room for improvement. Notably, while open-source
LLMs (e.g. LLaMA-3) show limited capability, those fine-tuned ones exhibit
marked improvements, outperforming all in-context learning-based methods (e.g.
GPT-4o). Moreover, our comparative human experiments highlight a striking
contrast in error types between LLMs and humans: LLMs primarily make
applicability errors, whereas humans mostly make statistical task confusion
errors. This divergence highlights distinct areas of proficiency and
deficiency, suggesting that combining LLM and human expertise could lead to
complementary strengths, inviting further investigation into their
collaborative potential. Our source code and data are available at
https://statqa.github.io/.",2024-06-12,2024,2024-06,chemistry
"Deep Learning Domain Adaptation to Understand Physico-Chemical Processes
  from Fluorescence Spectroscopy Small Datasets: Application to Ageing of Olive
  Oil","Fluorescence spectroscopy is a fundamental tool in life sciences and
chemistry, widely used for applications such as environmental monitoring, food
quality control, and biomedical diagnostics. However, analysis of spectroscopic
data with deep learning, in particular of fluorescence excitation-emission
matrices (EEMs), presents significant challenges due to the typically small and
sparse datasets available. Furthermore, the analysis of EEMs is difficult due
to their high dimensionality and overlapping spectral features. This study
proposes a new approach that exploits domain adaptation with pretrained vision
models, alongside a novel interpretability algorithm to address these
challenges. Thanks to specialised feature engineering of the neural networks
described in this work, we are now able to provide deeper insights into the
physico-chemical processes underlying the data. The proposed approach is
demonstrated through the analysis of the oxidation process in extra virgin
olive oil (EVOO) during ageing, showing its effectiveness in predicting quality
indicators and identifying the spectral bands, and thus the molecules involved
in the process. This work describes a significantly innovative approach in the
use of deep learning for spectroscopy, transforming it from a black box into a
tool for understanding complex biological and chemical processes.",2024-06-14,2024,2024-06,chemistry
PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes,"Multimodal Large Language Models (MLLMs) have seen growing adoption across
various scientific disciplines. These advancements encourage the investigation
of molecule-text modeling within synthetic chemistry, a field dedicated to
designing and conducting chemical reactions to synthesize new compounds with
desired properties and applications. Current approaches, however, often neglect
the critical role of multiple molecule graph interaction in understanding
chemical reactions, leading to suboptimal performance in synthetic chemistry
tasks. This study introduces PRESTO(Progressive Pretraining Enhances Synthetic
Chemistry Outcomes), a new framework that bridges the molecule-text modality
gap by integrating a comprehensive benchmark of pretraining strategies and
dataset configurations. It progressively improves multimodal LLMs through
cross-modal alignment and multi-graph understanding. Our extensive experiments
demonstrate that PRESTO offers competitive results in downstream synthetic
chemistry tasks. The code can be found at https://github.com/IDEA-XL/PRESTO.",2024-06-19,2024,2024-06,chemistry
"MR-Ben: A Meta-Reasoning Benchmark for Evaluating System-2 Thinking in
  LLMs","Large language models (LLMs) have shown increasing capability in
problem-solving and decision-making, largely based on the step-by-step
chain-of-thought reasoning processes. However, evaluating these reasoning
abilities has become increasingly challenging. Existing outcome-based
benchmarks are beginning to saturate, becoming less effective in tracking
meaningful progress. To address this, we present a process-based benchmark
MR-Ben that demands a meta-reasoning skill, where LMs are asked to locate and
analyse potential errors in automatically generated reasoning steps. Our
meta-reasoning paradigm is especially suited for system-2 slow thinking,
mirroring the human cognitive process of carefully examining assumptions,
conditions, calculations, and logic to identify mistakes.MR-Ben comprises 5,975
questions curated by human experts across a wide range of subjects, including
physics, chemistry, logic, coding, and more. Through our designed metrics for
assessing meta-reasoning on this benchmark, we identify interesting limitations
and weaknesses of current LLMs (open-source and closed-source models). For
example, with models like the o1 series from OpenAI demonstrating strong
performance by effectively scrutinizing the solution space, many other
state-of-the-art models fall significantly behind on MR-Ben, exposing potential
shortcomings in their training strategies and inference methodologies.",2024-06-20,2024,2024-06,chemistry
"From Text to Test: AI-Generated Control Software for Materials Science
  Instruments","Large language models (LLMs) are transforming the landscape of chemistry and
materials science. Recent examples of LLM-accelerated experimental research
include virtual assistants for parsing synthesis recipes from the literature,
or using the extracted knowledge to guide synthesis and characterization.
Despite these advancements, their application is constrained to labs with
automated instruments and control software, leaving much of materials science
reliant on manual processes. Here, we demonstrate the rapid deployment of a
Python-based control module for a Keithley 2400 electrical source measure unit
using ChatGPT-4. Through iterative refinement, we achieved effective instrument
management with minimal human intervention. Additionally, a user-friendly
graphical user interface (GUI) was created, effectively linking all instrument
controls to interactive screen elements. Finally, we integrated this AI-crafted
instrument control software with a high-performance stochastic optimization
algorithm to facilitate rapid and automated extraction of electronic device
parameters related to semiconductor charge transport mechanisms from
current-voltage (IV) measurement data. This integration resulted in a
comprehensive open-source toolkit for semiconductor device characterization and
analysis using IV curve measurements. We demonstrate the application of these
tools by acquiring, analyzing, and parameterizing IV data from a
Pt/Cr$_2$O$_3$:Mg/$\beta$-Ga$_2$O$_3$ heterojunction diode, a novel stack for
high-power and high-temperature electronic devices. This approach underscores
the powerful synergy between LLMs and the development of instruments for
scientific inquiry, showcasing a path for further acceleration in materials
science.",2024-06-23,2024,2024-06,chemistry
"Efficient Evolutionary Search Over Chemical Space with Large Language
  Models","Molecular discovery, when formulated as an optimization problem, presents
significant computational challenges because optimization objectives can be
non-differentiable. Evolutionary Algorithms (EAs), often used to optimize
black-box objectives in molecular discovery, traverse chemical space by
performing random mutations and crossovers, leading to a large number of
expensive objective evaluations. In this work, we ameliorate this shortcoming
by incorporating chemistry-aware Large Language Models (LLMs) into EAs. Namely,
we redesign crossover and mutation operations in EAs using LLMs trained on
large corpora of chemical information. We perform extensive empirical studies
on both commercial and open-source models on multiple tasks involving property
optimization, molecular rediscovery, and structure-based drug design,
demonstrating that the joint usage of LLMs with EAs yields superior performance
over all baseline models across single- and multi-objective settings. We
demonstrate that our algorithm improves both the quality of the final solution
and convergence speed, thereby reducing the number of required objective
evaluations. Our code is available at http://github.com/zoom-wang112358/MOLLEO",2024-06-23,2024,2024-06,chemistry
OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?,"In this report, we pose the following question: Who is the most intelligent
AI model to date, as measured by the OlympicArena (an Olympic-level,
multi-discipline, multi-modal benchmark for superintelligent AI)? We
specifically focus on the most recently released models: Claude-3.5-Sonnet,
Gemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic
medal Table approach to rank AI models based on their comprehensive performance
across various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet
shows highly competitive overall performance over GPT-4o, even surpassing
GPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)
Gemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and
Claude-3.5-Sonnet, but with a clear performance gap between them. (3) The
performance of AI models from the open-source community significantly lags
behind these proprietary models. (4) The performance of these models on this
benchmark has been less than satisfactory, indicating that we still have a long
way to go before achieving superintelligence. We remain committed to
continuously tracking and evaluating the performance of the latest powerful
models on this benchmark (available at
https://github.com/GAIR-NLP/OlympicArena).",2024-06-24,2024,2024-06,chemistry
KANQAS: Kolmogorov-Arnold Network for Quantum Architecture Search,"Quantum architecture Search (QAS) is a promising direction for optimization
and automated design of quantum circuits towards quantum advantage. Recent
techniques in QAS emphasize Multi-Layer Perceptron (MLP)-based deep Q-networks.
However, their interpretability remains challenging due to the large number of
learnable parameters and the complexities involved in selecting appropriate
activation functions. In this work, to overcome these challenges, we utilize
the Kolmogorov-Arnold Network (KAN) in the QAS algorithm, analyzing their
efficiency in the task of quantum state preparation and quantum chemistry. In
quantum state preparation, our results show that in a noiseless scenario, the
probability of success is 2 to 5 times higher than MLPs. In noisy environments,
KAN outperforms MLPs in fidelity when approximating these states, showcasing
its robustness against noise. In tackling quantum chemistry problems, we
enhance the recently proposed QAS algorithm by integrating curriculum
reinforcement learning with a KAN structure. This facilitates a more efficient
design of parameterized quantum circuits by reducing the number of required
2-qubit gates and circuit depth. Further investigation reveals that KAN
requires a significantly smaller number of learnable parameters compared to
MLPs; however, the average time of executing each episode for KAN is higher.",2024-06-25,2024,2024-06,chemistry
A Review of Large Language Models and Autonomous Agents in Chemistry,"Large language models (LLMs) have emerged as powerful tools in chemistry,
significantly impacting molecule design, property prediction, and synthesis
optimization. This review highlights LLM capabilities in these domains and
their potential to accelerate scientific discovery through automation. We also
review LLM-based autonomous agents: LLMs with a broader set of tools to
interact with their surrounding environment. These agents perform diverse tasks
such as paper scraping, interfacing with automated laboratories, and synthesis
planning. As agents are an emerging topic, we extend the scope of our review of
agents beyond chemistry and discuss across any scientific domains. This review
covers the recent history, current capabilities, and design of LLMs and
autonomous agents, addressing specific challenges, opportunities, and future
directions in chemistry. Key challenges include data quality and integration,
model interpretability, and the need for standard benchmarks, while future
directions point towards more sophisticated multi-modal agents and enhanced
collaboration between agents and experimental methods. Due to the quick pace of
this field, a repository has been built to keep track of the latest studies:
https://github.com/ur-whitelab/LLMs-in-science.",2024-06-26,2024,2024-06,chemistry
"PharmaGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical
  and Chemistry","Large language models (LLMs) have revolutionized Natural Language Processing
(NLP) by minimizing the need for complex feature engineering. However, the
application of LLMs in specialized domains like biopharmaceuticals and
chemistry remains largely unexplored. These fields are characterized by
intricate terminologies, specialized knowledge, and a high demand for precision
areas where general purpose LLMs often fall short. In this study, we introduce
PharmaGPT, a suite of domain specilized LLMs with 13 billion and 70 billion
parameters, specifically trained on a comprehensive corpus tailored to the
Bio-Pharmaceutical and Chemical domains. Our evaluation shows that PharmaGPT
surpasses existing general models on specific-domain benchmarks such as NAPLEX,
demonstrating its exceptional capability in domain-specific tasks. Remarkably,
this performance is achieved with a model that has only a fraction, sometimes
just one-tenth-of the parameters of general-purpose large models. This
advancement establishes a new benchmark for LLMs in the bio-pharmaceutical and
chemical fields, addressing the existing gap in specialized language modeling.
It also suggests a promising path for enhanced research and development, paving
the way for more precise and effective NLP applications in these areas.",2024-06-26,2024,2024-06,chemistry
Machine learning meets mass spectrometry: a focused perspective,"Mass spectrometry is a widely used method to study molecules and processes in
medicine, life sciences, chemistry, catalysis, and industrial product quality
control, among many other applications. One of the main features of some mass
spectrometry techniques is the extensive level of characterization (especially
when coupled with chromatography and ion mobility methods, or a part of tandem
mass spectrometry experiment) and a large amount of generated data per
measurement. Terabyte scales can be easily reached with mass spectrometry
studies. Consequently, mass spectrometry has faced the challenge of a high
level of data disappearance. Researchers often neglect and then altogether lose
access to the rich information mass spectrometry experiments could provide.
With the development of machine learning methods, the opportunity arises to
unlock the potential of these data, enabling previously inaccessible
discoveries. The present perspective highlights reevaluation of mass
spectrometry data analysis in the new generation of methods and describes
significant challenges in the field, particularly related to problems involving
the use of electrospray ionization. We argue that further applications of
machine learning raise new requirements for instrumentation (increasing
throughput and information density, decreasing pricing, and making more
automation-friendly software), and once met, the field may experience
significant transformation.",2024-06-27,2024,2024-06,chemistry
On the Expressive Power of Sparse Geometric MPNNs,"Motivated by applications in chemistry and other sciences, we study the
expressive power of message-passing neural networks for geometric graphs, whose
node features correspond to 3-dimensional positions. Recent work has shown that
such models can separate generic pairs of non-isomorphic geometric graphs,
though they may fail to separate some rare and complicated instances. However,
these results assume a fully connected graph, where each node possesses
complete knowledge of all other nodes. In contrast, often, in application,
every node only possesses knowledge of a small number of nearest neighbors.
  This paper shows that generic pairs of non-isomorphic geometric graphs can be
separated by message-passing networks with rotation equivariant features as
long as the underlying graph is connected. When only invariant intermediate
features are allowed, generic separation is guaranteed for generically globally
rigid graphs. We introduce a simple architecture, EGENNET, which achieves our
theoretical guarantees and compares favorably with alternative architecture on
synthetic and chemical benchmarks. Our code is available at
https://github.com/yonatansverdlov/E-GenNet.",2024-07-02,2024,2024-07,chemistry
"Unraveling Molecular Structure: A Multimodal Spectroscopic Dataset for
  Chemistry","Spectroscopic techniques are essential tools for determining the structure of
molecules. Different spectroscopic techniques, such as Nuclear magnetic
resonance (NMR), Infrared spectroscopy, and Mass Spectrometry, provide insight
into the molecular structure, including the presence or absence of functional
groups. Chemists leverage the complementary nature of the different methods to
their advantage. However, the lack of a comprehensive multimodal dataset,
containing spectra from a variety of spectroscopic techniques, has limited
machine-learning approaches mostly to single-modality tasks for predicting
molecular structures from spectra. Here we introduce a dataset comprising
simulated $^1$H-NMR, $^{13}$C-NMR, HSQC-NMR, Infrared, and Mass spectra
(positive and negative ion modes) for 790k molecules extracted from chemical
reactions in patent data. This dataset enables the development of foundation
models for integrating information from multiple spectroscopic modalities,
emulating the approach employed by human experts. Additionally, we provide
benchmarks for evaluating single-modality tasks such as structure elucidation,
predicting the spectra for a target molecule, and functional group predictions.
This dataset has the potential automate structure elucidation, streamlining the
molecular discovery pipeline from synthesis to structure determination. The
dataset and code for the benchmarks can be found at
https://rxn4chemistry.github.io/multimodal-spectroscopic-dataset.",2024-07-04,2024,2024-07,chemistry
"ArcaNN: automated enhanced sampling generation of training sets for
  chemically reactive machine learning interatomic potentials","The emergence of artificial intelligence has profoundly impacted
computational chemistry, particularly through machine-learned potentials
(MLPs), which offer a balance of accuracy and efficiency in calculating atomic
energies and forces to be used in molecular dynamics simulations. These MLPs
have significantly advanced molecular dynamics simulations across various
applications, including large-scale simulations of materials, interfaces, and
chemical reactions. Despite these advances, the construction of training
datasets - a critical component for the accuracy of MLPs - has not received
proportional attention. This is particularly critical for chemical reactivity
which depends on rare barrier-crossing events. Here we address this gap by
introducing ArcaNN, a comprehensive framework designed for generating training
datasets for reactive MLPs. ArcaNN employs a concurrent learning approach
combined with advanced sampling techniques to ensure accurate representation of
high-energy geometries. The framework integrates automated processes for
iterative training, exploration, new configuration selection, and energy and
force labeling, while ensuring reproducibility and documentation. We
demonstrate ArcaNN's capabilities through a paradigm nucleophilic substitution
reaction in solution, showcasing its effectiveness, the uniformly low error of
the resulting MLP everywhere along the chemical reaction coordinate, and its
potential for broad applications in reactive molecular dynamics. We also
provide guidelines on how to assess the quality of a NNP for a reactive system.",2024-07-10,2024,2024-07,chemistry
"Show, Don't Tell: Evaluating Large Language Models Beyond Textual
  Understanding with ChildPlay","We developed a benchmark set to assess the generalization of state-of-the-art
large language models on problems beyond linguistic tasks and evaluate it on a
systematic progression of GPT models (GPT-3.5, GPT-4, GPT-4o, GPT-4o-mini).
Using simple games like Tic-Tac-Toe, Connect Four, Battleship, and a Shape
Recognition Game, all encoded in ASCII, we test strategic capabilities and
spatial reasoning, core abilities any artificial intelligence would need to
master for solving problems in chemistry. To probe generalization, we introduce
two new games for spatial logic: LEGO Connect Language (LCL) and
Guess-the-SMILES (GtS), a operationally simple chemistry benchmark. Our results
show that GPT models provide meaningful responses for several tasks but,
generally, perform poorly. A systematic performance progression with increased
model capabilities (GPT-3.5, GPT-4, GPT-4o) is only observed for 4 out of the 7
benchmark tasks. All models consistently struggle with Battleship, LCL, and
GtS. This suggests that while GPT models can emulate conversational proficiency
and basic rule comprehension, they have limited generalization with respect to
strategy and spatial reasoning. Particularly poor performance is observed for
interpreting molecular graphs when encoded in ASCII. The results provided by
our open-source benchmark suite
(\href{https://github.com/BlueVelvetSackOfGoldPotatoes/child-play}{\texttt{ChildPlay}
GitHub Repository}) caution against claims of emergent intelligence in GPT
models, which appear more specialized than general.",2024-07-12,2024,2024-07,chemistry
"Automated essay scoring in Arabic: a dataset and analysis of a
  BERT-based system","Automated Essay Scoring (AES) holds significant promise in the field of
education, helping educators to mark larger volumes of essays and provide
timely feedback. However, Arabic AES research has been limited by the lack of
publicly available essay data. This study introduces AR-AES, an Arabic AES
benchmark dataset comprising 2046 undergraduate essays, including gender
information, scores, and transparent rubric-based evaluation guidelines,
providing comprehensive insights into the scoring process. These essays come
from four diverse courses, covering both traditional and online exams.
Additionally, we pioneer the use of AraBERT for AES, exploring its performance
on different question types. We find encouraging results, particularly for
Environmental Chemistry and source-dependent essay questions. For the first
time, we examine the scale of errors made by a BERT-based AES system, observing
that 96.15 percent of the errors are within one point of the first human
marker's prediction, on a scale of one to five, with 79.49 percent of
predictions matching exactly. In contrast, additional human markers did not
exceed 30 percent exact matches with the first marker, with 62.9 percent within
one mark. These findings highlight the subjectivity inherent in essay grading,
and underscore the potential for current AES technology to assist human markers
to grade consistently across large classes.",2024-07-15,2024,2024-07,chemistry
SciCode: A Research Coding Benchmark Curated by Scientists,"Since language models (LMs) now outperform average humans on many challenging
tasks, it has become increasingly difficult to develop challenging,
high-quality, and realistic evaluations. We address this issue by examining
LMs' capabilities to generate code for solving real scientific research
problems. Incorporating input from scientists and AI researchers in 16 diverse
natural science sub-fields, including mathematics, physics, chemistry, biology,
and materials science, we created a scientist-curated coding benchmark,
SciCode. The problems in SciCode naturally factorize into multiple subproblems,
each involving knowledge recall, reasoning, and code synthesis. In total,
SciCode contains 338 subproblems decomposed from 80 challenging main problems.
It offers optional descriptions specifying useful scientific background
information and scientist-annotated gold-standard solutions and test cases for
evaluation. Claude3.5-Sonnet, the best-performing model among those tested, can
solve only 4.6% of the problems in the most realistic setting. We believe that
SciCode demonstrates both contemporary LMs' progress towards becoming helpful
scientific assistants and sheds light on the development and evaluation of
scientific AI in the future.",2024-07-18,2024,2024-07,chemistry
"Text-Augmented Multimodal LLMs for Chemical Reaction Condition
  Recommendation","High-throughput reaction condition (RC) screening is fundamental to chemical
synthesis. However, current RC screening suffers from laborious and costly
trial-and-error workflows. Traditional computer-aided synthesis planning (CASP)
tools fail to find suitable RCs due to data sparsity and inadequate reaction
representations. Nowadays, large language models (LLMs) are capable of tackling
chemistry-related problems, such as molecule design, and chemical logic Q\&A
tasks. However, LLMs have not yet achieved accurate predictions of chemical
reaction conditions. Here, we present MM-RCR, a text-augmented multimodal LLM
that learns a unified reaction representation from SMILES, reaction graphs, and
textual corpus for chemical reaction recommendation (RCR). To train MM-RCR, we
construct 1.2 million pair-wised Q\&A instruction datasets. Our experimental
results demonstrate that MM-RCR achieves state-of-the-art performance on two
open benchmark datasets and exhibits strong generalization capabilities on
out-of-domain (OOD) and High-Throughput Experimentation (HTE) datasets. MM-RCR
has the potential to accelerate high-throughput condition screening in chemical
synthesis.",2024-07-21,2024,2024-07,chemistry
Exploring Quantum Active Learning for Materials Design and Discovery,"The meeting of artificial intelligence (AI) and quantum computing is already
a reality; quantum machine learning (QML) promises the design of better
regression models. In this work, we extend our previous studies of materials
discovery using classical active learning (AL), which showed remarkable economy
of data, to explore the use of quantum algorithms within the AL framework (QAL)
as implemented in the MLChem4D and QMLMaterials codes. The proposed QAL uses
quantum support vector regressor (QSVR) or a quantum Gaussian process regressor
(QGPR) with various quantum kernels and different feature maps. Data sets
include perovskite properties (piezoelectric coefficient, band gap, energy
storage) and the structure optimization of a doped nanoparticle (3Al@Si11)
chosen to compare with classical AL results. Our results revealed that the QAL
method improved the searches in most cases, but not all, seemingly correlated
with the roughness of the data. QAL has the potential of finding optimum
solutions, within chemical space, in materials science and elsewhere in
chemistry.",2024-07-26,2024,2024-07,chemistry
A Bayesian Flow Network Framework for Chemistry Tasks,"In this work, we introduce ChemBFN, a language model that handles chemistry
tasks based on Bayesian flow networks working on discrete data. A new accuracy
schedule is proposed to improve the sampling quality by significantly reducing
the reconstruction loss. We show evidence that our method is appropriate for
generating molecules with satisfied diversity even when a smaller number of
sampling steps is used. A classifier-free guidance method is adapted for
conditional generation. It is also worthwhile to point out that after
generative training, our model can be fine-tuned on regression and
classification tasks with the state-of-the-art performance, which opens the
gate of building all-in-one models in a single module style. Our model has been
open sourced at
https://github.com/Augus1999/bayesian-flow-network-for-chemistry.",2024-07-28,2024,2024-07,chemistry
"A Tutorial on the Use of Physics-Informed Neural Networks to Compute the
  Spectrum of Quantum Systems","Quantum many-body systems are of great interest for many research areas,
including physics, biology and chemistry. However, their simulation is
extremely challenging, due to the exponential growth of the Hilbert space with
the system size, making it exceedingly difficult to parameterize the wave
functions of large systems by using exact methods. Neural networks and machine
learning in general are a way to face this challenge. For instance, methods
like Tensor networks and Neural Quantum States are being investigated as
promising tools to obtain the wave function of a quantum mechanical system. In
this tutorial, we focus on a particularly promising class of deep learning
algorithms. We explain how to construct a Physics-Informed Neural Network
(PINN) able to solve the Schr\""odinger equation for a given potential, by
finding its eigenvalues and eigenfunctions. This technique is unsupervised, and
utilizes a novel computational method in a manner that is barely explored.
PINNs are a deep learning method that exploits Automatic Differentiation to
solve Integro-Differential Equations in a mesh-free way. We show how to find
both the ground and the excited states. The method discovers the states
progressively by starting from the ground state. We explain how to introduce
inductive biases in the loss to exploit further knowledge of the physical
system. Such additional constraints allow for a faster and more accurate
convergence. This technique can then be enhanced by a smart choice of
collocation points in order to take advantage of the mesh-free nature of the
PINN. The methods are made explicit by applying them to the infinite potential
well and the particle in a ring, a challenging problem to be learned by an
Artificial Intelligence agent due to the presence of complex-valued
eigenfunctions and degenerate states.",2024-07-30,2024,2024-07,chemistry
"CEAR: Automatic construction of a knowledge graph of chemical entities
  and roles from scientific literature","Ontologies are formal representations of knowledge in specific domains that
provide a structured framework for organizing and understanding complex
information. Creating ontologies, however, is a complex and time-consuming
endeavor. ChEBI is a well-known ontology in the field of chemistry, which
provides a comprehensive resource for defining chemical entities and their
properties. However, it covers only a small fraction of the rapidly growing
knowledge in chemistry and does not provide references to the scientific
literature. To address this, we propose a methodology that involves augmenting
existing annotated text corpora with knowledge from Chebi and fine-tuning a
large language model (LLM) to recognize chemical entities and their roles in
scientific text. Our experiments demonstrate the effectiveness of our approach.
By combining ontological knowledge and the language understanding capabilities
of LLMs, we achieve high precision and recall rates in identifying both the
chemical entities and roles in scientific literature. Furthermore, we extract
them from a set of 8,000 ChemRxiv articles, and apply a second LLM to create a
knowledge graph (KG) of chemical entities and roles (CEAR), which provides
complementary information to ChEBI, and can help to extend it.",2024-07-31,2024,2024-07,chemistry
Open-Source Molecular Processing Pipeline for Generating Molecules,"Generative models for molecules have shown considerable promise for use in
computational chemistry, but remain difficult to use for non-experts. For this
reason, we introduce open-source infrastructure for easily building generative
molecular models into the widely used DeepChem [Ramsundar et al., 2019] library
with the aim of creating a robust and reusable molecular generation pipeline.
In particular, we add high quality PyTorch [Paszke et al., 2019]
implementations of the Molecular Generative Adversarial Networks (MolGAN) [Cao
and Kipf, 2022] and Normalizing Flows [Papamakarios et al., 2021]. Our
implementations show strong performance comparable with past work [Kuznetsov
and Polykovskiy, 2021, Cao and Kipf, 2022].",2024-08-12,2024,2024-08,chemistry
"Plasmonic Particle Integration into Near-Infrared Photodetectors and
  Photoactivated Gas Sensors: Towards Sustainable Next-Generation Ubiquitous
  Sensing","Current challenges in environmental science, medicine, food chemistry as well
as the emerging use of artificial intelligence for solving problems in these
fields require distributed, local sensing. Such ubiquitous sensing requires
components with (1) high sensitivity, (2) power efficiency, (3)
miniaturizability and (4) the ability to directly interface with electronic
circuitry, i.e., electronic readout of sensing signals. Over the recent years,
several nanoparticle-based approaches have found their way into this field and
have demonstrated high performance. However, challenges remain, such as the
toxicity of many of today's narrow bandgap semiconductors for NIR detection and
the high energy consumption as well as low selectivity of state-of-the-art
commercialized gas sensors. With their unique light-matter interaction and
ink-based fabrication schemes, plasmonic nanostructures provide potential
technological solutions to these challenges, leading also to better
environmental performance. In this perspective we discuss recent approaches of
using plasmonic nanoparticles for the fabrication of NIR photodetectors and
light-activated, energy-efficient gas sensing devices. In addition, we point
out new strategies implying computational approaches for miniaturizable
spectrometers, exploiting the wide spectral tunability of plasmonic
nanocomposites, and for selective gas sensors, utilizing dynamic light
activation. The benefits of colloidal approaches for device fabrication are
discussed with regard to technological advantages and environmental aspects,
which have been barely considered so far.",2024-08-14,2024,2024-08,chemistry
"The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating
  Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation","Image-to-Image translation in Generative Artificial Intelligence (Generative
AI) has been a central focus of research, with applications spanning
healthcare, remote sensing, physics, chemistry, photography, and more. Among
the numerous methodologies, Generative Adversarial Networks (GANs) with
contrastive learning have been particularly successful. This study aims to
demonstrate that the Kolmogorov-Arnold Network (KAN) can effectively replace
the Multi-layer Perceptron (MLP) method in generative AI, particularly in the
subdomain of image-to-image translation, to achieve better generative quality.
Our novel approach replaces the two-layer MLP with a two-layer KAN in the
existing Contrastive Unpaired Image-to-Image Translation (CUT) model,
developing the KAN-CUT model. This substitution favors the generation of more
informative features in low-dimensional vector representations, which
contrastive learning can utilize more effectively to produce high-quality
images in the target domain. Extensive experiments, detailed in the results
section, demonstrate the applicability of KAN in conjunction with contrastive
learning and GANs in Generative AI, particularly for image-to-image
translation. This work suggests that KAN could be a valuable component in the
broader generative AI domain.",2024-08-15,2024,2024-08,chemistry
"Advancements in Molecular Property Prediction: A Survey of Single and
  Multimodal Approaches","Molecular Property Prediction (MPP) plays a pivotal role across diverse
domains, spanning drug discovery, material science, and environmental
chemistry. Fueled by the exponential growth of chemical data and the evolution
of artificial intelligence, recent years have witnessed remarkable strides in
MPP. However, the multifaceted nature of molecular data, such as molecular
structures, SMILES notation, and molecular images, continues to pose a
fundamental challenge in its effective representation. To address this,
representation learning techniques are instrumental as they acquire informative
and interpretable representations of molecular data. This article explores
recent AI/-based approaches in MPP, focusing on both single and multiple
modality representation techniques. It provides an overview of various molecule
representations and encoding schemes, categorizes MPP methods by their use of
modalities, and outlines datasets and tools available for feature generation.
The article also analyzes the performance of recent methods and suggests future
research directions to advance the field of MPP.",2024-08-18,2024,2024-08,chemistry
BatGPT-Chem: A Foundation Large Model For Retrosynthesis Prediction,"Retrosynthesis analysis is pivotal yet challenging in drug discovery and
organic chemistry. Despite the proliferation of computational tools over the
past decade, AI-based systems often fall short in generalizing across diverse
reaction types and exploring alternative synthetic pathways. This paper
presents BatGPT-Chem, a large language model with 15 billion parameters,
tailored for enhanced retrosynthesis prediction. Integrating chemical tasks via
a unified framework of natural language and SMILES notation, this approach
synthesizes extensive instructional data from an expansive chemical database.
Employing both autoregressive and bidirectional training techniques across over
one hundred million instances, BatGPT-Chem captures a broad spectrum of
chemical knowledge, enabling precise prediction of reaction conditions and
exhibiting strong zero-shot capabilities. Superior to existing AI methods, our
model demonstrates significant advancements in generating effective strategies
for complex molecules, as validated by stringent benchmark tests. BatGPT-Chem
not only boosts the efficiency and creativity of retrosynthetic analysis but
also establishes a new standard for computational tools in synthetic design.
This development empowers chemists to adeptly address the synthesis of novel
compounds, potentially expediting the innovation cycle in drug manufacturing
and materials science. We release our trial platform at
\url{https://www.batgpt.net/dapp/chem}.",2024-08-19,2024,2024-08,chemistry
"Leveraging Chemistry Foundation Models to Facilitate Structure Focused
  Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and
  Materials Design","Molecular property prediction and generative design via deep learning models
has been the subject of intense research given its potential to accelerate
development of new, high-performance materials. More recently, these workflows
have been significantly augmented with the advent of large language models
(LLMs) and systems of autonomous agents capable of utilizing pre-trained models
to make predictions in the context of more complex research tasks. While
effective, there is still room for substantial improvement within agentic
systems on the retrieval of salient information for material design tasks.
Within this context, alternative uses of predictive deep learning models, such
as leveraging their latent representations to facilitate cross-modal retrieval
augmented generation within agentic systems for task-specific materials design,
has remained unexplored. Herein, we demonstrate that large, pre-trained
chemistry foundation models can serve as a basis for enabling
structure-focused, semantic chemistry information retrieval for both
small-molecules, complex polymeric materials, and reactions. Additionally, we
show the use of chemistry foundation models in conjunction with multi-modal
models such as OpenCLIP facilitate unprecedented queries and information
retrieval across multiple characterization data domains. Finally, we
demonstrate the integration of these models within multi-agent systems to
facilitate structure and topological-based natural language queries and
information retrieval for different research tasks.",2024-08-21,2024,2024-08,chemistry
"Employing Artificial Intelligence to Steer Exascale Workflows with
  Colmena","Computational workflows are a common class of application on supercomputers,
yet the loosely coupled and heterogeneous nature of workflows often fails to
take full advantage of their capabilities. We created Colmena to leverage the
massive parallelism of a supercomputer by using Artificial Intelligence (AI) to
learn from and adapt a workflow as it executes. Colmena allows scientists to
define how their application should respond to events (e.g., task completion)
as a series of cooperative agents. In this paper, we describe the design of
Colmena, the challenges we overcame while deploying applications on exascale
systems, and the science workflows we have enhanced through interweaving AI.
The scaling challenges we discuss include developing steering strategies that
maximize node utilization, introducing data fabrics that reduce communication
overhead of data-intensive tasks, and implementing workflow tasks that cache
costly operations between invocations. These innovations coupled with a variety
of application patterns accessible through our agent-based steering model have
enabled science advances in chemistry, biophysics, and materials science using
different types of AI. Our vision is that Colmena will spur creative solutions
that harness AI across many domains of scientific computing.",2024-08-26,2024,2024-08,chemistry
Integrating Quantum Computing Resources into Scientific HPC Ecosystems,"Quantum Computing (QC) offers significant potential to enhance scientific
discovery in fields such as quantum chemistry, optimization, and artificial
intelligence. Yet QC faces challenges due to the noisy intermediate-scale
quantum era's inherent external noise issues. This paper discusses the
integration of QC as a computational accelerator within classical scientific
high-performance computing (HPC) systems. By leveraging a broad spectrum of
simulators and hardware technologies, we propose a hardware-agnostic framework
for augmenting classical HPC with QC capabilities. Drawing on the HPC expertise
of the Oak Ridge National Laboratory (ORNL) and the HPC lifecycle management of
the Department of Energy (DOE), our approach focuses on the strategic
incorporation of QC capabilities and acceleration into existing scientific HPC
workflows. This includes detailed analyses, benchmarks, and code optimization
driven by the needs of the DOE and ORNL missions. Our comprehensive framework
integrates hardware, software, workflows, and user interfaces to foster a
synergistic environment for quantum and classical computing research. This
paper outlines plans to unlock new computational possibilities, driving forward
scientific inquiry and innovation in a wide array of research domains.",2024-08-28,2024,2024-08,chemistry
"Towards Symbolic XAI -- Explanation Through Human Understandable Logical
  Relationships Between Features","Explainable Artificial Intelligence (XAI) plays a crucial role in fostering
transparency and trust in AI systems, where traditional XAI approaches
typically offer one level of abstraction for explanations, often in the form of
heatmaps highlighting single or multiple input features. However, we ask
whether abstract reasoning or problem-solving strategies of a model may also be
relevant, as these align more closely with how humans approach solutions to
problems. We propose a framework, called Symbolic XAI, that attributes
relevance to symbolic queries expressing logical relationships between input
features, thereby capturing the abstract reasoning behind a model's
predictions. The methodology is built upon a simple yet general multi-order
decomposition of model predictions. This decomposition can be specified using
higher-order propagation-based relevance methods, such as GNN-LRP, or
perturbation-based explanation methods commonly used in XAI. The effectiveness
of our framework is demonstrated in the domains of natural language processing
(NLP), vision, and quantum chemistry (QC), where abstract symbolic domain
knowledge is abundant and of significant interest to users. The Symbolic XAI
framework provides an understanding of the model's decision-making process that
is both flexible for customization by the user and human-readable through
logical formulas.",2024-08-30,2024,2024-08,chemistry
JaxLife: An Open-Ended Agentic Simulator,"Human intelligence emerged through the process of natural selection and
evolution on Earth. We investigate what it would take to re-create this process
in silico. While past work has often focused on low-level processes (such as
simulating physics or chemistry), we instead take a more targeted approach,
aiming to evolve agents that can accumulate open-ended culture and technologies
across generations. Towards this, we present JaxLife: an artificial life
simulator in which embodied agents, parameterized by deep neural networks, must
learn to survive in an expressive world containing programmable systems. First,
we describe the environment and show that it can facilitate meaningful
Turing-complete computation. We then analyze the evolved emergent agents'
behavior, such as rudimentary communication protocols, agriculture, and tool
use. Finally, we investigate how complexity scales with the amount of compute
used. We believe JaxLife takes a step towards studying evolved behavior in more
open-ended simulations. Our code is available at
https://github.com/luchris429/JaxLife",2024-09-01,2024,2024-09,chemistry
"Generative artificial intelligence for computational chemistry: a
  roadmap to predicting emergent phenomena","The recent surge in Generative Artificial Intelligence (AI) has introduced
exciting possibilities for computational chemistry. Generative AI methods have
made significant progress in sampling molecular structures across chemical
species, developing force fields, and speeding up simulations. This Perspective
offers a structured overview, beginning with the fundamental theoretical
concepts in both Generative AI and computational chemistry. It then covers
widely used Generative AI methods, including autoencoders, generative
adversarial networks, reinforcement learning, flow models and language models,
and highlights their selected applications in diverse areas including force
field development, and protein/RNA structure prediction. A key focus is on the
challenges these methods face before they become truly predictive, particularly
in predicting emergent chemical phenomena. We believe that the ultimate goal of
a simulation method or theory is to predict phenomena not seen before, and that
Generative AI should be subject to these same standards before it is deemed
useful for chemistry. We suggest that to overcome these challenges, future AI
models need to integrate core chemical principles, especially from statistical
mechanics.",2024-09-04,2024,2024-09,chemistry
"AI and Machine Learning Approaches for Predicting Nanoparticles Toxicity
  The Critical Role of Physiochemical Properties","This research investigates the use of artificial intelligence and machine
learning techniques to predict the toxicity of nanoparticles, a pressing
concern due to their pervasive use in various industries and the inherent
challenges in assessing their biological interactions. Employing models such as
Decision Trees, Random Forests, and XGBoost, the study focuses on analyzing
physicochemical properties like size, shape, surface charge, and chemical
composition to determine their influence on toxicity. Our findings highlight
the significant role of oxygen atoms, particle size, surface area, dosage, and
exposure duration in affecting toxicity levels. The use of machine learning
allows for a nuanced understanding of the intricate patterns these properties
form in biological contexts, surpassing traditional analysis methods in
efficiency and predictive power. These advancements aid in developing safer
nanomaterials through computational chemistry, reducing reliance on costly and
time-consuming experimental methods. This approach not only enhances our
understanding of nanoparticle behavior in biological systems but also
streamlines the safety assessment process, marking a significant stride towards
integrating computational techniques in nanotoxicology.",2024-09-06,2024,2024-09,chemistry
"Elsevier Arena: Human Evaluation of Chemistry/Biology/Health
  Foundational Large Language Models","arXiv admin comment: This version has been removed by arXiv administrators as
the submitter did not have the rights to agree to the license at the time of
submission",2024-09-09,2024,2024-09,chemistry
Can Large Language Models Unlock Novel Scientific Research Ideas?,"""An idea is nothing more nor less than a new combination of old elements""
(Young, J.W.). The widespread adoption of Large Language Models (LLMs) and
publicly available ChatGPT have marked a significant turning point in the
integration of Artificial Intelligence (AI) into people's everyday lives. This
study explores the capability of LLMs in generating novel research ideas based
on information from research papers. We conduct a thorough examination of 4
LLMs in five domains (e.g., Chemistry, Computer, Economics, Medical, and
Physics). We found that the future research ideas generated by Claude-2 and
GPT-4 are more aligned with the author's perspective than GPT-3.5 and Gemini.
We also found that Claude-2 generates more diverse future research ideas than
GPT-4, GPT-3.5, and Gemini 1.0. We further performed a human evaluation of the
novelty, relevancy, and feasibility of the generated future research ideas.
This investigation offers insights into the evolving role of LLMs in idea
generation, highlighting both its capability and limitations. Our work
contributes to the ongoing efforts in evaluating and utilizing language models
for generating future research ideas. We make our datasets and codes publicly
available.",2024-09-10,2024,2024-09,chemistry
"VisScience: An Extensive Benchmark for Evaluating K12 Educational
  Multi-modal Scientific Reasoning","Multi-modal large language models (MLLMs) have demonstrated promising
capabilities across various tasks by integrating textual and visual information
to achieve visual understanding in complex scenarios. Despite the availability
of several benchmarks aims to evaluating MLLMs in tasks from visual question
answering to complex problem-solving, most focus predominantly on mathematics
or general visual understanding tasks. This reveals a critical gap in current
benchmarks, which often overlook the inclusion of other key scientific
disciplines such as physics and chemistry. To address this gap, we meticulously
construct a comprehensive benchmark, named VisScience, which is utilized to
assess the multi-modal scientific reasoning across the three disciplines of
mathematics, physics, and chemistry. This benchmark comprises 3,000 questions
drawn from K12 education - spanning elementary school through high school -
equally distributed across three disciplines, with 1,000 questions per
discipline. The questions within VisScience span 21 distinct subjects and are
categorized into five difficulty levels, offering a broad spectrum of topics
within each discipline. With VisScience, we present a detailed evaluation of
the performance of 25 representative MLLMs in scientific reasoning.
Experimental results demonstrate that closed-source MLLMs generally outperform
open-source models. The best performance observed include a 53.4\% accuracy in
mathematics by Claude3.5-Sonnet, 38.2\% in physics by GPT-4o, and 47.0\% in
chemistry by Gemini-1.5-Pro. These results underscore the strengths and
limitations of MLLMs, suggesting areas for future improvement and highlighting
the importance of developing models that can effectively handle the diverse
demands of multi-modal scientific reasoning.",2024-09-10,2024,2024-09,chemistry
"Spiers Memorial Lecture: How to do impactful research in artificial
  intelligence for chemistry and materials science","Machine learning has been pervasively touching many fields of science.
Chemistry and materials science are no exception. While machine learning has
been making a great impact, it is still not reaching its full potential or
maturity. In this perspective, we first outline current applications across a
diversity of problems in chemistry. Then, we discuss how machine learning
researchers view and approach problems in the field. Finally, we provide our
considerations for maximizing impact when researching machine learning for
chemistry.",2024-09-16,2024,2024-09,chemistry
Machine Learning and Theory Ladenness -- A Phenomenological Account,"In recent years, the dissemination of machine learning (ML) methodologies in
scientific research has prompted discussions on theory ladenness. More
specifically, the issue of theory ladenness has remerged as questions about
whether and how ML models (MLMs) and ML modelling strategies are impacted by
the domain theory of the scientific field in which ML is used and implemented
(e.g., physics, chemistry, biology, etc). On the one hand, some have argued
that there is no difference between traditional (pre ML) and ML assisted
science. In both cases, theory plays an essential and unavoidable role in the
analysis of phenomena and the construction and use of models. Others have
argued instead that ML methodologies and models are theory independent and, in
some cases, even theory free. In this article, we argue that both positions are
overly simplistic and do not advance our understanding of the interplay between
ML methods and domain theories. Specifically, we provide an analysis of theory
ladenness in ML assisted science. Our analysis reveals that, while the
construction of MLMs can be relatively independent of domain theory, the
practical implementation and interpretation of these models within a given
specific domain still relies on fundamental theoretical assumptions and
background knowledge.",2024-09-17,2024,2024-09,chemistry
Smirk: An Atomically Complete Tokenizer for Molecular Foundation Models,"Text-based foundation models have become an important part of scientific
discovery, with molecular foundation models accelerating advancements in
molecular design and materials science. However, existing models are
constrained by closed-vocabulary tokenizers which capture only a fraction of
molecular space. In this work, we systematically evaluate thirty tokenizers,
including 19 chemistry-specific ones, for their coverage of the SMILES
molecular representation language, revealing significant gaps. To assess the
impact of tokenizer choice, we introduce n-gram language models as a low-cost
proxy and validate their effectiveness by training and fine-tuning 18
RoBERTa-style encoders for molecular property prediction. To overcome the
limitations of existing tokenizers, we propose two new tokenizers -- Smirk and
Smirk-GPE -- with full coverage of the OpenSMILES specification. Our results
highlight the need for open-vocabulary modeling and chemically diverse
benchmarks in cheminformatics. The proposed tokenizer framework systematically
integrates nuclear, electronic, and geometric degrees of freedom; this
facilitates applications in pharmacology, agriculture, biology, and energy
storage.",2024-09-19,2024,2024-09,chemistry
"What Would You Ask When You First Saw $a^2+b^2=c^2$? Evaluating LLM on
  Curiosity-Driven Questioning","Large language models (LLMs) can store a massive amount of knowledge, yet
their potential to acquire new knowledge remains unknown. We propose a novel
evaluation framework that evaluates this capability. This framework prompts
LLMs to generate questions about a statement introducing scientific knowledge,
simulating a curious person when facing the statement for the first time. We
score the qualities of the generated questions, thereby evaluating the
knowledge acquisition potential of the LLM. We apply controlled ablation
studies to validate our scoring procedures. Additionally, we created a
synthetic dataset consisting of 1101 statements in physics, chemistry, and
maths with distinct levels of difficulties, 300 general knowledge statements,
and 567 incorrect statements. Human evaluations were conducted to validate our
model assessments, achieving an approximate weighted Cohen's kappa of 0.7 on
all three metrics considered. We find that while large models like GPT-4 and
Mistral 8x7b are adept at generating coherent and relevant questions, the
smaller Phi-2 model is equally or more effective. This indicates that size does
not solely determine a model's knowledge acquisition potential. The proposed
framework quantifies a critical model capability that was commonly overlooked
and opens up research opportunities for developing more knowledgeable AI
systems",2024-09-19,2024,2024-09,chemistry
"ChemEval: A Comprehensive Multi-Level Chemical Evaluation for Large
  Language Models","There is a growing interest in the role that LLMs play in chemistry which
lead to an increased focus on the development of LLMs benchmarks tailored to
chemical domains to assess the performance of LLMs across a spectrum of
chemical tasks varying in type and complexity. However, existing benchmarks in
this domain fail to adequately meet the specific requirements of chemical
research professionals. To this end, we propose \textbf{\textit{ChemEval}},
which provides a comprehensive assessment of the capabilities of LLMs across a
wide range of chemical domain tasks. Specifically, ChemEval identified 4
crucial progressive levels in chemistry, assessing 12 dimensions of LLMs across
42 distinct chemical tasks which are informed by open-source data and the data
meticulously crafted by chemical experts, ensuring that the tasks have
practical value and can effectively evaluate the capabilities of LLMs. In the
experiment, we evaluate 12 mainstream LLMs on ChemEval under zero-shot and
few-shot learning contexts, which included carefully selected demonstration
examples and carefully designed prompts. The results show that while general
LLMs like GPT-4 and Claude-3.5 excel in literature understanding and
instruction following, they fall short in tasks demanding advanced chemical
knowledge. Conversely, specialized LLMs exhibit enhanced chemical competencies,
albeit with reduced literary comprehension. This suggests that LLMs have
significant potential for enhancement when tackling sophisticated tasks in the
field of chemistry. We believe our work will facilitate the exploration of
their potential to drive progress in chemistry. Our benchmark and analysis will
be available at {\color{blue} \url{https://github.com/USTC-StarTeam/ChemEval}}.",2024-09-21,2024,2024-09,chemistry
"Mitigating Exposure Bias in Score-Based Generation of Molecular
  Conformations","Molecular conformation generation poses a significant challenge in the field
of computational chemistry. Recently, Diffusion Probabilistic Models (DPMs) and
Score-Based Generative Models (SGMs) are effectively used due to their capacity
for generating accurate conformations far beyond conventional physics-based
approaches. However, the discrepancy between training and inference rises a
critical problem known as the exposure bias. While this issue has been
extensively investigated in DPMs, the existence of exposure bias in SGMs and
its effective measurement remain unsolved, which hinders the use of
compensation methods for SGMs, including ConfGF and Torsional Diffusion as the
representatives. In this work, we first propose a method for measuring exposure
bias in SGMs used for molecular conformation generation, which confirms the
significant existence of exposure bias in these models and measures its value.
We design a new compensation algorithm Input Perturbation (IP), which is
adapted from a method originally designed for DPMs only. Experimental results
show that by introducing IP, SGM-based molecular conformation models can
significantly improve both the accuracy and diversity of the generated
conformations. Especially by using the IP-enhanced Torsional Diffusion model,
we achieve new state-of-the-art performance on the GEOM-Drugs dataset and are
on par on GEOM-QM9. We provide the code publicly at
https://github.com/jia-975/torsionalDiff-ip.",2024-09-21,2024,2024-09,chemistry
PepINVENT: Generative peptide design beyond the natural amino acids,"Peptides play a crucial role in the drug design and discovery whether as a
therapeutic modality or a delivery agent. Non-natural amino acids (NNAAs) have
been used to enhance the peptide properties from binding affinity, plasma
stability to permeability. Incorporating novel NNAAs facilitates the design of
more effective peptides with improved properties. The generative models used in
the field, have focused on navigating the peptide sequence space. The sequence
space is formed by combinations of a predefined set of amino acids. However,
there is still a need for a tool to explore the peptide landscape beyond this
enumerated space to unlock and effectively incorporate de novo design of new
amino acids. To thoroughly explore the theoretical chemical space of the
peptides, we present PepINVENT, a novel generative AI-based tool as an
extension to the small molecule molecular design platform, REINVENT. PepINVENT
navigates the vast space of natural and non-natural amino acids to propose
valid, novel, and diverse peptide designs. The generative model can serve as a
central tool for peptide-related tasks, as it was not trained on peptides with
specific properties or topologies. The prior was trained to understand the
granularity of peptides and to design amino acids for filling the masked
positions within a peptide. PepINVENT coupled with reinforcement learning
enables the goal-oriented design of peptides using its chemistry-informed
generative capabilities. This study demonstrates PepINVENT's ability to explore
the peptide space with unique and novel designs, and its capacity for property
optimization in the context of therapeutically relevant peptides. Our tool can
be employed for multi-parameter learning objectives, peptidomimetics, lead
optimization, and variety of other tasks within the peptide domain.",2024-09-21,2024,2024-09,chemistry
Susceptibility Formulation of Density Matrix Perturbation Theory,"Density matrix perturbation theory based on recursive Fermi-operator
expansions provides a computationally efficient framework for time-independent
response calculations in quantum chemistry and materials science. From a
perturbation in the Hamiltonian we can calculate the first-order perturbation
in the density matrix, which then gives us the linear response in the
expectation values for some chosen set of observables. Here we present an
alternative, {\it dual} formulation, where we instead calculate the static
susceptibility of an observable, which then gives us the linear response in the
expectation values for any number of different Hamiltonian perturbations. We
show how the calculation of the susceptibility can be performed with the same
expansion schemes used in recursive density matrix perturbation theory,
including generalizations to fractional occupation numbers and self-consistent
linear response calculations, i.e. similar to density functional perturbation
theory. As with recursive density matrix perturbation theory, the dual
susceptibility formulation is well suited for numerically thresholded sparse
matrix algebra, which has linear scaling complexity for sufficiently large
sparse systems. Similarly, the recursive computation of the susceptibility also
seamlessly integrates with the computational framework of deep neural networks
used in artificial intelligence (AI) applications. This integration enables the
calculation of quantum response properties that can leverage cutting-edge
AI-hardware, such as Nvidia Tensor cores or Google Tensor Processing Units. We
demonstrate performance for recursive susceptibility calculations using Nvidia
Graphics Processing Units and Tensor cores.",2024-09-25,2024,2024-09,chemistry
"KALE-LM: Unleash The Power Of AI For Science Via Knowledge And Logic
  Enhanced Large Model","Artificial intelligence is gradually demonstrating its immense potential, and
increasing attention is being given to how AI can be harnessed to advance
scientific research. In this vision paper, we present our perspectives on how
AI can better assist scientific inquiry and explore corresponding technical
approach. We have proposed and open-sourced two large models of our KALE-LM
model series, KALE-LM-Chem(-1.5), which have achieved outstanding performance
in tasks related to the field of chemistry. We hope that our work serves as a
strong starting point, helping to realize more intelligent AI and promoting the
advancement of human science and technology, as well as societal development.",2024-09-27,2024,2024-09,chemistry
"Discrete Diffusion Schrödinger Bridge Matching for Graph
  Transformation","Transporting between arbitrary distributions is a fundamental goal in
generative modeling. Recently proposed diffusion bridge models provide a
potential solution, but they rely on a joint distribution that is difficult to
obtain in practice. Furthermore, formulations based on continuous domains limit
their applicability to discrete domains such as graphs. To overcome these
limitations, we propose Discrete Diffusion Schr\""odinger Bridge Matching
(DDSBM), a novel framework that utilizes continuous-time Markov chains to solve
the SB problem in a high-dimensional discrete state space. Our approach extends
Iterative Markovian Fitting to discrete domains, and we have proved its
convergence to the SB. Furthermore, we adapt our framework for the graph
transformation, and show that our design choice of underlying dynamics
characterized by independent modifications of nodes and edges can be
interpreted as the entropy-regularized version of optimal transport with a cost
function described by the graph edit distance. To demonstrate the effectiveness
of our framework, we have applied DDSBM to molecular optimization in the field
of chemistry. Experimental results demonstrate that DDSBM effectively optimizes
molecules' property-of-interest with minimal graph transformation, successfully
retaining other features. Source code is available
$\href{https://github.com/junhkim1226/DDSBM}{here}$.",2024-10-02,2024,2024-10,chemistry
"SciSafeEval: A Comprehensive Benchmark for Safety Alignment of Large
  Language Models in Scientific Tasks","Large language models (LLMs) have a transformative impact on a variety of
scientific tasks across disciplines including biology, chemistry, medicine, and
physics. However, ensuring the safety alignment of these models in scientific
research remains an underexplored area, with existing benchmarks primarily
focusing on textual content and overlooking key scientific representations such
as molecular, protein, and genomic languages. Moreover, the safety mechanisms
of LLMs in scientific tasks are insufficiently studied. To address these
limitations, we introduce SciSafeEval, a comprehensive benchmark designed to
evaluate the safety alignment of LLMs across a range of scientific tasks.
SciSafeEval spans multiple scientific languages-including textual, molecular,
protein, and genomic-and covers a wide range of scientific domains. We evaluate
LLMs in zero-shot, few-shot and chain-of-thought settings, and introduce a
""jailbreak"" enhancement feature that challenges LLMs equipped with safety
guardrails, rigorously testing their defenses against malicious intention. Our
benchmark surpasses existing safety datasets in both scale and scope, providing
a robust platform for assessing the safety and performance of LLMs in
scientific contexts. This work aims to facilitate the responsible development
and deployment of LLMs, promoting alignment with safety and ethical standards
in scientific research.",2024-10-02,2024,2024-10,chemistry
"SymmetricDiffusers: Learning Discrete Diffusion on Finite Symmetric
  Groups","Finite symmetric groups $S_n$ are essential in fields such as combinatorics,
physics, and chemistry. However, learning a probability distribution over $S_n$
poses significant challenges due to its intractable size and discrete nature.
In this paper, we introduce SymmetricDiffusers, a novel discrete diffusion
model that simplifies the task of learning a complicated distribution over
$S_n$ by decomposing it into learning simpler transitions of the reverse
diffusion using deep neural networks. We identify the riffle shuffle as an
effective forward transition and provide empirical guidelines for selecting the
diffusion length based on the theory of random walks on finite groups.
Additionally, we propose a generalized Plackett-Luce (PL) distribution for the
reverse transition, which is provably more expressive than the PL distribution.
We further introduce a theoretically grounded ""denoising schedule"" to improve
sampling and learning efficiency. Extensive experiments show that our model
achieves state-of-the-art or comparable performances on solving tasks including
sorting 4-digit MNIST images, jigsaw puzzles, and traveling salesman problems.
Our code is released at https://github.com/DSL-Lab/SymmetricDiffusers.",2024-10-03,2024,2024-10,chemistry
Text-guided Diffusion Model for 3D Molecule Generation,"The de novo generation of molecules with targeted properties is crucial in
biology, chemistry, and drug discovery. Current generative models are limited
to using single property values as conditions, struggling with complex
customizations described in detailed human language. To address this, we
propose the text guidance instead, and introduce TextSMOG, a new Text-guided
Small Molecule Generation Approach via 3D Diffusion Model which integrates
language and diffusion models for text-guided small molecule generation. This
method uses textual conditions to guide molecule generation, enhancing both
stability and diversity. Experimental results show TextSMOG's proficiency in
capturing and utilizing information from textual descriptions, making it a
powerful tool for generating 3D molecular structures in response to complex
textual customizations.",2024-10-04,2024,2024-10,chemistry
"REBIND: Enhancing ground-state molecular conformation via force-based
  graph rewiring","Predicting the ground-state 3D molecular conformations from 2D molecular
graphs is critical in computational chemistry due to its profound impact on
molecular properties. Deep learning (DL) approaches have recently emerged as
promising alternatives to computationally-heavy classical methods such as
density functional theory (DFT). However, we discover that existing DL methods
inadequately model inter-atomic forces, particularly for non-bonded atomic
pairs, due to their naive usage of bonds and pairwise distances. Consequently,
significant prediction errors occur for atoms with low degree (i.e., low
coordination numbers) whose conformations are primarily influenced by
non-bonded interactions. To address this, we propose REBIND, a novel framework
that rewires molecular graphs by adding edges based on the Lennard-Jones
potential to capture non-bonded interactions for low-degree atoms. Experimental
results demonstrate that REBIND significantly outperforms state-of-the-art
methods across various molecular sizes, achieving up to a 20\% reduction in
prediction error.",2024-10-04,2024,2024-10,chemistry
"How Do Large Language Models Understand Graph Patterns? A Benchmark for
  Graph Pattern Comprehension","Benchmarking the capabilities and limitations of large language models (LLMs)
in graph-related tasks is becoming an increasingly popular and crucial area of
research. Recent studies have shown that LLMs exhibit a preliminary ability to
understand graph structures and node features. However, the potential of LLMs
in graph pattern mining remains largely unexplored. This is a key component in
fields such as computational chemistry, biology, and social network analysis.
To bridge this gap, this work introduces a comprehensive benchmark to assess
LLMs' capabilities in graph pattern tasks. We have developed a benchmark that
evaluates whether LLMs can understand graph patterns based on either
terminological or topological descriptions. Additionally, our benchmark tests
the LLMs' capacity to autonomously discover graph patterns from data. The
benchmark encompasses both synthetic and real datasets, and a variety of
models, with a total of 11 tasks and 7 models. Our experimental framework is
designed for easy expansion to accommodate new models and datasets. Our
findings reveal that: (1) LLMs have preliminary abilities to understand graph
patterns, with O1-mini outperforming in the majority of tasks; (2) Formatting
input data to align with the knowledge acquired during pretraining can enhance
performance; (3) The strategies employed by LLMs may differ from those used in
conventional algorithms.",2024-10-04,2024,2024-10,chemistry
"Validation of the Scientific Literature via Chemputation Augmented by
  Large Language Models","Chemputation is the process of programming chemical robots to do experiments
using a universal symbolic language, but the literature can be error prone and
hard to read due to ambiguities. Large Language Models (LLMs) have demonstrated
remarkable capabilities in various domains, including natural language
processing, robotic control, and more recently, chemistry. Despite significant
advancements in standardizing the reporting and collection of synthetic
chemistry data, the automatic reproduction of reported syntheses remains a
labour-intensive task. In this work, we introduce an LLM-based chemical
research agent workflow designed for the automatic validation of synthetic
literature procedures. Our workflow can autonomously extract synthetic
procedures and analytical data from extensive documents, translate these
procedures into universal XDL code, simulate the execution of the procedure in
a hardware-specific setup, and ultimately execute the procedure on an
XDL-controlled robotic system for synthetic chemistry. This demonstrates the
potential of LLM-based workflows for autonomous chemical synthesis with
Chemputers. Due to the abstraction of XDL this approach is safe, secure, and
scalable since hallucinations will not be chemputable and the XDL can be both
verified and encrypted. Unlike previous efforts, which either addressed only a
limited portion of the workflow, relied on inflexible hard-coded rules, or
lacked validation in physical systems, our approach provides four realistic
examples of syntheses directly executed from synthetic literature. We
anticipate that our workflow will significantly enhance automation in
robotically driven synthetic chemistry research, streamline data extraction,
improve the reproducibility, scalability, and safety of synthetic and
experimental chemistry.",2024-10-08,2024,2024-10,chemistry
Chain-of-Thoughts for Molecular Understanding,"The adaptation of large language models (LLMs) to chemistry has shown
promising performance in molecular understanding tasks, such as generating a
text description from a molecule. However, proper reasoning based on molecular
structural information remains a significant challenge, e.g., even advanced
LLMs such as GPT-4o struggle to identify functional groups which are crucial
for inferring the molecular property of interest. To address this limitation,
we propose StructCoT, a structure-aware chain-of-thought (CoT) that enhances
LLMs' understanding of molecular structures by explicitly injecting the key
structural features of molecules. Moreover, we introduce two fine-tuning
frameworks for adapting the existing LLMs to use our StructCoT. Our experiments
demonstrate that incorporating StructCoT with our fine-tuning frameworks leads
to consistent improvements in both molecular understanding tasks.",2024-10-08,2024,2024-10,chemistry
"MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry
  Scientific Hypotheses","Scientific discovery contributes largely to human society's prosperity, and
recent progress shows that LLMs could potentially catalyze this process.
However, it is still unclear whether LLMs can discover novel and valid
hypotheses in chemistry. In this work, we investigate this central research
question: Can LLMs automatically discover novel and valid chemistry research
hypotheses given only a chemistry research background (consisting of a research
question and/or a background survey), without limitation on the domain of the
research question? After extensive discussions with chemistry experts, we
propose an assumption that a majority of chemistry hypotheses can be resulted
from a research background and several inspirations. With this key insight, we
break the central question into three smaller fundamental questions. In brief,
they are: (1) given a background question, whether LLMs can retrieve good
inspirations; (2) with background and inspirations, whether LLMs can lead to
hypothesis; and (3) whether LLMs can identify good hypotheses to rank them
higher. To investigate these questions, we construct a benchmark consisting of
51 chemistry papers published in Nature, Science, or a similar level in 2024
(all papers are only available online since 2024). Every paper is divided by
chemistry PhD students into three components: background, inspirations, and
hypothesis. The goal is to rediscover the hypothesis, given only the background
and a large randomly selected chemistry literature corpus consisting the ground
truth inspiration papers, with LLMs trained with data up to 2023. We also
develop an LLM-based multi-agent framework that leverages the assumption,
consisting of three stages reflecting the three smaller questions. The proposed
method can rediscover many hypotheses with very high similarity with the ground
truth ones, covering the main innovations.",2024-10-09,2024,2024-10,chemistry
Chemistry-Inspired Diffusion with Non-Differentiable Guidance,"Recent advances in diffusion models have shown remarkable potential in the
conditional generation of novel molecules. These models can be guided in two
ways: (i) explicitly, through additional features representing the condition,
or (ii) implicitly, using a property predictor. However, training property
predictors or conditional diffusion models requires an abundance of labeled
data and is inherently challenging in real-world applications. We propose a
novel approach that attenuates the limitations of acquiring large labeled
datasets by leveraging domain knowledge from quantum chemistry as a
non-differentiable oracle to guide an unconditional diffusion model. Instead of
relying on neural networks, the oracle provides accurate guidance in the form
of estimated gradients, allowing the diffusion process to sample from a
conditional distribution specified by quantum chemistry. We show that this
results in more precise conditional generation of novel and stable molecular
structures. Our experiments demonstrate that our method: (1) significantly
reduces atomic forces, enhancing the validity of generated molecules when used
for stability optimization; (2) is compatible with both explicit and implicit
guidance in diffusion models, enabling joint optimization of molecular
properties and stability; and (3) generalizes effectively to molecular
optimization tasks beyond stability optimization.",2024-10-09,2024,2024-10,chemistry
"DLGNet: Hyperedge Classification through Directed Line Graphs for
  Chemical Reactions","Graphs and hypergraphs provide powerful abstractions for modeling
interactions among a set of entities of interest and have been attracting a
growing interest in the literature thanks to many successful applications in
several fields. In particular, they are rapidly expanding in domains such as
chemistry and biology, especially in the areas of drug discovery and molecule
generation. One of the areas witnessing the fasted growth is the chemical
reactions field, where chemical reactions can be naturally encoded as directed
hyperedges of a hypergraph. In this paper, we address the chemical reaction
classification problem by introducing the notation of a Directed Line Graph
(DGL) associated with a given directed hypergraph. On top of it, we build the
Directed Line Graph Network (DLGNet), the first spectral-based Graph Neural
Network (GNN) expressly designed to operate on a hypergraph via its DLG
transformation. The foundation of DLGNet is a novel Hermitian matrix, the
Directed Line Graph Laplacian, which compactly encodes the directionality of
the interactions taking place within the directed hyperedges of the hypergraph
thanks to the DLG representation. The Directed Line Graph Laplacian enjoys many
desirable properties, including admitting an eigenvalue decomposition and being
positive semidefinite, which make it well-suited for its adoption within a
spectral-based GNN. Through extensive experiments on chemical reaction
datasets, we show that DGLNet significantly outperforms the existing
approaches, achieving on a collection of real-world datasets an average
relative-percentage-difference improvement of 33.01%, with a maximum
improvement of 37.71%.",2024-10-09,2024,2024-10,chemistry
"PEAR: A Robust and Flexible Automation Framework for Ptychography
  Enabled by Multiple Large Language Model Agents","Ptychography is an advanced computational imaging technique in X-ray and
electron microscopy. It has been widely adopted across scientific research
fields, including physics, chemistry, biology, and materials science, as well
as in industrial applications such as semiconductor characterization. In
practice, obtaining high-quality ptychographic images requires simultaneous
optimization of numerous experimental and algorithmic parameters.
Traditionally, parameter selection often relies on trial and error, leading to
low-throughput workflows and potential human bias. In this work, we develop the
""Ptychographic Experiment and Analysis Robot"" (PEAR), a framework that
leverages large language models (LLMs) to automate data analysis in
ptychography. To ensure high robustness and accuracy, PEAR employs multiple LLM
agents for tasks including knowledge retrieval, code generation, parameter
recommendation, and image reasoning. Our study demonstrates that PEAR's
multi-agent design significantly improves the workflow success rate, even with
smaller open-weight models such as LLaMA 3.1 8B. PEAR also supports various
automation levels and is designed to work with customized local knowledge
bases, ensuring flexibility and adaptability across different research
environments.",2024-10-11,2024,2024-10,chemistry
Analyzing Atomic Interactions in Molecules as Learned by Neural Networks,"While machine learning (ML) models have been able to achieve unprecedented
accuracies across various prediction tasks in quantum chemistry, it is now
apparent that accuracy on a test set alone is not a guarantee for robust
chemical modeling such as stable molecular dynamics (MD). To go beyond
accuracy, we use explainable artificial intelligence (XAI) techniques to
develop a general analysis framework for atomic interactions and apply it to
the SchNet and PaiNN neural network models. We compare these interactions with
a set of fundamental chemical principles to understand how well the models have
learned the underlying physicochemical concepts from the data. We focus on the
strength of the interactions for different atomic species, how predictions for
intensive and extensive quantum molecular properties are made, and analyze the
decay and many-body nature of the interactions with interatomic distance.
Models that deviate too far from known physical principles produce unstable MD
trajectories, even when they have very high energy and force prediction
accuracy. We also suggest further improvements to the ML architectures to
better account for the polynomial decay of atomic interactions.",2024-10-17,2024,2024-10,chemistry
"Dynamic Guided and Domain Applicable Safeguards for Enhanced Security in
  Large Language Models","With the extensive deployment of Large Language Models (LLMs), ensuring their
safety has become increasingly critical. However, existing defense methods
often struggle with two key issues: (i) inadequate defense capabilities,
particularly in domain-specific scenarios like chemistry, where a lack of
specialized knowledge can lead to the generation of harmful responses to
malicious queries. (ii) over-defensiveness, which compromises the general
utility and responsiveness of LLMs. To mitigate these issues, we introduce a
multi-agents-based defense framework, Guide for Defense (G4D), which leverages
accurate external information to provide an unbiased summary of user intentions
and analytically grounded safety response guidance. Extensive experiments on
popular jailbreak attacks and benign datasets show that our G4D can enhance
LLM's robustness against jailbreak attacks on general and domain-specific
scenarios without compromising the model's general functionality.",2024-10-23,2024,2024-10,chemistry
"An Open Quantum Chemistry Property Database of 120 Kilo Molecules with
  20 Million Conformers","Artificial intelligence is revolutionizing computational chemistry, bringing
unprecedented innovation and efficiency to the field. To further advance
research and expedite progress, we introduce the Quantum Open Organic Molecular
(QO2Mol) database -- a large-scale quantum chemistry dataset designed for
professional and transformative research in organic molecular sciences under an
open-source license. The database comprises 120,000 organic molecules and
approximately 20 million conformers, encompassing 10 different elements (C, H,
O, N, S, P, F, Cl, Br, I), with heavy atom counts exceeding 40. Utilizing the
high-precision B3LYP/def2-SVP quantum mechanical level, each conformation was
meticulously computed for quantum mechanical properties, including potential
energy and forces. These molecules are derived from fragments of compounds in
ChEMBL, ensuring their structural relevance to real-world compounds. Its
extensive coverage of molecular structures and diverse elemental composition
enables comprehensive studies of structure-property relationships, enhancing
the accuracy and applicability of machine learning models in predicting
molecular behaviors. The QO2Mol database and benchmark codes are available at
https://github.com/saiscn/QO2Mol/ .",2024-10-25,2024,2024-10,chemistry
"Can Stories Help LLMs Reason? Curating Information Space Through
  Narrative","Narratives are widely recognized as a powerful tool for structuring
information and facilitating comprehension of complex ideas in various domains
such as science communication. This paper investigates whether incorporating
narrative elements can assist Large Language Models (LLMs) in solving complex
problems more effectively. We propose a novel approach, Story of Thought (SoT),
integrating narrative structures into prompting techniques for problem-solving.
This approach involves constructing narratives around problem statements and
creating a framework to identify and organize relevant information. Our
experiments show that using various LLMs with SoT consistently surpasses using
them with other techniques on physics, chemistry, math, and biology questions
in both the GPQA and JEEBench datasets. The narrative-based information
curation process in SoT enhances problem comprehension by contextualizing
critical in-domain information and highlighting causal relationships within the
problem space.",2024-10-25,2024,2024-10,chemistry
A Foundation Model for Chemical Design and Property Prediction,"Artificial intelligence (AI) has significantly advanced computational
chemistry research in various tasks. However, traditional AI methods often rely
on task-specific model designs and training, which constrain both the
scalability of model size and generalization across different tasks. Here, we
introduce ChemFM, a large foundation model specifically developed for
chemicals. ChemFM comprises 3 billion parameters and is pre-trained on 178
million molecules using self-supervised causal language modeling to extract
generalizable molecular representations. This model can be adapted to diverse
downstream chemical applications using either full-parameter or
parameter-efficient fine-tuning methods. ChemFM consistently outperforms
state-of-the-art task-specific AI models across all tested tasks. Notably, it
achieves up to 67.48% performance improvement across 34 property prediction
benchmarks, up to 33.80% reduction in mean average deviation between
conditioned and actual properties of generated molecules in conditional
molecular generation tasks, and up to 3.7% top-1 accuracy improvement across 4
reaction prediction datasets. Moreover, ChemFM demonstrates its superior
performance in predicting antibiotic activity and cytotoxicity, highlighting
its potential to advance the discovery of novel antibiotics. We anticipate that
ChemFM will significantly advance chemistry research by providing a foundation
model capable of effectively generalizing across a broad range of tasks with
minimal additional training.",2024-10-28,2024,2024-10,chemistry
Bridging Geometric States via Geometric Diffusion Bridge,"The accurate prediction of geometric state evolution in complex systems is
critical for advancing scientific domains such as quantum chemistry and
material modeling. Traditional experimental and computational methods face
challenges in terms of environmental constraints and computational demands,
while current deep learning approaches still fall short in terms of precision
and generality. In this work, we introduce the Geometric Diffusion Bridge
(GDB), a novel generative modeling framework that accurately bridges initial
and target geometric states. GDB leverages a probabilistic approach to evolve
geometric state distributions, employing an equivariant diffusion bridge
derived by a modified version of Doob's $h$-transform for connecting geometric
states. This tailored diffusion process is anchored by initial and target
geometric states as fixed endpoints and governed by equivariant transition
kernels. Moreover, trajectory data can be seamlessly leveraged in our GDB
framework by using a chain of equivariant diffusion bridges, providing a more
detailed and accurate characterization of evolution dynamics. Theoretically, we
conduct a thorough examination to confirm our framework's ability to preserve
joint distributions of geometric states and capability to completely model the
underlying dynamics inducing trajectory distributions with negligible error.
Experimental evaluations across various real-world scenarios show that GDB
surpasses existing state-of-the-art approaches, opening up a new pathway for
accurately bridging geometric states and tackling crucial scientific challenges
with improved accuracy and applicability.",2024-10-31,2024,2024-10,chemistry
"Pre-trained Molecular Language Models with Random Functional Group
  Masking","Recent advancements in computational chemistry have leveraged the power of
trans-former-based language models, such as MoLFormer, pre-trained using a vast
amount of simplified molecular-input line-entry system (SMILES) sequences, to
understand and predict molecular properties and activities, a critical step in
fields like drug discovery and materials science. To further improve
performance, researchers have introduced graph neural networks with graph-based
molecular representations, such as GEM, incorporating the topology, geometry,
2D or even 3D structures of molecules into pre-training. While most of
molecular graphs in existing studies were automatically converted from SMILES
sequences, it is to assume that transformer-based language models might be able
to implicitly learn structure-aware representations from SMILES sequences. In
this paper, we propose \ours{} -- a SMILES-based \underline{\em M}olecular
\underline{\em L}anguage \underline{\em M}odel, which randomly masking SMILES
subsequences corresponding to specific molecular \underline{\em F}unctional
\underline{\em G}roups to incorporate structure information of atoms during the
pre-training phase. This technique aims to compel the model to better infer
molecular structures and properties, thus enhancing its predictive
capabilities. Extensive experimental evaluations across 11 benchmark
classification and regression tasks in the chemical domain demonstrate the
robustness and superiority of \ours{}. Our findings reveal that \ours{}
outperforms existing pre-training models, either based on SMILES or graphs, in
9 out of the 11 downstream tasks, ranking as a close second in the remaining
ones.",2024-11-03,2024,2024-11,chemistry
"Exploring the Benefits of Domain-Pretraining of Generative Large
  Language Models for Chemistry","A proliferation of Large Language Models (the GPT series, BLOOM, LLaMA, and
more) are driving forward novel development of multipurpose AI for a variety of
tasks, particularly natural language processing (NLP) tasks. These models
demonstrate strong performance on a range of tasks; however, there has been
evidence of brittleness when applied to more niche or narrow domains where
hallucinations or fluent but incorrect responses reduce performance. Given the
complex nature of scientific domains, it is prudent to investigate the
trade-offs of leveraging off-the-shelf versus more targeted foundation models
for scientific domains. In this work, we examine the benefits of in-domain
pre-training for a given scientific domain, chemistry, and compare these to
open-source, off-the-shelf models with zero-shot and few-shot prompting. Our
results show that not only do in-domain base models perform reasonably well on
in-domain tasks in a zero-shot setting but that further adaptation using
instruction fine-tuning yields impressive performance on chemistry-specific
tasks such as named entity recognition and molecular formula generation.",2024-11-05,2024,2024-11,chemistry
"Bio-xLSTM: Generative modeling, representation and in-context learning
  of biological and chemical sequences","Language models for biological and chemical sequences enable crucial
applications such as drug discovery, protein engineering, and precision
medicine. Currently, these language models are predominantly based on
Transformer architectures. While Transformers have yielded impressive results,
their quadratic runtime dependency on the sequence length complicates their use
for long genomic sequences and in-context learning on proteins and chemical
sequences. Recently, the recurrent xLSTM architecture has been shown to perform
favorably compared to Transformers and modern state-space model (SSM)
architectures in the natural language domain. Similar to SSMs, xLSTMs have a
linear runtime dependency on the sequence length and allow for constant-memory
decoding at inference time, which makes them prime candidates for modeling
long-range dependencies in biological and chemical sequences. In this work, we
tailor xLSTM towards these domains and propose a suite of architectural
variants called Bio-xLSTM. Extensive experiments in three large domains,
genomics, proteins, and chemistry, were performed to assess xLSTM's ability to
model biological and chemical sequences. The results show that models based on
Bio-xLSTM a) can serve as proficient generative models for DNA, protein, and
chemical sequences, b) learn rich representations for those modalities, and c)
can perform in-context learning for proteins and small molecules.",2024-11-06,2024,2024-11,chemistry
"ChemToolAgent: The Impact of Tools on Language Agents for Chemistry
  Problem Solving","To enhance large language models (LLMs) for chemistry problem solving,
several LLM-based agents augmented with tools have been proposed, such as
ChemCrow and Coscientist. However, their evaluations are narrow in scope,
leaving a large gap in understanding the benefits of tools across diverse
chemistry tasks. To bridge this gap, we develop ChemToolAgent, an enhanced
chemistry agent over ChemCrow, and conduct a comprehensive evaluation of its
performance on both specialized chemistry tasks and general chemistry
questions. Surprisingly, ChemToolAgent does not consistently outperform its
base LLMs without tools. Our error analysis with a chemistry expert suggests
that: For specialized chemistry tasks, such as synthesis prediction, we should
augment agents with specialized tools; however, for general chemistry questions
like those in exams, agents' ability to reason correctly with chemistry
knowledge matters more, and tool augmentation does not always help.",2024-11-11,2024,2024-11,chemistry
Polymetis:Large Language Modeling for Multiple Material Domains,"As the application of large language models in various fields continues to
expand, materials science also ushers in opportunities for AI-driven
innovation. The traditional way of relying on manual search for materials
science-related information is now using artificial intelligence technology as
an auxiliary tool to improve the efficiency of materials science research. To
accelerate researchers' knowledge acquisition and intelligent decision-making
support in materials science research, this paper proposes a large language
model Polymetis model for a variety of materials fields, aiming to provide
highly professional knowledge answers in the field of materials, covering
energy materials, functional materials, alloy materials, physical chemistry,
biology, and other material directions. The model uses a dataset of about 2
million material knowledge instructions, and in the process of building the
dataset, we developed the Intelligent Extraction Large Model (IELM), which is
specially used to extract and form structured knowledge from scientific texts,
avoiding a large number of costs that need to be manually annotated, and
improving efficiency. We inject this data into the GLM4-9B model for learning
to enhance its inference capabilities in a variety of material domains. In
addition, we have introduced enhanced prompt strategies to ensure that the
answers to the model are more organized and comprehensive, providing efficient
and comprehensive intelligent support for the diverse needs of materials
science exploration, and promoting the development of material science.",2024-11-13,2024,2024-11,chemistry
"Energy-GNoME: A Living Database of Selected Materials for Energy
  Applications","Artificial Intelligence (AI) in materials science is driving significant
advancements in the discovery of advanced materials for energy applications.
The recent GNoME protocol identifies over 380,000 novel stable crystals. From
this, we identify over 33,000 materials with potential as energy materials
forming the Energy-GNoME database. Leveraging Machine Learning (ML) and Deep
Learning (DL) tools, our protocol mitigates cross-domain data bias using
feature spaces to identify potential candidates for thermoelectric materials,
novel battery cathodes, and novel perovskites. Classifiers with both structural
and compositional features identify domains of applicability, where we expect
enhanced accuracy of the regressors. Such regressors are trained to predict key
materials properties like, thermoelectric figure of merit (zT), band gap (Eg),
and cathode voltage ($\Delta V_c$). This method significantly narrows the pool
of potential candidates, serving as an efficient guide for experimental and
computational chemistry investigations and accelerating the discovery of
materials suited for electricity generation, energy storage and conversion.",2024-11-15,2024,2024-11,chemistry
"BioNeMo Framework: a modular, high-performance library for AI model
  development in drug discovery","Artificial Intelligence models encoding biology and chemistry are opening new
routes to high-throughput and high-quality in-silico drug development. However,
their training increasingly relies on computational scale, with recent protein
language models (pLM) training on hundreds of graphical processing units
(GPUs). We introduce the BioNeMo Framework to facilitate the training of
computational biology and chemistry AI models across hundreds of GPUs. Its
modular design allows the integration of individual components, such as data
loaders, into existing workflows and is open to community contributions. We
detail technical features of the BioNeMo Framework through use cases such as
pLM pre-training and fine-tuning. On 256 NVIDIA A100s, BioNeMo Framework trains
a three billion parameter BERT-based pLM on over one trillion tokens in 4.2
days. The BioNeMo Framework is open-source and free for everyone to use.",2024-11-15,2024,2024-11,chemistry
"How to Build a Quantum Supercomputer: Scaling from Hundreds to Millions
  of Qubits","In the span of four decades, quantum computation has evolved from an
intellectual curiosity to a potentially realizable technology. Today,
small-scale demonstrations have become possible for quantum algorithmic
primitives on hundreds of physical qubits and proof-of-principle
error-correction on a single logical qubit. Nevertheless, despite significant
progress and excitement, the path toward a full-stack scalable technology is
largely unknown. There are significant outstanding quantum hardware,
fabrication, software architecture, and algorithmic challenges that are either
unresolved or overlooked. These issues could seriously undermine the arrival of
utility-scale quantum computers for the foreseeable future. Here, we provide a
comprehensive review of these scaling challenges. We show how the road to
scaling could be paved by adopting existing semiconductor technology to build
much higher-quality qubits, employing system engineering approaches, and
performing distributed quantum computation within heterogeneous
high-performance computing infrastructures. These opportunities for research
and development could unlock certain promising applications, in particular,
efficient quantum simulation/learning of quantum data generated by natural or
engineered quantum systems. To estimate the true cost of such promises, we
provide a detailed resource and sensitivity analysis for classically hard
quantum chemistry calculations on surface-code error-corrected quantum
computers given current, target, and desired hardware specifications based on
superconducting qubits, accounting for a realistic distribution of errors.
Furthermore, we argue that, to tackle industry-scale classical optimization and
machine learning problems in a cost-effective manner, heterogeneous
quantum-probabilistic computing with custom-designed accelerators should be
considered as a complementary path toward scalability.",2024-11-15,2024,2024-11,chemistry
"Umbrella Reinforcement Learning -- computationally efficient tool for
  hard non-linear problems","We report a novel, computationally efficient approach for solving hard
nonlinear problems of reinforcement learning (RL). Here we combine umbrella
sampling, from computational physics/chemistry, with optimal control methods.
The approach is realized on the basis of neural networks, with the use of
policy gradient. It outperforms, by computational efficiency and implementation
universality, all available state-of-the-art algorithms, in application to hard
RL problems with sparse reward, state traps and lack of terminal states. The
proposed approach uses an ensemble of simultaneously acting agents, with a
modified reward which includes the ensemble entropy, yielding an optimal
exploration-exploitation balance.",2024-11-21,2024,2024-11,chemistry
ChemSafetyBench: Benchmarking LLM Safety on Chemistry Domain,"The advancement and extensive application of large language models (LLMs)
have been remarkable, including their use in scientific research assistance.
However, these models often generate scientifically incorrect or unsafe
responses, and in some cases, they may encourage users to engage in dangerous
behavior. To address this issue in the field of chemistry, we introduce
ChemSafetyBench, a benchmark designed to evaluate the accuracy and safety of
LLM responses. ChemSafetyBench encompasses three key tasks: querying chemical
properties, assessing the legality of chemical uses, and describing synthesis
methods, each requiring increasingly deeper chemical knowledge. Our dataset has
more than 30K samples across various chemical materials. We incorporate
handcrafted templates and advanced jailbreaking scenarios to enhance task
diversity. Our automated evaluation framework thoroughly assesses the safety,
accuracy, and appropriateness of LLM responses. Extensive experiments with
state-of-the-art LLMs reveal notable strengths and critical vulnerabilities,
underscoring the need for robust safety measures. ChemSafetyBench aims to be a
pivotal tool in developing safer AI technologies in chemistry. Our code and
dataset are available at https://github.com/HaochenZhao/SafeAgent4Chem.
Warning: this paper contains discussions on the synthesis of controlled
chemicals using AI models.",2024-11-23,2024,2024-11,chemistry
"Probing the limitations of multimodal language models for chemistry and
  materials research","Recent advancements in artificial intelligence have sparked interest in
scientific assistants that could support researchers across the full spectrum
of scientific workflows, from literature review to experimental design and data
analysis. A key capability for such systems is the ability to process and
reason about scientific information in both visual and textual forms - from
interpreting spectroscopic data to understanding laboratory setups. Here, we
introduce MaCBench, a comprehensive benchmark for evaluating how
vision-language models handle real-world chemistry and materials science tasks
across three core aspects: data extraction, experimental understanding, and
results interpretation. Through a systematic evaluation of leading models, we
find that while these systems show promising capabilities in basic perception
tasks - achieving near-perfect performance in equipment identification and
standardized data extraction - they exhibit fundamental limitations in spatial
reasoning, cross-modal information synthesis, and multi-step logical inference.
Our insights have important implications beyond chemistry and materials
science, suggesting that developing reliable multimodal AI scientific
assistants may require advances in curating suitable training data and
approaches to training those models.",2024-11-25,2024,2024-11,chemistry
"Uni-Electrolyte: An Artificial Intelligence Platform for Designing
  Electrolyte Molecules for Rechargeable Batteries","Electrolyte is a very important part of rechargeable batteries such as
lithium batteries. However, the electrolyte innovation is facing grand
challenges due to the complicated solution chemistry and infinite molecular
space (>1060 for small molecules). This work reported an artificial
intelligence (AI) platform, namely Uni-Electrolyte, for designing advanced
electrolyte molecules, which mainly includes three parts, i.e. EMolCurator,
EMolForger, and EMolNetKnittor. New molecules can be designed by combining
high-throughput screening and generative AI models from more than 100 million
alternative molecules in the EMolCurator module. The molecule properties
including frontier molecular orbital information, formation energy, binding
energy with a Li ion, viscosity, and dielectric constant, can be adopted as the
screening parameters. The EMolForger, and EMolNetKnittor module can predict the
retrosynthesis pathway and reaction pathway with electrodes for a given
molecule, respectively. With the assist of advanced AI methods, the
Uni-Electrolyte is strongly supposed to discover new electrolyte molecules and
chemical principles, promoting the practical application of next-generation
rechargeable batteries.",2024-11-30,2024,2024-11,chemistry
"ActPC-Chem: Discrete Active Predictive Coding for Goal-Guided
  Algorithmic Chemistry as a Potential Cognitive Kernel for Hyperon &
  PRIMUS-Based AGI","We explore a novel paradigm (labeled ActPC-Chem) for biologically inspired,
goal-guided artificial intelligence (AI) centered on a form of Discrete Active
Predictive Coding (ActPC) operating within an algorithmic chemistry of rewrite
rules. ActPC-Chem is envisioned as a foundational ""cognitive kernel"" for
advanced cognitive architectures, such as the OpenCog Hyperon system,
incorporating essential elements of the PRIMUS cognitive architecture. The
central thesis is that general-intelligence-capable cognitive structures and
dynamics can emerge in a system where both data and models are represented as
evolving patterns of metagraph rewrite rules, and where prediction errors,
intrinsic and extrinsic rewards, and semantic constraints guide the continual
reorganization and refinement of these rules. Using a virtual ""robot bug""
thought experiment, we illustrate how such a system might self-organize to
handle challenging tasks involving delayed and context-dependent rewards,
integrating causal rule inference (AIRIS) and probabilistic logical abstraction
(PLN) to discover and exploit conceptual patterns and causal constraints. Next,
we describe how continuous predictive coding neural networks, which excel at
handling noisy sensory data and motor control signals, can be coherently merged
with the discrete ActPC substrate. Finally, we outline how these ideas might be
extended to create a transformer-like architecture that foregoes traditional
backpropagation in favor of rule-based transformations guided by ActPC. This
layered architecture, supplemented with AIRIS and PLN, promises structured,
multi-modal, and logically consistent next-token predictions and narrative
sequences.",2024-12-21,2024,2024-12,chemistry
"""Did my figure do justice to the answer?"" : Towards Multimodal Short
  Answer Grading with Feedback (MMSAF)","Assessments play a vital role in a student's learning process by providing
feedback on a student's proficiency level in a subject. While assessments often
make use of short answer questions, it is often difficult to grade such
questions at a large scale. Moreover, such questions often involve students
drawing supporting diagrams along with their textual explanations. Such
questions often promote multimodal literacy and are aligned with
competency-based questions, which demand a deeper cognitive processing ability
from students. However, existing literature does not deal with the automatic
grading of such answers. Thus, to bridge this gap, we propose the Multimodal
Short Answer Grading with Feedback (MMSAF) problem along with a dataset of 2197
data points. Additionally, we provide an automated framework for generating
such datasets. Our evaluations on existing Large Language Models (LLMs) over
this dataset achieved an overall accuracy of 55% on the Level of Correctness
labels and 75% on Image Relevance labels. As per human experts, Pixtral was
more aligned towards human judgement and values for biology and ChatGPT for
physics and chemistry and achieved a score of 4 or more out of 5 in most
parameters.",2024-12-27,2024,2024-12,chemistry
"From Generalist to Specialist: A Survey of Large Language Models for
  Chemistry","Large Language Models (LLMs) have significantly transformed our daily life
and established a new paradigm in natural language processing (NLP). However,
the predominant pretraining of LLMs on extensive web-based texts remains
insufficient for advanced scientific discovery, particularly in chemistry. The
scarcity of specialized chemistry data, coupled with the complexity of
multi-modal data such as 2D graph, 3D structure and spectrum, present distinct
challenges. Although several studies have reviewed Pretrained Language Models
(PLMs) in chemistry, there is a conspicuous absence of a systematic survey
specifically focused on chemistry-oriented LLMs. In this paper, we outline
methodologies for incorporating domain-specific chemistry knowledge and
multi-modal information into LLMs, we also conceptualize chemistry LLMs as
agents using chemistry tools and investigate their potential to accelerate
scientific research. Additionally, we conclude the existing benchmarks to
evaluate chemistry ability of LLMs. Finally, we critically examine the current
challenges and identify promising directions for future research. Through this
comprehensive survey, we aim to assist researchers in staying at the forefront
of developments in chemistry LLMs and to inspire innovative applications in the
field.",2024-12-28,2024,2024-12,chemistry
